<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/assets/logo.png?v=2.0.0" type="image/png" sizes="16x16"><link rel="icon" href="/assets/logo.png?v=2.0.0" type="image/png" sizes="32x32"><meta name="description" content="Spark 作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行,  在国内工作中主流的环境为Yarn，不过逐渐容器式环境也慢慢流行起来。接下来，我们就分别看看不同环境下 Spark 的运行。">
<meta property="og:type" content="article">
<meta property="og:title" content="二、Spark运行环境">
<meta property="og:url" content="https://wxler.github.io/2021/03/26/214809/index.html">
<meta property="og:site_name" content="Layne&#39;s Blog">
<meta property="og:description" content="Spark 作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行,  在国内工作中主流的环境为Yarn，不过逐渐容器式环境也慢慢流行起来。接下来，我们就分别看看不同环境下 Spark 的运行。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326215135.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326222814.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326222924.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326223450.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327100604.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327124528.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125039.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125605.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125916.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327151322.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327152008.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327154926.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327155326.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327155728.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328152100.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328152345.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155109.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155457.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155556.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328160258.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328160521.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328161045.png">
<meta property="og:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328161149.png">
<meta property="article:published_time" content="2021-03-26T13:48:09.000Z">
<meta property="article:modified_time" content="2021-03-28T15:34:56.045Z">
<meta property="article:author" content="wxler">
<meta property="article:tag" content="Spark">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326215135.png"><meta name="keywords" content="wxler, Layne's Blog"><meta name="description" content="博客，分享，开源，心得"><title>二、Spark运行环境 | Layne's Blog</title><link ref="canonical" href="https://wxler.github.io/2021/03/26/214809/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.0.0"><link rel="dns-prefetch" href="https://hm.baidu.com"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement('script');
  hm.src = 'https://hm.baidu.com/hm.js?01911aa0fc6bdb840626994292397110';
  hm.async = true;

  if (true) {
    hm.setAttribute('data-pjax', '');
  }
  var s = document.getElementsByTagName('script')[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":true},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"ocean","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: true,
  pjax: {"avoidBanner":true},
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 4.2.1"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">分类</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/message/"><span class="header-nav-menu-item__icon"><i class="fa fa-comment"></i></span><span class="header-nav-menu-item__text">留言板</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-user"></i></span><span class="header-nav-menu-item__text">关于</span></a></div></div><div class="header-nav-search"><span class="header-nav-search__icon"><i class="fas fa-search"></i></span><span class="header-nav-search__text">搜索</span></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Layne's Blog</div><div class="header-banner-info__subtitle">一个爱好coding的男孩纸</div></div><div class="header-banner-arrow"><div class="header-banner-arrow__icon"><i class="fas fa-angle-down"></i></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">二、Spark运行环境</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2021-03-26</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2021-03-28</span></span><span class="post-meta-item post-meta-item--wordcount"><span class="post-meta-item__icon"><i class="far fa-file-word"></i></span><span class="post-meta-item__info">字数统计</span><span class="post-meta-item__value">4k</span></span><span class="post-meta-item post-meta-item--readtime"><span class="post-meta-item__icon"><i class="far fa-clock"></i></span><span class="post-meta-item__info">阅读时长</span><span class="post-meta-item__value">28分</span></span></div></header><div class="post-body"><p>Spark 作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行,  在国内工作中主流的环境为Yarn，不过逐渐容器式环境也慢慢流行起来。接下来，我们就分别看看不同环境下 Spark 的运行。</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326215135.png"  alt="" />
      </p>
<a id="more"></a>
<p><strong>文章目录</strong></p>
<p><ul class="markdownIt-TOC">
<li><a href="#1-local%E6%A8%A1%E5%BC%8F">1. Local模式</a></li>
<li><a href="#2-%E5%90%AF%E5%8A%A8-local-%E7%8E%AF%E5%A2%83">2.  启动 Local 环境</a></li>
<li><a href="#3-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7">3. 命令行工具</a></li>
<li><a href="#4-%E9%80%80%E5%87%BA%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F">4. 退出本地模式</a></li>
<li><a href="#5-%E6%8F%90%E4%BA%A4%E5%BA%94%E7%94%A8">5. 提交应用</a></li>
<li><a href="#6-standalone-%E6%A8%A1%E5%BC%8F">6. Standalone 模式</a>
<ul>
<li><a href="#61-%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6">6.1 解压缩文件</a></li>
<li><a href="#62-%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">6.2 修改配置文件</a></li>
<li><a href="#63-%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4">6.3 启动集群</a></li>
<li><a href="#64-%E6%8F%90%E4%BA%A4%E5%BA%94%E7%94%A8">6.4 提交应用</a></li>
<li><a href="#65-%E6%8F%90%E4%BA%A4%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E">6.5 提交参数说明</a></li>
<li><a href="#66-%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1">6.6 配置历史服务</a></li>
</ul>
</li>
<li><a href="#7-%E9%85%8D%E7%BD%AE%E9%AB%98%E5%8F%AF%E7%94%A8ha">7. 配置高可用（HA）</a></li>
<li><a href="#8-yarn-%E6%A8%A1%E5%BC%8F">8. Yarn 模式</a>
<ul>
<li><a href="#81-%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6">8.1 解压缩文件</a></li>
<li><a href="#82-%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">8.2 修改配置文件</a></li>
<li><a href="#83-%E5%90%AF%E5%8A%A8-hdfs-%E4%BB%A5%E5%8F%8A-yarn-%E9%9B%86%E7%BE%A4">8.3 启动 HDFS 以及 YARN 集群</a></li>
<li><a href="#84-%E6%8F%90%E4%BA%A4%E5%BA%94%E7%94%A8">8.4 提交应用</a></li>
<li><a href="#85-%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8">8.5 配置历史服务器</a></li>
</ul>
</li>
<li><a href="#9-k8s-mesos-%E6%A8%A1%E5%BC%8F">9. K8S &amp; Mesos 模式</a></li>
<li><a href="#10-windows-%E6%A8%A1%E5%BC%8F">10. Windows 模式</a>
<ul>
<li><a href="#101-%E8%A7%A3%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6">10.1 解压缩文件</a></li>
<li><a href="#102-%E5%90%AF%E5%8A%A8%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83">10.2 启动本地环境</a></li>
<li><a href="#103-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8F%90%E4%BA%A4%E5%BA%94%E7%94%A8">10.3 命令行提交应用</a></li>
</ul>
</li>
<li><a href="#11-%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%E5%AF%B9%E6%AF%94">11. 部署模式对比</a></li>
<li><a href="#12-%E7%AB%AF%E5%8F%A3%E5%8F%B7">12. 端口号</a></li>
</ul>
</p>

        <h2 id="1-local模式"   >
          <a href="#1-local模式" class="heading-link"><i class="fas fa-link"></i></a>1. Local模式</h2>
      
<p>所谓的 Local 模式，就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学，调试，演示等，之前在 IDEA 中运行代码的环境我们称之为开发环境，不太一样。</p>
<p>将 <code>spark-3.0.0-bin-hadoop3.2.tgz</code> 文件上传到 Linux 并解压缩，放置在指定位置，路径中不要包含中文或空格，后续如果涉及到解压缩操作，不再强调。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module</span><br><span class="line"><span class="built_in">cd</span> /opt/module </span><br><span class="line">mv spark-3.0.0-bin-hadoop3.2 spark-local</span><br></pre></td></tr></table></div></figure>

        <h2 id="2-启动-local-环境"   >
          <a href="#2-启动-local-环境" class="heading-link"><i class="fas fa-link"></i></a>2.  启动 Local 环境</h2>
      
<ol>
<li>进入解压缩后的路径，执行如下指令</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-local</span><br><span class="line">bin/spark-shell</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326222814.png"  alt="" />
      </p>
<ol start="2">
<li>启动成功后，可以输入网址进行 Web UI 监控页面访问</li>
</ol>
<figure class="highlight tex"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://虚拟机地址:4040</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326222924.png"  alt="" />
      </p>

        <h2 id="3-命令行工具"   >
          <a href="#3-命令行工具" class="heading-link"><i class="fas fa-link"></i></a>3. 命令行工具</h2>
      
<p>在解压缩文件夹下的 data 目录中，添加 word.txt 文件，文件内容如下：</p>
<figure class="highlight tex"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br></pre></td></tr></table></div></figure>
<p>在命令行工具中执行如下代码指令（和 IDEA 中代码简化版一致）</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">"data/word.txt"</span>).flatMap(_.split(<span class="string">" "</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).collect</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210326223450.png"  alt="" />
      </p>

        <h2 id="4-退出本地模式"   >
          <a href="#4-退出本地模式" class="heading-link"><i class="fas fa-link"></i></a>4. 退出本地模式</h2>
      
<p>按键 Ctrl+C 或输入 Scala 指令</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:quit</span><br></pre></td></tr></table></div></figure>

        <h2 id="5-提交应用"   >
          <a href="#5-提交应用" class="heading-link"><i class="fas fa-link"></i></a>5. 提交应用</h2>
      
<p>在<code>spark-local</code>目录下执行如下指令：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--<span class="class"><span class="keyword">class</span> <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> <span class="title">\</span></span></span><br><span class="line"><span class="class"><span class="title">--master</span> <span class="title">local</span>[2] <span class="title">\</span></span></span><br><span class="line"><span class="class">.<span class="title">/examples/jars/spark-examples_2</span>.12<span class="title">-3</span>.0.0.<span class="title">jar</span> <span class="title">\</span></span></span><br><span class="line"><span class="class">10</span></span><br></pre></td></tr></table></div></figure>
<ol>
<li><code>--class</code> 表示要执行程序的主类，此处可以更换为咱们自己写的应用程序</li>
<li><code>--master local[2]</code>  部署模式，默认为本地模式，数字表示分配的虚拟 CPU 核数量</li>
<li><code>spark-examples_2.12-3.0.0.jar</code>  运行的应用类所在的 jar 包，实际使用时，可以设定为咱们自己打的 jar 包</li>
<li>数字 10 表示程序的入口参数，用于设定当前应用的任务数量</li>
</ol>

        <h2 id="6-standalone-模式"   >
          <a href="#6-standalone-模式" class="heading-link"><i class="fas fa-link"></i></a>6. Standalone 模式</h2>
      
<blockquote>
<p>使用spark必须安装hadoop吗？</p>
<p>一般都是要先装hadoop的，如果你只是玩Spark On Standalon 或 Local 的话，就不需要，如果你想用Spark On Yarn或者是需要去hdfs取数据的话，就应该先装hadoop。</p>
</blockquote>
<p>local 本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的集群中去执行，这里我们来看看只使用 Spark 自身节点运行的<strong>集群模式</strong>，也就是我们所谓的独立部署（Standalone）模式。</p>
<p>Spark 的Standalone 模式体现了经典的 master-slave  模式。</p>
<p>现在我们来实现Standalone模式，集群规划：</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327100604.png"  alt="" />
      </p>
<p>下面所有操作都在spark1主机上进行</p>

        <h3 id="61-解压缩文件"   >
          <a href="#61-解压缩文件" class="heading-link"><i class="fas fa-link"></i></a>6.1 解压缩文件</h3>
      
<p>将 <code>spark-3.0.0-bin-hadoop3.2.tgz</code> 文件上传到 spark1 并解压缩在指定位置</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module</span><br><span class="line"><span class="built_in">cd</span> /opt/module </span><br><span class="line">mv spark-3.0.0-bin-hadoop3.2 spark-standalone</span><br></pre></td></tr></table></div></figure>

        <h3 id="62-修改配置文件"   >
          <a href="#62-修改配置文件" class="heading-link"><i class="fas fa-link"></i></a>6.2 修改配置文件</h3>
      
<ol>
<li>进入解压缩后路径的 conf 目录，复制 slaves.template 并修改文件名为 slaves</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></div></figure>
<ol start="2">
<li>修改 slaves 文件，添加 work 节点</li>
</ol>
<figure class="highlight tex"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark1</span><br><span class="line">spark2</span><br><span class="line">spark3</span><br></pre></td></tr></table></div></figure>
<ol start="3">
<li>复制 spark-env.sh.template 并修改文件名为 <span class="exturl"><a class="exturl__link"   href="http://spark-env.sh"  target="_blank" rel="noopener">spark-env.sh</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></div></figure>
<ol start="4">
<li>修改 <span class="exturl"><a class="exturl__link"   href="http://spark-env.sh"  target="_blank" rel="noopener">spark-env.sh</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 文件，添加 JAVA_HOME 环境变量和集群对应的 master 节点</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/default</span><br><span class="line">SPARK_MASTER_HOST=spark1</span><br><span class="line">SPARK_MASTER_PORT=7077</span><br></pre></td></tr></table></div></figure>
<p>注意： 7077 端口，相当于 hadoop3 内部通信的 8020 端口，此处的端口需要确认自己的 Hadoop配置</p>
<ol start="5">
<li>分发 spark-standalone 目录到其他虚拟机上</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/</span><br><span class="line">scp -r  spark-standalone spark2:/opt/module</span><br><span class="line">scp -r  spark-standalone spark3:/opt/module</span><br></pre></td></tr></table></div></figure>

        <h3 id="63-启动集群"   >
          <a href="#63-启动集群" class="heading-link"><i class="fas fa-link"></i></a>6.3 启动集群</h3>
      
<ol>
<li>执行脚本命令：</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-standalone/</span><br><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327124528.png"  alt="" />
      </p>
<ol start="2">
<li>查看三台服务器运行进程</li>
</ol>
<p>在三台虚拟机上分别输入<code>jps</code>出现如下信息</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####### spark1</span></span><br><span class="line">[root@spark1 spark-standalone]<span class="comment"># jps</span></span><br><span class="line">1241 Master</span><br><span class="line">1387 Jps</span><br><span class="line">1307 Worker</span><br><span class="line"><span class="comment">####### spark2</span></span><br><span class="line">[root@spark2 module]<span class="comment"># jps</span></span><br><span class="line">1284 Jps</span><br><span class="line">1223 Worker</span><br><span class="line"><span class="comment">####### spark3</span></span><br><span class="line">[root@spark3 spark-standalone]<span class="comment"># jps</span></span><br><span class="line">1289 Jps</span><br><span class="line">1228 Worker</span><br></pre></td></tr></table></div></figure>
<ol start="3">
<li>查看 Master 资源监控 Web UI 界面: <code>http://spark1:8080</code></li>
</ol>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125039.png"  alt="" />
      </p>

        <h3 id="64-提交应用"   >
          <a href="#64-提交应用" class="heading-link"><i class="fas fa-link"></i></a>6.4 提交应用</h3>
      
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://spark1:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></div></figure>
<p>说明</p>
<ol>
<li><code>--class</code> 表示要执行程序的主类</li>
<li><code>--master spark://spark1:7077</code>  独立部署模式，连接到 Spark 集群</li>
<li><code>spark-examples_2.12-3.0.0.jar</code>  运行类所在的 jar 包</li>
<li>数字 10 表示程序的入口参数，用于设定当前应用的任务数量</li>
</ol>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125605.png"  alt="" />
      </p>
<p>执行任务时，会产生多个 Java 进程</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@spark2 module]<span class="comment"># jps </span></span><br><span class="line">1362 CoarseGrainedExecutorBackend  //执行节点进程</span><br><span class="line">1378 Jps</span><br><span class="line">1223 Worker</span><br><span class="line">[root@spark3 spark-standalone]<span class="comment"># jps</span></span><br><span class="line">1360 Jps</span><br><span class="line">1347 CoarseGrainedExecutorBackend</span><br><span class="line">1228 Worker</span><br></pre></td></tr></table></div></figure>
<p>执行任务时，默认采用服务器集群节点的总核数，每个节点内存 1024M。</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327125916.png"  alt="" />
      </p>

        <h3 id="65-提交参数说明"   >
          <a href="#65-提交参数说明" class="heading-link"><i class="fas fa-link"></i></a>6.5 提交参数说明</h3>
      
<p>在提交应用中，一般会同时一些提交参数</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class &lt;main-class&gt;</span><br><span class="line">--master &lt;master-url&gt; \</span><br><span class="line">... <span class="comment"># other options</span></span><br><span class="line">&lt;application-jar&gt; \</span><br><span class="line">[application-arguments]</span><br></pre></td></tr></table></div></figure>
<div class="table-container"><table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
<th>可选值举例</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--class</code></td>
<td>Spark 程序中包含主函数的类</td>
<td></td>
</tr>
<tr>
<td><code>--master</code></td>
<td>Spark 程序运行的模式(环境)</td>
<td>模式：<code>local[*]</code>、<code>spark://spark1:7077</code>、<code>Yarn</code></td>
</tr>
<tr>
<td><code>--executor-memory 1G</code></td>
<td>指定每个 executor 可用内存为 1G</td>
<td>符合集群内存配置即可，具体情况具体分析。</td>
</tr>
<tr>
<td><code>--total-executor-cores 2</code></td>
<td>指定所有 executor 使用的 cpu 核数为 2 个</td>
<td>符合集群内存配置即可，具体情况具体分析。</td>
</tr>
<tr>
<td><code>--executor-cores</code></td>
<td>指定每个 executor 使用的 cpu 核数</td>
<td>符合集群内存配置即可，具体情况具体分析。</td>
</tr>
<tr>
<td><code>application-jar</code></td>
<td>打包好的应用 jar，包含依赖。这个 URL 在集群中全局可见。  比如 <code>hdfs://</code>  共享存储系统，如果是<code>file:// path</code> ，那么所有的节点的path 都包含同样的 jar</td>
<td>符合集群内存配置即可，具体情况具体分析。</td>
</tr>
<tr>
<td><code>application-arguments</code></td>
<td>传给 main()方法的参数</td>
<td></td>
</tr>
</tbody>
</table></div>

        <h3 id="66-配置历史服务"   >
          <a href="#66-配置历史服务" class="heading-link"><i class="fas fa-link"></i></a>6.6 配置历史服务</h3>
      
<p>由于 spark-shell 停止掉后，集群监控 <code>spark1:4040</code> 页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况。</p>
<p>以下指令在spark1虚拟机上执行</p>
<ol>
<li>复制 spark-defaults.conf.template 并修改文件名为 spark-defaults.conf</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></div></figure>
<ol start="2">
<li>修改 spark-default.conf 文件，配置日志存储路径</li>
</ol>
<figure class="highlight sh"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs://spark1:8020/sparklog</span><br></pre></td></tr></table></div></figure>
<p>注意：需要启动 hadoop 集群，HDFS 上的 sparklog 目录需要提前存在。</p>
<p>如果目录不存在，可以在hadoop集群上执行如下命令创建：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">hadoop fs -mkdir /sparklog</span><br></pre></td></tr></table></div></figure>
<ol start="3">
<li>修改 spark-env .sh 文件,  添加日志配置</li>
</ol>
<figure class="highlight sh"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">"</span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080 </span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://spark1:8020/sparklog </span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30"</span></span><br></pre></td></tr></table></div></figure>
<ul>
<li>参数 1 含义：WEB UI 访问的端口号为 18080</li>
<li>参数 2 含义：指定历史服务器日志存储路径</li>
<li>参数 3 含义：指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</li>
</ul>
<ol start="4">
<li>分发配置文件</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/spark-standalone</span><br><span class="line">scp -r  conf spark2:`<span class="built_in">pwd</span>`</span><br><span class="line">scp -r  conf spark3:`<span class="built_in">pwd</span>`</span><br></pre></td></tr></table></div></figure>
<ol start="5">
<li>重新启动集群和历史服务</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br><span class="line">sbin/start-all.sh</span><br><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></div></figure>
<ol start="6">
<li>重新执行任务</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://spark1:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></div></figure>
<ol start="7">
<li>查看历史服务：<code>http://spark1:18080</code></li>
</ol>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327151322.png"  alt="" />
      </p>

        <h2 id="7-配置高可用ha"   >
          <a href="#7-配置高可用ha" class="heading-link"><i class="fas fa-link"></i></a>7. 配置高可用（HA）</h2>
      
<p>所谓的高可用是因为当前集群中的 Master 节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个 Master 节点，一旦处于活动状态的 Master发生故障时，由备用 Master 提供服务，保证作业可以继续执行。这里的高可用一般采用Zookeeper 设置</p>
<p>现在我们来实现高可用，集群规划为：</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327152008.png"  alt="" />
      </p>
<p>以下指令没有特别说明，均在spark1上执行</p>
<ol>
<li>停止集群</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br></pre></td></tr></table></div></figure>
<ol start="2">
<li>启动 Zookeeper</li>
</ol>
<p>在三台虚拟机上分别执行：<code>zkServer.sh start</code></p>
<ol start="3">
<li>修改 <span class="exturl"><a class="exturl__link"   href="http://spark-env.sh"  target="_blank" rel="noopener">spark-env.sh</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> 文件添加如下配置</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">注释如下内容：</span><br><span class="line"><span class="comment"># SPARK_MASTER_HOST=spark1</span></span><br><span class="line"><span class="comment"># SPARK_MASTER_PORT=7077</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">添加如下内容:</span><br><span class="line"><span class="comment">#Master 监控页面默认访问端口为 8080，但是可能会和 Zookeeper 冲突，所以改成 8989，也可以自定义，访问 UI 监控页面时请注意</span></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=8989</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_DAEMON_JAVA_OPTS=<span class="string">"</span></span><br><span class="line"><span class="string">-Dspark.deploy.recoveryMode=ZOOKEEPER </span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.url=spark1,spark2,spark3</span></span><br><span class="line"><span class="string">-Dspark.deploy.zookeeper.dir=/spark"</span></span><br></pre></td></tr></table></div></figure>
<ol start="4">
<li>分发配置文件</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/spark-standalone</span><br><span class="line">scp -r  conf spark2:`<span class="built_in">pwd</span>`</span><br><span class="line">scp -r  conf spark3:`<span class="built_in">pwd</span>`</span><br></pre></td></tr></table></div></figure>
<ol start="5">
<li>启动集群</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></div></figure>
<p>在浏览器打开<code>http://spark1:8989</code>，可以看到spark1节点处于活动状态</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327154926.png"  alt="" />
      </p>
<ol start="6">
<li>启动 spark2 的单独 Master 节点，此时 linux2 节点 Master 状态处于备用状态</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@spark2 spark-standalone]<span class="comment"># pwd</span></span><br><span class="line">/opt/module/spark-standalone</span><br><span class="line">[root@spark2 spark-standalone]<span class="comment"># sbin/start-master.sh</span></span><br></pre></td></tr></table></div></figure>
<p>在浏览器打开<code>http://spark2:8989</code></p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327155326.png"  alt="" />
      </p>
<ol start="7">
<li>提交应用到高可用集群</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://spark1:7077,spark2:7077 \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></div></figure>
<ol start="8">
<li>停止 linux1 的 Master 资源监控进程</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root<span class="meta">@spark</span>1 spark-standalone]# jps</span><br><span class="line"><span class="number">3600</span> <span class="type">Worker</span></span><br><span class="line"><span class="number">3537</span> <span class="type">Master</span></span><br><span class="line"><span class="number">2193</span> <span class="type">SecondaryNameNode</span></span><br><span class="line"><span class="number">3893</span> <span class="type">Jps</span></span><br><span class="line"><span class="number">2775</span> <span class="type">HistoryServer</span></span><br><span class="line"><span class="number">3352</span> <span class="type">QuorumPeerMain</span></span><br><span class="line"><span class="number">2028</span> <span class="type">DataNode</span></span><br><span class="line"><span class="number">1950</span> <span class="type">NameNode</span></span><br><span class="line">[root<span class="meta">@spark</span>1 spark-standalone]# kill <span class="number">-9</span> <span class="number">3537</span></span><br></pre></td></tr></table></div></figure>
<ol start="9">
<li>查看 linux2 的 Master  资源监控 Web UI，稍等一段时间后（大概15s），linux2 节点的 Master 状态提升为活动状态</li>
</ol>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210327155728.png"  alt="" />
      </p>

        <h2 id="8-yarn-模式"   >
          <a href="#8-yarn-模式" class="heading-link"><i class="fas fa-link"></i></a>8. Yarn 模式</h2>
      
<p>独立部署（Standalone）模式由 Spark 自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark 主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的 Yarn 环境下 Spark 是如何工作的（其实是因为在国内工作中，Yarn 使用的非常多）。</p>

        <h3 id="81-解压缩文件"   >
          <a href="#81-解压缩文件" class="heading-link"><i class="fas fa-link"></i></a>8.1 解压缩文件</h3>
      
<p>将 <code>spark-3.0.0-bin-hadoop3.2.tgz</code> 文件上传到 linux 并解压缩，放置在指定位置。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf spark<span class="number">-3.0</span><span class="number">.0</span>-bin-hadoop3<span class="number">.2</span>.tgz -<span class="type">C</span> /opt/module</span><br><span class="line">cd /opt/module </span><br><span class="line">mv spark<span class="number">-3.0</span><span class="number">.0</span>-bin-hadoop3<span class="number">.2</span> spark-yarn</span><br></pre></td></tr></table></div></figure>
<p>下面的所有命令都只在spark1虚拟机上执行</p>

        <h3 id="82-修改配置文件"   >
          <a href="#82-修改配置文件" class="heading-link"><i class="fas fa-link"></i></a>8.2 修改配置文件</h3>
      
<ol>
<li>修改 hadoop 配置文件<code>/opt/hadoop-2.6.5/etc/hadoop/yarn-site.xml</code>,  并分发</li>
</ol>
<figure class="highlight xml"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是 true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是 true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></div></figure>
<ol start="2">
<li>修改 <code>/opt/module/spark-yarn/conf/spark-env.sh</code>，添加 JAVA_HOME 和 YARN_CONF_DIR 配置</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/module/spark-yarn/conf</span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在最后添加</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/default</span><br><span class="line">YARN_CONF_DIR=/opt/hadoop-2.6.5/etc/hadoop</span><br></pre></td></tr></table></div></figure>

        <h3 id="83-启动-hdfs-以及-yarn-集群"   >
          <a href="#83-启动-hdfs-以及-yarn-集群" class="heading-link"><i class="fas fa-link"></i></a>8.3 启动 HDFS 以及 YARN 集群</h3>
      
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh <span class="comment"># 启动HDFS</span></span><br><span class="line">start-yarn.sh <span class="comment"># 启动yarn</span></span><br><span class="line">sbin/start-all.sh <span class="comment">#启动Spark</span></span><br></pre></td></tr></table></div></figure>

        <h3 id="84-提交应用"   >
          <a href="#84-提交应用" class="heading-link"><i class="fas fa-link"></i></a>8.4 提交应用</h3>
      
<p>先<code>cd /opt/module/spark-yarn/</code> 再提交应用：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></div></figure>
<ul>
<li><code>--deploy-mode cluster</code>：以集群模式执行，控制台不显示执行结果</li>
</ul>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328152100.png"  alt="" />
      </p>
<p>查看<code>http://spark1:8088</code>页面</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328152345.png"  alt="" />
      </p>

        <h3 id="85-配置历史服务器"   >
          <a href="#85-配置历史服务器" class="heading-link"><i class="fas fa-link"></i></a>8.5 配置历史服务器</h3>
      
<ol>
<li>复制 <code>spark-defaults.conf.template</code> 并修改文件名为 <code>spark-defaults.conf</code></li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></div></figure>
<ol start="2">
<li>修改 spark-default.conf 文件，配置日志存储路径</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs://spark1:8020/sparklog</span><br></pre></td></tr></table></div></figure>
<p>注意：需要启动 hadoop 集群，HDFS 上的目录需要提前存在。</p>
<p>如果目录不存在，可以在hadoop集群上执行如下命令创建：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line">hadoop fs -mkdir /sparklog</span><br></pre></td></tr></table></div></figure>
<ol start="3">
<li>修改 spark-env .sh 文件,  添加日志配置</li>
</ol>
<figure class="highlight sh"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">"</span></span><br><span class="line"><span class="string">-Dspark.history.ui.port=18080 </span></span><br><span class="line"><span class="string">-Dspark.history.fs.logDirectory=hdfs://spark1:8020/sparklog </span></span><br><span class="line"><span class="string">-Dspark.history.retainedApplications=30"</span></span><br></pre></td></tr></table></div></figure>
<ul>
<li>参数 1 含义：WEB UI 访问的端口号为 18080</li>
<li>参数 2 含义：指定历史服务器日志存储路径</li>
<li>参数 3 含义：指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</li>
</ul>
<ol start="4">
<li>修改 spark-defaults.conf，再最后添加</li>
</ol>
<figure class="highlight plain"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.historyServer.address&#x3D;spark1:18080</span><br><span class="line">spark.history.ui.port&#x3D;18080</span><br></pre></td></tr></table></div></figure>
<ol start="5">
<li>启动历史服务</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-history-server.sh</span><br></pre></td></tr></table></div></figure>
<ol start="6">
<li>重新提交应用</li>
</ol>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">./examples/jars/spark-examples_2.12-3.0.0.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></div></figure>
<ul>
<li><code>--deploy-mode client</code>：以客户端模式执行，控制台显示执行结果</li>
</ul>
<p>查看<code>http://spark1:18080/</code></p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155109.png"  alt="" />
      </p>

        <h2 id="9-k8s-mesos-模式"   >
          <a href="#9-k8s-mesos-模式" class="heading-link"><i class="fas fa-link"></i></a>9. K8S &amp; Mesos 模式</h2>
      
<p>Mesos 是 Apache 下的开源分布式资源管理框架，它被称为是分布式系统的内核，在Twitter 得到广泛使用，管理着 Twitter 超过 30,0000 台服务器上的应用部署，但是在国内，依然使用着传统的 Hadoop 大数据框架，所以国内使用 Mesos 框架的并不多， 但是原理其实都差不多，这里我们就不做过多讲解了。</p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155457.png"  alt="" />
      </p>
<p>容器化部署是目前业界很流行的一项技术，基于 Docker 镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是 Kubernetes（k8s），而 Spark也在最近的版本中支持了 k8s 部署模式。这里我也不做过多的讲解。给个链接大家自己感受一下：<span class="exturl"><a class="exturl__link"   href="https://spark.apache.org/docs/latest/running-on-kubernetes.html"  target="_blank" rel="noopener">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328155556.png"  alt="" />
      </p>

        <h2 id="10-windows-模式"   >
          <a href="#10-windows-模式" class="heading-link"><i class="fas fa-link"></i></a>10. Windows 模式</h2>
      
<p>在自己学习时，每次都需要启动虚拟机，启动集群，这是一个比较繁琐的过程，并且会占大量的系统资源，导致系统执行变慢，不仅仅影响学习效果，也影响学习进度，Spark 非常暖心地提供了可以在 windows 系统下启动本地集群的方式，这样，在不使用虚拟机的情况下，也能学习 Spark 的基本使用，摸摸哒！</p>
<p>在学习Spark时，一般情况下都会采用 windows 系统的集群来学习 Spark。</p>

        <h3 id="101-解压缩文件"   >
          <a href="#101-解压缩文件" class="heading-link"><i class="fas fa-link"></i></a>10.1 解压缩文件</h3>
      
<p>将文件 spark-3.0.0-bin-hadoop3.2.tgz 解压缩到无中文无空格的路径中</p>

        <h3 id="102-启动本地环境"   >
          <a href="#102-启动本地环境" class="heading-link"><i class="fas fa-link"></i></a>10.2 启动本地环境</h3>
      
<ol>
<li>执行解压缩文件路径下 bin 目录中的 spark-shell.cmd 文件，启动 Spark 本地环境</li>
</ol>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328160258.png"  alt="" />
      </p>
<ol start="2">
<li>在 bin 目录中创建 input 目录，并添加 word.txt 文件,  在word.txt中输入以下内容</li>
</ol>
<figure class="highlight tex"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br><span class="line">Hello Scala</span><br><span class="line">Hello Spark</span><br></pre></td></tr></table></div></figure>
<p>在命令行中输入脚本代码</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">"input/word.txt"</span>).flatMap(_.split(<span class="string">" "</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).collect</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328160521.png"  alt="" />
      </p>

        <h3 id="103-命令行提交应用"   >
          <a href="#103-命令行提交应用" class="heading-link"><i class="fas fa-link"></i></a>10.3 命令行提交应用</h3>
      
<p>在 bin 目录下打开cmd，输入</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --class org.apache.spark.examples.SparkPi --master <span class="built_in">local</span>[2] ../examples/jars/spark-examples_2.12-3.0.0.jar 10</span><br></pre></td></tr></table></div></figure>
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328161045.png"  alt="" />
      </p>

        <h2 id="11-部署模式对比"   >
          <a href="#11-部署模式对比" class="heading-link"><i class="fas fa-link"></i></a>11. 部署模式对比</h2>
      
<p>
        <img   class="lazyload lazyload-gif"
          src="/images/loading.svg" data-src="https://gitee.com/wxler/blogimg/raw/master/imgs/20210328161149.png"  alt="" />
      </p>

        <h2 id="12-端口号"   >
          <a href="#12-端口号" class="heading-link"><i class="fas fa-link"></i></a>12. 端口号</h2>
      
<ul>
<li>Spark 查看当前 Spark-shell 运行任务情况端口号：4040（计算）</li>
<li>Spark Master 内部通信服务端口号：7077</li>
<li>Standalone 模式下，Spark Master Web 端口号：8080（资源）</li>
<li>Spark 历史服务器端口号：18080</li>
<li>Hadoop YARN 任务运行情况查看端口号：8088</li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://wxler.github.io">wxler</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://wxler.github.io/2021/03/26/214809/">https://wxler.github.io/2021/03/26/214809/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="https://wxler.github.io/tags/Spark/">Spark</a></span></div><div class="post-share"><div class="social-share" data-sites="qzone, qq, weibo, wechat, douban, linkedin, facebook, twitter, google">分享到：</div></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2021/03/28/161528/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">三、Spark运行架构</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2021/03/26/204025/"><span class="paginator-prev__text">Scala常见操作总结</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div><div class="comments" id="comments"><div id="valine-container"></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-local模式"><span class="toc-text">
          1. Local模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-启动-local-环境"><span class="toc-text">
          2.  启动 Local 环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-命令行工具"><span class="toc-text">
          3. 命令行工具</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-退出本地模式"><span class="toc-text">
          4. 退出本地模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-提交应用"><span class="toc-text">
          5. 提交应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-standalone-模式"><span class="toc-text">
          6. Standalone 模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#61-解压缩文件"><span class="toc-text">
          6.1 解压缩文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#62-修改配置文件"><span class="toc-text">
          6.2 修改配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#63-启动集群"><span class="toc-text">
          6.3 启动集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#64-提交应用"><span class="toc-text">
          6.4 提交应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#65-提交参数说明"><span class="toc-text">
          6.5 提交参数说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#66-配置历史服务"><span class="toc-text">
          6.6 配置历史服务</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-配置高可用ha"><span class="toc-text">
          7. 配置高可用（HA）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-yarn-模式"><span class="toc-text">
          8. Yarn 模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#81-解压缩文件"><span class="toc-text">
          8.1 解压缩文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#82-修改配置文件"><span class="toc-text">
          8.2 修改配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#83-启动-hdfs-以及-yarn-集群"><span class="toc-text">
          8.3 启动 HDFS 以及 YARN 集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#84-提交应用"><span class="toc-text">
          8.4 提交应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#85-配置历史服务器"><span class="toc-text">
          8.5 配置历史服务器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-k8s-mesos-模式"><span class="toc-text">
          9. K8S &amp; Mesos 模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-windows-模式"><span class="toc-text">
          10. Windows 模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#101-解压缩文件"><span class="toc-text">
          10.1 解压缩文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#102-启动本地环境"><span class="toc-text">
          10.2 启动本地环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#103-命令行提交应用"><span class="toc-text">
          10.3 命令行提交应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-部署模式对比"><span class="toc-text">
          11. 部署模式对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-端口号"><span class="toc-text">
          12. 端口号</span></a></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/assets/myhexo.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">Practical And Realistic</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/wxler" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span></a><a class="sidebar-ov-social-item" href="mailto:wangxiaolei1516@qq.com" target="_blank" rel="noopener" data-popover="邮箱" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fa fa-envelope"></i></span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">125</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">21</div><div class="sidebar-ov-state-item__name">分类</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">58</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2020~2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>wxler. All Rights Reserved.</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v4.2.1</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.0.0</span></div><div>托管于 <a href="https://github.com/wxler/" rel="noopener" target="_blank">Github</a></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><div class="search-mask"></div><div class="search-popup"><span class="search-close"></span><div class="search-input"><input placeholder="搜索文章（支持多关键词，请用空格分隔）"></div><div class="search-results"></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="https://cdn.jsdelivr.net/npm/ribbon.js@latest/dist/ribbon.min.js" size="120" alpha="0.6" zIndex="-1"></script><script src="https://cdn.jsdelivr.net/npm/lazyload@2.0.0-rc.2/lazyload.min.js"></script><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><script>function initSearch() {
  var isXML = true;
  var search_path = 'search.json';

  if (!search_path) {
    search_path = 'search.xml';
  } else if (/json$/i.test(search_path)) {
    isXML = false;
  }

  var path = '/' + search_path;
  $.ajax({
    url: path,
    dataType: isXML ? 'xml' : 'json',
    async: true,
    success: function (res) {
      var datas = isXML ? $('entry', res).map(function () {
        // 将 XML 转为 JSON
        return {
          title: $('title', this).text(),
          content: $('content', this).text(),
          url: $('url', this).text()
        };
      }).get() : res;
      var $input = $('.search-input input');
      var $result = $('.search-results');
      // 搜索对象（标题、内容）的权重，影响显示顺序
      var WEIGHT = { title: 100, content: 1 };
      var searchPost = function () {
        var searchText = $input.val().toLowerCase().trim();
        // 根据空白字符分隔关键字
        var keywords = searchText.split(/[\s]+/);
        // 搜索结果
        var matchPosts = [];

        // 有多个关键字时，将原文字整个保存下来
        if (keywords.length > 1) {
          keywords.push(searchText);
        }
        // 防止未输入字符时搜索
        if (searchText.length > 0) {
          datas.forEach(function (data) {
            var isMatch  = false;
            // 没有标题的文章使用预设的 i18n 变量代替
            var title = (data.title && data.title.trim()) || '[ 文章无标题 ]';
            var titleLower = title && title.toLowerCase();
            // 删除 HTML 标签 和 所有空白字符
            var content = data.content && data.content.replace(/<[^>]+>/g, '');
            var contentLower = content && content.toLowerCase();
            // 删除重复的 /
            var postURL = data.url && decodeURI(data.url).replace(/\/{2,}/g, '/');
            // 标题中匹配到的关键词
            var titleHitSlice = [];
            // 内容中匹配到的关键词
            var contentHitSlice = [];

            keywords.forEach(function (keyword) {
              /**
              * 获取匹配的关键词的索引
              * @param {String} keyword 要匹配的关键字
              * @param {String} text 原文字
              * @param {Boolean} caseSensitive 是否区分大小写
              * @param {Number} weight 匹配对象的权重。权重大的优先显示
              * @return {Array}
              */
              function getIndexByword (word, text, caseSensitive, weight) {
                if (!word || !text) {
                  return [];
                };

                var startIndex = 0; // 每次匹配的开始索引
                var index = -1;     // 匹配到的索引值
                var result = [];    // 匹配结果

                if (!caseSensitive) {
                  word = word.toLowerCase();
                  text = text.toLowerCase();
                }

                while((index = text.indexOf(word, startIndex)) !== -1) {
                  var hasMatch = false;
                  // 索引位置相同的关键词，保留长度较长的
                  titleHitSlice.forEach(function (hit) {
                    if (hit.index === index && hit.word.length < word.length) {
                      hit.word = word;
                      hasMatch = true;
                    }
                  });
                  startIndex = index + word.length;
                  !hasMatch && result.push({ index: index, word: word, weight: weight });
                }
                return result;
              }
              titleHitSlice = titleHitSlice.concat(getIndexByword(keyword, titleLower, false, WEIGHT.title));
              contentHitSlice = contentHitSlice.concat(getIndexByword(keyword, contentLower, false, WEIGHT.content));
            });

            var hitTitle = titleHitSlice.length;
            var hitContent = contentHitSlice.length;

            if (hitTitle > 0 || hitContent > 0) {
              isMatch = true;
            }
            if (isMatch) {
              ;[titleHitSlice, contentHitSlice].forEach(function (hit) {
                // 按照匹配文字的索引的递增顺序排序
                hit.sort(function (left, right) {
                  return left.index - right.index;
                });
              });
              /**
              * 给文本中匹配到的关键词添加标记，从而进行高亮显示
              * @param {String} text 原文本
              * @param {Array} hitSlice 匹配项的索引信息
              * @param {Number} start 开始索引
              * @param {Number} end 结束索引
              * @return {String}
              */
              function highlightKeyword (text, hitSlice, start, end) {
                if (!text || !hitSlice || !hitSlice.length) {
                  return;
                }

                var result = '';
                var startIndex = start;
                var endIndex = end;
                hitSlice.forEach(function (hit) {
                  if (hit.index < startIndex) {
                    return;
                  }

                  var hitWordEnd = hit.index + hit.word.length;
                  result += text.slice(startIndex, hit.index);
                  result += '<b>' + text.slice(hit.index, hitWordEnd) + '</b>';
                  startIndex = hitWordEnd;
                });
                result += text.slice(startIndex, endIndex);
                return result;
              }

              var postData = {};
              // 文章总的搜索权重
              var postWeight = titleHitSlice.length * WEIGHT.title + contentHitSlice.length * WEIGHT.content;
              // 标记匹配关键词后的标题
              var postTitle = highlightKeyword(title, titleHitSlice, 0, title.length) || title;
              // 标记匹配关键词后的内容
              var postContent;
              // 显示内容的长度
              var SHOW_WORD_LENGTH = 200;
              // 命中关键词前的字符显示长度
              var SHOW_WORD_FRONT_LENGTH = 20;
              var SHOW_WORD_END_LENGTH = SHOW_WORD_LENGTH - SHOW_WORD_FRONT_LENGTH;

              // 截取匹配的第一个字符，前后共 200 个字符来显示
              if (contentHitSlice.length > 0) {
                var firstIndex = contentHitSlice[0].index;
                var start = firstIndex > SHOW_WORD_FRONT_LENGTH ? firstIndex - SHOW_WORD_FRONT_LENGTH : 0;
                var end = firstIndex + SHOW_WORD_END_LENGTH;
                postContent = highlightKeyword(content, contentHitSlice, start, end);
              } else { // 未匹配到内容，直接截取前 200 个字符来显示
                postContent = content.slice(0, SHOW_WORD_LENGTH);
              }
              postData.title = postTitle;
              postData.content = postContent;
              postData.url = postURL;
              postData.weight = postWeight;
              matchPosts.push(postData);
            }
          });
        }

        var resultInnerHtml = '';
        if (matchPosts.length) {
          // 按权重递增的顺序排序，使权重大的优先显示
          matchPosts.sort(function (left, right) {
            return right.weight - left.weight;
          });
          resultInnerHtml += '<ul>';
          matchPosts.forEach(function (post) {
            resultInnerHtml += '<li><a class="search-results-title" href="' + post.url + '">';
            resultInnerHtml += post.title;
            resultInnerHtml += '</a><div class="search-results-content">';
            resultInnerHtml += post.content;
            resultInnerHtml += '</div></li>';
          });
          resultInnerHtml += '</ul>';
        } else {
          resultInnerHtml += '<div class="search-results-none"><i class="far fa-meh"></i></div>';
        }
        $result.html(resultInnerHtml);
      };
      $input.on('input', searchPost);
      $input.on('keyup', function (e) {
        if (e.keyCode === Stun.utils.codeToKeyCode('Enter')) {
          searchPost();
        }
      });
    }
  });
}

function closeSearch () {
  $('body').css({ overflow: 'auto' });
  $('.search-popup').css({ display: 'none' });
  $('.search-mask').css({ display: 'none' });
}

window.addEventListener('DOMContentLoaded', function () {
  Stun.utils.pjaxReloadLocalSearch = function () {
    $('.header-nav-search').on('click', function (e) {
      e.stopPropagation();
      $('body').css('overflow', 'hidden');
      $('.search-popup')
        .velocity('stop')
        .velocity('transition.expandIn', {
          duration: 300,
          complete: function () {
            $('.search-popup input').focus();
          }
        });
      $('.search-mask')
        .velocity('stop')
        .velocity('transition.fadeIn', {
          duration: 300
        });

      initSearch();
    });
    $('.search-mask, .search-close').on('click', function () {
      closeSearch();
    });
    $(document).on('keydown', function (e) {
      // Escape <=> 27
      if (e.keyCode === Stun.utils.codeToKeyCode('Escape')) {
        closeSearch();
      }
    });
  };

  Stun.utils.pjaxReloadLocalSearch();
}, false);</script><script src="https://cdn.jsdelivr.net/npm/pjax@latest/pjax.min.js"></script><script>window.addEventListener('DOMContentLoaded', function () {
  var pjax = new Pjax({"selectors":["head title","#main",".pjax-reload"],"history":true,"scrollTo":false,"scrollRestoration":false,"cacheBust":false,"debug":false,"currentUrlFullReload":false,"timeout":0});
  // 加载进度条的计时器
  var loadingTimer = null;

  // 重置页面 Y 方向上的滚动偏移量
  document.addEventListener('pjax:send', function () {
    $('.header-nav-menu').removeClass('show');
    if (CONFIG.pjax && CONFIG.pjax.avoidBanner) {
      $('html').velocity('scroll', {
        duration: 500,
        offset: $('#header').height(),
        easing: 'easeInOutCubic'
      });
    }

    var loadingBarWidth = 20;
    var MAX_LOADING_WIDTH = 95;

    $('.loading-bar').addClass('loading');
    $('.loading-bar__progress').css('width', loadingBarWidth + '%');
    clearInterval(loadingTimer);
    loadingTimer = setInterval(function () {
      loadingBarWidth += 3;
      if (loadingBarWidth > MAX_LOADING_WIDTH) {
        loadingBarWidth = MAX_LOADING_WIDTH;
      }
      $('.loading-bar__progress').css('width', loadingBarWidth + '%');
    }, 500);
  }, false);

  window.addEventListener('pjax:complete', function () {
    clearInterval(loadingTimer);
    $('.loading-bar__progress').css('width', '100%');
    $('.loading-bar').removeClass('loading');
    setTimeout(function () {
      $('.loading-bar__progress').css('width', '0');
    }, 400);
    $('link[rel=prefetch], script[data-pjax-rm]').each(function () {
      $(this).remove();
    });
    $('script[data-pjax], #pjax-reload script').each(function () {
      $(this).parent().append($(this).remove());
    });

    if (Stun.utils.pjaxReloadBoot) {
      Stun.utils.pjaxReloadBoot();
    }
    if (Stun.utils.pjaxReloadScroll) {
      Stun.utils.pjaxReloadScroll();
    }
    if (Stun.utils.pjaxReloadSidebar) {
      Stun.utils.pjaxReloadSidebar();
    }
    if (false) {
      if (Stun.utils.pjaxReloadHeader) {
        Stun.utils.pjaxReloadHeader();
      }
      if (Stun.utils.pjaxReloadScrollIcon) {
        Stun.utils.pjaxReloadScrollIcon();
      }
      if (Stun.utils.pjaxReloadLocalSearch) {
        Stun.utils.pjaxReloadLocalSearch();
      }
    }
  }, false);
}, false);</script><div id="pjax-reload"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.css" rel="stylesheet" type="text/css"><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/copy-tex.min.js"></script></div><script src="https://cdn.jsdelivr.net/npm/leancloud-storage@latest/dist/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@latest/dist/Valine.min.js"></script><script data-pjax="">function loadValine () {
  var GUEST_INFO = ['nick', 'mail', 'link'];
  var guest_info = 'nick,mail';

  guest_info = guest_info.split(',').filter(function(item) {
    return GUEST_INFO.indexOf(item) > -1;
  });
  new Valine({
    el: '#valine-container',
    appId: 'kBUfBo302Sl5ViCNcWef6wYT-gzGzoHsz',
    appKey: 'hq4rU6YND5ziczBa2PLLUBiM',
    notify: true,
    verify: false,
    placeholder: '有什么需要和我说的，请填写昵称与邮箱(邮箱不会公开显示)，点击评论吧(支持匿名评论)！',
    avatar: 'mp',
    meta: guest_info,
    pageSize: '15' || 10,
    visitor: false,
    recordIP: false,
    lang: '' || 'zh-cn',
    path: window.location.pathname
  });
}

if (true) {
  loadValine();
} else {
  window.addEventListener('DOMContentLoaded', loadValine, false);
}</script><script src="/js/utils.js?v=2.0.0"></script><script src="/js/stun-boot.js?v=2.0.0"></script><script src="/js/scroll.js?v=2.0.0"></script><script src="/js/header.js?v=2.0.0"></script><script src="/js/sidebar.js?v=2.0.0"></script></body></html>