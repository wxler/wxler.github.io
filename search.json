[{"title":"useNumpyLinearPredict","url":"/2020/07/16/useNumpyLinearPredict/","content":"## 知识储备\n\n### Scikit-learn\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。其优点为：\n- 简单高效的数据挖掘和数据分析工具\n- 让每个人能够在复杂环境中重复使用\n- 建立NumPy、Scipy、MatPlotLib之上\n\n安装方法 pip install scikit-learn\n\n### boston房价数据解读\n\n使用sklearn.datasets.load_boston即可加载相关数据。该数据集是一个回归问题。每个类的观察值数量是均等的，共有506个观察，13个输入变量和1个输出变量。每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等，具体如下：\n- CRIM：城镇人均犯罪率。\n- ZN：住宅用地超过 25000 sq.ft. 的比例。\n- INDUS：城镇非零售商用土地的比例。\n- CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n- NOX：一氧化氮浓度。\n- RM：住宅平均房间数。\n- AGE：1940 年之前建成的自用房屋比例。\n- DIS：到波士顿五个中心区域的加权距离。\n- RAD：辐射性公路的接近指数。\n- TAX：每 10000 美元的全值财产税率。\n- PTRATIO：城镇师生比例。\n- B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n- LSTAT：人口中地位低下者的比例。\n- MEDV：自住房的平均房价，以千美元计。\n- 预测平均值的基准性能的均方根误差（RMSE）是约 9.21 千美元。\n\n### 标准差公式\n\n如x1,x2,x3...xn的平均数为M，则方差可表示为：\n\n![image.png](attachment:image.png)\n\n样本标准差=方差的算术平方根=s=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/(n-1) )  \n总体标准差=σ=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/n )  \n如是总体，标准差公式根号内除以n  \n如是样本，标准差公式根号内除以（n-1)。  \n因为我们大量接触的是样本，所以普遍使用根号内除以（n-1)。  \n\n\n```python\na=np.array([[1,2,3],[4,5,6]])\nnp.mean(a,axis=1)\n```\n\n\n\n\n    array([2., 5.])\n\n\n\n\n```python\n# axis = 1表示行，ddof = 1是除以n-1\nnp.std(a, axis = 1,ddof = 1) \n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\n# ddof默认为0,是除以n\nnp.std(a, axis = 1) \n```\n\n\n\n\n    array([0.81649658, 0.81649658])\n\n\n\n\n```python\n# 求所有数平均值\nnp.mean(a)\n```\n\n\n\n\n    3.5\n\n\n\n### Linear及MSE_loss求导公式\n\n损失函数\n$L = \\frac{1}{2N}\\sum_{i=1}^{N}(z^{i} - y^{i})^{2} $\n\n线性函数\n$z^i = \\sum_{j=0}^{N}x_j^{(i)}w^{(j)} + b^{(j)}$\n\n对 $w$ 偏导，得到$w$ 更新梯度\n$\\frac{\\partial L}{\\partial w_j} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})x_j^{(i)}$\n\n对 $b$ 偏导，得到$b$ 更新梯度\n$\\frac{\\partial L}{\\partial b} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})$\n\n## 数据加载\n\n\n```python\nfrom sklearn.datasets import load_boston\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n\n```python\ndata = load_boston()\nX_ = data['data']\ny = data['target']\nprint(type(data), type(X_), type(y))\nprint('data keys:', data.keys())\nprint('X_.shape:', X_.shape)\nprint('y.shape:', y.shape)\n```\n\n    <class 'sklearn.utils.Bunch'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n    data keys: dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n    X_.shape: (506, 13)\n    y.shape: (506,)\n    \n\n## 数据规范化\n\n\n```python\n# 转化为标准正态分布\nX_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis = 0)\ny = y.reshape(-1,1) # reshape转化为vector\nprint(X_.shape)\nprint(y.shape)\n```\n\n    (506, 13)\n    (506, 1)\n    \n\n## 建立激活函数\n\n\n```python\ndef sigmoid(x):\n    r = 1 / (1 + np.exp(-x))\n    return r\nnums = np.arange(-10, 10, step = 1)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(nums, sigmoid(nums), c='red')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x1a73d60cd88>]\n\n\n\n\n![png](output_21_1.png)\n\n\n\n```python\ndef relu(x):\n    return (x > 0) * x\nfig, ax = plt.subplots(figsize = (10, 4))\nnums = np.arange(-10, 10, step = 1)\nax.plot(nums, relu(nums), c = 'blue')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x1a73d659108>]\n\n\n\n\n![png](output_22_1.png)\n\n\n## 定义模型\n\n线性模型：$y = wx + b $\n\n\n```python\ndef Linear(x, w, b):\n    y_pre = x.dot(w) + b\n    return y_pre\n```\n\n**在计算损失时，需要把每个样本的损失都考虑到，所以我们需要对单个样本的损失函数进行求和，并除以样本总数N。**\n\n\n```python\ndef MSE_loss(y_pre, y):\n    loss = np.mean(np.square(y_pre - y))\n    return loss\n```\n\n\n```python\ndef gradient(x, y_pre, y):\n    n = x.shape[0]\n    grad_w = x.T.dot(y_pre - y)/n\n    grad_b = np.mean(y_pre - y)\n    return grad_w, grad_b\n    \n```\n\n\n```python\n# 初始化网络\nn = X_.shape[0] # 样本数量506\nn_features = X_.shape[1] #特征数量13\n\n# 初始化网络参数\n# randn从标准正态分布中返回一个或多个样本值\nW = np.random.randn(n_features, 1)\nb = np.zeros(1)\n\n#设定学习率\nlearning_rate = 1e-2\n\n#训练次数\nepoch = 10000\n```\n\n## 训练(不加激活函数)\n\n\n```python\nlosses = []\n# 训练 \nfor t in range(epoch):\n    # 向前传播\n    y_pred = Linear(X_, W, b)\n    # 计算损失函数\n    loss = MSE_loss(y_pred,y)\n    losses.append(loss)\n    grad_w, grad_b = gradient(X_, y_pred, y)\n    \n    #权重更新\n    W = W - grad_w * learning_rate\n    b = b - grad_b * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x1a73d6bb0c8>]\n\n\n\n\n![png](output_31_1.png)\n\n\n\n```python\nn_hidden = 10 #设计隐藏神经元个数（可修改）\nW1 = np.random.randn(n_features, n_hidden)  # 维度 n_features * n_hidden\nb1 = np.zeros(n_hidden)                     # 维度 1 * n_hidden\nW2 = np.random.randn(n_hidden, 1)           # 维度 n_hidden * 1\nb2 = np.zeros(1)                            # 维度1\n```\n\n## 训练(加激活函数)\n\n\n```python\n# 训练\nlosses = []\nfor t in range(epoch):\n    #向前传播\n    y_pred1 = Linear(X_, W1, b1)     # 维度 n * n_hidden\n    y_relu = relu(y_pred1)           # 维度 n * n_hidden\n    y_pred = Linear(y_relu, W2, b2) # 维度 n * 1\n    \n    #计算损失函数\n    loss = MSE_loss(y_pred, y)\n    losses.append(loss)\n    \n    #反向传播，求梯度\n    grad_y_pred = y_pred - y                 # 维度n*1\n    grad_w2 = y_relu.T.dot(grad_y_pred) / n  # 维度n_hidden*1\n    grad_b2 = np.mean(grad_y_pred, axis = 0) # 维度1*1\n    grad_relu = grad_y_pred.dot(W2.T)        # 维度n*n_hidden\n    #注意：y_pred1与relu直接相关\n    grad_relu[y_pred1 < 0] = 0\n    grad_w1 = X_.T.dot(grad_relu) / n        # 维度n_features* n_hidden\n    grad_b1 = np.mean(grad_relu, axis = 0)   # 维度n_hidden*1\n    \n    #更新梯度\n    W1 = W1 - grad_w1 * learning_rate\n    b1 = b1 - grad_b1 * learning_rate\n    W2 = W2 - grad_w2 * learning_rate\n    b2 = b2 - grad_b2 * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x1a73d71e448>]\n\n\n\n\n![png](output_34_1.png)\n\n\n参考文档\n\n[波士顿房价数据集解读](https://blog.csdn.net/appleyuchi/article/details/84998894)\n"},{"title":"使用numpy实现线性模型预测boston房价","url":"/2020/07/16/使用numpy实现线性模型预测boston房价/","content":"\n\n## 知识储备\n\n### Scikit-learn\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。其优点为：\n- 简单高效的数据挖掘和数据分析工具\n- 让每个人能够在复杂环境中重复使用\n- 建立NumPy、Scipy、MatPlotLib之上\n\n安装方法 pip install scikit-learn\n\n### boston房价数据解读\n\n使用sklearn.datasets.load_boston即可加载相关数据。该数据集是一个回归问题。每个类的观察值数量是均等的，共有506个观察，13个输入变量和1个输出变量。每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等，具体如下：\n- CRIM：城镇人均犯罪率。\n- ZN：住宅用地超过 25000 sq.ft. 的比例。\n- INDUS：城镇非零售商用土地的比例。\n- CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n- NOX：一氧化氮浓度。\n- RM：住宅平均房间数。\n- AGE：1940 年之前建成的自用房屋比例。\n- DIS：到波士顿五个中心区域的加权距离。\n- RAD：辐射性公路的接近指数。\n- TAX：每 10000 美元的全值财产税率。\n- PTRATIO：城镇师生比例。\n- B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n- LSTAT：人口中地位低下者的比例。\n- MEDV：自住房的平均房价，以千美元计。\n- 预测平均值的基准性能的均方根误差（RMSE）是约 9.21 千美元。\n\n### 标准差公式\n\n如x1,x2,x3...xn的平均数为M，则方差可表示为：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125539.png)\n\n样本标准差=方差的算术平方根=s=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/(n-1) )  \n总体标准差=σ=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/n )  \n如是总体，标准差公式根号内除以n  \n如是样本，标准差公式根号内除以（n-1)。  \n因为我们大量接触的是样本，所以普遍使用根号内除以（n-1)。  \n\n\n```python\na=np.array([[1,2,3],[4,5,6]])\nnp.mean(a,axis=1)\n```\n\n\n\n\n    array([2., 5.])\n\n\n\n\n```python\n# axis = 1表示行，ddof = 1是除以n-1\nnp.std(a, axis = 1,ddof = 1) \n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\n# ddof默认为0,是除以n\nnp.std(a, axis = 1) \n```\n\n\n\n\n    array([0.81649658, 0.81649658])\n\n\n\n\n```python\n# 求所有数平均值\nnp.mean(a)\n```\n\n\n\n\n    3.5\n\n\n\n### Linear及MSE_loss求导公式\n\n损失函数\n$L = \\frac{1}{2N}\\sum_{i=1}^{N}(z^{i} - y^{i})^{2} $\n\n线性函数\n$z^i = \\sum_{j=0}^{N}x_j^{(i)}w^{(j)} + b^{(j)}$\n\n对 $w$ 偏导，得到$w$ 更新梯度\n$\\frac{\\partial L}{\\partial w_j} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})x_j^{(i)}$\n\n对 $b$ 偏导，得到$b$ 更新梯度\n$\\frac{\\partial L}{\\partial b} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})$\n\n## 数据加载\n\n\n```python\nfrom sklearn.datasets import load_boston\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n\n```python\ndata = load_boston()\nX_ = data['data']\ny = data['target']\nprint(type(data), type(X_), type(y))\nprint('data keys:', data.keys())\nprint('X_.shape:', X_.shape)\nprint('y.shape:', y.shape)\n```\n\n    <class 'sklearn.utils.Bunch'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n    data keys: dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n    X_.shape: (506, 13)\n    y.shape: (506,)\n    \n\n## 数据规范化\n\n\n```python\n# 转化为标准正态分布\nX_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis = 0)\ny = y.reshape(-1,1) # reshape转化为vector\nprint(X_.shape)\nprint(y.shape)\n```\n\n    (506, 13)\n    (506, 1)\n    \n\n## 建立激活函数\n\n\n```python\ndef sigmoid(x):\n    r = 1 / (1 + np.exp(-x))\n    return r\nnums = np.arange(-10, 10, step = 1)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(nums, sigmoid(nums), c='red')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125621.png)\n\n\n```python\ndef relu(x):\n    return (x > 0) * x\nfig, ax = plt.subplots(figsize = (10, 4))\nnums = np.arange(-10, 10, step = 1)\nax.plot(nums, relu(nums), c = 'blue')\n```\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125708.png)\n\n\n## 定义模型\n\n线性模型：$y = wx + b $\n\n\n```python\ndef Linear(x, w, b):\n    y_pre = x.dot(w) + b\n    return y_pre\n```\n\n**在计算损失时，需要把每个样本的损失都考虑到，所以我们需要对单个样本的损失函数进行求和，并除以样本总数N。**\n\n\n```python\ndef MSE_loss(y_pre, y):\n    loss = np.mean(np.square(y_pre - y))\n    return loss\n```\n\n\n```python\ndef gradient(x, y_pre, y):\n    n = x.shape[0]\n    grad_w = x.T.dot(y_pre - y)/n\n    grad_b = np.mean(y_pre - y)\n    return grad_w, grad_b\n    \n```\n\n\n```python\n# 初始化网络\nn = X_.shape[0] # 样本数量506\nn_features = X_.shape[1] #特征数量13\n\n# 初始化网络参数\n# randn从标准正态分布中返回一个或多个样本值\nW = np.random.randn(n_features, 1)\nb = np.zeros(1)\n\n#设定学习率\nlearning_rate = 1e-2\n\n#训练次数\nepoch = 10000\n```\n\n## 训练(不加激活函数)\n\n\n```python\nlosses = []\n# 训练 \nfor t in range(epoch):\n    # 向前传播\n    y_pred = Linear(X_, W, b)\n    # 计算损失函数\n    loss = MSE_loss(y_pred,y)\n    losses.append(loss)\n    grad_w, grad_b = gradient(X_, y_pred, y)\n    \n    #权重更新\n    W = W - grad_w * learning_rate\n    b = b - grad_b * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125735.png)\n\n\n```python\nn_hidden = 10 #设计隐藏神经元个数（可修改）\nW1 = np.random.randn(n_features, n_hidden)  # 维度 n_features * n_hidden\nb1 = np.zeros(n_hidden)                     # 维度 1 * n_hidden\nW2 = np.random.randn(n_hidden, 1)           # 维度 n_hidden * 1\nb2 = np.zeros(1)                            # 维度1\n```\n\n## 训练(加激活函数)\n\n\n```python\n# 训练\nlosses = []\nfor t in range(epoch):\n    #向前传播\n    y_pred1 = Linear(X_, W1, b1)     # 维度 n * n_hidden\n    y_relu = relu(y_pred1)           # 维度 n * n_hidden\n    y_pred = Linear(y_relu, W2, b2) # 维度 n * 1\n    \n    #计算损失函数\n    loss = MSE_loss(y_pred, y)\n    losses.append(loss)\n    \n    #反向传播，求梯度\n    grad_y_pred = y_pred - y                 # 维度n*1\n    grad_w2 = y_relu.T.dot(grad_y_pred) / n  # 维度n_hidden*1\n    grad_b2 = np.mean(grad_y_pred, axis = 0) # 维度1*1\n    grad_relu = grad_y_pred.dot(W2.T)        # 维度n*n_hidden\n    #注意：y_pred1与relu直接相关\n    grad_relu[y_pred1 < 0] = 0\n    grad_w1 = X_.T.dot(grad_relu) / n        # 维度n_features* n_hidden\n    grad_b1 = np.mean(grad_relu, axis = 0)   # 维度n_hidden*1\n    \n    #更新梯度\n    W1 = W1 - grad_w1 * learning_rate\n    b1 = b1 - grad_b1 * learning_rate\n    W2 = W2 - grad_w2 * learning_rate\n    b2 = b2 - grad_b2 * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125832.png)\n\n参考文档\n\n[波士顿房价数据集解读](https://blog.csdn.net/appleyuchi/article/details/84998894)\n","tags":["numpy","线性回归"],"categories":["project实战"]},{"title":"特征图大小的计算方式","url":"/2020/07/15/featureMapCompute/","content":"\n\n卷积中的特征图大小计算方式有两种，分别是‘VALID’和‘SAME’，**卷积和池化都适用，卷积除不尽的结果都向下取整，池化除不尽的结果都向上取整。**\n<!-- more -->\n\n## VALID和SAME理解\n1、如果计算方式采用'VALID'，则：\n$$W_{out} = \\frac{ W_{in}-K}{stride} + 1$$\n\n其中，$W_{out}$为输出特征图的大小，$W_{in}$为输入特征图的大小，K为卷积核大小，stride为卷积步长。\n\n\n2、如果计算方式采用'SAME'，则输出特征图的大小与输入特征图的大小保持不变：\n$$W_{out} = \\frac{ W_{in}+2*padding-K}{stride} + 1$$\n\n其中，padding为特征图填充的圈数\n\n若采用'SAME'方式，kernel_size=1时，padding=0；kernel_size=3时，padding=1；kernel_size=5时，padding=3，以此类推，可以保持输出特征图的大小与输入特征图的大小保持不变。\n\n对于tensorflow,paading只能指定为`one of \"valid\" or \"same\"`，但是对于pytorch，padding只能指定为整数，默认为0\n\n## 例题解析\n\n输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为：97\n\n解析：\n\n$$输出尺寸 = \\frac{ 输入尺寸-filter尺寸+2*padding}{stride} + 1\n$$\n\n一层卷积：\n\n$$输出尺寸 = \\frac{ 200-5+2*1}{2} + 1 = 向下取整(99.5)=99\n$$\n\n池化：\n\n$$输出尺寸 = \\frac{ 99-3+2*0}{1} + 1 = 97\n$$\n\n二层卷积：\n\n$$输出尺寸 = \\frac{ 97-3+2*1}{1} + 1 = 97\n$$\n\n计算尺寸不被整除只在GoogLeNet中遇到过。**卷积向下取整，池化向上取整**。\n\n\n参考文档\n[特征图大小的计算](https://www.cnblogs.com/tianqizhi/p/9706344.html)  \n\n\n> 特别声明：本文摘自[https://www.cnblogs.com/tianqizhi/p/9706344.html](特征图大小的计算),只做个人学习交流和参考手册使用，不作任何商业目的\n\n\n\n","tags":["featureMap","卷积","池化"],"categories":["深度学习"]},{"title":"奥卡姆剃刀","url":"/2020/07/15/motto/","content":"任何一件事情，都要从简单的开始做起，若无必要，勿增实体！\n\n![img](https://gitee.com/wxler/blogimg/raw/master/imgs/20200715105539.jpg)\n","categories":["Life"]},{"title":"git基本使用方法","url":"/2020/06/17/gitUseMethod/","content":"由于平时写代码和博客常常用到git和github，每次用到都去百度，感觉太麻烦了，也大大降低了效率，索性自己整理一下常用到的git指令和使用方法，对git的使用能有一个系统的认识。这里只介绍一下基本用法，对更高级的用法如果以后用到再进行补充。\n<!-- more -->\n\n## git安装和配置\ngit的安装和配置在我的这篇[搭建个人博客](https://wxler.github.io/2020/06/01/hexoCreateAndConfig/#%E5%AE%89%E8%A3%85git)里，请自行参考配置，主要有一下几点：\n- 下载安装git程序\n- 配置github账户\n- 配置SSH KEY\n## git工作原理\nGit是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。Git在执行更新操作时，更像是对数据的一组快照，每次你提交更新，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git不再重新存储该文件，而是只保留一个链接指向之前存储的文件。  \n![upload successful](/images/pasted-22.png)  \n如上图所示，在version2中的B即是因为File B没有改变，所以直接存储了一个指向FileB的链接。只有修改了的文件才会产生一个新的文件，覆盖原来的文件。\ngit的工作原理/流程如下:  \n![upload successful](/images/pasted-21.png)  \n- Workspace：工作区(本地目录文件)\n- Index / Stage：暂存区/缓存区\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n## 基本操作\n### 初始化仓库\n仓库的初始化有两种方式：一种是直接从远程仓库克隆，另一种则是直接从当前目录初始化。远程初始化命令在[从远程仓库获取](#从远程仓库获取)，本地初始化命令的方法是首先创建一个文件夹，我命名为mygit，然后执行如下命令：  \n```bash\n$ git init\n```\n执行完毕后，当前目录下会出现一个隐藏的.git文件夹，git所需的数据和资源都放在改目录中。\n\n### 查看仓库状态\n通过`git status`来查看仓库状态，执行效果如下：  \n![upload successful](/images/pasted-24.png)  \n可以看到nothing to commit，表示本地工作区没有要提交的文件，我们再创建一个one.txt的文件，然后在执行`git status`，效果如下： \n![upload successful](/images/pasted-25.png)  \n从结果Untracked files可以看到，one.txt还没有被add到暂存区。\n\n### 添加文件到暂存区\n`git add`命令可以将一个文件添加到暂存区,执行如下命令将one.txt添加到暂存区：\n```bash\ngit add one.txt\n```\n将one.txt添加到暂存区后，再次执行`git status`,可看到如下效果：  ![upload successful](/images/pasted-26.png)  \n从Changes to be committed可以看出，one.txt已被添加到暂存区，但还未被添加到本地仓库。\n\n### 提交到本地仓库\n当文件提交到暂存区之后，执行`git commit`命令将当前暂存区的文件提交到本地仓库，执行如下命令：\n```bash\ngit commit -m '新增一个one.txt'\n```\n-m是指将当前暂存区的文件提交到本地仓库的时候，加上提交备注/说明，再次执行`git status`,可以看到已经没有要add或commit的文件了。这里要强调一下，如果直接执行`git commit`命令，会自动打开一个vi编辑器，在里面输入备注/说明即可。此外，当我们提交成功后，还可以通过`git commit --amend  `修改备注信息。\n### 查看更改前后的差异\n使用`git diff`命令可以查看**工作区和暂存区的区别**，在one.txt里面写入一行hello world，然后执行`git diff`命令，结果如下：  \n![upload successful](/images/pasted-27.png)  \n根据结果可以看到新增了一行hello world，如果我们要比较**工作区与最新本地版本库的区别**，可以执行`git diff HEAD`，结果如下：  \n![upload successful](/images/pasted-30.png)  \n\n### 查看提交历史\n使用`git log`查看提交历史，我们首先将工作区的内容提交到本地仓库，执行`git add one.txt`将更改后的one.txt添加到暂存区，执行` git commit -m '添加了一行hello world'`将暂存区的内容提交到本地仓库，然后执行`git log`，结果如下：  \n![upload successful](/images/pasted-29.png)  \n\n## git撤销修改\n### 工作区的代码撤销\n使用`git checkout`撤销工作区的代码。我们先向one.txt添加一行hello everyone，执行`cat one.txt`查看内容，再执行`git checkout -- one.txt`撤销之前的操作，让one,txt恢复之前的状态，然后执行`cat one.txt`再次查看内容，效果如下：  \n![upload successful](/images/pasted-31.png)  \n可以看到，工作区的内容已经被修改,这时候本地文件刚刚添加的内容就被撤销了。\n### 暂存区的代码撤销\n使用`git reset HEAD`撤销暂存区的代码。首先在one.txt添加一行hello people，执行`git add one.txt`将更改的内容提交到暂存区，`git reset HEAD`来撤销暂存区的代码，如下图：  \n![upload successful](/images/pasted-32.png)  \n撤销暂存区的代码之后，如需要将代码添加到暂存区，则需要再次执行`git add`命令\n### 本地仓库的代码撤销\n可以使用`git reset --hard <版本号>`来撤销本地仓库的代码，版本号有几种不同的写法：\n1. 可以使用HEAD^来描述版本，一个^表示前一个版本，两个^^表示前两个版本，以此类推。\n2. 也可以使用数字来代替^，比如说前100个版本可以写作HEAD~100。\n3. 也可以直接写版本号，表示跳转到某一个版本处。我们每次提交成功后，都会生成一个哈希码作为版本号，所以这里我们也可以直接填版本号，哈希码很长，但是我们不用全部输入，只需要输入前面几个字符即可，就能识别出来。执行`git log`后那一串长符号就是哈希码版本号。\n\n依次执行如下命令：\n```bash\n$ git add 'one.txt'\n$ git commit -m '添加一行hello people'\n$ git reset --hard head^\n```\n执行`git reset --hard head^`后的效果如下：\n![upload successful](/images/pasted-36.png)  \n可以从结果看出，前半部分816b208是执行撤销操作以后，当前版本的版本号前七位，后半部分是该版本的备注，可以用`git log`来查看不同版本的版本号和备注。  \n\n再次查看本地one.txt文件，发现本地目录的刚刚添加的内容已经没有了，如需要再次提交到本地仓库，则可执行`git add`和`git commit`命令。**需要注意的是，当撤销到最开始版本的时候，`git reset --hard head^`就不能再用了，否则会报如下的错误：**  \n![upload successful](/images/pasted-37.png)  \n\n## git分支管理\n### 查看分支\n通过`git branch`来查看当前仓库有哪些分支和我们处于哪一分支中，如下所示：  \n![upload successful](/images/pasted-33.png)  \n可以看到，当前本地仓库只有一个master分支，这是git默认创建出来的，master前面的\\*表示我们当前处于这一个分支中。\n### 分支创建和切换\n可以利用`git branch <分支名>`来创建一个分支，利用`git checkout <分支名>`来切换分支，如下所示： \n![upload successful](/images/pasted-34.png)  \n### 分支合并\n由于math分支是从master分支中创建出来的，所以此时math分支的内容和master分支的内容是一致的，现在，我们在math分支向one.txt添加一行hello branch math(由于刚刚执行了[本地仓库的代码撤销](#本地仓库的代码撤销)，所以one.txt现在的内容是空白的)，此时math分支的one.txt和math分支的one.txt就不同了，具体效果如下：  \n![upload successful](/images/pasted-35.png)  \n执行完毕后，我们也可以在本地查看，先在math分支下，打开one.txt可以看到我们刚刚添加的内容，然后再切换到master分支，再从本地打开one.txt文件，就看不到内容了。\n**可以通过`git merge <分支名>`合并分支**，先切换到master分支，然后执行` git merge math`合并math分支到master分支上，效果如下：  \n![upload successful](/images/pasted-39.png)  \n可以看到再次在master分支下查看one.txt，就可以显示math分支的内容了。\n\n通常合并分支时，git一般使用”Fast forward”模式，fast-forward方式表示当条件允许时，git直接把HEAD指针指向合并分支的头，完成合并，这种方式合并速度快，但是在整个过程中没有创建commit。在这种模式下，删除分支后，会丢掉分支信息，可使用带参数 `–no-ff`来禁用”Fast forward”模式，即删除时可以实用`git merge --no-ff <分支名>`\n\n### 以图表方式查看分支\n可以用`git log --graph`命令来直观的查看分支的创建和合并等操作，合并math和master分支前的效果如下： \n![upload successful](/images/pasted-38.png)    \n合并math和master分支后的效果如下：   \n![upload successful](/images/pasted-40.png)  \n\n### 解决冲突\n我们创建一个新的分支dev,并在dev分支下给one.txt添加一行12345，然后提交，如下所示：  \n![upload successful](/images/pasted-41.png)   \n同样，我们现在切换到master分支上来，也在one.txt添加一行内容，内容为56789，并提交，如下所示：  \n![upload successful](/images/pasted-42.png)  \n现在，我们将dev分支合并到master上来，如下所示：\n![upload successful](/images/pasted-43.png)  \n从结果中可以看出，=======之前是主分支的内容，=======之后是dev分支的内容，此时我们用文本编辑器修改one.txt的冲突然后提交即可，如下所示：  \n![upload successful](/images/pasted-44.png)  \n\n**分支策略：首先master主分支应该是非常稳定的，也就是用来发布新版本，一般情况下不允许在上面干活，干活一般情况下在新建的dev分支上干活，干完后，dev分支代码可以合并到主分支master上来。**\n\n## github远程仓库\n### 关联远程仓库\n在此之前我相信你已经配置SSH KEY，如果没有，可以参考我的这篇[搭建个人博客](https://wxler.gitee.io/2020/06/01/hexoCreateAndConfig/#git%E9%85%8D%E7%BD%AE)里进行配置，配置完成以后在github上创建一个仓库，这里命名为test，我们可以看到仓库的地址，例如：`https://github.com/wxler/test.git`。然后将我们之前的本地仓库和这个远程仓库进行关联，使用`git remote add`命令，如下：\n```bash\n$ git remote add origin https://github.com/wxler/test.git\n```\n### 推送到远程仓库\n把本地库的内容推送到远程，使用`git push -u origin master`命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了–u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令,不用加-u了,效果如下：  \n![upload successful](/images/pasted-45.png)  \n推送成功后，可以立刻在github页面中看到远程库的内容已经和本地一模一样了。从现在起，只要本地作了提交，就可以通过命令：`git push origin master`把本地master分支的最新修改推送到github上了，现在你就拥有了真正的分布式版本库了。  \n**我们一般不把其它分支推送到远程仓库，master主分支是最稳定的版本，一般情况下不允许在上面干活，干活一般情况下在新建的分支上干活，干完后，把分支代码可以合并到主分支master上来。**当然，你也可以将其它分支推送到远程仓库，可以执行如下命令：\n```bash\n$ git checkout fa\n$ git push -u origin fa\n```\n### 从远程仓库获取\n我们可以通过git clone命令克隆一个远程仓库到本地,方式也简单，在本地创建一个空文件夹，执行如下命令：\n```bash\n$ git clone https://github.com/wxler/test.git\n```\n此时克隆的是master分支到本地仓库，我们可以通过`git branch -a`来查看本地仓库和远程仓库的信息，-a参数可以同时显示本地仓库和远程仓库的信息，如下：  \n![upload successful](/images/pasted-46.png)  \n我们也可以把远程仓库其它分支的内容clone下来，可以执行如下命令：\n```bash\n$ git branch fa origin/dev\n$ git checkout dev\n```\n上面的指令表示根据远程仓库的dev分支创建一个本地仓库的dev分支，然后再切换到dev分支，**注意由于dev分支就是从远程仓库克隆下来的，所以这里可以不添加-u参数。**\n\n### 从远程仓库更新\n使用`git pull`获取远程仓库最新的代码和数据，例如，我们可以通过以下代码将远程主机的master分支最新内容拉下来后与当前本地分支直接合并\n```bash\ngit pull origin master\n```\n\n## git命令大全\ngit常用命令速查表，方便查阅：  \n![upload successful](/images/pasted-47.png)\n\n## 遗留问题\n到现在，我们就可以使用git的大多数操作了，但是还有git的一些操作平常没有用到，我也就不主动去一个个试了，毕竟一口吃不成胖子，查了也记不住，就不自找苦吃了，遗留的问题主要有：\n- git分支衍合\n- git标签管理\n- bug分支&stash功能\n\n## 参考文档\n[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)\n[Git从入门到熟练使用](https://www.jianshu.com/p/34cfe097e06a)\n[史上最简单Git入门教程](https://www.cnblogs.com/jjlee/p/10305194.html)\n[git命令大全](https://www.jianshu.com/p/46ffff059092)\n\n>特别声明：本篇博客只做个人学习交流和参考手册使用，不作任何商业目的，内容上较多参考了[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)，根据自己实际应用进行删减，并加上了自己的理解和补充，如有侵权，请联系博主本人删除。","tags":["git"],"categories":["git使用"]},{"title":"使用hexo平台从0搭建个人博客","url":"/2020/06/01/hexoCreateAndConfig/","content":"搭建这个博客，花费了我不少时间，这期间我遇到各种各样的问题，这些问题本可以避免，因操作不规范、对指令代码的不理解、网络不稳定、配置上的错误，使得最后暴露出来的各种bug很不容易解决。前前后后我也重新搭建了三次，经历了心态上的各种起伏。为此，我记录下我制作的过程，让想和我一样自建博客的人少走一些弯路。\n\n我使用的hexo博客框架，stun主题，搭建环境和过程可分为几个部分:\n\n1. 安装git\n2. 安装nodejs\n3. 安装hexo\n4. hexo搭桥github\n5. hexo-admin使用\n6. npm&hexo常用命令\n<!-- more -->\n\n## 安装git\n\n### git下载\n下载[git](https://git-scm.com/download)，双击安装，然后一直next，按键Ctrl+r，然后在弹出框中出入cmd，在弹出的界面输入git，回车,出来一大串命令符就代表安装成功了。可以使用git version查看自己的git版本。\n\n### git配置\n\n1. git安装好去GitHub上注册一个账号，注册好后，桌面空白地方右键选择Git Bash，要git账户进行环境配置  \n```bash\n//usename是用户名\ngit config --global user.name \"username\"\ngit config --global user.email \"username@email.com\"\n```\n2. 当以上命令执行结束后，可用 `git config --global --list` 命令查看配置是否OK  \n![upload successful](/images/pasted-8.png?show=inline)\n3. 在命令框中输入命令`ssh-keygen -t rsa`，连敲三次回车键，结束后去系统盘目录下（一般在 C:\\Users\\你的用户名.ssh）(mac: /Users/用户/.ssh）查看是否有。ssh文件夹生成，此文件夹中以下两个文件  \n![upload successful](/images/pasted-9.png?show=inline)\n4. 将ssh文件夹中的公钥（ id_rsa.pub）添加到GitHub管理平台中，在GitHub的个人账户的设置中找到如下界面，title随便起一个，将公钥（ id_rsa.pub）文件中内容复制粘贴到key中，然后点击Ass SSH key  \n![upload successful](/images/pasted-10.png?show=inline)\n5、测试一下配置是否成功，在Git Bush命令框（就是刚才配置账号和邮箱的命令框）中继续输入命令`ssh -T git@github.com`，回车,出现如下界面即说明成功  \n![upload successful](/images/pasted-11.png?show=inline)\n\n## 安装nodejs\nHexo是基于nodeJS环境的静态博客，里面的npm工具很有用。下载[nodejs](https://nodejs.org/en/)，(说明：LTS为长期支持版，Current为当前最新版)，下载后一路next进行安装，在git bash下使用node -v查看版本。\n\n## 安装hexo\n我建议先看一下npm&hexo常用命令部分，了解命令的结构和大体含义之后，在配置的过程中可以避免很多错误，少走很多弯路。  \n执行 `npm config list`查看当前的配置，如下所示：  \n![upload successful](/images/pasted-12.png?show=inline)\n可以看到，最初的镜像地址是官方的npm镜像，我最初使用的就是这个配置，执行起来很不稳定，导致大多数错误都是网络问题导致的,执行如下命令,切换淘宝镜像\n```bash\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\nnpm config set registry https://registry.npm.taobao.org\n```\n接下来，就可以安装hexo了，执行`npm install -g hexo-cli`或`npm install -g hexo`，如果之前安装失败，可以先执行`npm uninstall hexo-cli -g`或`npm uninstall hexo -g` 卸载hexo，再进行安装，结果如下：  \n![upload successful](/images/pasted-14.png?show=inline)\n查看版本信息` hexo v`  \n![upload successful](/images/pasted-16.png?show=inline)\n初始化hexo,执行 `hexo init myblog`，然后`cd myblog`，再次执行`hexo v`，就可以看到hexo的版本：  \n![upload successful](/images/pasted-18.png?show=inline)  \n打开myblog文件夹，我们可以看到hexo的结构\n> * node_modules：是依赖包\n> * public：存放的是生成的页面\n> * scaffolds：命令生成文章等的模板\n> * source：用命令创建的各种文章\n> * themes：主题\n> * _config.yml：整个博客的配置\n> * db.json：source解析所得到的\n> * package.json：项目所需模块项目的配置信息  \n\n\n到这里我们的hexo博客就安装完成啦，只有搭桥到github,才能进行部署。\n\n\n## hexo搭桥github\n创建一个repo，名称为yourname.github.io,其中yourname是你的github名称，按照这个规则创建才有用，这个仓库就是存放你博客的地方。\n1. 用编辑器打开你的blog项目，修改_config.yml  \n```text\ndeploy:  \n\ttype: git\n\trepo:https://github.com/YourgithubName/YourgithubName.github.io.git\n\tbranch: master\n```\n2. 回到gitbash中，进入你的blog目录，分别执行以下命令：\n```bash\nhexo clean\nhexo generate\nhexo server\n```\n需要注意的是，hexo 3.0把服务器独立成个别模块，需要单独安装：`npm i hexo-server`\n3. 打开浏览器输入：`http://localhost:4000`\n4. 先安装一波：`npm install hexo-deployer-git --save`（这样才能将你写好的文章部署到github服务器上并让别人浏览到） \n5. 执行命令\n```bash\nhexo clean\nhexo generate\nhexo deploy\n```\n6. 在浏览器中输入`http://yourgithubname.github.io`就可以看到你的个人博客啦。\n\n我使用的主题是stun，如果大家也想使用这个主题，可以到[ hexo-theme-stun](https://liuyib.github.io/hexo-theme-stun/zh-CN/)查阅配置。\n\n\n## hexo-admin使用\n\n\n用原生的方法来管理博文十分的不便，因此便有了Hexo Admin这一插件来方便我们的操作。执行`npm install --save hexo-admin`安装hexo-admin，安装成功后，在`http://localhost:4000/admin`就可以访问hexo-admin页面。\n详细情形我就不多说了，推荐大家到[hexo博客使用hexo-admin插件管理文章](https://blog.csdn.net/nineya_com/article/details/103380243?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)，这位作者的[hexo-admin插件windows系统插入图片失败问题](https://blog.csdn.net/nineya_com/article/details/103384546)修复了windows下粘贴图片的裂图和显示功能，我使用起来非常好，推荐大家看看。\n\n除此之外，我还要强调一点，hexo-admin创建文章的时候，首先创建英文名，再在里面编辑成中文，这样你的文章显示的链接就不会带有中文了。hexo-admin的文章只有未发布状态才能删除，并且删除后在source/_discarded文件夹，未发布变成draft,发布直接到post。\n\n## npm&hexo常用命令\n### npm&cnpm介绍\nnpm（node package manager）：nodejs的包管理器，用于node插件管理（包括安装、卸载、管理依赖等），使用`npm -v`查看版本信息。\n\ncnpm:因为npm安装插件是从国外服务器下载，受网络的影响比较大，可能会出现异常，如果npm的服务器在中国就好了，所以我们乐于分享的淘宝团队干了这事。来自官网：“这是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步”，更多详情可以查看[淘宝 NPM 镜像](https://developer.aliyun.com/mirror/NPM?from=tnpm)，使用`cnpm -v`查看版本信息。\n\n\nnpm和cnpm安装命令一样，只不过是多了一个c。\n\n### npm命令\n使用npm命令首先要设置下载的镜像，模式是npm官网的镜像(服务器在国外)，建议设置国内的淘宝镜像,设置以后我们就可以用npm从淘宝镜像下载数据了  \n永久使用：  \n`npm config set registry https://registry.npm.taobao.org`  \n临时使用：  \n`npm install node-sass --registry=http://registry.npm.taobao.org`  \n还有个清除缓存命令，可以解决些奇怪的问题:  \n`npm cache clean --force`  \n查看已安装的npm插件，这个命令很实用，可以查看缺少哪些插件  \n`npm ls --depth 0`   \n可以通过定制的 cnpm 命令行工具代替默认的 npm  \n`npm install -g cnpm --registry=http://registry.npm.taobao.org`  \n**在使用过程中要么用npm，要么用cnpm，不能混用**  \n查看当前的配置命令`npm config list `,操作之前一定要先查看配置再进行操作。  \n**下面需要强调后缀参数的作用和区别**  \n`npm install packagename --save 或 -S`    \n--save、-S参数意思是把模块的版本信息保存到dependencies（生产环境依赖）中，即你的package.json文件的dependencies字段中。  \n`npm install packagename --save-dev 或 -D`  \n--save-dev 、 -D参数意思是吧模块版本信息保存到devDependencies（开发环境依赖）中，即你的package.json文件的devDependencies字段中。  \n`npm install packagename -g 或 --global`  \n安装全局的模块（不加参数的时候默认安装本地模块），\n**使用npm安装插件的时候一定要加上--save添加依赖，否则容易出错** ，更多关于npm详情，请点击[npm常用命令及参数详解](https://segmentfault.com/a/1190000012099112?utm_source=tag-newest)\n### hexo命令\n\n`hexo init`  \n初始化站点，生成一个简单网站所需的各种文件。\n\n`hexo clean == hexo c`  \n清除缓存 网页正常情况下可以忽略此条命令\n\n`hexo generate == hexo g`  \n生效新增、修改、更新的文件\n\n`hexo server == hexo s`  \n启动本地网站，可在本地观察网站效果\n\n`hexo s --debug`  \n以调试模式启动本地网站，在此模式下，对文件的更改无需停止网站只需刷新即可看到效果，调试非常方便\n\n\n`hexo clean && hexo s`  \n一次执行两个命令\n\n`hexo deploy == hexo d`  \nhexo的一键部署功能，执行此命令即可将网站发布到配置中的仓库地址，执行此命令前需要配置站点配置文件_config.yml","tags":["hexo"],"categories":["hexo博客平台搭建"]}]