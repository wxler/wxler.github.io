[{"title":"hexo设置permalink以比避免url中出现中文","url":"/2020/11/24/204707/","content":"\n当我把hexo的博客标题的时候，url中就会出现中文，很不雅观，这里我通过permalink设置博客链接！\n\n\n\n<!-- more -->\n\n\n\n## 第一步\n\n在_config.yml文件中修改permalink\n\n```bash\n# permalink: :year/:month/:day/:title/ 这是之前的设置\npermalink: :year/:month/:day/:id/\npermalink_defaults:\n```\n\n## 第二步\n\n第一步的`:id`是自己添加的，因此需要在`scaffolds/post.md`中添加id，如下:\n\n```bash\ntitle: {{ title }}\nid: \ndate: {{ date }}\ncategories: Life  #文章分类\ntags: [tag1,tag2]  #文章标签，多标签时使用英文逗号隔开\n```\n\n我一般是把id设置为时分秒，如现在是`20:47:07`，我将id设置为`204707`\n\n\n\n\n\n参考文档\n\n[hexo设置permalink-避免url中出现中文](https://blog.csdn.net/weixin_30394669/article/details/97839708)  ","tags":["hexo"],"categories":["工具"]},{"title":"Anaconda中离线升级jupyterlab并为jupyterlab安装插件","url":"/2020/11/24/194523/","content":"\n## Anaconda中升级jupyterlab\n\n我之前尝试了如下两种方法，升级失败：\n\n- `conda update -c conda-forge jupyterlab`\n- 在Anaconda Navigator 界面升级\n\n后来直接在[anaconda官网](https://anaconda.org/)下载jupyterlab的安装文件，然后执行`conda install 文件名`就安装成功了。\n<!-- more -->\n\n\n\n\n首先，在[anaconda官网](https://anaconda.org/)下载文件时，在搜索栏输入jupyterlab，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706193847540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n然后点击文件名，进如下页面，再点击Files就可以下载文件\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706194046685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n最后，打开Anaconda Powershell Prompt（如果配置了环境变量，直接打开cmd也可以），`cd 文件所在目录`，执行`conda install 文件名`就成功啦。比如我下载的是jupyterlab-2.1.5-py_0.tar.bz2，执行`conda install jupyterlab-2.1.5-py_0.tar.bz2`即可，**安装成功后，会默认覆盖Anaconda自带的jupyterlab，所以就意味着升级了jupyterlab**，安装jupyterlab之后，并不能在shell命令窗口直接输入jupyterlab直接启动，但是可以在Anaconda Navigator界面启动。如果想要在shell窗口启动，则需要配置conda环境变量。\n\n**这个安装方法其实算是一类离线安装方法，无法通过命令安装的anaconda插件，都可以在[anaconda官网](https://anaconda.org/)下载之后离线安装**\n\n## 升级jupyterlab插件出现问题\n升级之和，之前在低版本jupyterlab下安装的一部分插件就可能过时，在Anaconda Powershell Prompt执行`jupyter labextension list`就可以查看插件的情况，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706195338601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n遇见过时的插件，可以执行`jupyter labextensio update 插件名`或`jupyter labextension update --all`来更新插件，但是我尝试了之后，没有一个插件能够更新成功，索性就执行`jupyter labextensio uninstall 插件名`把过时的插件都卸载了，然后执行`jupyter labextensio install 插件名`安装需要的插件即可，比如我要安装jupyter的目录插件，可以执行：\n\n```powershell\njupyter labextension install @jupyterlab/toc\n或者\njupyter labextension install https://github.com/jupyterlab/jupyterlab-toc.git\n```\n\n## conda&jupyterlab插件相关命令\n### conda命令\n删除一个名为 mytest 的环境或库。-n为该环境或库的名字，--all 说明删除 mytest 环境下的所有内容，也就是这个环境被删除了：`conda remove -n mytest --all`\n\n删除一个库`conda remove 库名`,卸载一个库`conda uninstall 库名 --force`，根据帮助中的描述,这两个命令是一样的。假如如果你安装了tensorflow和numpy,想把numpy降级到另外一个版本。使用conda uninstall numpy会把tensorflow、pytorch等其他依赖numpy的库一起删除.此时加上conda uninstall numpy --force就仅卸载numpy了.一定要看看conda 的帮助.然后在安装需要的numpy版本。\n\n在不指定的情况下，conda install命令默认从 conda 官网 https://conda.anaconda.org/ 上下载。比如下面的，conda-forge 是一个用户，他上传了一个 opencv 的 python 库。opencv=3.2.0 指定了版本，不指定的情况下，下载最新版本：\n```powershell\nconda install -c conda-forge opencv=3.2.0\n```\n当然，你也可以使用 -c 参数，指定一个远程仓库，从这个仓库中下载：\n```powershell\nconda install -c https://conda.anaconda.org/menpo opencv3\n```\n\n### jupyterlab插件命令\n- 更新插件：`jupyter labextensio update 插件名`\n- 更新所有插件：`jupyter labextension update --all`\n- 卸载插件：`jupyter labextensio uninstall 插件名`\n- 安装插件：`jupyter labextensio install 插件名`\n- 远程仓库安装插件：`jupyter labextension install 参考地址`\n- 安装制定版本插件：`jupyter labextensio install 插件名=版本号`\n- 查看已安装插件：`jupyter labextension list`\n\n\n\n\n\n\n参考文档\n\n[附录C：conda相关命令](https://www.jianshu.com/p/b2b46dd6332b)","categories":["工具"]},{"title":"数据预处理：归一化/标准化详解","url":"/2020/11/24/192901/","content":"\n## 前言\n\n一般而言，样本的原始特征中的每一维特征由于来源以及度量单位不同，其特征取值的分布范围往往差异很大，比如身高、体重、血压等它们的度量和分布范围往往是不一样的。当我们计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。这样，**对于基于相似度比较的机器学习方法（比如最近邻分类器），必须先对样本进行预处理，将各个维度的特征归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理想的结果**。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但是会导致训练效率比较低。\n\n<!-- more -->\n\n\n\n\n\n## 归一化的必要性及价值\n现在假设一个只有一层的网络：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723211349432.png)\n我们知道，tanh 函数的导数在区间 [−2, 2] 上是敏感的，其余的导数接近于 0，tanh图像如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723211508510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n因此，如果 $w1x1 + w2x2 + b$ 过大或过小，都会导致梯度过小，难以训练。**为了提高训练效率，我们需要使$w1x1 + w2x2 + b$在 [−2, 2] 区间，我们需要将w1 设得小一点，比如在 [−0.1, 0.1] 之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数**。因此，如果每一个特征的取值范围都在相似的区间，比如 [0, 1] 或者 [−1, 1]，那该多好啊，我们就不太需要区别对待每一个参数，减少人工干预。\n\n>我们经常见到，归一化、标准化、规范化，其实他们的含义是一样的，都是消除数据量纲带来的差异，加快模型的训练效率\n\n除了参数初始化之外，不同输入特征的取值范围差异比较大时，梯度下降法的效率也会受到影响。下图给出了数据归一化对梯度的影响。其中，图a为未归一化数据的等高线图。**取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛**。如果我们把数据归一化为取值范围相同，如图b所示，大部分位置的梯度方向近似于最优搜索方向。这样，**在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高**。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723212620723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n## 归一化的方式\n归一化的方法有很多种，最常用的是最小最大归一化和标准归一化\n\n**最小最大归一化**使结果落到[0,1]区间，转换函数如下：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723213531858.png)\n\n*其中 min(x) 和 max(x) 分别是特征 x 在所有样本上的最小值和最大值。*\n\n**标准归一化**也叫 z-score 归一化，将每一个维特征都处理为符合标准正态分布（均值为 0，标准差为 1）。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723214316862.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*这里 σ 不能为 0。如果标准差为 0，说明这一维特征没有任务区分性，可以直接删掉。在标准归一化之后，每一维特征都服从标准正态分布。*\n\n## 总结\n\n总的来说，归一化的好处是：帮助你去除数据的量纲和数据大小的差异，让数据每一个特征的取值范围都在相似的区间，可以让数据在同一个数量级下来做一个比较。这样做可以让模型更快的收敛，因为它不需要去考虑那些夸大的特征，把所有特征的尺度看的同等重要\n\n参考文档\n神经网络与深度学习[邱锡鹏著]","categories":["数据预处理"]},{"title":"深入理解model.eval()与torch.no_grad()","url":"/2020/11/24/192512/","content":"\n我们用pytorch搭建神经网络经常见到model.eval()与torch.no_grad()，它们有什么区别？是怎么工作的呢？现在就让我们来探究其中的奥秘\n<!-- more -->\n\n## model.eval()\n\n- 使用model.eval()切换到测试模式，不会更新模型的k，b参数\n- 通知dropout层和batchnorm层在train和val中间进行切换\n在train模式，**dropout层会按照设定的参数p设置保留激活单元的概率（保留概率=p，比如keep_prob=0.8），batchnorm层会继续计算数据的mean和var并进行更新**\n在val模式下，**dropout层会让所有的激活单元都通过，而batchnorm层会停止计算和更新mean和var，直接使用在训练阶段已经学出的mean和var值**\n- model.eval()不会影响各层的gradient计算行为，即gradient计算和存储与training模式一样，只是不进行反向传播(backprobagation)\n\n## torch.no_grad()\n使用方法：\n```python\nwith torch.no_grad()：\n\t# 代码块\n```\n\n\n- 用于停止autograd模块的工作，起到加速和节省显存的作用（具体行为就是停止gradient计算，从而节省了GPU算力和显存）\n- 不会影响dropout和batchnorm层的行为\n\n\n`model.eval()`与`torch.no_grad()`可以同时用，更加节省cpu的算力\n\n## 思考\n\n在val模式下，为什么让dropout层所有的激活单元都通过，因为train阶段的dropout层已经屏蔽掉了一些激活单元，在val模式下，让所有的激活单元都通过还能预测数据吗?\n**在val模式下，让所有的激活单元都通过当然能预测数据了，相当于学习时限定你每次只能选择一份资料学，考试时开卷所有资料你都带着。val模式下，虽然让所有的激活单元都通过，但是对于各个神经元的输出， 要乘上训练时的删除比例后再输出。**","tags":["pytorch"],"categories":["pytorch"]},{"title":"使用VGG迁移学习开启《猫狗大战挑战赛》","url":"/2020/11/24/181519/","content":" 使用VGG迁移学习开启《猫狗大战挑战赛》，内容如下：\n一、前言\n二、加载数据集\n三、数据预处理\n四、构建VGG模型\n五、训练VGG模型\n六、保存与测试模型\n七、总结\n\n \n\n<!-- more -->\n\n\n\n\n\n# 一、前言\n\n猫狗大战挑战由Kaggle于2013年举办的，目前比赛已经结束，不过仍然可以把[AI研习社猫狗大战赛平台](https://god.yanxishe.com/41)作为练习赛每天提交测试结果，该平台数据集包含猫狗图片共24000张，没有任何标注数据，选手需要训练模型正确识别猫狗图片，**1= dog，0 = cat**。这里使用在 ImageNet 上预训练的 VGG 网络模型进行测试，因为原网络的分类结果是1000类，所以要进行迁移学习，对原网络进行 fine-tune （即固定前面若干层，作为特征提取器，只重新训练最后两层），并把测试结果提交到该平台。那么，现在就让我们开始吧。\n\n\n\n\n\n# 二、加载数据集\n\n前期如何把**解压后的竞赛数据集**放到colab上着实耗费了我大量的时间，我认为非常有必要把这个单独作为一章讲一下。如果你本地有很强的GPU，不需要在colab上跑代码，这章节可以忽略，由于我的电脑跑不动这么多数据，GPU也不行，所以只能在colab上运行。在这个过程中许多问题本是可以避免的，由于对一些操作和指令不熟练，导致许多时间白白流失，即打消了初学者的自信心，也拖慢了实验的进度，究其原因，主要有以下几点：\n\n1. 在google drive上传和解压数据集时间特别慢，需要数十个小时\n\n2. colab运行时间有时限，长时间不操作（大概20分钟左右）会导致当前训练的数据被回收\n\n3. 猫狗大战数据集是没有标签的，需要自己定义Dataset类加载数据\n\n现在就来一个个解决上面的几个痛点吧！\n\n**（1）colab上传和解压大数据集**\n\n我们的目的是要在colab上读取竞赛数据集的图片，达到目的的方式有三个：\n\n- 方式一：把数据集压缩包上传到google drive，在drive上解压\n- 方式二：数据集解压后再上传到google drive\n- 方式三：把数据集压缩包上传到google drive，在colab连接的虚拟机上解压\n\n上面几种方式哪个好呢？我先不直接说结果，来实验下吧！\n\n首先，采用方式一，把数据集压缩包上传到google drive，在drive上解压，操作很简单，在google drive上右键上传[竞赛数据集cat_dog.rar](https://static.leiphone.com/cat_dog.rar)，文件大小521MB，上传时间二十多分钟，上传完毕后，再drive上解压，现在痛点来了，**时间竟然要十几个小时**，具体操作如下：\n\n- 打开colab，挂载google drive，方法可以参考我的博客[Google Colab挂载drive上的数据文件](https://blog.csdn.net/qq_37555071/article/details/107544680)。\n\n- 解压drive上的cat_dog.rar文件，命令为\n\n  ```bash\n  ! apt-get install rar\n  !unrar x \"/content/drive/Colab/人工智能课/cat_dog.rar\" \"/content/drive/Colab/人工智能课/\"\n  ```\n\n  解压过程如下：\n\n  ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120155811.png)\n\n\n\n\n我大致算了一下，每张图片解压时间5秒钟左右，24000张图片要大约33小时啊！！！所以，这种方式直接pass掉。\n\n再来看，方式二，把数据集解压后再上传到google drive，解压后的数据集文件夹大小虽然只有五百多兆，但上传速度特别慢，大概要5至7个小时，**并且一旦中间断网或是网络不稳定，极有可能导致数据损坏**。我就是花费了大半天时间把所有解压后的文件上传完了，由于中间网络不稳定，导致数据读取不正确，最终这种方式也放弃了，哎，说多了都是泪！\n\n最后，就只有方式三了，把数据集压缩包上传到google drive，在colab连接的虚拟机上解压文件，方法是：\n\n- 将google drive上数据集文件cat_dog.rar拷贝到colab连接的虚拟机上\n  ```bash\n  !cp -i /content/drive/Colab/人工智能课/cat_dog.rar /content/\n  ```\n- 在虚拟机上解压压缩文件：\n  ```bash\n  ! apt-get install rar\n  ! unrar x cat_dog.rar\n  ```\n  运行过程如下：![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120162337.png)\n\n\n\n这种方式速度非常快，如果操作正确，**解压时间仅有一分钟左右**，非常值得推荐！\n\n**（2）阻止Colab自动掉线**\n\n在colab上训练代码，页面隔一段时间无操作之后就会自动掉线，之前训练的数据都会丢失。现在你体会到我之前连续几个小时在google drive解压数据集文件的艰辛路程了吧。不过好在最后终于找到了一种可以让其自动保持不离线的方法，用一个js程序自动点击连接按钮。代码如下：\n\n```js\nfunction ClickConnect(){\n  console.log(\"Working\"); \n  document\n    .querySelector(\"#top-toolbar > colab-connect-button\")\n    .shadowRoot\n    .querySelector(\"#connect\")\n    .click()\n}\n \nsetInterval(ClickConnect,60000)\n```\n\n使用方式是：按快捷键`ctrl+shift+i`，并选择`Console`，然后复制粘贴上面的代码，并点击回车，该程序便可以运行了，如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120163050.png)\n\n**（3）猫狗大战数据集是没有标签的，需要自己定义Dataset类才能加载数据**\n\n猫狗大战数据集是没有标签的，但是从其训练集和验证集的图片名字可以获取标签，这就需要我们自己定义Dataset类了，由于这个部分篇幅较多，我们放在下一章讲吧。\n\n\n\n\n\n\n\n# 三、数据预处理\n\n传统的mnist数据集是集成到`torchvision.datasets`，我们使用`datasets.MNIST`就可以方便加载数据，不用做过多的其它处理，而猫狗大战竞赛数据集是如下图方式，并没有用标签对文件夹分类存放，所以我们需要通过图片名称获取标签，并自定义Dataset类加载图片。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120201612.png)\n\n我定义的Dataset类如下所示：\n\n```python\nfrom torch.utils.data import Dataset,DataLoader\n# 创建自己的类：MyDataset,继承 Dataset 类\nclass MyDataset(Dataset):\n    def __init__(self, txt, data_path=None, transform=None, target_transform=None, loader=default_loader):\n        super(MyDataset, self).__init__()\n        file_path = data_path + txt\n        file = open(file_path, 'r', encoding='utf8')\n        imgs = []\n        for line in file:\n            line = line.split()\n            imgs.append((line[0],line[1].rstrip('\\n')))\n\n        self.imgs = imgs\n        self.transform = transform\n        self.target_transform = target_transform\n        self.loader = loader\n        self.data_path = data_path\n\n    # 可以通过索引进行条用，如data[1]\n    def __getitem__(self, index):\n        # 按照索引读取每个元素的具体内容\n        imgName, label = self.imgs[index]\n        # imgPath = self.data_path + imgName\n        imgPath = imgName\n        # 调用那张图片读哪张，最大限度发挥GPU显存\n        img = self.loader(imgPath)\n        if self.transform is not None:\n            img = self.transform(img)\n            label = torch.from_numpy(np.array(int(label)))\n        return img, label\n\n    def __len__(self):\n        # 数据集的图片数量\n        return len(self.imgs)\n    \n# 定义读取文件的各式\ndef default_loader(path):\n    return Image.open(path).convert('RGB')\n```\n\n具体要加载图片数据还要进行几个处理，即事先准备好train、val数据集的路径和标签，以及test数据集的路径，然后使用`MyDataset`加载图片路径文件，最后就可以通过`torch.utils.data.DataLoader`加载图片数据了。具体步骤如下：\n\n（1）首先，读取cat_dog文件夹下的图片路径\n\n```python\n#读一个文件夹下的所有文件名称\ndef read_file_name(file_dir):\n    filename = []\n    for root, dirs, files in os.walk(file_dir):\n        filename = files #当前路径下所有非目录子文件\n        break #这里只要图片文件，执行一次即可退出\n    return filename\n```\n\n（2）然后将文件名格式化为竞赛要求的类型，这里cat标签为0，dog为1\n\n```python\n# 将文件名格式化为要求的类型，这里cat标签为0，dog为1\ndef format_inputAndlabel(file_dir):\n    format_result = []\n    filename = read_file_name(file_dir)\n    for n in filename:#cat为0，dog为1\n        if \"cat\" in n:\n            format_result.append(n+\" 0\")\n        else:\n            format_result.append(n+\" 1\")\n    return format_result\n```\n\n（3）分别传入train、test、val路径读取数据\n\n```python\n# 格式化读取train、test、val\nformat_train_result = format_inputAndlabel(\"cat_dog/train\")\nformat_test_result = format_inputAndlabel(\"cat_dog/test\")\nformat_val_result = format_inputAndlabel(\"cat_dog/val\")\n```\n\n（4）由于自定义的DataSet必须知道文件路径，所以先将格式化的文件名写入文件里，再用自定义的MyDataset读取\n\n```python\ndef convert_format(content):\n  result = []\n  for t in content:\n    v = t.split('.')\n    result.append(int(v[0]))\n  return result\n# 写入train、val文件\ndef write_file(path,file_prefix,content):\n  with open(path, 'w', encoding='utf8') as f:\n      for line in content:\n          f.write(file_prefix+line+'\\n')\n# 写入test文件，由于读取时候文件名是乱序的，因此要先排序\ndef write_test_file(path,test_file_prefix,content):\n  content=convert_format(content)\n  content.sort() #排序\n  with open(path, 'w', encoding='utf8') as f:\n      for line in content: \n          f.write(test_file_prefix+str(line)+'.jpg 0'+'\\n')# test文件没有标签，默认用0填充就行\n\n# 因为自定义的DataSet必须知道文件路径，所以先将格式化的文件名写入文件里，再用自定义MyDataset读取\nwrite_file(path=\"cat_dog/train.txt\",file_prefix=\"cat_dog/train/\",content=format_train_result)\nwrite_file(path=\"cat_dog/val.txt\",file_prefix=\"cat_dog/val/\",content=format_val_result)\nwrite_test_file(path=\"cat_dog/test.txt\",test_file_prefix=\"cat_dog/test/\",content=format_test_result)\n```\n\n（5）对数据进行预处理变换\n\n```python\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision.transforms as transforms\n# 预处理设置\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ntrain_transformer = transforms.Compose([\n    transforms.Resize(256),\n    transforms.transforms.RandomResizedCrop((224), scale = (0.5,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize])\n\n# val和test是类似的，训练的时候可以多一些增强，这里只做验证就可以\nval_transformer = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize\n])\n```\n\n（6）使用`MyDataset`加载图片路径文件\n\n```python\n# 数据集加载方式设置\ncmd_path='cat_dog/'\ntrainset = MyDataset(txt='train.txt',data_path=cmd_path,transform=train_transformer)\nvalset = MyDataset(txt='val.txt',data_path=cmd_path,transform=val_transformer)\ntestset = MyDataset(txt='test.txt',data_path=cmd_path,transform=val_transformer)\nprint('训练集：',trainset.__len__())\nprint('验证集：',valset.__len__())\nprint('测试集：',testset.__len__())\n\"\"\"\n输出：\n训练集： 20000\n验证集： 2000\n测试集： 2000\n\"\"\"\n```\n\n（7）使用`torch.utils.data.DataLoader`加载图片数据，并将其放入`dataloaders_dict`\n\n```python\nbatchsize=128\n# 构建DataLoader\ntrain_loader = DataLoader(trainset, batch_size = batchsize, drop_last = False, shuffle = True)\n## val_loader和train_loader不做shuffle\nval_loader = DataLoader(valset, batch_size = batchsize, drop_last = False, shuffle = False)\ntest_loader = DataLoader(testset, batch_size = batchsize, drop_last = False, shuffle = False)\ndataloaders_dict = {'train':train_loader,'val':val_loader,'test':test_loader}\n```\n\n最终，数据集文件被放入`dataloaders_dict`，后面就可以通过该字典方便的传入相应的数据集了。\n\n\n\n# 四、构建VGG模型\n\nVGG 模型如下图所示，主体由三种元素组成：\n\n- 卷积层（CONV）是发现图像中局部的 pattern\n- 全连接层（FC）是在全局上建立特征的关联\n- 池化（Pool）是给图像降维以提高特征的 invariance(不变性)\n\n关于VGG模型的更详细介绍，可以参考我的博客[深入解读VGG网络结构](https://blog.csdn.net/qq_37555071/article/details/108199352)\n\n![VGG](http://fenggao-image.stor.sinaapp.com/20191006215625.jpg)\n\n\n\n默认情况下，当我们加载预训练的模型时，所有参数都具有`requires_grad = True`，如果我们从头开始或进行微调训练就不用更改。但是，如果我们要进行特征提取，并且只想为新初始化的图层计算梯度，那么我们希望所有其他参数都不需要梯度更新，需要用`set_parameter_requires_grad`函数将模型中参数的requires_grad属性设置为False，具体如下：\n\n```python\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n```\n\n这里我使用预训练好的VGG模型进行迁移学习，只想更新最后一层的参数，并且希望所有其他参数都不需要梯度更新，所以要用`set_parameter_requires_grad`函数将模型最后一层参数的requires_grad属性设置为False，由于猫狗大战数据集是二分类，需要把最后的`nn.Linear` 层由1000类，替换为2类。如下：\n\n```python\ndef initialize_model(num_classes, feature_extract, use_pretrained=True):\n    # 初始化模型变量\n    model_vgg = None\n    # 加载预训练模型\n    model_vgg = models.vgg16(pretrained=use_pretrained)\n    # 更改输出层\n    set_parameter_requires_grad(model_vgg, feature_extract)\n    model_vgg.classifier[6] = nn.Linear(4096, num_classes)\n    model_vgg.classifier.add_module('7',torch.nn.LogSoftmax(dim = 1))\n    return model_vgg\n\nmodel_vgg_new = initialize_model(num_classes=2,feature_extract = True,use_pretrained=True)\nprint(model_vgg_new.classifier)\n```\n\n输出`model_vgg_new`的`classifier`层，如下所示，可以看到最后一层全连接输出为2，并且使用`LogSoftmax`为output层。\n\n```tex\nSequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=2, bias=True)\n  (7): LogSoftmax(dim=1)\n)\n```\n\n\n\n# 五、训练VGG模型\n\n训练定义好的VGG模型，即训练最后一层全连接层，具体操作步骤如下：\n\n（1）创建损失函数和优化器\n\n损失函数 `NLLLoss()` 的输入是一个对数概率向量和一个目标标签，它不会为我们计算对数概率，适合最后一层是`log_softmax()`的网络。Adam优化器是目前性能比较好的优化器之一，因此这里采用Adam。\n\n```python\n'''\n第一步：创建损失函数和优化器\n'''\n# 损失函数\ncriterion = nn.NLLLoss()\n# 学习率\nlr = 0.001\n# 优化器\noptimizer_vgg = torch.optim.Adam(model_vgg_new.classifier[6].parameters(),lr = lr)\n```\n\n（2）判断是否存在GPU设备，并将model切换到相应的device\n\n```py\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('Using gpu: %s ' % torch.cuda.is_available())\nmodel_vgg_new.to(device)\n```\n\n（3）训练模型\n\n这里我定义了一个`train_model`训练的方法，并将验证集上结果最好的一次训练存储下来，为了减少训练时间，我把`epoch`设置为4\n\n```python\n'''\n第三步：训练模型\n'''\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n    since = time.time()\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # 每个epoch都进行训练和验证\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # 将模型设置为训练模式\n            else:\n                model.eval()   # 将模型设置为验证模式\n\n            running_loss = 0.0 # 记录训练时的loss下降过程\n            running_corrects = 0\n\n            # 遍历数据\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # 梯度初始化\n                optimizer.zero_grad()\n                # 前向传播\n                outputs = model(inputs)\n                loss = criterion(outputs, labels.long())\n                # 得到预测结果\n                _, preds = torch.max(outputs, 1)\n                # 仅在训练时更新梯度，反向传播，backward + optimize\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # 将验证集上结果最好的一次训练存储下来\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history\n\n# 训练\nmodel_new_vgg, hist = train_model(model_vgg_new, dataloaders_dict, criterion, optimizer_vgg, num_epochs=4)\n\n```\n\n经过4次epoch，输出的记录如下，可以看到虽然训练次数不多，但是在验证集上效果还是很不错的\n\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nplt.title(u\"val acc plot\")\nplt.xlabel(u\"epoch\")\nplt.ylabel(u\"val acc\")\nacc= hist\nplt.xticks(range(len(acc)))\nplt.plot(acc)\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120204636.png)\n\n\n\n\n\n\n\n# 六、保存与测试模型\n\n（1）保存训练好的模型\n\npytorch保存和加载模型有两种方式，**不同的保存方式对应不同的读取方式**，两者各有利弊。\n\n方式一：直接保存整个模型\n\n```python\ntorch.save(model_new_vgg, 'model_new_vgg.pt')\nmodel_new_vgg = torch.load('model_new_vgg.pt')\n```\n\n方式二：只保存模型中的参数\n\n```python\nmodel = initialize_model(num_classes=2,feature_extract = True,use_pretrained=True)\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"model_new_vgg.pt\"))\n```\n\n可以看到，用第一种方法能够直接保存模型，加载模型的时候直接把读取的模型给一个参数就行。而第二种方法则只是保存参数，在读取模型参数前**要先定义一个模型**（模型必须与原模型相同的构造），然后对这个模型导入参数。虽然麻烦，但是可以**同时保存多个模型**的参数，而第一种方法则不能，而且第一种方法**有时不能保证模型的相同性**（你读取的模型并不是你想要的）。所以，这里我采用第二种方式来保存并加载模型。\n\n（2）对模型进行测试\n\n接下来就要用test数据集对模型进行测试了，把测试结果保存到`pred_outputs`，具体如下：\n\n```python\ndef test_model(model, test_loader):\n    model.eval() #把训练好的参数冻结\n    total,correct = 0,0\n    pos = 0\n    pred_outputs= np.empty(len(test_loader.dataset),dtype=np.int)\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            pred_outputs[pos:pos+len(preds)]=preds.cpu().numpy()\n            pos += len(preds)\n    return pred_outputs\n\npred_outputs = test_model(model,dataloaders_dict['test'])\n```\n\n（3）将测试结果写入`cat_dog_result.csv`\n\n```python\nwith open(\"cat_dog_result.csv\", 'w') as f:\n    for i in range(len(test_loader.dataset)):\n        f.write(\"{},{}\\n\".format(i, pred_outputs[i]))\n```\n\n因为我是在colab环境上训练的，还要把`cat_dog_result.csv`拷贝到google drive才能下载，命令如下：\n\n```bash\n!cp -i /content/cat_dog_result.csv /content/drive/\n```\n\n（4）提交测试结果\n\n把`cat_dog_result.csv`提交到[AI研习社猫狗大战--经典图像分类题](https://god.yanxishe.com/41)，现在就让我们见证奇迹的时刻吧！\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120181445.png)\n\n可以看到，只训练了4次epoch，测试就达到了98.9的准确率，把epoch设置得更大，结果应该会更好，由于时间原因，就不训练了。\n\n\n\n\n\n# 七、总结\n\n从加载猫狗大战竞赛数据集到colab上，到测试完模型并提交，我大概花费了几天的时间，并且主要时间不是用在定义模型和调参上，而是如何处理数据上。我认为这次的收获还是很大的，因为我知道了**如何以最快最有效的方式在colab上加载要训练的数据**，并定义了自己Dataset类，**以后对于任何类型、任何格式的训练数据，我应该都能定义相应Dataset类并且去处理它**。这次我用了近三天，下次可能一个小时不到就搞定了，这难道不是一个巨大的进步吗？此外，我通过预训练好的VGG模型进行迁移学习，训练了猫狗大战数据集，仅训练了4次epoch，测试数据就达到了98.9的准确率，说明预训练好的VGG模型是非常容易学习的，以后再遇到类似的识别分类任务，就不需要从头开始训练了，真的是非常快速又方便。\n\n最后，附上我的colab共享地址：https://drive.google.com/file/d/1t-DVQwo92dBuy3JgNhdYFD_CndwyBE3U/view?usp=sharing\n\n里面格式有点乱，但是内容一点都不少哦！","tags":["VGG"],"categories":["神经网络"]},{"title":"Hexo博客发布和配置的一些常用命令","url":"/2020/11/24/165533/","content":"\nHexo博客发布和配置的一些常用命令，在此记录！如果遇到新的且使用的命令，会不端完善！\n<!-- more -->\n\n\n\n## 基本命令\n\n`hexo init`  \n初始化站点，生成一个简单网站所需的各种文件。\n\n`hexo clean == hexo c`  \n清除缓存 网页正常情况下可以忽略此条命令\n\n`hexo generate == hexo g`  \n生效新增、修改、更新的文件\n\n`hexo server == hexo s`  \n启动本地网站，可在本地观察网站效果，同时也可以输入`http://localhost:4000/admin`管理文章\n\n`hexo s --draft`\n这个发布时可以预览草稿\n\n`hexo s --debug`  \n以调试模式启动本地网站，在此模式下，对文件的更改无需停止网站只需刷新即可看到效果，调试非常方便\n\n\n`hexo clean && hexo s`  \n一次执行两个命令\n\n`hexo deploy == hexo d`  \nhexo的一键部署功能，执行此命令即可将网站发布到配置中的仓库地址，执行此命令前需要配置站点配置文件_config.yml\n\n**一键本地启动**：`hexo clean && hexo g && hexo s`\n\n**一键部署**：`hexo clean && hexo g && hexo d`\n\n\n\n## 创建和发布文章\n\n`hexo new [layout] <title>`\n新建一篇新文章，会自动按照模板里面的格式创建文章\n\n里面的布局（layout），默认为 post，布局共有三种：\n\n```tex\npost\tsource/_posts\npage\tsource\ndraft\tsource/_drafts\n```\n\n**发布草稿命令：**\n\n1. `hexo publish 文章文件名`\n2. 或者是手动将`_drafts`目录下的草稿移动到`_posts`目录下即可发布草稿为正式文章。\n\n\n\n## PicGO图床快捷键\n快捷键为：`ctrl+shift+p`\n\n\n\n## Hexo博客头部配置\n\n（1）文章置顶\n\n在文章的 Front-Matter 中，使用 `top: true` 来实现置顶。在文章的 Front-Matter 中，使用 `top: true` 来实现置顶。\n\n（2）自定义样式\n\n如果你想修改主题的样式，推荐将样式代码添加到 `source/css/_custom` 目录下的 `index.styl` 文件中。这样，当主题更新时，不会覆盖你已经修改了的样式代码。\n\n> 当然，你也可以进行模块化分类：在该目录下新建样式文件，然后通过 `@import xxx` 语句在同目录下的 `index.styl` 文件中引入你新建的样式文件。\n\n（3）文章目录\n\n启用文章目录后，默认对所有文章页面生效。你可以在 Front-Matter 中，设置 `toc: false` 来指定某篇文章不启用该功能。\n\n","categories":["工具"]},{"title":"Typora需要注意的换行符","url":"/2020/11/24/104944/","content":"\n在Typora中一定要换行符，包括普通换行，以及整个段落的换行，这些和普通的markdown编辑器是不太一样的\n\n\n\n\n\n<!-- more -->\n\n（1）首先，Typora中如果只按`Enter`键，**则把其看做另起一个段落**，段落之间的间距是比较大的，从Typora的界面上就可以看出来，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124110809.png)\n\n（2）其次，如果要只换行，而不另起一个段落，则需要使用`<br/>`或`<br/>`或按下`Shift`+`Enter`键，这时候不会另起一段，两行仍然在一个段落里面，此时间距是比较小的，如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111640.png)\n\n\n\n（3）另外，需要注意的是，对于**有序或无序排列**，如果要在一个排列里面写多行东西，不要只按`Enter`键，这样会另起一段，Typora会使所有的排序当做单独的一段，在源码模式下可以看到如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111559.png)\n\n（4）可以采用`<br/>`或`<br/>`或按下`Shift`+`Enter`键的方式另起一行，这就所有的排序就在一段内了，如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111952.png)\n\n\n\n（5）先按下两个空格，再按下`Shift`+`Enter`键，会出现如下符号，我认为这和只用`Shift`+`Enter`是一样的效果，目前还没发现什么问题，以后若发现区别会再补充。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124132953.png)\n\n\n\n（6）需要注意的是，一定要勾选，菜单栏中编辑->空格与换行->保留单独的换行符，如下图所示，这样才能使用`Shift`+`Enter`键的方式另起一行，如果不勾选，只能用`<br/>`或`<br/>`的方式另起一行。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124112415.png)\n\n","categories":["工具"]},{"title":"使用pytorch的auto_grad实现线性模型对mnist数据集多分类","url":"/2020/07/18/181520/","content":"\n使用pytorch的auto_grad实现线性模型对mnist数据集多分类，选取mnist100张图片，前80张为测试集，后20张为训练集，eporch 500次\n\n\n## 知识储备\n\n使用多个线性模型进行多分类 原理：每一个线性模型做二分类  \n多个线性模型 = 感知机，实质就是每一个线性模型做二分类\n\n<!-- more -->\n\n## 数据加载&归一化\n\n\n```python\nimport torch\nfrom mnist import MNIST\nimport numpy as np\nimport pdb\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nmndata = MNIST('dataset/python-mnist')\nimage_data_all, image_label_all = mndata.load_training()\nimage_data = image_data_all[0:100]\nimage_data = np.array(image_data,dtype = np.float)/255\nimage_label = image_label_all[0:100]\nimage_label = np.array(image_label,dtype = np.int)\nprint(image_data.shape,image_label.shape)\n```\n\n    (100, 784) (100,)\n\n\n## 定义模型\n\n\n```python\ndef model(image_data_one,weights,bias):\n    \"\"\"\n    这里直接使用图片本身作特征，也可以提取features后传入模型中\n    \"\"\"\n    # image_data_one转化为二维\n    xt = torch.from_numpy(image_data_one.reshape(1,28*28))\n    y = xt.mm(weights)+bias\n    return y\n\ndef get_acc(image_data,image_label,weights,bias,start_i,end_i):\n    correct = 0\n    # 这里可以不加，因为loss计算于此无关\n    with torch.no_grad():\n        for i in range(start_i,end_i):\n            y = model(image_data[i],weights,bias)\n            # 获取第i张图片的label\n            gt = image_label[i]\n            # 获取与y最近接的label值\n            pred = torch.argmin(torch.from_numpy(np.array([torch.min((torch.abs(y-j))).item() for j in range(0,10)]))).item()\n            if gt == pred:\n                correct += 1\n    # 确保万一，除法分子或分母一个指定为float        \n    return float(correct/float(end_i-start_i))\n```\n\n\n```python\n#显示训练集和测试集精度变换\ndef show_acc(train_accs,test_accs):\n    plt.figure(figsize = (10,4))\n    plt.title('train_accs and test_accs')\n    plt.plot(np.arange(len(train_accs)), train_accs, color='green', label='train_accs')\n    plt.plot(np.arange(len(test_accs)), test_accs, color='red', label='test_accs')\n    plt.legend() # 显示图例\n    plt.xlabel('index')\n    plt.ylabel('accs')\n    plt.show()\n```\n\n\n```python\ndef train_model(image_data,image_label,weights,bias,lr):\n    loss_value_before=1000000000000000.\n    loss_value=10000000000000.\n    train_accs = []\n    test_accs = []\n    for epoch in range(0,500): \n        loss_value_before=loss_value\n        loss_value=0\n        for i in range(0,80):\n            y = model(image_data[i],weights,bias)\n            # 获取第i张图片的label\n            gt = image_label[i]\n            # 只关心一个值，更新的时候也只更新对应线性模型的weights和bias\n            loss = torch.sum((y[0,gt:gt+1]-gt).mul(y[0,gt:gt+1]-gt))\n            loss_value += loss.data.item()\n            loss.backward()\n            weights.data.sub_(weights.grad.data*lr)\n            weights.grad.data.zero_()\n            bias.data.sub_(bias.grad.data*lr)\n            bias.grad.data.zero_()            \n\n        train_acc = get_acc(image_data,image_label,weights,bias,0,80)\n        test_acc = get_acc(image_data,image_label,weights,bias,80,100)\n        train_accs.append(train_acc)\n        test_accs.append(test_acc)\n        #print(\"epoch=%s,loss=%s/%s,train/test_acc=%s/%s,\"%(epoch,loss_value,loss_value_before,train_acc,test_acc))\n    show_acc(train_accs,test_accs)\n```\n\n## 训练\n\n\n```python\nweights = torch.randn(28*28,10,dtype = torch.float64,requires_grad = True)\nbias = torch.zeros(10,dtype = torch.float64,requires_grad = True)\nlr = 1e-3\n# 对模型进行训练：\ntrain_model(image_data,image_label,weights,bias,lr)    \n```\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200718181909.png)\n\n> 由于样本少，导致程序过拟合，结果是训练集精度高，测试集精度低。\n","tags":["pytorch","MLP"],"categories":["project实战"]},{"title":"numpy和torch数据类型转化","url":"/2020/07/18/164540/","content":"\n在实际计算过程中，float类型使用最多，因此这里只介绍numpy和torch数据float类型转化，其他类型同理。\n<!-- more -->\n\n## numpy数据类型转化\n\n- numpy使用astype转化数据类型，float默认转化为64位，可以使用`np.float32`指定为32位\n\n\n```python\n#numpy转化float类型\na= np.array([1,2,3])\na = a.astype(np.float)\nprint(a)\nprint(a.dtype)\n```\n\n`[1. 2. 3.]`  \n`float64`\n    \n\n- 不要使用a.dtype指定数据类型，会使数据丢失\n\n\n```python\n#numpy转化float类型\nb= np.array([1,2,3])\nb.dtype= np.float32\nprint(b)\nprint(b.dtype)\n```\n\n`[1.e-45 3.e-45 4.e-45]`  \n`float32`\n    \n\n- 不要用float代替np.float，否则可能出现意想不到的错误\n- 不能从np.float64位转化np.float32，会报错\n- np.float64与np.float32相乘，结果为np.float64\n\n> 在实际使用过程中，可以指定为np.float，也可以指定具体的位数，如np.float，不过直接指定np.float更方便。\n\n## torch数据类型转化\n\n- torch使用`torch.float()`转化数据类型，float默认转化为32位，torch中没有`torch.float64()`这个方法\n\n\n```python\n# torch转化float类型\nb = torch.tensor([4,5,6])\nb = b.float()\nb.dtype\n```\n\n\n\n\n    torch.float32\n\n\n\n- `np.float64`使用`torch.from_numpy`转化为torch后也是64位的\n\n\n```python\nprint(a.dtype)\nc = torch.from_numpy(a)\nc.dtype\n```\n\n`float64`  \n`torch.float64`\n\n\n\n- 不要用float代替torch.float，否则可能出现意想不到的错误\n- torch.float32与torch.float64数据类型相乘会出错，因此相乘的时候注意指定或转化数据float具体类型\n\n> np和torch数据类型转化大体原理一样，只有相乘的时候，torch.float不一致不可相乘，np.float不一致可以相乘，并且转化为np.float64\n","tags":["numpy","pytorch"]},{"title":"Google Colab挂载drive上的数据文件","url":"/2020/07/18/103558/","content":"\nGoogle Colab是完全云端的，所以，每次如果想让他访问谷歌云盘的内容，必须要先进性授权操作，直接在colab的jupyter中进行绑定授权操作\n\n**每次在Google Colab中打开notebook文件时，都必须重新执行命令获得授权。**\n<!-- more -->\n\n## 获取授权脚本代码\n```bash\n!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n!apt-get update -qq 2>&1 > /dev/null\n!apt-get -y install -qq google-drive-ocamlfuse fuse\nfrom google.colab import auth\nauth.authenticate_user()\nfrom oauth2client.client import GoogleCredentials\ncreds = GoogleCredentials.get_application_default()\nimport getpass\n!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\nvcode = getpass.getpass()\n!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n```\n**期间会输入两次授权码，点击相应链接复制即可**\n\n## 挂载到drive上\n```bash\n!mkdir -p drive\n!google-drive-ocamlfuse drive\n```\n\n## 切换到工作文件夹\n\n```python\n# 指定当前的工作文件夹\nimport os\n# google drive中的文件路径为/content/drive\nos.chdir(\"/content/drive/Colab\") \n```\n也可以使用`%cd`切换工作路径，推荐使用\n\n\n## 几个常用命令\n\n- `%cd`切换工作目录\n- `!ls`查看当前目录下的文件\n- `!pwd`查看当前的工作路径\n\n\n\n参考文档\n\n[谷歌云盘Colaboratory如何载入文件](https://blog.csdn.net/Einstellung/article/details/81006408)  \n","tags":["colab"],"categories":["Google Colab使用"]},{"title":"使用numpy实现逻辑回归对IRIS数据集二分类","url":"/2020/07/16/175900/","content":"使用numpy实现逻辑回归对IRIS数据集二分类，使用对数似然损失(Log-likelihood Loss)，并显示训练后loss变化曲线。\n\n知识储备如下：\n- 逻辑回归Logistic Regression\n- 对数似然损失\n- IRIS数据集介绍\n- np.concatenate使用\n<!-- more -->\n\n\n## 知识储备\n\n### 逻辑回归Logistic Regression\n\n$$y = \\frac{1}{1+e^{-(wx+b)}}$$\n名字虽然叫回归，但是一般处理的是分类问题，尤其是二分类，比如垃圾邮件的识别，推荐系统，医疗判断等，因为其逻辑与实现简单，在工业界有着广泛的应用。\n\n__优点__：\n\n* 实现简单，计算代价不高，易于理解和实现, 广泛的应用于工业问题上；\n* 分类时计算量非常小，速度很快，存储资源低；\n\n__缺点__：\n\n* 容易欠拟合，当特征空间很大时，逻辑回归的性能不是很好；\n* 不能很好地处理大量多类特征或变量；\n\n### 对数似然损失\n对数损失, 即对数似然损失(Log-likelihood Loss), 也称逻辑斯特回归损失(Logistic Loss)或交叉熵损失(cross-entropy Loss), 是在概率估计上定义的。它常用于(multi-nominal, 多项)逻辑斯特回归和神经网络,以及一些期望极大算法的变体,可用于评估分类器的概率输出。可参考[对数损失函数(Logarithmic Loss Function)的原理和 Python 实现](https://www.cnblogs.com/klchang/p/9217551.html)了解详情\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716170728.png)\n\n损失函数:\n\n\n$$L=\\frac{1}{m}*\\sum_i^m -y_ilog(f(x_i))-(1-y_i)log(1-f(x_i))$$\n梯度计算：\n$$\\frac{\\partial L}{\\partial w} = \\frac{1}{m}X^T*(f(x)-y)$$\n\n权重更新：\n$$w = w -\\alpha\\frac{\\partial L}{\\partial w}$$\n\n### IRIS数据集介绍\n\n该数据集包含4个特征变量，1个类别变量。iris每个样本都包含了4个特征：花萼长度，花萼宽度，花瓣长度，花瓣宽度，以及1个类别变量（label）。详情见[加载数据](#加载数据)\n\n### np.concatenate使用\n\n\n```python\na = np.array([[1, 2],[3, 4]])\nb = np.array([[5, 6]])\nnp.concatenate((a, b), axis = 0)\n```\n\n\n\n\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n\n\n\n\n```python\nnp.concatenate((a, b.T), axis = 1)\n```\n\n\n\n\n    array([[1, 2, 5],\n           [3, 4, 6]])\n\n\n\n## 加载数据\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import load_iris\n%matplotlib inline\n```\n\n\n```python\ndataset = load_iris()\ninputs = dataset['data']\ntarget = dataset['target']\nprint('inputs.shape:', inputs.shape)\nprint('target.shape:', target.shape)\n# 三个类别\nprint('labels:', set(target))\n```\n\n    inputs.shape: (150, 4)\n    target.shape: (150,)\n    labels: {0, 1, 2}\n\n\n\n```python\ntarget\n```\n\n\n\n\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n           2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n           2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n\n```python\nvalues = [np.sum(target == 0), np.sum(target == 1), np.sum(target == 2)]\nplt.pie(values,labels=[0, 1, 2], autopct = '%.1f%%')\nplt.show()\n```\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171020.png)\n\n\n关于参数train_test_split的`random_state`的解释：  \n>Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls.   \nrandom_state即随机数种子，**目的是为了保证程序每次运行都分割一样的训练集和测试集。否则，同样的算法模型在不同的训练集和测试集上的效果不一样。**\n\n\n```python\nfrom sklearn.model_selection import train_test_split\n# 只取前两类， 做二分类\ntwo_class_input = inputs[:100]\ntwo_class_target = target[:100]\nx_train, x_test, y_train, y_test = train_test_split(\n                    two_class_input,two_class_target,\n                    test_size = 0.3,\n                    random_state = 0)\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n```\n\n    (70, 4) (30, 4) (70, 1) (30, 1)\n\n\n\n```python\n# add one feature to x\nx_train = np.concatenate([x_train, np.ones((x_train.shape[0], 1))], axis = 1)\nx_test = np.concatenate([x_test, np.ones((x_test.shape[0], 1))], axis = 1)\nprint(x_train.shape, x_test.shape)\n```\n\n    (70, 5) (30, 5)\n\n\n## 定义模型\n\n\n```python\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\nx = np.arange(-10, 10, step = 0.1)\nfig, ax = plt.subplots(figsize = (8, 4))\nax.plot(x, sigmoid(x), c = 'green')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x28f77053348>]\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171106.png)\n\n\n\n```python\ncompute_loss = lambda pred_y, y: np.mean(-y * np.log(pred_y)-(1-y) * np.log(1-pred_y))\n# weight and bias init\nw = np.random.randn(5, 1)\n# 上一个loss\nlosses = []\nlast_loss = 10000\npred_y =sigmoid(np.dot(x_train, w))\n# 当前loss\nnow_loss = compute_loss(pred_y, y_train)\ni = 0\nwhile abs(now_loss - last_loss)>1e-4:\n    last_loss = now_loss\n    i = i + 1\n    # 计算梯度\n    grad = x_train.T.dot((pred_y - y_train)) / len(y_train)\n    # 更新梯度\n    w = w - 0.001 * grad\n    \n    # 前导计算\n    pred_y = sigmoid(np.dot(x_train, w))\n    now_loss = compute_loss(pred_y, y_train)\n    losses.append(now_loss)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x28f77053508>]\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171124.png)\n\n\n## 测试样例\n\n\n```python\n# 测试\ntest_pred = sigmoid(np.dot(x_test, w))\npre_test_y = np.array(test_pred > 0.5, dtype = np.float32)\nacc = np.sum(pre_test_y == y_test) / len(y_test)\nprint(\"the accary of model is {}\".format(acc*100))\n```\n\n    the accary of model is 100.0\n\n\n\n```python\nprint(pre_test_y.reshape(1,-1))\nprint(y_test.reshape(1,-1))\n```\n\n`[[0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n      0. 0. 0. 1. 1. 1.]]`   \n`[[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1]]`\n    \n","tags":["numpy","逻辑回归"],"categories":["project实战"]},{"title":"使用numpy实现线性模型预测boston房价","url":"/2020/07/16/115900/","content":"使用numpy实现线性模型预测boston房价，激活函数为Relu，使用MSE_loss，手动求导，并显示训练后loss变化曲线。\n\n知识储备如下：\n- Scikit-learn\n- boston房价数据解读\n- 标准差公式\n- Linear及MSE_loss求导公式\n<!-- more -->\n\n## 知识储备\n\n### Scikit-learn\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。其优点为：\n- 简单高效的数据挖掘和数据分析工具\n- 让每个人能够在复杂环境中重复使用\n- 建立NumPy、Scipy、MatPlotLib之上\n\n安装方法 pip install scikit-learn\n\n### boston房价数据解读\n\n使用sklearn.datasets.load_boston即可加载相关数据。该数据集是一个回归问题。每个类的观察值数量是均等的，共有506个观察，13个输入变量和1个输出变量。每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等，具体如下：\n- CRIM：城镇人均犯罪率。\n- ZN：住宅用地超过 25000 sq.ft. 的比例。\n- INDUS：城镇非零售商用土地的比例。\n- CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n- NOX：一氧化氮浓度。\n- RM：住宅平均房间数。\n- AGE：1940 年之前建成的自用房屋比例。\n- DIS：到波士顿五个中心区域的加权距离。\n- RAD：辐射性公路的接近指数。\n- TAX：每 10000 美元的全值财产税率。\n- PTRATIO：城镇师生比例。\n- B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n- LSTAT：人口中地位低下者的比例。\n- MEDV：自住房的平均房价，以千美元计。\n- 预测平均值的基准性能的均方根误差（RMSE）是约 9.21 千美元。\n\n### 标准差公式\n\n如x1,x2,x3...xn的平均数为M，则方差可表示为：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125539.png)\n\n样本标准差=方差的算术平方根=s=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/(n-1) )  \n总体标准差=σ=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/n )  \n如是总体，标准差公式根号内除以n  \n如是样本，标准差公式根号内除以（n-1)。  \n因为我们大量接触的是样本，所以普遍使用根号内除以（n-1)。  \n\n\n```python\na=np.array([[1,2,3],[4,5,6]])\nnp.mean(a,axis=1)\n```\n\n\n\n\n    array([2., 5.])\n\n\n\n\n```python\n# axis = 1表示行，ddof = 1是除以n-1\nnp.std(a, axis = 1,ddof = 1) \n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\n# ddof默认为0,是除以n\nnp.std(a, axis = 1) \n```\n\n\n\n\n    array([0.81649658, 0.81649658])\n\n\n\n\n```python\n# 求所有数平均值\nnp.mean(a)\n```\n\n\n\n\n    3.5\n\n\n\n### Linear及MSE_loss求导公式\n\n损失函数\n$L = \\frac{1}{2N}\\sum_{i=1}^{N}(z^{i} - y^{i})^{2}$\n\n线性函数\n$z^i = \\sum_{j=0}^{N}x_j^{(i)}w^{(j)} + b^{(j)}$\n\n对 $w$ 偏导，得到$w$ 更新梯度\n$\\frac{\\partial L}{\\partial w_j} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})x_j^{(i)}$\n\n对 $b$ 偏导，得到$b$ 更新梯度\n$\\frac{\\partial L}{\\partial b} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})$\n\n## 数据加载\n\n\n```python\nfrom sklearn.datasets import load_boston\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n\n```python\ndata = load_boston()\nX_ = data['data']\ny = data['target']\nprint(type(data), type(X_), type(y))\nprint('data keys:', data.keys())\nprint('X_.shape:', X_.shape)\nprint('y.shape:', y.shape)\n```\n\n\n`<class 'sklearn.utils.Bunch'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> ` \n`data keys: dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])  `\n`X_.shape: (506, 13)  `\n `y.shape: (506,)  `\n\n\n\n\n\n## 数据规范化\n\n\n```python\n# 转化为标准正态分布\nX_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis = 0)\ny = y.reshape(-1,1) # reshape转化为vector\nprint(X_.shape)\nprint(y.shape)\n```\n\n`(506, 13)  `\n`(506, 1)`\n    \n\n## 建立激活函数\n\n\n```python\ndef sigmoid(x):\n    r = 1 / (1 + np.exp(-x))\n    return r\nnums = np.arange(-10, 10, step = 1)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(nums, sigmoid(nums), c='red')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125621.png)\n\n\n```python\ndef relu(x):\n    return (x > 0) * x\nfig, ax = plt.subplots(figsize = (10, 4))\nnums = np.arange(-10, 10, step = 1)\nax.plot(nums, relu(nums), c = 'blue')\n```\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125708.png)\n\n\n## 定义模型\n\n线性模型：$y = wx + b$\n\n\n```python\ndef Linear(x, w, b):\n    y_pre = x.dot(w) + b\n    return y_pre\n```\n\n**在计算损失时，需要把每个样本的损失都考虑到，所以我们需要对单个样本的损失函数进行求和，并除以样本总数N。**\n\n\n```python\ndef MSE_loss(y_pre, y):\n    loss = np.mean(np.square(y_pre - y))\n    return loss\n```\n\n\n```python\ndef gradient(x, y_pre, y):\n    n = x.shape[0]\n    grad_w = x.T.dot(y_pre - y)/n\n    grad_b = np.mean(y_pre - y)\n    return grad_w, grad_b\n    \n```\n\n\n```python\n# 初始化网络\nn = X_.shape[0] # 样本数量506\nn_features = X_.shape[1] #特征数量13\n\n# 初始化网络参数\n# randn从标准正态分布中返回一个或多个样本值\nW = np.random.randn(n_features, 1)\nb = np.zeros(1)\n\n#设定学习率\nlearning_rate = 1e-2\n\n#训练次数\nepoch = 10000\n```\n\n## 训练(不加激活函数)\n\n\n```python\nlosses = []\n# 训练 \nfor t in range(epoch):\n    # 向前传播\n    y_pred = Linear(X_, W, b)\n    # 计算损失函数\n    loss = MSE_loss(y_pred,y)\n    losses.append(loss)\n    grad_w, grad_b = gradient(X_, y_pred, y)\n    \n    #权重更新\n    W = W - grad_w * learning_rate\n    b = b - grad_b * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125735.png)\n\n\n```python\nn_hidden = 10 #设计隐藏神经元个数（可修改）\nW1 = np.random.randn(n_features, n_hidden)  # 维度 n_features * n_hidden\nb1 = np.zeros(n_hidden)                     # 维度 1 * n_hidden\nW2 = np.random.randn(n_hidden, 1)           # 维度 n_hidden * 1\nb2 = np.zeros(1)                            # 维度1\n```\n\n## 训练(加激活函数)\n\n\n```python\n# 训练\nlosses = []\nfor t in range(epoch):\n    #向前传播\n    y_pred1 = Linear(X_, W1, b1)     # 维度 n * n_hidden\n    y_relu = relu(y_pred1)           # 维度 n * n_hidden\n    y_pred = Linear(y_relu, W2, b2) # 维度 n * 1\n    \n    #计算损失函数\n    loss = MSE_loss(y_pred, y)\n    losses.append(loss)\n    \n    #反向传播，求梯度\n    grad_y_pred = y_pred - y                 # 维度n*1\n    grad_w2 = y_relu.T.dot(grad_y_pred) / n  # 维度n_hidden*1\n    grad_b2 = np.mean(grad_y_pred, axis = 0) # 维度1*1\n    grad_relu = grad_y_pred.dot(W2.T)        # 维度n*n_hidden\n    #注意：y_pred1与relu直接相关\n    grad_relu[y_pred1 < 0] = 0\n    grad_w1 = X_.T.dot(grad_relu) / n        # 维度n_features* n_hidden\n    grad_b1 = np.mean(grad_relu, axis = 0)   # 维度n_hidden*1\n    \n    #更新梯度\n    W1 = W1 - grad_w1 * learning_rate\n    b1 = b1 - grad_b1 * learning_rate\n    W2 = W2 - grad_w2 * learning_rate\n    b2 = b2 - grad_b2 * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125832.png)\n\n参考文档\n\n[波士顿房价数据集解读](https://blog.csdn.net/appleyuchi/article/details/84998894)\n","tags":["numpy","线性回归"],"categories":["project实战"]},{"title":"奥卡姆剃刀","url":"/2020/07/15/0/","content":"任何一件事情，都要从简单的开始做起，若无必要，勿增实体！\n\n![img](https://gitee.com/wxler/blogimg/raw/master/imgs/20200715105539.jpg)\n","categories":["Life"]},{"title":"git基本使用方法","url":"/2020/06/17/115900/","content":"由于平时写代码和博客常常用到git和github，每次用到都去百度，感觉太麻烦了，也大大降低了效率，索性自己整理一下常用到的git指令和使用方法，对git的使用能有一个系统的认识。这里只介绍一下基本用法，对更高级的用法如果以后用到再进行补充。\n<!-- more -->\n\n## git安装和配置\ngit的安装和配置在我的这篇[搭建个人博客](https://wxler.github.io/2020/06/01/hexoCreateAndConfig/#%E5%AE%89%E8%A3%85git)里，请自行参考配置，主要有一下几点：\n- 下载安装git程序\n- 配置github账户\n- 配置SSH KEY\n## git工作原理\nGit是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。Git在执行更新操作时，更像是对数据的一组快照，每次你提交更新，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git不再重新存储该文件，而是只保留一个链接指向之前存储的文件。  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125501.png)\n如上图所示，在version2中的B即是因为File B没有改变，所以直接存储了一个指向FileB的链接。只有修改了的文件才会产生一个新的文件，覆盖原来的文件。\ngit的工作原理/流程如下:  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125536.png)\n\n- Workspace：工作区(本地目录文件)\n- Index / Stage：暂存区/缓存区\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n## 基本操作\n\n### 初始化仓库\n仓库的初始化有两种方式：一种是直接从远程仓库克隆，另一种则是直接从当前目录初始化。远程初始化命令在[从远程仓库获取](#从远程仓库获取)，本地初始化命令的方法是首先创建一个文件夹，我命名为mygit，然后执行如下命令：  \n```bash\n$ git init\n```\n执行完毕后，当前目录下会出现一个隐藏的.git文件夹，git所需的数据和资源都放在改目录中。\n\n### 查看仓库状态\n\n通过`git status`来查看仓库状态，执行效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125612.png)\n可以看到nothing to commit，表示本地工作区没有要提交的文件，我们再创建一个one.txt的文件，然后在执行`git status`，效果如下： \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130149.png)\n从结果Untracked files可以看到，one.txt还没有被add到暂存区。\n\n### 添加文件到暂存区\n\n`git add`命令可以将一个文件添加到暂存区,执行如下命令将one.txt添加到暂存区：\n```bash\ngit add one.txt\n```\n将one.txt添加到暂存区后，再次执行`git status`,可看到如下效果：  ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125701.png)\n从Changes to be committed可以看出，one.txt已被添加到暂存区，但还未被添加到本地仓库。\n\n### 提交到本地仓库\n\n当文件提交到暂存区之后，执行`git commit`命令将当前暂存区的文件提交到本地仓库，执行如下命令：\n```bash\ngit commit -m '新增一个one.txt'\n```\n-m是指将当前暂存区的文件提交到本地仓库的时候，加上提交备注/说明，再次执行`git status`,可以看到已经没有要add或commit的文件了。这里要强调一下，如果直接执行`git commit`命令，会自动打开一个vi编辑器，在里面输入备注/说明即可。此外，当我们提交成功后，还可以通过`git commit --amend  `修改备注信息。\n### 查看更改前后的差异\n使用`git diff`命令可以查看**工作区和暂存区的区别**，在one.txt里面写入一行hello world，然后执行`git diff`命令，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130230.png)\n根据结果可以看到新增了一行hello world，如果我们要比较**工作区与最新本地版本库的区别**，可以执行`git diff HEAD`，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130230.png)\n\n### 查看提交历史\n\n使用`git log`查看提交历史，我们首先将工作区的内容提交到本地仓库，执行`git add one.txt`将更改后的one.txt添加到暂存区，执行` git commit -m '添加了一行hello world'`将暂存区的内容提交到本地仓库，然后执行`git log`，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125804.png)\n\n## git撤销修改\n\n### 工作区的代码撤销\n\n使用`git checkout`撤销工作区的代码。我们先向one.txt添加一行hello everyone，执行`cat one.txt`查看内容，再执行`git checkout -- one.txt`撤销之前的操作，让one,txt恢复之前的状态，然后执行`cat one.txt`再次查看内容，效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125909.png)  \n可以看到，工作区的内容已经被修改,这时候本地文件刚刚添加的内容就被撤销了。\n\n### 暂存区的代码撤销\n\n使用`git reset HEAD`撤销暂存区的代码。首先在one.txt添加一行hello people，执行`git add one.txt`将更改的内容提交到暂存区，`git reset HEAD`来撤销暂存区的代码，如下图：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130403.png)\n撤销暂存区的代码之后，如需要将代码添加到暂存区，则需要再次执行`git add`命令\n\n### 本地仓库的代码撤销\n\n可以使用`git reset --hard <版本号>`来撤销本地仓库的代码，版本号有几种不同的写法：\n1. 可以使用HEAD^来描述版本，一个^表示前一个版本，两个^^表示前两个版本，以此类推。\n2. 也可以使用数字来代替^，比如说前100个版本可以写作HEAD~100。\n3. 也可以直接写版本号，表示跳转到某一个版本处。我们每次提交成功后，都会生成一个哈希码作为版本号，所以这里我们也可以直接填版本号，哈希码很长，但是我们不用全部输入，只需要输入前面几个字符即可，就能识别出来。执行`git log`后那一串长符号就是哈希码版本号。\n\n依次执行如下命令：\n```bash\n$ git add 'one.txt'\n$ git commit -m '添加一行hello people'\n$ git reset --hard head^\n```\n执行`git reset --hard head^`后的效果如下：\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130427.png)  \n可以从结果看出，前半部分816b208是执行撤销操作以后，当前版本的版本号前七位，后半部分是该版本的备注，可以用`git log`来查看不同版本的版本号和备注。  \n\n再次查看本地one.txt文件，发现本地目录的刚刚添加的内容已经没有了，如需要再次提交到本地仓库，则可执行`git add`和`git commit`命令。**需要注意的是，当撤销到最开始版本的时候，`git reset --hard head^`就不能再用了，否则会报如下的错误：**  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130454.png)\n\n## git分支管理\n\n### 查看分支\n通过`git branch`来查看当前仓库有哪些分支和我们处于哪一分支中，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130516.png) \n可以看到，当前本地仓库只有一个master分支，这是git默认创建出来的，master前面的\\*表示我们当前处于这一个分支中。\n\n### 分支创建和切换\n可以利用`git branch <分支名>`来创建一个分支，利用`git checkout <分支名>`来切换分支，如下所示： \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130558.png)\n\n### 分支合并\n\n由于math分支是从master分支中创建出来的，所以此时math分支的内容和master分支的内容是一致的，现在，我们在math分支向one.txt添加一行hello branch math(由于刚刚执行了[本地仓库的代码撤销](#本地仓库的代码撤销)，所以one.txt现在的内容是空白的)，此时math分支的one.txt和math分支的one.txt就不同了，具体效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130558.png)  \n执行完毕后，我们也可以在本地查看，先在math分支下，打开one.txt可以看到我们刚刚添加的内容，然后再切换到master分支，再从本地打开one.txt文件，就看不到内容了。\n**可以通过`git merge <分支名>`合并分支**，先切换到master分支，然后执行` git merge math`合并math分支到master分支上，效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130633.png)  \n可以看到再次在master分支下查看one.txt，就可以显示math分支的内容了。\n\n通常合并分支时，git一般使用”Fast forward”模式，fast-forward方式表示当条件允许时，git直接把HEAD指针指向合并分支的头，完成合并，这种方式合并速度快，但是在整个过程中没有创建commit。在这种模式下，删除分支后，会丢掉分支信息，可使用带参数 `–no-ff`来禁用”Fast forward”模式，即删除时可以实用`git merge --no-ff <分支名>`\n\n### 以图表方式查看分支\n可以用`git log --graph`命令来直观的查看分支的创建和合并等操作，合并math和master分支前的效果如下： \n    ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130807.png)\n合并math和master分支后的效果如下：   \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130807.png)\n\n### 解决冲突\n\n我们创建一个新的分支dev,并在dev分支下给one.txt添加一行12345，然后提交，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130943.png)  \n同样，我们现在切换到master分支上来，也在one.txt添加一行内容，内容为56789，并提交，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130943.png)  \n现在，我们将dev分支合并到master上来，如下所示：\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131003.png)  \n从结果中可以看出，=======之前是主分支的内容，=======之后是dev分支的内容，此时我们用文本编辑器修改one.txt的冲突然后提交即可，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131140.png)\n\n**分支策略：首先master主分支应该是非常稳定的，也就是用来发布新版本，一般情况下不允许在上面干活，干活一般情况下在新建的dev分支上干活，干完后，dev分支代码可以合并到主分支master上来。**\n\n## github远程仓库\n\n### 关联远程仓库\n在此之前我相信你已经配置SSH KEY，如果没有，可以参考我的这篇[搭建个人博客](https://wxler.gitee.io/2020/06/01/hexoCreateAndConfig/#git%E9%85%8D%E7%BD%AE)里进行配置，配置完成以后在github上创建一个仓库，这里命名为test，我们可以看到仓库的地址，例如：`https://github.com/wxler/test.git`。然后将我们之前的本地仓库和这个远程仓库进行关联，使用`git remote add`命令，如下：\n```bash\n$ git remote add origin https://github.com/wxler/test.git\n```\n### 推送到远程仓库\n把本地库的内容推送到远程，使用`git push -u origin master`命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了–u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令,不用加-u了,效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131213.png) \n推送成功后，可以立刻在github页面中看到远程库的内容已经和本地一模一样了。从现在起，只要本地作了提交，就可以通过命令：`git push origin master`把本地master分支的最新修改推送到github上了，现在你就拥有了真正的分布式版本库了。  \n**我们一般不把其它分支推送到远程仓库，master主分支是最稳定的版本，一般情况下不允许在上面干活，干活一般情况下在新建的分支上干活，干完后，把分支代码可以合并到主分支master上来。**当然，你也可以将其它分支推送到远程仓库，可以执行如下命令：\n\n```bash\n$ git checkout fa\n$ git push -u origin fa\n```\n### 从远程仓库获取\n我们可以通过git clone命令克隆一个远程仓库到本地,方式也简单，在本地创建一个空文件夹，执行如下命令：\n```bash\n$ git clone https://github.com/wxler/test.git\n```\n此时克隆的是master分支到本地仓库，我们可以通过`git branch -a`来查看本地仓库和远程仓库的信息，-a参数可以同时显示本地仓库和远程仓库的信息，如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131310.png)\n我们也可以把远程仓库其它分支的内容clone下来，可以执行如下命令：\n\n```bash\n$ git branch fa origin/dev\n$ git checkout dev\n```\n上面的指令表示根据远程仓库的dev分支创建一个本地仓库的dev分支，然后再切换到dev分支，**注意由于dev分支就是从远程仓库克隆下来的，所以这里可以不添加-u参数。**\n\n### 从远程仓库更新\n使用`git pull`获取远程仓库最新的代码和数据，例如，我们可以通过以下代码将远程主机的master分支最新内容拉下来后与当前本地分支直接合并\n```bash\ngit pull origin master\n```\n\n## git命令大全\ngit常用命令速查表，方便查阅：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131337.png)\n\n## 遗留问题\n\n到现在，我们就可以使用git的大多数操作了，但是还有git的一些操作平常没有用到，我也就不主动去一个个试了，毕竟一口吃不成胖子，查了也记不住，就不自找苦吃了，遗留的问题主要有：\n- git分支衍合\n- git标签管理\n- bug分支&stash功能\n\n## 参考文档\n[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)\n[Git从入门到熟练使用](https://www.jianshu.com/p/34cfe097e06a)\n[史上最简单Git入门教程](https://www.cnblogs.com/jjlee/p/10305194.html)\n[git命令大全](https://www.jianshu.com/p/46ffff059092)\n\n>特别声明：本篇博客只做个人学习交流和参考手册使用，不作任何商业目的，内容上较多参考了[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)，根据自己实际应用进行删减，并加上了自己的理解和补充，如有侵权，请联系博主本人删除。","tags":["git"],"categories":["git使用"]},{"title":"使用hexo平台从0搭建个人博客","url":"/2020/06/01/122000/","content":"搭建这个博客，花费了我不少时间，这期间我遇到各种各样的问题，这些问题本可以避免，因操作不规范、对指令代码的不理解、网络不稳定、配置上的错误，使得最后暴露出来的各种bug很不容易解决。前前后后我也重新搭建了三次，经历了心态上的各种起伏。为此，我记录下我制作的过程，让想和我一样自建博客的人少走一些弯路。\n\n我使用的hexo博客框架，stun主题，搭建环境和过程可分为几个部分:\n\n1. 安装git\n2. 安装nodejs\n3. 安装hexo\n4. hexo搭桥github\n5. hexo-admin使用\n6. npm&hexo常用命令\n<!-- more -->\n\n## 安装git\n\n### git下载\n下载[git](https://git-scm.com/download)，双击安装，然后一直next，按键Ctrl+r，然后在弹出框中出入cmd，在弹出的界面输入git，回车,出来一大串命令符就代表安装成功了。可以使用git version查看自己的git版本。\n\n### git配置\n\n1. git安装好去GitHub上注册一个账号，注册好后，桌面空白地方右键选择Git Bash，要git账户进行环境配置  \n```bash\n//usename是用户名\ngit config --global user.name \"username\"\ngit config --global user.email \"username@email.com\"\n```\n2. 当以上命令执行结束后，可用 `git config --global --list` 命令查看配置是否OK  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133328.png)\n3. 在命令框中输入命令`ssh-keygen -t rsa`，连敲三次回车键，结束后去系统盘目录下（一般在 C:\\Users\\你的用户名.ssh）(mac: /Users/用户/.ssh）查看是否有。ssh文件夹生成，此文件夹中以下两个文件  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133402.png)\n4. 将ssh文件夹中的公钥（ id_rsa.pub）添加到GitHub管理平台中，在GitHub的个人账户的设置中找到如下界面，title随便起一个，将公钥（ id_rsa.pub）文件中内容复制粘贴到key中，然后点击Ass SSH key  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133430.png)\n5、测试一下配置是否成功，在Git Bush命令框（就是刚才配置账号和邮箱的命令框）中继续输入命令`ssh -T git@github.com`，回车,出现如下界面即说明成功  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133448.png)\n\n## 安装nodejs\n\nHexo是基于nodeJS环境的静态博客，里面的npm工具很有用。下载[nodejs](https://nodejs.org/en/)，(说明：LTS为长期支持版，Current为当前最新版)，下载后一路next进行安装，在git bash下使用node -v查看版本。\n\n## 安装hexo\n\n我建议先看一下npm&hexo常用命令部分，了解命令的结构和大体含义之后，在配置的过程中可以避免很多错误，少走很多弯路。  \n执行 `npm config list`查看当前的配置，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133516.png)\n可以看到，最初的镜像地址是官方的npm镜像，我最初使用的就是这个配置，执行起来很不稳定，导致大多数错误都是网络问题导致的,执行如下命令,切换淘宝镜像\n\n```bash\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\nnpm config set registry https://registry.npm.taobao.org\n```\n接下来，就可以安装hexo了，执行`npm install -g hexo-cli`或`npm install -g hexo`，如果之前安装失败，可以先执行`npm uninstall hexo-cli -g`或`npm uninstall hexo -g` 卸载hexo，再进行安装，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133610.png)\n查看版本信息` hexo v`  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133628.png)\n初始化hexo,执行 `hexo init myblog`，然后`cd myblog`，再次执行`hexo v`，就可以看到hexo的版本：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133657.png)  \n打开myblog文件夹，我们可以看到hexo的结构\n\n> * node_modules：是依赖包\n> * public：存放的是生成的页面\n> * scaffolds：命令生成文章等的模板\n> * source：用命令创建的各种文章\n> * themes：主题\n> * _config.yml：整个博客的配置\n> * db.json：source解析所得到的\n> * package.json：项目所需模块项目的配置信息  \n\n\n到这里我们的hexo博客就安装完成啦，只有搭桥到github,才能进行部署。\n\n## hexo搭桥github\n\n创建一个repo，名称为yourname.github.io,其中yourname是你的github名称，按照这个规则创建才有用，这个仓库就是存放你博客的地方。\n1. 用编辑器打开你的blog项目，修改_config.yml  \n```text\ndeploy:  \n\ttype: git\n\trepo:https://github.com/YourgithubName/YourgithubName.github.io.git\n\tbranch: master\n```\n2. 回到gitbash中，进入你的blog目录，分别执行以下命令：\n```bash\nhexo clean\nhexo generate\nhexo server\n```\n需要注意的是，hexo 3.0把服务器独立成个别模块，需要单独安装：`npm i hexo-server`\n3. 打开浏览器输入：`http://localhost:4000`\n4. 先安装一波：`npm install hexo-deployer-git --save`（这样才能将你写好的文章部署到github服务器上并让别人浏览到） \n5. 执行命令\n```bash\nhexo clean\nhexo generate\nhexo deploy\n```\n6. 在浏览器中输入`http://yourgithubname.github.io`就可以看到你的个人博客啦。\n\n我使用的主题是stun，如果大家也想使用这个主题，可以到[ hexo-theme-stun](https://liuyib.github.io/hexo-theme-stun/zh-CN/)查阅配置。\n\n\n## hexo-admin使用\n\n\n用原生的方法来管理博文十分的不便，因此便有了Hexo Admin这一插件来方便我们的操作。执行`npm install --save hexo-admin`安装hexo-admin，安装成功后，在`http://localhost:4000/admin`就可以访问hexo-admin页面。\n详细情形我就不多说了，推荐大家到[hexo博客使用hexo-admin插件管理文章](https://blog.csdn.net/nineya_com/article/details/103380243?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)，这位作者的[hexo-admin插件windows系统插入图片失败问题](https://blog.csdn.net/nineya_com/article/details/103384546)修复了windows下粘贴图片的裂图和显示功能，我使用起来非常好，推荐大家看看。\n\n除此之外，我还要强调一点，hexo-admin创建文章的时候，首先创建英文名，再在里面编辑成中文，这样你的文章显示的链接就不会带有中文了。hexo-admin的文章只有未发布状态才能删除，并且删除后在source/_discarded文件夹，未发布变成draft,发布直接到post。\n\n## npm&hexo常用命令\n### npm&cnpm介绍\nnpm（node package manager）：nodejs的包管理器，用于node插件管理（包括安装、卸载、管理依赖等），使用`npm -v`查看版本信息。\n\ncnpm:因为npm安装插件是从国外服务器下载，受网络的影响比较大，可能会出现异常，如果npm的服务器在中国就好了，所以我们乐于分享的淘宝团队干了这事。来自官网：“这是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步”，更多详情可以查看[淘宝 NPM 镜像](https://developer.aliyun.com/mirror/NPM?from=tnpm)，使用`cnpm -v`查看版本信息。\n\n\nnpm和cnpm安装命令一样，只不过是多了一个c。\n\n### npm命令\n使用npm命令首先要设置下载的镜像，模式是npm官网的镜像(服务器在国外)，建议设置国内的淘宝镜像,设置以后我们就可以用npm从淘宝镜像下载数据了  \n永久使用：  \n`npm config set registry https://registry.npm.taobao.org`  \n临时使用：  \n`npm install node-sass --registry=http://registry.npm.taobao.org`  \n还有个清除缓存命令，可以解决些奇怪的问题:  \n`npm cache clean --force`  \n查看已安装的npm插件，这个命令很实用，可以查看缺少哪些插件  \n`npm ls --depth 0`   \n可以通过定制的 cnpm 命令行工具代替默认的 npm  \n`npm install -g cnpm --registry=http://registry.npm.taobao.org`  \n**在使用过程中要么用npm，要么用cnpm，不能混用**  \n查看当前的配置命令`npm config list `,操作之前一定要先查看配置再进行操作。  \n**下面需要强调后缀参数的作用和区别**  \n`npm install packagename --save 或 -S`    \n--save、-S参数意思是把模块的版本信息保存到dependencies（生产环境依赖）中，即你的package.json文件的dependencies字段中。  \n`npm install packagename --save-dev 或 -D`  \n--save-dev 、 -D参数意思是吧模块版本信息保存到devDependencies（开发环境依赖）中，即你的package.json文件的devDependencies字段中。  \n`npm install packagename -g 或 --global`  \n安装全局的模块（不加参数的时候默认安装本地模块），\n**使用npm安装插件的时候一定要加上--save添加依赖，否则容易出错** ，更多关于npm详情，请点击[npm常用命令及参数详解](https://segmentfault.com/a/1190000012099112?utm_source=tag-newest)\n\n### hexo命令\n\n`hexo init`  \n初始化站点，生成一个简单网站所需的各种文件。\n\n`hexo clean == hexo c`  \n清除缓存 网页正常情况下可以忽略此条命令\n\n`hexo generate == hexo g`  \n生效新增、修改、更新的文件\n\n`hexo server == hexo s`  \n启动本地网站，可在本地观察网站效果，同时也可以输入`http://localhost:4000/admin`管理文章\n\n`hexo s --debug`  \n以调试模式启动本地网站，在此模式下，对文件的更改无需停止网站只需刷新即可看到效果，调试非常方便\n\n\n`hexo clean && hexo s`  \n一次执行两个命令\n\n`hexo deploy == hexo d`  \nhexo的一键部署功能，执行此命令即可将网站发布到配置中的仓库地址，执行此命令前需要配置站点配置文件_config.yml","tags":["hexo"],"categories":["工具"]}]