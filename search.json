[{"title":"Linux进程管理命令nohup、&、jobs、fg、bg、ps、kill","url":"/2021/02/10/115802/","content":"\n对Linux进程的管理是我们经常遇到的，如何查看一个进程的状态？如何把一个后台的进程调至进程执行？如何杀死一个进程......看了本文后，你将会全部掌握！\n<!-- more -->\n\n\n\n## 1. nohup\n\nnohup的用法：\n\n- 用途：不挂断地运行命令。\n- 语法：`nohup Command [ Arg … ] [　& ]`\n  - 在默认情况下（非重定向时），会输出一个名叫 nohup.out 的文件到当前目录下。\n  - 如果当前目录的 nohup.out 文件不可写，输出重定向到 `$HOME/nohup.out` （`$HOME`为用户主目录）文件中。\n  - 如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。\n- 参数说明：\n  - Command：要执行的命令。\n  - Arg：一些参数，可以指定输出文件。\n  - &：让命令在后台执行，终端退出后命令仍旧执行。\n\n\n\n现在，来尝试一下！\n\n创建my.sh文件，文件内容如下：\n\n```bash\n#!/bin/bash\necho  \"hello\"\necho  \"----------\"\nsleep  20  #休眠20s\necho  \"world\"\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x my.sh  # 给my.sh增加执行权限\n[root@layne bashdir]# nohup ./my.sh &\n[1] 2064  #这个2064就是my.sh进程的id\n[root@layne bashdir]# nohup: ignoring input and appending output to `nohup.out' #看到这个信息说明运行成功，再按一下回车即可回到当前shell命令行\n\n[root@layne bashdir]# cat nohup.out\nhello\n----------\n[root@layne bashdir]# cat nohup.out #等待20s再次查看\nhello\n----------\nworld\n[1]+  Done                    nohup ./my.sh\n```\n\n以下命令在后台执行 my.sh 脚本，并重定向输入到 my.log 文件：\n\n```bash\nnohup ./my.sh > my.log 2>&1 &\n```\n\n解释**`2>&1`** ：将标准错误 2 重定向到标准输出 &1 ，标准输出 &1 再被重定向输入到 my.log 文件中。这样无论正确的输出，还是错误的输出都将重定向到my.log文件中。\n\n## 2. &\n\n`&`用在一个命令的最后，可以把这个命令放到**后台执行**，可以输入jobs 查看后台执行的命令。如下所示：\n\n```bash\n[root@layne bashdir]# sleep 30 & #休眠30s，并放在后台执行\n[1] 2156\n[root@layne bashdir]# jobs  # 查看后台的进程\n[1]+  Running                 sleep 30 &\n```\n\n\n\n## 3. jobs\n\njobs命令用于查看正在执行的后台进程，但只能看当前终端生效的进程，如果关闭当前终端后，在另一个终端下，`jobs`已经无法看到后台跑得程序了，此时利用ps（进程查看命令）。\n\njobs的选项如下：\n\n```tex\n-l：显示进程号；\n-p：仅任务对应的显示进程号；\n-n：显示任务状态的变化；\n-r：仅输出运行状态（running）的任务；\n-s：仅输出停止状态（stoped）的任务。\n```\n\njobs命令一般和`-l`搭配使用，可以显示后台执行进程的进程号。\n\n这里介绍一些常见的快捷键和进程命令：\n\n- `ctrl+c` 停止当前正在执行的进程，相当于直接kill掉。\n- `ctrl+z` 将当前正在执行的进程放到后台，并且暂停执行，此时进程处于stop状态。\n- `fg` **将后台中的进程调至前台继续运行**。如果后台中有多个命令，可以用`fg %jobnumbe`将选中的命令调出，`%jobnumber`是通过jobs命令查到的后台任务的编号，不是进程的pid号。\n- `bg`  **将一个在后台暂停的命令**，变成继续执行。如果后台中有多个命令，可以用`bg %jobnumber`将选中的命令调出。\n\n我们首先看看`jobs -l`输出的信息：\n\n```bash\n[root@layne bashdir]# sleep 30 &\n[2] 2157\n[1]   Done                    sleep 30\n[root@layne bashdir]# jobs -l\n[2]+  2157 Running                 sleep 30 &\n```\n\n上面`jobs -l`输出4列信息，第一列表示任务编号（jobnumber），第二列表示任务所对应的进程号（pid)，第三列表示任务的运行状态，第四列表示启动任务的命令。\n\n现在，我们多启动几个后台进程，让它们处于不同的状态，并用`fg`和`bg`命令调用它们到前台执行：\n\n```bash\n[root@layne bashdir]# sleep 60  #执行后，按下ctrl+z将该进程放置后台，并暂定执行\n^Z\n[1]+  Stopped                 sleep 60\n[root@layne bashdir]# sleep 40 &   # 让该进程放到后台执行\n[2] 2159\n[root@layne bashdir]# nohup ./my.sh &\n[3] 2160\n[root@layne bashdir]# nohup: ignoring input and appending output to `nohup.out'\n\n[root@layne bashdir]# jobs -l\n[1]+  2158 Stopped                 sleep 60\n[2]   2159 Running                 sleep 40 &\n[3]-  2160 Running                 nohup ./my.sh &\n[root@layne bashdir]# fg  # 等待60s，可以看到另外两个进程也执行完了，如果这里使用fg 2，则将任务号为2的进程调至前台执行\nsleep 60\n[2]   Done                    sleep 40\n[3]-  Done                    nohup ./my.sh\n```\n\n从上述执行过程会发现，输入`jobs -l`后，任务号（jobnumber）后面有 `+` 和 `-` 两个标志，其中，`+` 代表我们输入fg或bg的时候，将该进程调至前台执行。当我们把带有`+`的进程调至前台执行后，`-`标志的进程就自动变成`+`了，下次我们再执行fg或bg，就会调用`-`变为`+`的那个进程了。\n\n这里不用纠结 `fg` 和 `bg` 的区别，fg是将后台中的进程调至前台继续运行，bg将一个在后台暂停的命令变成继续执行。我在使用过程中，并没有很在意，不过用的最多的还是`fg`命令。\n\n\n\n## 4. ps\n\nps命令用于查看当前系统运行的进程信息。\n\n常用选项：\n\n- a ： 显示所有程序\n- x ：显示所有程序，不区分终端机\n- u ：以用户为主的格式来显示\n- `-f` 显示程序间的关系\n- `-e` 显示所有程序\n\n**常用组合 :**\n\n`ps aux` 观察系统所有的进程数据\n\n`ps -ef` 显示所有进程基本信息（比`aux`较简略一些）\n\n示例：\n\n```bash\n[root@layne bashdir]# nohup ./my.sh &\n[1] 2179\n[root@layne bashdir]# nohup: ignoring input and appending output to `nohup.out'\n\n[root@layne bashdir]# ps aux | grep my.sh  # 查看包含my.sh进程的信息\nroot       2179  0.0  0.1 106072  1332 pts/0    S    21:06   0:00 /bin/bash ./my.sh\nroot       2184  0.0  0.0 103256   872 pts/0    S+   21:07   0:00 grep my.sh\n[root@layne bashdir]# ps aux | head -5  # 查看当前系统所有正在执行进程的前5条\nUSER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot          1  0.0  0.1  19232  1424 ?        Ss   10:08   0:01 /sbin/init\nroot          2  0.0  0.0      0     0 ?        S    10:08   0:00 [kthreadd]\nroot          3  0.0  0.0      0     0 ?        S    10:08   0:00 [migration/0]\nroot          4  0.0  0.0      0     0 ?        S    10:08   0:00 [ksoftirqd/0]\n```\n\n上述输出的含义：\n\n- USER：该 process 所属的使用者。\n- PID ：该 process 的进程标识符。  \n- %CPU：该 process 使用掉的 CPU 资源百分比。\n- %MEM：该 process 所占用的物理内存百分比。\n- VSZ ：该 process 使用掉的虚拟内存量 (Kbytes) 。\n- RSS ：该 process 占用的物理的内存量 (Kbytes) 。\n- TTY ：该 process 是在哪个终端机上面运作，若与终端机无关则显示 `?`。另外，tty1-tty6 是本机上面的登入者程序，若为 pts/0 等，**则表示为由网络连接进主机的程序**。 \n- STAT：该进程目前的状态，状态显示与`ps -l`的 S 旗标相同 (R/S/D/T/Z) \n- START：该 process 被触发启动的时间\n- TIME ：该 process 实际使用 CPU 运作的时间。 \n- COMMAND：该程序的实际命令\n\n\n\n## 5. kill\n\nkill命令用于杀死进程，主要有两个选项：\n\n- `kill -9 pid` （见人就杀，不做善后工作）\n- `kill -15 pid` （调用destory等方法善后）\n\n**优先使用 `-15`选项，因为`-15`温柔一些，会做一些善后的处理（比如释放所占用的资源），如果使用`-15`无法杀死进程，再用`-9` 选项**\n\n一般情况下，先用ps命令查找要杀死进程的pid，再用kill命令杀死进程，例如：\n\n```bash\n[root@layne bashdir]# sleep 30 &\n[1] 2194\n[root@layne bashdir]# ps -aux | grep sleep\nWarning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQ\nroot       2194  0.0  0.0 100916   620 pts/0    S    21:16   0:00 sleep 30\nroot       2196  0.0  0.0 103256   864 pts/0    S+   21:16   0:00 grep sleep\n[root@layne bashdir]# kill -15 2194\n```\n\n\n\n\n\n【参考文档】\nhttps://ipcmen.com/jobs\nhttps://www.runoob.com/linux/linux-comm-nohup.html\nhttps://www.linuxprobe.com/linux-nohup.html\nhttps://blog.csdn.net/u011630575/article/details/48288663\n\n\n\n\n\n\n","tags":["Linux"],"categories":["Linux"]},{"title":"Linux中的bash语法详解","url":"/2021/02/10/111447/","content":"\nLinux中的bash语法，主要介绍bash的io、变量、分支、循环等基本操作。\n<!-- more -->\n\n@[TOC](文章目录)\n\n\n\n\nshell就是一个bash程序（进程），就是一个解释器，启动器\n\n脚本本质：\n\n- #!/bin/bash\n- #!/usr/bin/python\n\n上面的不是普通的注释，是你用`./`执行的时候，默认走的哪一个解释器\n\n用`bash test.sh`执行的时候，是不看第一行的`#!/bin/bash`或`#!/usr/bin/python` ，直接用bash解释器。\n\n同样的，用`sh test.sh`执行的时候也一样，其直接用sh解释器。\n\n但是，用`./ test.sh`执行的时候，要看第一行，然后选择走哪一个解释器。\n\n脚本读取（或解释执行）方式常用的有五种：\n\n- `bash filename`\n- `sh filename`\n- `./filename`\n- `source filename `\n- `. filename`\n\n说明： `./*.sh`的执行方式等价于`sh ./*.sh`或者`bash ./*.sh`，**此三种执行脚本的方式都是重新启动一个子shell，在子shell中执行此脚本。**\n\n`source ./*.sh`和 `. ./*.sh`的执行方式是等价的，即两种执行方式都是在当前shell进程中执行此脚本，而不是重新启动一个子shell执行。\n\n一个重要的点：**父shell进程中没有被export导出的变量（即非环境变量）是不能被子shell进程继承的，但是在父进程中被export的变量可以被子shll进程使用。子shell进程中的所有变量（无论是否被export）都不能被父进程使用**\n\n\n\n## 1. bash基本使用\n\n```bash\n[root@layne ~]# bash  # 启动一个新的bash进程，该bash进程为之前bash的子进程\n[root@layne ~]# echo $$  # 打印当前bash的PID\n1852\n[root@layne ~]# pstree -p # 打印进程树，并显示进程id\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1030)───bash(1219)───bash(1852)───pstree(1862)\n        └─udevd(354)───udevd(640)\n[root@layne ~]# exit # （第一次输入exit，退出当前bash，再输入exit会退出ssh连接的bash，即就断掉连接了）\nexit\n[root@layne ~]# echo $$\n1219\n[root@layne ~]# pstree -p\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1030)───bash(1219)───pstree(1863)\n        └─udevd(354)───udevd(640)\n```\n\n可以看到，当我们用ssh连接虚拟机时，会启动`sshd`进程，进入bash命令行界面后，会启动`bash`进程，这个bash进程是sshd进程的子进程，当我们在命令行中输入`bash`会启动一个新的bash进程，这个新的bash进程是之前bash进程的子进程。\n\n现在我们来验证：**父shell进程中没有被export导出的变量（即非环境变量）是不能被子shell进程继承的，但是在父进程中被export的变量可以被子shll进程使用。**\n\n```bash\n[root@layne ~]# name=layne\n[root@layne ~]# age=24\n[root@layne ~]# echo \"$name,$age\"\nlayne,24\n[root@layne ~]# export name\n[root@layne ~]# bash\n[root@layne ~]# echo \"$name,$age\"\nlayne,\n```\n\n可以看到，在子进程的bash，只能输出被export导出的变量（即环境变量），不能输出普通变量。\n\n还有一个重要点：**子shell进程中的所有变量（无论是否被export）都不能被父进程使用**。验证如下：\n\n```bash\n[root@layne bashdir]# GH=lazz\n[root@layne bashdir]# export GH\n[root@layne bashdir]# echo $GH\nlazz\n[root@layne bashdir]# exit\nexit\n[root@layne bashdir]# echo $GH #输出空\n\n```\n\n\n\n另外，在`.sh`文件的开头一般输入下列中的一个：\n\n```bash\n#!/bin/bash\n#!/usr/bin/python\n#!/bin/awk -f\n```\n\n用于指定该脚本由哪个程序负责解释执行。\n\n现在我们创建两个文件mysh.sh和mysh1.sh，这两个文件内容分别为：\n\nmysh.sh内容\n\n```bash\n#!/bin/bash\necho \"hello mysh\"\necho $$\n```\n\nmysh1.sh内容\n\n```bash\n#!/bin/bash\necho \"hello mysh1\"\necho $$\npstree -p\n```\n\n下面是执行过程：\n\n```bash\n[root@layne bashdir]# ll\ntotal 8\n-rwxr-xr-x 1 root root 49 Feb  9 16:27 mysh1.sh\n-rwxr-xr-x 1 root root 39 Feb  9 16:27 mysh.sh\n[root@layne bashdir]# chmod -x mysh.sh  # 清除执行权限\n[root@layne bashdir]# chmod -x mysh1.sh\n[root@layne bashdir]# ll\ntotal 8\n-rw-r--r-- 1 root root 49 Feb  9 16:27 mysh1.sh\n-rw-r--r-- 1 root root 39 Feb  9 16:27 mysh.sh\n[root@layne bashdir]# source mysh.sh\nhello mysh\n1219\n[root@layne bashdir]# source mysh1.sh\nhello mysh1\n1219\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1030)───bash(1219)───pstree(1890)\n        └─udevd(354)───udevd(640)\n[root@layne bashdir]# pstree\ninit─┬─auditd───{auditd}\n     ├─crond\n     ├─6*[mingetty]\n     ├─mysqld_safe───mysqld───27*[{mysqld}]\n     ├─ntpd\n     ├─rsyslogd───3*[{rsyslogd}]\n     ├─sshd───sshd───bash───pstree\n     └─udevd───udevd\n[root@layne bashdir]# ./mysh.sh\n-bash: ./mysh.sh: Permission denied\n[root@layne bashdir]# chmod +x mysh.sh\n[root@layne bashdir]# ./mysh.sh\nhello mysh\n1894\n[root@layne bashdir]# chmod +x mysh1.sh\n[root@layne bashdir]# ./mysh1.sh\nhello mysh1\n1898\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1030)───bash(1219)───mysh1.sh(1898)───pstree(1899)\n        └─udevd(354)───udevd(640)\n\n```\n\n可以发现：\n\n- 当前shell执行脚本：`source  mysh.sh` ，**不需要执行权限就可以执行**\n- 子进程执行：`bash mysh.sh`或者`./mysh.sh`，需要该文件具有可执行权限才能执行\n\n\n\n `.sh`文件中的函数格式为：\n\n```bash\nfunName() {\n  各种命令\n}\n```\n\n在下面的例子中会用到。\n\n\n\n## 2. bash的io\n\n程序自身都有I/O\n\n- 0：标准输入\n- 1：标准输出\n- 2：错误输出\n\n例如：\n\n```bash\nls / /hello 1> log.out 2> log.err\n```\n\n上面命令把正确的输出放在log.out里面，把错误的输出放在log.err里面。\n\n下面，我们看几个常用场景\n\n（1）输出重定向： 重定向从左到右绑定\n\n```bash\n# 命令1： 将错误输出（2）绑定到标准输出（1），此时标准输出先输出到控制台,然后才是标准输出重定向到文件。两个重定向的绑定没有关系，所以第二个标准输出1> mylog.log的数据仍然是正确的输出\nls  /  /hello   2>&1  1> mylog.log\n## 命令2：先让标准输出重定向到文件，然后将错误输出绑定到标准输出，也就是左边绑定的文件。\nls  /  /hello   1> mylog1.log  2>&1\n## 命令3：标准输出和错误输出都重定向到文件\nls  /  /hello   >& mylog2.log\n## 命令4：作用同命令3\nls  /  /hello  &> mylog3.log\n```\n\n\n\n（2）现在，我们创建rd.sh文件，内容如下：\n\n```bash\n#!/bin/bash\nread -p \"请输入一个整数：\" num\necho $num\nread -p \"再输入一个数：\"\necho $REPLY\n```\n\n执行结果：\n\n```bash\n[root@layne bashdir]# chmod +x rd.sh\n[root@layne bashdir]# ./rd.sh\n请输入一个整数：123\n123\n再输入一个数：45\n45\n```\n\n`sh -x rd.sh` 检查你写的脚本，执行到哪一步，把执行的过程打出来\n\n```bash\n[root@layne bashdir]# sh -x rd.sh\n+ read -p $'\\350\\257\\267\\350\\276\\223\\345\\205\\245\\344\\270\\200\\344\\270\\252\\346\\225\\264\\346\\225\\260\\357\\274\\232' num\n请输入一个整数：123\n+ echo 123\n123\n+ read -p $'\\345\\206\\215\\350\\276\\223\\345\\205\\245\\344\\270\\200\\344\\270\\252\\346\\225\\260\\357\\274\\232'\n再输入一个数：45\n+ echo 45\n45\n```\n\n（3）**将标准输入重定向到字符串，read读取后赋值给指定的变量：**\n\n```bash\n[root@layne bashdir]# read  aaa  0<<<\"hello\"  # 赋给变量aaa\n[root@layne bashdir]# echo $aaa\nhello\n```\n\n上面 `<<<`将标准输入重定向到字符串\n\n（4）`cat 0<<CATEOF`用在脚本中用于向控制台打印n行，比如：\n\n```bash\n[root@layne bashdir]# cat 0<<CATEOF\n> aaaaa\n> bbbbb\n> ccccc\n> CATEOF\naaaaa\nbbbbb\nccccc\n```\n\n创建catof.sh文件，内容为：\n\n```bash\n#!/bin/bash\ncat 0<<CATEOF\n这里有一个bug\n这个bug是index out of bounds exception\nCATEOF\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x catof.sh \n[root@layne bashdir]# ./catof.sh\n这里有一个bug\n这个bug是index out of bounds exception\n```\n\n（5）exec：使用指定的命令替换当前shell命令。\n\n以读写方式打开到`www.baidu.com`的80端口的tcp连接\n\n```bash\n[root@layne bashdir]# exec 8<> /dev/tcp/www.baidu.com/80 # 创建文件描述符8，并赋值\n[root@layne bashdir]# echo -e \"GET / HTTP/1.0\\n\" >&8  # 表示重定向到8文件描述符\n[root@layne bashdir]# cat <&8 # 从文件描述符8读取信息\nHTTP/1.0 200 OK\nAccept-Ranges: bytes\nCache-Control: no-cache\nContent-Length: 14615\nContent-Type: text/html\n...\n```\n\necho的`-e`选项含义为：激活转义字符。使用-e选项时，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出：\n\n- `\\a` 发出警告声；\n- `\\b` 删除前一个字符；\n- `\\c` 最后不加上换行符号；\n- `\\f` 换行但光标仍旧停留在原来的位置；\n- `\\n` 换行且光标移至行首；\n- `\\r` 光标移至行首，但不换行；\n- `\\t` 插入tab；\n- `\\v` 与`\\f`相同；\n- `\\\\` 插入`\\`字符；\n- `\\nnn` 插入nnn（八进制）所代表的ASCII字符；\n\n\n\n`echo -e \"GET / HTTP/1.0\\n\" >&8`  表示重定向到8文件描述符\n\n`cat <&8`   从文件描述符8读取信息\n\n\n\n## 3. bash的变量\n\n### 3.1 bash中变量的类型\n\n-\t本地变量\n-\t局部变量\n-\t位置变量\n-\t特殊变量\n-\t环境变量\n\n\n\n### 3.2 本地变量\n\n-\t当前shell所有\n-\t生命周期跟当前shell一样\n\n看下面的例子：\n\n```bash\n[root@layne bashdir]# a=99 # 定义一个变量\n[root@layne bashdir]# echo $a # 输出变量a\n99\n[root@layne bashdir]# myfunc() {\n>   myvar=99\n>   echo  $myvar\n> }\n[root@layne bashdir]# echo $myvar  #访问不到\n\n[root@layne bashdir]# myfunc  #调用函数\n99\n[root@layne bashdir]# echo $myvar    #可以访问到\n99\n[root@layne bashdir]# abc=sxt\n[root@layne bashdir]# echo $abc\nsxt\n[root@layne bashdir]# echo \"$abcisnothere\"  #访问不到\n\n[root@layne bashdir]# echo \"${abc}isnothere\" #可以访问\nsxtisnothere\n[root@layne bashdir]# echo \"$abc isnotthere\"\nsxt isnotthere\n[root@layne bashdir]# echo \"{$abc}isnotthere\"\n{sxt}isnotthere\n```\n\n\n\n### 3.3 局部变量\n\n-\t只能用于函数\n-\t`local var=100` 定义一个局部变量\n\n看例子：\n\n```bash\n[root@layne bashdir]# unset myvar # 取消变量\n[root@layne bashdir]# echo $myvar\n\n[root@layne bashdir]#  myfunc(){\n> local myvar=101\n> echo $myvar\n> }\n[root@layne bashdir]# echo $myvar #访问不到局部变量\n\n[root@layne bashdir]# \n\n```\n\n继续往下看：\n\n```bash\n[root@layne bashdir]# funa(){\n> a=1\n> local b=2\n> echo \"a = $a\"\n> echo \"b = $b\"\n> }\n[root@layne bashdir]# funa\na = 1\nb = 2\n[root@layne bashdir]# echo \"$a,$b\" #b访问不到\n1,\n```\n\n上面，a是本地变量，b是局部变量，本地变量生命周期跟当前shell一样，局部变量的声明周期在一个函数内，函数执行完，局部变量就消失了。\n\n### 3.4 位置变量\n\n直接看例子：\n\n```bash\n[root@layne bashdir]# myfun1(){\n> echo $1\n> }\n[root@layne bashdir]# myfun1  \n\n[root@layne bashdir]# myfun1 hello # hello为函数myfun1的参数\nhello\n[root@layne bashdir]# myfun2(){\n> echo $4\n> }\n[root@layne bashdir]# myfun2 a b c\n\n[root@layne bashdir]# myfun2 a b c d\nd\n[root@layne bashdir]# myfunc3(){\n> echo $13\n> }\n[root@layne bashdir]# myfunc3 1 2 3 4 5 6 7 8 9 a b c d e f\n13\n[root@layne bashdir]# myfunc3 a b c d 1 2 3 4 5 6 7 8 9\na3\n[root@layne bashdir]# myfunc3(){\n> echo ${13}\n> }\n[root@layne bashdir]# myfunc3 1 2 3 4 5 6 7 8 9 a b c d\nd\n```\n\n可以看到，`$n`为函数的第n个位置变量（第n个参数），`${13}`是函数的第13个参数，不能写为`$13`\n\n再来看一个例子，创建文件mysh1.h，内容如下：\n\n```bash\n#!/bin/bash\necho $1\necho $2\necho ${10}                     \n```\n\n执行结果：\n\n```bash\n[root@layne bashdir]# source mysh1.sh a b 1 2 3 4 5 6 7 8 9\na\nb\n8\n```\n\n### 3.5 特殊变量\n\n-\t`$#`：位置参数个数\n-\t`$*`：参数列表，所有的参数作为一个字符串，以空格隔开\n-\t`$@`：参数列表，双引号引用为单独的字符串，所有的参数作为单个的字符串，以空格隔开\n-\t`$$`：当前shell的PID\n-\t`$?`：上一个命令的退出状态\n- 0：成功\n- 其他：失败\n\n\n\n例子：创建mysh2.sh，内容如下：\n\n```bash\n#!/bin/bash\necho \"number of args:$#\"\necho \"string of args:$*\"\necho \"args:$@\"\necho \"current pid:$$\"\npstree -p\n```\n\n\n\n执行结果：\n\n```bash\n[root@layne bashdir]# chmod +x mysh2.sh\n[root@layne bashdir]# ./mysh2.sh a b 1 2 3 4 5  #创建子shell进程执行\nnumber of args:7\nstring of args:a b 1 2 3 4 5\nargs:a b 1 2 3 4 5\ncurrent pid:2033\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1945)───bash(1947)───mysh2.sh(2033)───pstree(2034)\n        └─udevd(354)───udevd(640)\n[root@layne bashdir]# source mysh2.sh a b 1 2 3 4 5 #在当前shell执行\nnumber of args:7\nstring of args:a b 1 2 3 4 5\nargs:a b 1 2 3 4 5\ncurrent pid:1947\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1945)───bash(1947)───pstree(2036)\n        └─udevd(354)───udevd(640)\n\n```\n\n\n\n\n\n**`$?`用于获取上一个命令的退出状态**\n\n```bash\n[root@layne bashdir]# mydir=/root\n[root@layne bashdir]# myfile=mysh2.sh\n[root@layne bashdir]# [ -d $mydir ] && echo \"$mydir is dir\"  # [ -d $mydir ]用于测试该变量是否是一个目录\n/root is dir\n[root@layne bashdir]# [ -d $myfile ] && echo \"$mydir is dir\"\n[root@layne bashdir]# [ -d $mydir ]\n[root@layne bashdir]# echo $?\n0  # 0相当于成立\n[root@layne bashdir]# [ -d $myfile ]\n[root@layne bashdir]# echo $?\n1\n```\n\n\n\n### 3.6 数组\n\nBash提供了一维数组变量。任何变量都可以作为一个数组；内建命令 declare 可以显式地定义数组。数组的**大小没有上限（初始创建多大的数组，可以超过这个大小继续往后赋值）**，也没有限制在连续对成员引用和赋值时有什么要求。数组以整数为下标，从0开始。\n\n如果变量赋值时使用语法 `name[subscript]=value`，那么就会自动创建数组。 subscript 被当作一个算术表达式，结果必须是大于等于 0 的值。数组赋值可以使用复合赋值的方式，形式是 `name=(value1 value2 ... valuen)`，这里每个 value 的形式都是[subscript]=string。string 必须出现。如果出现了可选的括号和下标，将为这个下标赋值，否则被 赋值的元素的下标是语句中上一次赋值的下标加一。下标从 0 开始。这个语法也被内建命令 declare 所接受。单独的数组元素可以用上面介绍的语法 `name[subscript]=value`  来赋值 \n\n数组的任何元素都可以用 `${name[subscript]}` 来引用。花括号是必须的，以避免和路径扩展冲突。如果subscript 是 `@` 或是 `*`，它扩展为 name 的所有成员。这两种下标只有在双引号中才不同。在双引号中，`${name[*]}` 扩展为一个词，**由所有数组成员的值组成**，用特殊变量 IFS 的 第  一 个 字 符 分 隔；`${name[@]}`将 name 的**每个成员**扩展为一个词。如果数组没有成员，`${name[@]}` 扩展为空串。这种不同类似于特殊参数 `* `和` @` 的扩展 (参见上面的 Special  Parameters 段落)。`${&#35;name[subscript]}` 扩展为 `${name[subscript]}` 的长度。如果 subscript 是  `*` 或者是 `@`，扩展结果是数组中元素的个数。**引用没有下标数组变量等价于引用元素 0。**       \n\n**内建命令 unset 用于销毁数组**。`unset name[subscript]` 将销毁下标是 subscript 的 元 素 。 `unset name`, 这里 name 是一个数组，或者 `unset name[subscript]`, 这里 subscript 是  `*` 或者是 `@`，将销毁整个数组。         内建命令 declare,  local, 和 readonly 都能接受` -a` 选项，从而指定一个数组。内建命令 read 可 以接受 `-a` 选项，从标准输入读入一列词来为数组赋值。内建命令 set 和  declare 使用一种可以重用为输入的格式来显示数组元素。  \n\n```bash\n[root@layne bashdir]# sxt=(a  b  c)  #数组\n[root@layne bashdir]# echo  $sxt\na\n[root@layne bashdir]# echo  ${sxt[1]}\nb\n[root@layne bashdir]# echo  ${sxt[*]}\na b c\n[root@layne bashdir]# echo  ${sxt[@]}\na b c\n```\n\n注意：`echo $sxt[1] ` 是错误的写法\n\n\n\n### 3.7 管道\n\n直接看例子：\n\n```bash\n[root@layne bashdir]# a=9\n[root@layne bashdir]# echo $a\n9\n[root@layne bashdir]# b=22 | echo ok #启动子进程给b赋值22\nok\n[root@layne bashdir]# echo $b #访问不到子进程的数据，父进程访问不了子进程的结果\n```\n\n**管道两边的命令在当前shell的两个子进程中执行。**\n\n\n\n### 3.8 $$和$PASHPID\n\n**`$$`和`$BASHPID`的区别**\n\n- `$$`是在哪个进程中执行命令，该值就是哪个shell进程的PID\n- `echo \"hello\"| echo $BASHPID` 这里的id是前面执行`echo \"hello\"`的shell的id，而`echo $$` 是当前shell的id\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210209185227.png)\n\n另外，我们创建一个test.sh再来测试一下，test.sh内容如下：\n\n```bash\n#!/bin/bash\necho \"\\$\\$ value:$$\"\necho \"BASHPID value:$BASHPID\"\npstree -p\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x test.sh\n[root@layne bashdir]# ./test.sh\n$$ value:2208\nBASHPID value:2208\ninit(1)─┬─auditd(899)───{auditd}(900)\n        ├─crond(1312)\n        ├─mingetty(1338)\n        ├─mingetty(1340)\n        ├─mingetty(1342)\n        ├─mingetty(1344)\n        ├─mingetty(1346)\n        ├─mingetty(1348)\n        ├─ntpd(973)\n        ├─rsyslogd(915)─┬─{rsyslogd}(917)\n        │               ├─{rsyslogd}(919)\n        │               └─{rsyslogd}(920)\n        ├─sshd(965)───sshd(1945)───bash(1947)───test.sh(2208)───pstree(2209)\n        └─udevd(354)───udevd(640)\n\n```\n\n可以看到，在子进程执行的时候，`$$`和`$BASHPID` 输出的都是当前进程的ID\n\n另外，再创建test1.sh，内容如下：\n\n```bash\n#!/bin/bash\n\necho \"\\$\\$ outside of subshell = $$\"                              # 9602\necho \"\\$BASH_SUBSHELL  outside of subshell = $BASH_SUBSHELL\"      # 0\necho \"\\$BASHPID outside of subshell = $BASHPID\"                   # 9602\n\necho\n\n( echo \"\\$\\$ inside of subshell = $$\"                             # 9602\n  echo \"\\$BASH_SUBSHELL inside of subshell = $BASH_SUBSHELL\"      # 1\n  echo \"\\$BASHPID inside of subshell = $BASHPID\" )                # 9603\n  # Note that $$ returns PID of parent process.\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x test1.sh\n[root@layne bashdir]# ./test1.sh\n$$ outside of subshell = 2214\n$BASH_SUBSHELL  outside of subshell = 0\n$BASHPID outside of subshell = 2214\n\n$$ inside of subshell = 2214\n$BASH_SUBSHELL inside of subshell = 1\n$BASHPID inside of subshell = 2215\n```\n\n我的理解： `$$`表示脚本文件在其下运行的进程ID。对于任何给定的脚本，当它运行时，**它将只有一个“主”进程标识**。不管您调用了多少个子shell，`$$`将始终返回与脚本关联的第一个进程标识。 `$BASHPID`将显示当前bash实例的进程ID，因此在子shell中它将与可能调用它的**“顶级”**bash不同。`$BASH_SUBSHELL` 表示你所在的“subshell级别”。如果你不在任何子级别，则级别为零。如果你在主程序中启动子shell，则该子shell级别为1。如果在该子shell内启动子shell，则级别为2，依此类推。\n\n\n\n## 4. bash的基本语法\n\n### 4.1 单引号和双引号\n\n单引号将其中的内容都作为了字符串来，忽略所有的命令和特殊字符，类似于一个字符串的用法\n\n双引号与单引号的区别在于其可以包含特殊字符（单引号直接输出内部字符串，不解析特殊字符；双引号内则会解析特殊字符），包括`', \", $, \\`，如果要忽略特殊字符，就可以利用`\\`来转义，忽略特殊字符，作为普通字符输出：\n\n```bash\n[root@layne bashdir]# var=3\n[root@layne bashdir]# echo '$var'\n$var\n[root@layne bashdir]# echo \"$var\"\n3\n[root@layne bashdir]# echo \"Here \\\"this is a string\\\" is a string\"\nHere \"this is a string\" is a string\n```\n\n### 4.2 命令替换\n\n命令替换允许我们**将shell命令的输出赋值给变量**。它是脚本编程中的一个主要部分。\n\n命令替换会创建子shell进程来运行相应的命令。子shell是由运行该脚本的shell所创建出来的一个独立的子进程，由该子进程执行的命令无法使用（父）脚本中所创建的变量（除非是export的环境变量）。\n\n反引号提升扩展优先级，**先执行反引号的内容，再执行其他的**。\n\n```bash\n[root@layne bashdir]# myvar=echo \"hello\"\n-bash: hello: command not found\n[root@layne bashdir]# myvar=`echo \"hello\"` #使用反引号，先创建子shell执行echo \"hello\"，再将执行的结果赋给myvar\n[root@layne bashdir]# echo $myvar\nhello\n```\n\n再来看一个例子：\n\n```bash\n[root@layne tdir]# scp /root/tdir/test.txt  layne2:/root/tdir #把当前主机的test.txt文件copy到layne2主机的同一个目录下，前提是layne2的/root/tdir目录存在\nroot@layne2's password: \ntest.txt                                                                                   100%   20     0.0KB/s   00:00    \n[root@layne tdir]# scp /root/tdir/log.txt layne2:`pwd` # 作用同上，相当于先输入pwd，把pwd的返回结果赋值给`pwd`\nroot@layne2's password: \nlog.txt                                                                                    100%   12     0.0KB/s   00:00    \n[root@layne tdir]# \n```\n\n\n\n### 4.3 逻辑判断\n\n- command1 && command2\n  - n 如果command1退出状态是0（0代表正确），则执行command2\n- command1  ||  command2\n  - n 如果command1的退出状态不是0，则执行command2\n\n```bash\n[root@layne2 ~]# test -d /hello || echo \"文件夹/hello不存在\"\n文件夹/hello不存在\n[root@layne2 ~]# test -d /bin && echo \"文件夹/bin存在\"\n文件夹/bin存在\n[root@layne2 ~]# test -f a.txt && rm -f a.txt && touch a.txt #-f 判断是不是文件\n[root@layne2 ~]# ls / && echo ok\nbin  boot  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  sbin  selinux  srv  sys  tmp  usr  var\nok\n[root@layne2 ~]# ls / || echo ok\nbin  boot  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  sbin  selinux  srv  sys  tmp  usr  var\n```\n\n\n\n### 4.4 表达式\n\n**（1）算术表达式**\n\n- let  算数运算表达式\n  - `let  C=$A+$B`    （很重要）\n- $[算术表达式]\n  - `C=$[$A+$B]`\n- $((算术表达式))\n  - `C=$((A+B))`\n  - `C=$((A+B+1))`   #在原来结果的基础上再加1\n- expr算术表达式\n  - 表达式中各操作数及运算符之间要有空格，同时要使用命令引用\n  - ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210209223824.png)\n\n```bash\n[root@layne2 ~]# a=1\n[root@layne2 ~]# b=2\n[root@layne2 ~]# let c=$a+$b\n[root@layne2 ~]# echo $c\n3\n[root@layne2 ~]# d=$((a+b+1))\n[root@layne2 ~]# echo $d\n4\n[root@layne2 ~]# ((a++))\n[root@layne2 ~]# echo $a\n2\n[root@layne2 ~]# e=$((--d+a))\n[root@layne2 ~]# echo $e\n5\n```\n\n\n\n**（2）条件表达式**\n\n-\t[  表达式  ]\n-\ttest  表达式\n-\t[[  表达式  ]]\n\n```bash\ntest  3  -gt  2  &&  echo  ok\n等价于\n[  3  -gt  2  ]  &&  echo  ok\n\ntest  3  -gt  8  &&  echo  ok\n等价于\n[  3  -gt  8  ]  &&  echo  ok\n```\n\n\n\n## 5. bash的分支\n\n-\tif\n-\tcase\n\n\n\n### 5.1 if分支\n\n**单分支结构**\n\n```tex\nif [ 条件判断 ] \n then\n    //命令\nfi\n\n或者\n\nif [ 条件判断 ]; then \n 条件成立执行，命令;\nfi # 将if反过来写,就成为fi，结束if语句 \n```\n\n **双分支结构**\n\n```bash\nif [ 条件1 ];then \n 条件1成立执行，指令集1\nelse \n 条件1不成执行指令集2; \n fi\n```\n\n **多分支结构**\n\n```bash\nif [ 条件1 ];then\n 条件1成立，执行指令集1\nelif [ 条件2 ];then\n 条件2成立，执行指令集2\nelse\n 条件都不成立，执行指令集3 \n fi\n```\n\n**使用[命令判断**\n\n```bash\nif [ 3 -gt 2 ]; then\n  echo  ok \nfi\n\nif [ 3 -gt 2 ]\nthen\n  echo  ok \nfi\n```\n\n示例：\n\n创建sh01.sh，内容为：\n\n```bash\n#!/bin/bash\na=20\nif [ $a -gt $1 ];\nthen\n  echo \"你输入的数字太小\"\nelif [ $a -eq $1 ];\nthen\n  echo \"恭喜哈，数字相等\"\nelse\n  echo \"你输入的数字太大\"\nfi \n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x sh01.sh\n你输入的数字太大\n[root@layne bashdir]# ./sh01.sh 20\n恭喜哈，数字相等\n[root@layne bashdir]# ./sh01.sh 15\n你输入的数字太小\n[root@layne bashdir]# ./sh01.sh 25\n你输入的数字太大\n[root@layne bashdir]# ./sh01.sh\n./sh01.sh: line 3: [: 20: unary operator expected\n./sh01.sh: line 6: [: 20: unary operator expected\n你输入的数字太大\n```\n\n注意：`if`和中括号之间要有空格，中括号和条件表达式之间要有空格\n\n`;`和then之前有空格没空格都可以\n\n\n\n### 5.2 case分支\n\n```bash\ncase $变量名称 in “值1\") \n  程序段1\n  ;;\n“值2\") \n  程序段2\n  ;;\n*)\nexit 1\n  ;;\nesac # esac是case的逆置，代表case的结尾\n\n```\n\n上面`*`类似java里面的default\n\n`exit 1` 是`echo $?`获取到的返回值，`exit 0`代表正确的返回，`exit 1`代表错误的返回结果\n\n\n\n案例：判断用户输入的是哪个数，1-7显示输入的数字，1显示 Mon,2 :Tue,3:Wed,4:Thu,5:Fir,6-7:weekend,其它值的时候，提示：please input [1,7]，该如何实现？\n\n创建sh02.sh，内容为：\n\n```bash\n#!/bin/bash\nread -p \"please input a number[1,7]:\" num\ncase $num in\n1)\n    echo \"Mon\"\n;;\n2)\n    echo \"Tue\"\n;;\n3)\n    echo \"Wed\"\n;;\n4)\n    echo \"Thu\"\n;;\n5)\n    echo \"Fir\"\n;;\n[6-7])\n    echo \"weekend\"\n;;\n*)\n    echo \"please input [1,7]\"\n;;\n\nesac\n\n或者\n#!/bin/bash\n# Mon,2 :Tue,3:Wed,4:Thu,5:Fir,6-7:weekend\ncase $1 in 1)\n   echo \"Mon\"\n   exit 0\n;;\n2)\n   echo \"Tue\"\n   exit 0\n;;\n3)\n   echo \"Wed\"\n   exit 0\n;;\n4)\n   echo \"Thu\"\n   exit 0\n;;\n5)\n   echo \"Fir\"\n   exit 0\n;;\n[6-7])\n   echo \"weekend\"\n   exit 0\n;;\n*)\n   echo \"please input [1,7]\"\n   exit 1\n;;\n\nesac\n```\n\n\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x sh02.sh\n[root@layne bashdir]# ./sh02.sh\nplease input a number[1,7]:5\nFir\n[root@layne bashdir]# ./sh02.sh\nplease input a number[1,7]:8\nplease input [1,7]\n```\n\n\n\n## 6. bash的循环\n\n### 6.1 while循环\n\n```bash\nwhile [ condition ] ; do # 如果do换一行就不要;了\n  命令\ndone\n或者\nwhile [ condition ] \n do\n  命令\ndone\n```\n\n注意：while也与中括号之间有空格\n\n案例一：每隔两秒打印系统负载情况，如何实现？\n\n创建while1.sh，内容如下：\n\n```bash\n#!/bin/bash\nwhile true\n do\n   uptime   #显示系统负载情况\n   sleep 2 #休眠2秒\n done\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x while1.sh\n[root@layne bashdir]# ./while1.sh\n 23:05:07 up 12:56,  1 user,  load average: 0.00, 0.00, 0.00\n 23:05:09 up 12:56,  1 user,  load average: 0.00, 0.00, 0.00\n 23:05:11 up 12:56,  1 user,  load average: 0.00, 0.00, 0.00\n # 按ctrl +c 终止进程\n```\n\n案例二：使用while循环，编写shell脚本，计算1+2+3+…+100的和并输出，如何实现？\n\n创建while2.sh，内容如下：\n\n```bash\n#!/bin/bash\nsum=0\ni=1\nwhile [ $i -le 100 ]  #while和[之间要加一个空格  true则执行\ndo\n  sum=$((sum+i))\n  i=$((i+1)) #运算结果为变量赋值可以使用$(( … ))\ndone\necho \"the result of '1+2+3+...+100' is $sum\"\n\n或者：\n\n#!/bin/bash\nsum=0\ni=1\nwhile [ $i -le 100 ]  #while和[之间要加一个空格  true则执行\ndo\n  let sum=$sum+$i\n  let i=$i+1 #运算结果为变量赋值可以使用$(( … )) 或let i++ 或 let i+=1\ndone\necho \"the result of '1+2+3+...+100' is $sum\"\n```\n\n\n\n### 6.2 for循环\n\n```bash\nfor 变量名 in 变量取值列表\ndo\n  命令\ndone\n```\n\n案例1：创建for1.sh，输入以下内容\n\n```bash\n#!/bin/sh\nfor num in 1 2 3 4 \ndo \n  echo $num\ndone\n```\n\n执行：\n\n```bash\n[root@layne bashdir]# chmod +x for1.sh\n[root@layne bashdir]# ./for1.sh\n1\n2\n3\n4\n```\n\n**使用大括号的方法：**\n\n```bash\n[root@layne bashdir]# echo {1..8}\n1 2 3 4 5 6 7 8\n[root@layne bashdir]# echo {a..z}\na b c d e f g h i j k l m n o p q r s t u v w x y z\n[root@layne bashdir]# echo 10.13.20.{1..3}\n10.13.20.1 10.13.20.2 10.13.20.3\n```\n\n编辑for1.sh，输入以下内容：\n\n```bash\n#!/bin/sh\nfor num in {1..4} \ndo \n  echo $num\ndone\n```\n\n\n\n案例2：使用`seq –s 分隔符 起始 步长 终点 `\n\n```bash\n[root@layne bashdir]# seq -s \" \" 2 2 100\n2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98 100\n[root@layne bashdir]# seq -s \" \" 1 1 5\n1 2 3 4 5\n```\n\n创建for2.sh ，内容为：\n\n```bash\n#!/bin/sh\nfor num in `seq -s \" \" 1 1 5`\ndo\n  echo $num\ndone\n```\n\n**注意：for后面\\`\\`里面是执行的命令**\n\n执行for2.sh：\n\n```bash\n[root@layne bashdir]# chmod +x for2.sh\n[root@layne bashdir]# ./for2.sh\n1\n2\n3\n4\n5\n```\n\n\n\n## 7. bash练习\n\n### 7.1 案例1\n\n-\t用户给定路径\n-\t输出文件大小最大的文件\n-\t递归子目录\n\n`$IFS`默认空格、制表符和换行符 都可以识别\n\nfor循环的时候 空格、制表符和换行符都可以识别（在不改`$IFS`情况下），如果要改变`$IFS`，让它识别这三个中的一个，比如让它只识别换行符，把`IFS=$'\\n'`，这样一行一个循环，即一次一行来循环操作，不用管一行里面的空格或制表符。\n\n`du -a` 列出所有的文件与目录\n\n```bash\n[root@layne bashdir]# du #不用-a，不会列出所有的\n32\t./rdir\n120\t.\n[root@layne bashdir]# du -a\n4\t./rdir/a.sh\n4\t./rdir/test.txt\n32\t./rdir\n4\t./mylog2.log\n4\t./log.err\n4\t./mylog.log\n4\t./mylog3.log\n4\t./nohup.out\n4\t./test.sh\n4\t./my.log\n4\t./sh01.sh\n...\n```\n\n步骤一：\n\n思路：使用du命令加-a遍历用户指定目录（`$1`获取）的所有文件，使用管道将结果传递给sort，让sort使用数值序倒序排序，依次输出各个条目。\n\n```bash\n#!/bin/bash\noldIFS=$IFS\nIFS=$'\\n'  # 将for循环获取不同元素的标记修改为换行符\n# for循环获取元素的时候使用空格区分各个不同的元素\nfor  item  in  `du  -a  $1 |  sort   -nr`; do\n  echo  $item\ndone\nIFS=$oldIFS    #用完后重置IFS变量的值。\n```\n\n- `$1`是第一个参数\n- `sort  -nr` ：因为du输出的两列，第一列是大小，第二列是目录或文件，中间用制表符（\\t）隔开，sort可以默认识别这种写法，并默把两列分开后用第一列排序，这里是缩写，全称为`sort -t '\\t' -k 1 -nr sort.txt`\n\n**因为要获取最大的文件，需要改进**\n\n```bash\n#!/bin/bash\noldIFS=$IFS\nIFS=$'\\n'  # 将for循环获取不同元素的标记修改为换行符\n# for循环获取元素的时候使用空格区分各个不同的元素\nfor  item  in  `du -a  $1 |  sort -nr`; do\n  fileName=`echo  $item | awk '{print  $2}'`\n  if  [  -f  $fileName  ]; then\n      echo  $fileName\n      break\n  fi\ndone\nIFS=$oldIFS    #用完后重置IFS变量的值。\n```\n\n- awk默认也是识别制表符，换行符，空格等\n- **`awk '{print $2}'`** **这是取第二列，不是文件的第二个参数**\n\n\n\n### 7.2 案例2\n\n问题：\n\n​    循环遍历文件每一行：流程控制语句 IFS\n\n- 定义一个计数器\n- 打印num正好是文件行数\n\n思路：\n-\t管道\n-\t重定向\n-\t命令替换\n\n\n\n**方案一**：\n\n思路：定义一个计数器，使用for循环从文件内容按行获取元素，每个元素是一行，在for循环中递增计数器用于计行数\n\n```bash\n#!/bin/bash\nnum=0\noldIFS=$IFS\nIFS=$'\\n'\n# hello world are you ok\nfor  item  in  `cat  $1`; do\n  echo $item\n  ((num++))  # 或$((num++)) 或 let num++\ndone\necho \"line number is :$num\"\nIFS=$oldIFS\n```\n\n解释：\n\n```bash\nfor item in `cat $1`; do\n```\n\n这里for循环可以识别换行符，所以可以遍历（即一行循环一次）\n\n**方案二：**\n\n思路：先使用**wc数出总行数**，然后使用带下标的for循环分页遍历该文件，打印出每行，最后打印出总行数。\n\n注意：\n\n1、`cat $1 | wc -l `：返回行数\n\n2、如果for循环想要java的写法，则可以在for后面用两个`((`包起来 ，如`for ((i=1;i<=lines;i++))`\n\n```bash\n#!/bin/bash\nnum=0\nlines=`cat $1 | wc  -l`\nhello=$1\nfor  ((i=1;i<=lines;i++)); do\n  line=`head  -$i  $hello |  tail  -1`\n  echo $line\n  ((num++))\ndone\necho \"line number is :$num\"\n```\n\n\n\n**方案三：**\n\n思路：将while的read标准输入重定向到文件file.txt，按行读取，每读一行，就打读到的行记录，同时计数器+1，最后得出总行数。\n\n```bash\n#!/bin/bash\nnum=0\nwhile  read  line  ;do\n   echo  $line\n   ((num++))\ndone  <  $1\necho  \"line number is : $num\"\n```\n\n解释：`>>`和`>`都属于输出重定向，`<`属于输入重定向\n\n\n\n**while read line [linux] shell 学习**可参考：https://blog.csdn.net/qq_22083251/article/details/80484176\n\n写的不错。\n\n\n\n**方案四：**\n\n使用管道命令，**但是通过管道无法向父进程传递数据**（**管道两边的命令在当前shell的两个子进程中执行**），需要将结果数据写到文件中，运行结束后，将数据读出来即可\n\n```bash\n#!/bin/bash\nnum=0    # 该num和管道后面的num不是一回事，因为num没有export\ncat   $1  |  while  read  line; do\n  echo  $line\n  ((num++))    #即使当前环境没有num这个变量，((num++))一样可以使用\n  done\necho  \"line number is: $num\"  > $2 #将结果重定向到一个文件\n```\n\n\n","tags":["Linux"],"categories":["Linux"]},{"title":"使用Xftp和lrzsz在Linux与Windows之间互传文件","url":"/2021/02/04/212039/","content":"\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210204212602.png)\n<!-- more -->\n\n\n一般，我们使用Xftp向Linux中传输文件，该软件以可视化的形式显示Linux中的文件目录，真的是对新手非常友好，下面就让我们来看看吧！\n\n首先，安装Xftp软件（可以向博主获取）并打开，点击弹出框右上角的“新建”按钮：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203183652.png)\n\n依次输入名称、主机（用IP地址）、协议（用SFTP）、端口（22）、用户名（root）、密码，然后点击“确定”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203183805.png)\n\n再双击新建好的连接，就可以成功连接到Linux系统了。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203184044.png)\n\n想要将本地的文件上传到Linux系统中，只需要将文件从左侧拖到右侧即可。\n\n同样的，如果想要把Linux中的文件下载到Windows平台下，只需要将文件从右侧拖到左侧即可。\n\n另外，有一个非常小巧的工具lrzsz，也非常适合在Linux和Windows之间互传文件。\n\n输入`yum install lrzsz -y` 安装 lrzsz，想要上传文件，只需要将文件拖到连接Linux的Shell中即可。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203184450.png)\n\n当把文件拖到Shell中时，会自动调用lrzsz的`rz -E`命令。\n\n同样，如果想要把文件从Linux下载到本地，只需要输入`sz 文件名`。如下图，我下载一个etc目录下的my.cnf文件到本地：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203184757.png)\n\n其实，lrzsz的原理是客户端和服务器模式，服务器是我们的Linux系统，客户端是我们本地的PC机。`rz`是receive的意思，即服务器收到文件，`sz`是send的意思，即服务器向客户端发送文件。\n\n有了lrzsz，我们就不需要专门打开Xftp软件了，直接用命令就可以完成文件的传输工作。不过，还是建议小文件用lrzsz，大文件用Xftp，毕竟lrzsz还只是个小工具，大文件伤不起呀！\n\n\n\n","tags":["Linux","Xftp","lrzsz"],"categories":["Linux"]},{"title":"Linux切换运行级别、关闭防火墙、禁用selinux、关闭sshd、时间同步、修改时区、拍摄快照、克隆操作、修改语言环境","url":"/2021/02/04/211133/","content":"\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210204212150.png)\n<!-- more -->\n\n\n\n@[TOC](文章目录)\n\n\n\n## 1. Linux运行级别及切换\n\n在系统输入`vim /etc/inittab`可以查看系统的运行级别：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203105614.png)\n\n可以看到，Linux有7个运行级别，分别是：\n\n- 0： 系统停止（关机）\n- 1：单用户模式\n- 2：无网络的多用户模式\n- 3：有网络的多用户模式（完整多用户模式）\n- 4：未使用\n- 5：图形化界面\n- 6：重启\n\n`id:3:initdefault`表示系统初始化的运行级别为3，一般常用的运行级别是3 和 5。如果要修改系统初始化的运行级别，那么只需修改 “id：” 后面的数字即可。\n\n**查看当前运行级别**\n\n输入`runlevel`可以查看系统当前的运行级别：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203110129.png)\n\n上图，`N`表示自系统启动后运行级别尚未更改，`3`表示系统的当前运行级别。\n\n**切换运行级别**\n\n除了通过修改`inittab`文件中的默认运行级别之外，管理员还可以通过`init `命令来任意切换 7个级别，值得一提的是，`init 0`和`init 6`等效于 shutdown 和 reboot 。\n\n执行`init`命令，将系统级别切换到5，再将级别切换回3：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203110555.png)\n\n上图，`5 3`表示系统更改之前的运行级别为5，当前运行级别为3。\n\n**查看系统中所有服务在各运行级别中的启动状态**\n\n输入`chkconfig`：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203110752.png)\n\n上图0代表关闭，1代表启用。\n\n**查看network服务在各运行级别中的启动状态**\n\n输入`chkconfig --list network`\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203121539.png)\n\n\n\n\n\n\n\n## 2. 关闭防火墙并禁止开机启动\n\n在Linux系统中，`iptables`表示防火墙的服务名，输入`chkconfig --list iptables`查看防火墙在系统各运行级别的启动状态。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203122603.png)\n\n可以看到，iptables在运行级别2，3，4，5是on，\n\n输入命令`chkconfig iptables off`全部**禁止开机启动**：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203123324.png)\n\n现在我们只是禁止了开机启动，并没有关闭当前运行的防火墙服务，可以输入`service iptables status`查看防火墙的状态：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203123824.png)\n\n可以看到，防火墙还在运行状态，输入命令`service iptables stop`以关闭防火墙服务：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203124002.png)\n\n到了这里，防火墙服务以及防火墙开机启动都关闭成功了。\n\n## 3. 禁用selinux\n\n安全增强型 Linux（Security-Enhanced Linux）简称 seLinux，它是一个 Linux 内核模块，也是 Linux 的一个安全子系统。selinux可能会带来一些权限方面的问题，这是我们在开发过程中不愿看到的，一般将其关闭。\n\n首先在命令行输入`getenforce` 查看selinux的状态：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203130235.png)\n\n可以看到，selinux在运行中。\n\n在命令行输入 `vim /etc/selinux/config` 编辑selinux的配置文件：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203130621.png)\n\n将`SELINUX=enforcing`注释，增加一行`SELINUX=disabled`，保存并退出，输入`init 6`重启虚拟机才能生效。\n\n\n\n## 4. 关闭sshd服务\n\n一般我们通过**关闭sshd服务的DNS以加快SSH登录速度**。\n\n在命令行输入`vim /etc/ssh/sshd_config` ，在vim的命令模式下输入`/UseDNS`查找UseDNS的位置（可以使用n选择下一个匹配的项目），然后将去掉UseDNS的注释，并将yes改为no，保存退出。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203131358.png)\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203131637.png)\n\n输入`service sshd restart`重启sshd服务：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203131815.png)\n\n重启之后，修改的配置项就加载了。\n\n\n\n## 5. 时间同步\n\n输入`date`可以查看当前时间：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203132029.png)\n\n发现时间不对，这时输入`yum install ntp -y`，安装完ntp之后系统中多了两个服务：`ntpd`和`ntpdate`，如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203132432.png)\n\n可以看到，ntpd的状态都是off，也就是这个服务不会开机启动，现在设置ntp为开机启动。\n\n输入`chkconfig ntpd on`，再次通过`chkconfig`查看：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203132717.png)\n\n这时，ntpd服务在系统的2、3、4、5级别上已设置为开机启动。\n\n输入 `service ntpd status`查看ntpd的服务状态，如果显示stopped表示没有启动，此时输入`service ntpd start`启动服务，**过几分钟**（5分组左右）就通过网络自动同步到当前时间了。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203133012.png)\n\n## 6. 修改时区\n\n输入`date`查看当前系统的时间和时区：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203150127.png)\n\n可以看到，当前时区为EST（英国时间），现在我们要改为CST（北京时间），可以采用如下步骤：\n\n（1）拷贝时区文件\n\n输入 `cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime`\n\n（2）修改/etc/sysconfig/clock\n\n输入`vim /etc/sysconfig/clock`将文件里的内容改为：\n\n```bash\nZONE=\"Asia/Shanghai\"\nUTC=true\nARC=false\n```\n\n这里补充一下，ZONE、UTC、ARC、SRM：\n\n- ZONE：指定时区，ZONE的值是一个文件的相对路径名，这个文件是相对 /usr/share/zoneinfo 目录下的一个时区文件。比如ZONE的值可以是：“Asia/Shanghai\"、\"US/Pacific\"、\"UTC\" 等。\n- UTC：指定BIOS中保存的时间是否是GMT/UTC时间，true表示BIOS里面保存的时间是UTC时间，false表示BIOS里面保存的时间是本地时间。\n- ARC：这个选项一般配置false，在一些特殊硬件（Alpha）下才配置该选项为true。\n- SRM：同ARC，该选项一般配置false，在一些特殊硬件下才配置该选项为false。\n\n（3）修改/etc/profile\n\n输入以下命令追加写入到/etc/profile中：\n\n```bash\necho \"TZ='Asia/Shanghai'; export TZ  \">>/etc/profile\nsource /etc/profile #编译立即生效\n```\n\n需要注意的是：\n\n- **/etc/profile**：影响所有用户\n- **~/.bashrc**：影响当前用户\n\n想要了解更多source和profile的内容，可参考[source /etc/profile作用](https://blog.csdn.net/llzhang_fly/article/details/104980029)\n\n（4）再次输入`date`查看，发现已经修改成功了\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203153352.png)\n\n\n\n\n\n## 7. 删除70-persistent-net.rules文件\n\n我们先来看看为什么要删除70-persistent-net.rules文件：\n\n- 许多Linux distribution使用udev来动态管理**设备文件**，并根据设备的信息对其进行持久化命名。\n- udev 会在系统引导的过程中识别网卡，**将mac地址和网卡名称对应起来**，并记录在udev的规则脚本中。\n- 当我们在克隆新的虚拟机时，会自动为虚拟机的网卡生成MAC地址。由于你使用的是以前系统虚拟硬盘的信息，而该系统中已经有eth0（表示第一块有线网卡）的信息，对于这个新的网卡，udev会自动将其命名为eth1 （累加的原则）。\n- udev记录网络规则的脚本为：/etc/udev/rules.d/70-persistent-net.rules，当克隆新虚拟机打开该文件后，会发现，里面有eth0，eth1 这两个网卡的信息，但实际上输入`ifconfig`时只能发现eth1这一个网卡的信息，这是因为eth0根本就不存在。\n\n我在第一次克隆完虚拟机后，输入`vim /etc/udev/rules.d/70-persistent-net.rules` 确实发现有两条mac地址和网卡名称的对应记录，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203134321.png)\n\n此时，系统使用的是新的网卡eth1，，输入 `vi /etc/sysconfig/network-scripts/ifcfg-eth0`查看当前虚拟机的网络配置文件，可以发现该虚拟机使用是eth0，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203134641.png)\n\n这样就对应不上了，此时解决的方法有两个。\n\n**方法一：将70-persistent-net.rules中eth0的那条记录删除，将eht1改为eth0**\n\n但是，如果我们要克隆多台虚拟机，采用方法一，岂不是要修改多次，所以最好采用方法二。\n\n**方法二：输入`rm -rf /etc/udev/rules.d/70-persistent-net.rules`删除70-persistent-net.rules**\n\n删除70-persistent-net.rules后，再输入`init 0`关机，这时再克隆虚拟机。启动新克隆的虚拟机后，系统会自动产生70-persistent-net.rules文件，并且只有eth0这一个网卡记录，这样就对应上了，可以愉快的联网了。\n\n\n\n## 8. 拍摄快照\n\n虽然开机的时候也可以拍摄快照，但为了防止系统的不稳定，最好在关机之后拍，因为系统在运行过程中也会产生数据。\n\n拍摄快照的步骤如下：\n\n（1）点击下图按钮\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203154109.png)\n\n（2）点击“拍摄快照”，输入快照名称，再点击弹出框的拍摄快照。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203154314.png)\n\n这样就完成了一个快照的拍摄了。\n\n## 9. 克隆虚拟机\n\n虚拟机的克隆有两种方式**链接克隆**和**完整克隆**。\n\n- **链接克隆**就是在被克隆的虚拟机上创建了一个链接指向新的虚拟机，但是如果被克隆的虚拟机系统损坏，则在此基础上所有链接克隆的虚拟机都将不能用。但是链接克隆一个好处是克隆出来的虚拟机不会占用整个虚拟机的磁盘空间，同时链接克隆速度比较快，不用经历安装虚拟机要命的超长等待时间。\n- **完整克隆**是对被克隆虚拟机的一个完整副本，此副本虚拟机完全独立，但需要较多的存储磁盘空间。\n\n这里为了速度和存储空间，我们选择链接克隆的方式。步骤如下：\n\n（1）点击下图按钮\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203154109.png)\n\n（2）选择一个虚拟机的快照，点击“克隆”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203160606.png)\n\n（3）点击下一步，选择“现有快照”，再点下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203160701.png)\n\n（4）选择创建链接克隆，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203160805.png)\n\n（5）填写克隆的虚拟机名称，选择位置，点击完成。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203160852.png)\n\n此时，克隆操作已经完成，但是新克隆出来的虚拟机还不能上网，必须进程配置。\n\n启动新克隆的虚拟机并登陆，用户名和密码与原来的虚拟机一样。\n\n登陆完毕后，输入 `vim /etc/sysconfig/network`修改计算机名称（hostname）：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203161605.png)\n\n然后输入 `vim /etc/sysconfig/network-scripts/ifcfg-eth0` 配置网络：\n\n这是修改之前的网络配置\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203161822.png)\n\n这是修改之后的网络配置\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203162011.png)\n\n把网络的IP地址修改一下，别和之前的冲突就行。\n\n重启layne1虚拟机，使用XShell连接，在XShell中输入`ssh root@192.168.218.51`\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203162457.png)\n\n点击“接受并保存”，输入密码，连接成功！\n\n输入`ifconfig`查看网络配置，可以看到，刚刚配置已经生效。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203162612.png)\n\n输入`ping www.baidu.com`，连网成功\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203162718.png)\n\n输入`vim /etc/hosts`编辑CentOS的hosts文件，将`192.168.218.50`改为`192.168.218.51`，将`layne`改为`layne1`\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203163146.png)\n\n输入`ping layne1`，可以看到，layne1被解析为了`192.168.218.51`，大功告成。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203163316.png)\n\n在自己的windows上，进入`C:\\Windows\\System32\\drivers\\etc`目录修改host文件：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210203163650.png)\n\n然后，windows平台就可以和克隆的虚拟机进行通信了。\n\n\n\n## 10. 修改语言环境\n\n首先，查看当前语言环境：\n\n```bash\n[root@layne ~]# echo $LANG\nen_US.UTF-8\n```\n\n所以需要修改系统的语言环境：\n\n```bash\n[root@layne ~]# LANG=zh_CN.UTF-8\n[root@layne ~]# echo $LANG\nzh_CN.UTF-8\n```\n\n这样就修改为中文环境了，但是这样修改**在断开连接或者下次重启系统**，就无效了。如何才能长期有效呢？\n\n输入`vim /etc/sysconfig/i18n`，将之前的语言变量注释，加入以下信息即可：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210207113321.png)\n\n\n\n\n\n\n\n\n\n参考文档\n\n[修改系统时间为UTC时间](https://blog.csdn.net/weixin_34346099/article/details/93569068)\n\n","tags":["Linux","selinux"],"categories":["Linux"]},{"title":"把Linux系统中的yum替换为清华源，速度瞬间从5KB/s变到3.5MB/s","url":"/2021/02/04/211126/","content":"\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210204211713.png)\n<!-- more -->\n\n\n\n在Linux系统中，使用yum安装软件特别方便，可恨的是，yum原本镜像为`mirror.centos.org`，服务器在国外，下载速度5KB/s，真的等的我花儿都谢了。\n\n我网上找了很多资料，首先找到了阿里云的镜像，奈何阿里云官方把CentOS-6的yum源给删了，最低支持CentOS-7的，我用的是CentOS-6.5（大家可以输入`cat /etc/centos-release`查看版本当前操作系统版本） ，无奈，那就换个源吧！\n\n功夫不负有心人，终于在[清华大学开源软件镜像站](https://mirrors.tuna.tsinghua.edu.cn/)找到了下面一句话：\n\n> 该文件夹只提供 CentOS 7 与 8，架构仅为 `x86_64` ，如果需要较早版本的 CentOS，请参考 centos-vault 的帮助，若需要其他架构，请参考 centos-altarch 的帮助。\n\n我点到`centos-vault`下，尝试了一下，还真的可以，每秒几MB，真的发大了，哈哈。\n\n下面，我们来一步一步配置CentOS-6的yum源吧！\n\n（1）在Linux命令行中输入如下命令，备份`CentOS-Base.repo`文件\n\n```bash\ncp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\n```\n\n（2）输入`vi /etc/yum.repos.d/CentOS-Base.repo`编辑`CentOS-Base.repo`文件，将 在 `mirrorlist=` 开头行前面加 `#` 注释掉；并将 `baseurl=` 开头行取消注释（如果被注释的话），把该行内的域名及路径（例如`mirror.centos.org/centos`）替换为 `mirrors.tuna.tsinghua.edu.cn/centos-vault`。以上步骤可以被下方的命令一步完成：\n\n```bash\nsed -e 's|^mirrorlist=|#mirrorlist=|g' \\\n    -e 's|^#baseurl=http://mirror.centos.org/centos/|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/|g' \\\n    -i.bak \\\n    /etc/yum.repos.d/CentOS-Base.repo\n```\n\n按理说，到这里应该就可以了，我试着执行`yum install vim`试了一下，出现了`404 Not Found`\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202231401.png)\n\n\n\n到底怎么回事呢？我试着访问了下`https://mirrors.tuna.tsinghua.edu.cn/centos-vault/6/`，还真访问不到。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202231606.png)\n\n我再试着把上述链接的6改为了6.0，访问`https://mirrors.tuna.tsinghua.edu.cn/centos-vault/6.0/`，竟然访问到了。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202231800.png)\n\n找到了出错原因，那就好办了，依次执行以下命令：\n\n```bash\ncp /etc/yum.repos.d/CentOS-Base.repo.bak /etc/yum.repos.d/CentOS-Base1.repo.bak #为了以防万一，再次备份CentOS-Base.repo文件\nmv /etc/yum.repos.d/CentOS-Base.repo.bak /etc/yum.repos.d/CentOS-Base.repo #将CentOS-Base.repo.bak重命名为CentOS-Base.repo\nvi /etc/yum.repos.d/CentOS-Base.repo\n:%s/$releasever/6.0/g #将文件中$releasever全部改成6.0\nyum clean all && yum makecache # 清除和缓存\n```\n\n再次执行`yum install vim -y`，嘻嘻，每秒3.5MB，赚大发了。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202232628.png)\n\n\n\n最后，补充几个其它的源：\n\n**企业贡献：**\n搜狐开源镜像站：http://mirrors.sohu.com/\n网易开源镜像站：http://mirrors.163.com/\n\n**大学教学：**\n北京理工大学：\n[http://mirror.bit.edu.cn](http://mirror.bit.edu.cn/) (IPv4 only)\n[http://mirror.bit6.edu.cn](http://mirror.bit6.edu.cn/) (IPv6 only)\n北京交通大学：\n[http://mirror.bjtu.edu.cn](http://mirror.bjtu.edu.cn/) (IPv4 only)\n[http://mirror6.bjtu.edu.cn](http://mirror6.bjtu.edu.cn/) (IPv6 only)\n[http://debian.bjtu.edu.cn](http://debian.bjtu.edu.cn/) (IPv4+IPv6)\n兰州大学：http://mirror.lzu.edu.cn/\n厦门大学：http://mirrors.xmu.edu.cn/\n清华大学：\nhttp://mirrors.tuna.tsinghua.edu.cn/ (IPv4+IPv6)\nhttp://mirrors.6.tuna.tsinghua.edu.cn/ (IPv6 only)\nhttp://mirrors.4.tuna.tsinghua.edu.cn/ (IPv4 only)\n天津大学：http://mirror.tju.edu.cn/\n中国科学技术大学：\nhttp://mirrors.ustc.edu.cn/ (IPv4+IPv6)\nhttp://mirrors4.ustc.edu.cn/\nhttp://mirrors6.ustc.edu.cn/\n东北大学：\nhttp://mirror.neu.edu.cn/ (IPv4 only)\nhttp://mirror.neu6.edu.cn/ (IPv6 only)\n电子科技大学：http://ubuntu.uestc.edu.cn/\n\n\n\n亲测，只有搜狐源、东北大学、清华大学维护CentOS6，其它的应该最低从CentOS7开始维护。\n\n\n\n\n\n","tags":["Linux","yum"],"categories":["Linux"]},{"title":"在vmware中安装CentOS虚拟机，保姆式教学！","url":"/2021/02/04/205940/","content":"\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210204211554.png)\n\n<!-- more -->\n\n\n\n## 1. 安装vmware、Xshell、Xftp\n\n现在vmware用的最多的两个版本是12和15：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202170216.png)\n\n这两个版本，根据系统的不同来安装，建议windows7安装vmware12.5.6，windows10安装vmware15.1.0（本文所有软件可联系博主获取软件）。\n\nXftp和Xshell可以方便在windows平台上操作虚拟机：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202170644.png)\n\nXshell用于连接本地和远程的虚拟机，Xftp可以方便在windows和vmware之间传输文件。安装的时候要注意，选择家庭/教育版安装，不要选择商业版。\n\n安装软件时直接点下一步即可！\n\n## 2. 创建vmware虚拟机\n\n（1）启动vmware软件，点击“创建新的虚拟机”，或者右上角”文件“新建虚拟机。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202171714.png)\n\n\n\n（2）选择“自定义”，点击“下一步”\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202171923.png)\n\n（3）选择“WorkStation12.x”硬件兼容性，该版本兼容的产品最多。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202172021.png)\n\n（4）选择“稍后安装操作系统”，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202172213.png)\n\n（5）在客户机操作系统中选择“Linux”，“版本”建议选择为**CentOS 6 64位**，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202172404.png)\n\n（6）填写“虚拟机名称”，选择“位置”，“位置”是将新建的虚拟机文件安装到哪个目录，建议选择安装在大一点的磁盘目录，路径不要出现中文和空格（注意创建二级目录）。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202172652.png)\n\n（7）选择“处理器数据”和“每个处理器的内核数量”，如果你的处理器有8核，可以把每个处理器的内核数量设置为2，一般的电脑处理器为4核，建议两个都设置为1。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202173122.png)\n\n（8）虚拟机的内存建议设置为1024MB，如果你的电脑内存很大（超过16GB），可设置为2048MB。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202173513.png)\n\n（9）网络类型选择“使用网络地址转换(NAT)”，关于vmware的三种模式，可以参考[VMware的三种网络模式 — NAT模式、桥接模式、仅主机模式](https://blog.csdn.net/qq_37555071/article/details/113575483)。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202173632.png)\n\n（10）I/O控制器类型，选择默认值\"LSI Logic(L)\"，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202182204.png)\n\n（11）虚拟磁盘类型也选择默认值“SCSI”，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202182243.png)\n\n（12）选择默认选项“创建新虚拟磁盘”，点击下一步。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202182438.png)\n\n（13）磁盘容量可以设置为20GB，选择“将虚拟磁盘存储为单个文件”以提高性能，这里不要勾选“立即分配所有磁盘空间”，否则会立即分配20GB空间，不勾选意味着所占空间会随着虚拟机中的文件增多而逐渐增大。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202182649.png)\n\n（14）虚拟机磁盘文件的命名默认即可。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202183034.png)\n\n（15）这一步会显示新建虚拟机的信息，直接点击完成。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202183218.png)\n\n## 3. 配置虚拟机镜像文件\n\n（1）点击“编辑虚拟机设置”\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202184318.png)\n\n（2）选中“CD/DVD(IDE)”，选择右侧的“使用ISO映像文件”，点击“浏览”，选择自己的ISO文件（我的为CentOS-6.5），点击“确定”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202184209.png)\n\n（3）点击“开启虚拟机”\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202184511.png)\n\n（4）把鼠标点进去，使用“↑”、“↓”键移动，这里选择默认的“Intall or upgrade an existing system”安装镜像文件。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202190512.png)\n\n（5）使用“←”、“→”键选择“Skip”跳过磁盘检查，按回车键。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202184858.png)\n\n（6）直接点击回车。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202184954.png)\n\n（7）在CentOS图形安装界面，点击右下角的“Next”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202185935.png)\n\n（8）选择“English\"，不要选择中文。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202190119.png)\n\n（9）选择\"U.S.English\"美式英语，点击”Next\"。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202190229.png)\n\n（10）选择磁盘的类型，这里选择默认值“Basic Storage Devices”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202190712.png)\n\n（11）第一次使用，在磁盘分区时不需要保留磁盘上的数据，所以点击“Yes, discard any data”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202190852.png)\n\n（12）这里配置操作系统主机名和网络，直接默认即可（默认主机名localhost，网络为localdomain)，点击“Next”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202191139.png)\n\n（13）时区选择“Asia/Shanghai”，点击右下角“Next”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202191302.png)\n\n（14）设置密码，直接填123456即可，点击“Next\"会提示密码太简单，再点击“Use Anyway”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202191411.png)\n\n（15）这里选择磁盘分区方式，选择最后一个”Create Custom Layout“，自定义磁盘分区，然后点击右下角”Next“。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202191742.png)\n\n（16）创建标准分区，选择第一个“Standard Partition”，然后再点击右下角“Create”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202192346.png)\n\n（17）选择挂载点“/boot”，文件类型“ext4”，大小设置为200MB，选择“Fixed Size”（确定大小），点击右下角“OK”创建第一个分区。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202192645.png)\n\n（18）继续点击Create，选择“Standard Partition”，设置swap分区（交换分区），大小设置为2048MB，选择“Fixed Size”（确定大小），点击右下角“OK”创建第二个分区。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202193124.png)\n\n（19）再次继续点击Create，选择“Standard Partition”，设置最后一个分区，将新分区挂载到“/”（根分区），文件类型设置为“ext4”，选择“Fill to maximum allowable size”（充满磁盘剩余总容量），点击右下角“OK”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202193409.png)\n\n（20）三个分区创建完毕后，点击右下角“Next”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202193650.png)\n\n（21）点击“Format”格式化磁盘分区。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202193744.png)\n\n（22）点击“Write changes to disk”进行格式化\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202193918.png)\n\n（23）这里按照默认配置在/dev/sda设备安装boot loader，用于启动/dev/sda3上的CentOS系统，直接点击右下角\"Next\"即可。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202194022.png)\n\n（24）现在开始安装系统，一共205个包需要安装。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202194217.png)\n\n（25）最后点击reboot重启虚拟机\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202203147.png)\n\n（26）重启虚拟机后，输入用户名root，按回车键，再输入密码（123456），再点击回车进入系统。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202203418.png)\n\n\n\n## 4. 配置虚拟机网络\n\n（1）使用vi编辑\"**/etc/sysconfig/network**\"，设置计算机的名称\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202204047.png)\n\n（2）按小写的i进入编辑模式，修改HOSTNAME为自己设置的主机如，如`HOSTNAME=layne`，第一行不变，修改完之后，按ESC键退出编辑模式，输入`:wq`保存并退出。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202204345.png)\n\n出现下面的提示就表示保存成功了：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202205115.png)\n\n这里补充几个vi的常用命令，后面会经常用到。\n\n- `u` 撤销\n- `dd` 删除一行\n- `yy p` 复制粘贴\n- `:wq` 保存并退出\n- `:q!`  只退出不保存\n- `o` 另开一行\n- `r` 替换\n- `:.,$d` 清空文档\n\n更多vi命令，可参考[Linux——vi命令详解](https://blog.csdn.net/cyl101816/article/details/82026678)。\n\n（3）输入`vi /etc/sysconfig/network-scripts/ifcfg-eth0`编辑网络配置文件，在输入过程中可以按`Tab`键提示和补全。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202205405.png)\n\n上图中：\n\n- DEVICE表示硬件的名称，eth0表示第一块有线网卡\n- HWADDR表示该有线网卡的MAC地址\n- TYPE表示该网卡的类型，Ethernet指以太网\n- UUID表示该网卡设备的编号，操作系统中每个设备都有一个唯一的编号\n- ONBOOT表示该网卡是否随系统启动而启动\n- BOOTPROTO表示网卡连接网络的类型，默认是dhcp的\n\n为了配置IP地址、子网掩码、网关、DNS，我们需要首先查看vmware的网络编辑器。\n\n（4）在vmware中选择“编辑”，点击“虚拟网络编辑器”\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202205840.png)\n\n（5）在虚拟网络编辑器中，点击“更改设置”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202210049.png)\n\n（6）选中“NAT模式”，查看子网IP和子网掩码。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202210211.png)\n\n上图中，我的子网IP是`192.168.218.0`，子网掩码是`255.255.255.0`，也可以点击上图右侧的”NAT设置“查看详情。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202210444.png)\n\n上图中，可以看到子网IP、子网掩码、网关IP（不要更改），所以在虚拟机中可配置：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202211110.png)\n\n在上图中，我做的操作是：\n\n- 删除了MAC地址行和UUID行\n- 将ONBOOT修改为yes，随系统启动\n- BOOTPROTO修改为static，表示静态IP地址配置\n- 配置IP地址`IPADDR=192.168.218.50`（前三位是自己的网络号，后一位可以自己设置）\n- 配置子网掩码`NETMASK=255.255.255.0`\n- 配置网关`GATEWAY=192.168.218.2`\n- 配置首选DNS解析地址`DNS1=192.168.218.2`\n- 配置备选DNS解析地址`DNS2=11.114.114.114`\n\n然后，按ESC键退出编辑模式，按`:wq`保存退出。\n\n（7）输入`service network restart`重启网络，然后输入`ping www.baidu.com`看看网络是否配置成功。需要注意的是，Linux中的ping默认不会停止，可以使用`Ctrl+C`停止该命令的执行。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202211925.png)\n\n（8）输入`vi /etc/hosts`编辑CentOS的hosts文件，添加本地解析条目。下图`192.168.218.50`是刚刚设置的IP地址，`layne`是之前配置的主机名。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202212217.png)\n\n保存退出后，输入`ping layne`，可以看到，layne被解析为了`192.168.218.50`\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202212413.png)\n\n## 5. 用Xshell连接虚拟机\n\n（1）打开安装的Xshell软件，输入`ssh root@192.168.218.50`回车。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213011.png)\n\n（2）在弹出的对话框中，在弹出的对话框中输入密码123456，点击“确定”登陆成功。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213346.png)\n\n注意，此时用户名为root，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213445.png)\n\n\n\n（3）登录成功后，输入`reboot`重启虚拟机，也可以输入`init 6`重启虚拟机（`init 0`是关闭虚拟机）。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213620.png)\n\n\n\n（4）重启后再次输入`ssh root@192.168.218.50`，此时用户名为`layne`。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213739.png)\n\n（5）输入ifconfig查看网络配置，下图可以看到，配置生效\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202213930.png)\n\n再ping百度试一下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202214029.png)\n\nOK，大功告成了。\n\n\n","tags":["Linux","vmware","CentOS"],"categories":["Linux"]},{"title":"VMware的三种网络模式 — NAT模式、桥接模式、仅主机模式","url":"/2021/02/02/221724/","content":"\n我们在配置vmware时，有三种模式，分别是**NAT模式**、**桥接模式**、**仅主机模式**，现在让我们来看看这三种模式吧。\n<!-- more -->\n\n## 1. NAT模式\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202174313.png)\n\n在NAT网络中，会用到VMware Network AdepterVMnet8**虚拟网卡**，主机上的VMware Network AdepterVMnet8虚拟网卡被直接连接到VMnet8虚拟交换机上与虚拟网卡进行通信。虚拟网卡只是作为主机与虚拟机通信的接口，并不是依靠虚拟网卡VMware Network AdepterVMnet8来联网的，它仍然依靠于宿主机器所在的网络来访问公网。NAT模式下虚拟机的TCP/IP配置信息是由VMnet8虚拟网卡的DHCPserver提供的，无法进行手工改动。该模式下，虚拟机可以和宿主机可以互相访问，但不可访问宿主机所在网络的其它计算机。采用NAT模式最大的优势是将虚拟系统接入互联网非常简单，只要求宿主机器能访问互联网即可，不需要配置IP地址、子网掩码、网关等，但DNS地址还是要根据实际情况填的。\n\n下面是简化后的NAT拓扑图：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202180908.png)\n\n上面可能不太好理解，先来打个比方。我们将局域网看成是一个有若干居民居住的小区，这个小区对外面的世界来说有一个或者几个能被识别的地址。路由器就是该小区的收发室，也是小区与外界联络的唯一通道；而局域网和外网之间的数据就看成是各种各样的快递包裹，小区居民与外界的联络均是靠这些进出的包裹进行的。\n\n小区里每个居民都有小区内部地址（局域网IP），但这个地址对外并不公开。外来的包裹只能送到收发室这个统一地址（路由器的公网IP），由收发室来决定哪个包裹送到哪个居民家去；而小区内所有居民发出去的包裹不能直接发到外面，只能送到收发室，由收发室贴上小区统一地址（公网IP）以后再往外发送。所以对外界来说，收发到小区居民的包裹是统一收自或发送到小区收发室的，并不知道具体来自/发送给哪个小区居民。路由器的这种工作模式就叫做NAT模式。\n\n## 2. 桥接模式\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202175608.png)\n\n\n\n桥接模式是通过虚拟网桥将主机上的网卡与虚拟交换机 VMnet0连接在一起，虚拟机上的虚拟网卡(并不是 VMware Network Adapter VMnet1和 VMware Network Adapter VMnet8)都连接在虚拟交换机Vmnet0上，所以桥接模式的虚拟机必须与主机在同一网段且子网掩码，网关与DNS也要与主机网卡一致。所以虚拟机与宿主机和物理机处于同一个局域网中，可以和本局域网中的其它真实主机进行通讯。在桥接模式下，需要手工为虚拟系统配置IP地址、子网掩码，并且还要和宿主机器处于同一网段中。\n\n简化后的桥接模式拓扑图：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202181047.png)\n\n同样的，我们仍然以小区的例子来解释这个工作模式。\n\n桥接模式的小区呢和前面的NAT模式小区有所不同，桥接模式小区每个居民都拥有一个对外界公开的地址，居民们收取和发送包裹都直接使用自己的地址（公网IP），而不是收发室的地址（路由器的公网IP）。这样一来，外界就能看到他们收发到小区的包裹具体是来自/给到哪个居民了，在这种模式下，收发室（路由器）并不需要对进出包裹（数据包）进行公私地址的转换，只是提供了一个收发的通道。\n\n## 3. 仅主机模式\n\n仅主机模式，是一种比NAT模式更加封闭的的网络连接模式，它将创建完全包含在主机中的专用网络，使用的虚拟网卡是VMnet1。仅主机模式的虚拟网卡仅对主机可见，并在虚拟机和主机系统之间提供网络连接。在默认情况下，使用仅主机模式网络连接的虚拟机无法连接到Internet(在主机上安装合适的路由或代理软件，或者在Windows系统的主机上使用Internet连接共享功能，仍然可以让虚拟机连接到Internet或其他网络)。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210202181232.png)","tags":["vmware"],"categories":["工具"]},{"title":"我花了72小时，用了近4万字，总结了65道操作系统知识点！","url":"/2021/01/28/163906/","content":"\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128164145.png)\n<!-- more -->\n\n> 本人是北京航空航天大学21软件学院的一名在读硕士，下面是我研究生复试和面试整理的操作系统知识点，覆盖了操作系统的全部内容，我相信无论是企业面试和还是考试，都不会超出里面的范围。现在发布出来，供大家参考，希望大家能有所收获。\n\n\n\n话不多说，直接来干货。\n\n@[TOC](文章目录)\n\n\n\n## 1、操作系统的目标\n\n**方便性** 方便用户使用\n\n**有效性** 提高系统资源的利用率和系统的吞吐量（系统的吞吐量表示在单位时间内实际处理的数据量）\n\n**可扩充性** 能够方便地增加新的功能和模块\n\n**开放性** 能够遵循国际标准，凡遵循国际标准所开发的硬件和软件，都能彼此兼容，方便地实现互联。\n\n## 2、操作系统的作用\n\n**操作系统提供了用户与计算机硬件之间的接口** 用户在操作系统的帮助下能够方便快捷地操作计算机硬件运行自己的程序。\n\n**操作系统实现了对计算机系统资源的管理** 操作系统能够合理分配计算机系统的各种资源，提高系统资源的利用率和系统的吞吐量\n\n**操作系统实现了对计算机硬件的抽象** 操作系统屏蔽了计算机硬件物理接口的具体细节，用户只需要了解操作系统提供的操作命令，就可以实现对计算机硬件的操作。\n\n## 3、脱机输入/输出(Off-Line I/O)技术\n\n为了缓和CPU和I/O设备之间速度不匹配的矛盾，而引入了脱机输入、脱机输出技术。 该技术是利用专门的外围控制机， 先将低速IO 设备上的数据传送到高速磁盘上，或者相反。这样当处理机需要输入数据时，再从磁盘上高速地调入内存，极大地提高了输入速度。 反之，当处理机需要输出数据时，也可以由处理机把数据从内存输出到高速磁盘上，处理机便可去做自己的事情。由于数据的输入和输出是在脱离主机的情况下进行的，故称之为**脱机输入/输出技术**。这种脱机I/O方式的主要优点为：\n\n- 减少了CPU的空间时间\n- 提高了I/O速度\n\n反之，将在主机的直接控制下进行输入/输出的IO方式称之为**联机输入/输出（On-Line I/O）技术**。另外，如果用一道程序来模拟脱机输入时的外围控制机功能，则将该技术称之为**假脱机技术**即**SPOOLing**（Simultaneaus Periphernal Operating OnLine)技术，**SPOOLing**技术详情见下面题目。\n\n## 4、分时、实时、分布式、批处理系统的区别？\n\n（1）批处理系统\n\n批处理系统的特征是**将磁带上的一批作业能自动地逐个地调入内存依次运行**，而无需人工干预。批处理系统分为单道批处理系统和多道批处理系统。\n\n**单道批处理系统**的工作方式：每次从外存上只调入一道程序进入内存运行，各道作业的完成顺序在正常情况下与它们进入内存的顺序完全相同，只有当程序完成或发生异常情况时，才换入其后继程序进入内存运行。\n\n**多道批处理系统**的工作方式：用户所提交的作业都**先存放在外存上**并排成一个队列，称为“后备队列”；然后，由**作业调度程序按一定的算法**从后备队列中选择若干个作业调入内存，使它们共享CPU和系统中的各种资源。由于同时在内存中存在若干道程序，这样便可以利用一个程序执行I/O操作的空档时间，让CPU去运行另一道程序。\n\n（2）分时系统\n\n分时系统的引入是为了满足用户对人机交互的需要。\n\n分时系统的工作方式：在一台主机上连接了多个带有显示器和键盘的终端，同时允许多个用户通过自己的终端，以交互式方式使用计算机，共享主机的资源。**分时系统为了满足人机交互，必须做到及时接受和及时处理**。\n\n要做到及时接收多个用户键盘输入的命令，只需配置一个多路卡。多路卡的作用是，实现分时多路复用，以很快的速度周期性地扫描各个终端，接收各用户从终端上输入的数据。此外，为了能使从终端输入的数据被依次逐条地进行处理，还需要为每个终端配置一个缓冲区，用来暂存用户键入的命令（或数据）。\n\n要做到及时处理用户的作业（程序），可将用户提交的作用直接调入内存（不像批处理系统那样，把用户提交的作业依次从磁盘调入内存，这时仍有作业在外存上驻留等待调用，分时系统为了及时处理用户的作业，需要把所有用户提交的作业直接调入内存），并使处理机采用轮转的运行方式。为了避免一个作业长期独占处理机，引入了时间片的概念，系统规定每个作业只能运行一个时间片（如30ms），然后就暂停该作业的运行，并立即调度下一个作业运行。\n\n（3）实时系统\n\n实时系统是指系统能及时(或实时)响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。实时操作系统要追求的目标是：对外部请求在严格时间范围内做出反应，有高可靠性和及时性。常见实时系统有工业控制系统、信息查询系统、多媒体系统、嵌入式系统等。\n\n工业控制系统能够实时采集现场数据，能对采集的数据及时处理，进而自动的控制相应设备执行。如火炮的自动控制系统，导弹的制导系统。\n\n信息查询系统能够接收从远程终端发来的服务请求，根据用户提出的请求，对信息进行检索和处理，并能及时对用户做出正确的回答。如飞机和火车的订票系统。\n\n多媒体系统是指用于播放音频和视频的系统，为了保证有好的视觉和听觉感受，它必须是实时信息处理系统。\n\n嵌入式系统用于对设备进行控制或对其中的信息做出处理，除了将各种类型的芯片嵌入到各种仪器和设备中，还需要配置嵌入式OS，它同样需要具有实时控制和处理的功能。\n\n（4）分布式操作系统\n\n分布式操作系统是支持分布式处理的软件系统，是在由通信网络互联的多处理机体系结构上执行任务的系统。它将负载分散到多个计算机硬件服务器上，能够提供更好的性能和可用性。\n\n分布式操作系统通常配置为共享内存和任务的服务器群集。这些服务器协同工作，提供比单个大型计算机服务器更大功率、更大容量、更高性能。\n\n## 5、操作系统的基本特性\n\n操作系统的基本特性是并发、共享、虚拟、异步\n\n（1）并发\n\n并发性和并行性是既相似又有区别的两个概念。并发性是指两个或多个事件在同一时间间隔内发生；而并行性是指两个或多个事件在同一时刻发生。\n\n倘若在计算机系统中有多个处理机，处理多个可并发执行的程序，这样，多个程序便可同时执行。\n\n而在单处理机系统，每一时刻只能运行一个程序，比如说0~20ms，20~40ms，40~60ms分别运行A、B、C程序，宏观上有三道程序同时执行，我们可以说这个程序是并发执行的。\n\n（2）共享\n\n共享是指系统中的资源，可供内存中多个并发执行的进程（或线程）**共同**使用。共享有两种工作方式，互斥共享方式和同时访问方式。\n\n互斥共享方式：规定在一段时间内只允许一个进程（或线程）访问某资源，如临界资源，当某一进程访问完并释放该资源后，才允许另一进程进行访问。\n\n同时访问方式：允许在一段时间内由多个进程同时访问某资源。\n\n（3）虚拟\n\n”虚拟“技术通过空分复用或时分复用，将一条物理信道变为若干条逻辑信道，使原来只能供一对用户通话的物理信道，变为能够供多个用户同时通话的逻辑信道。一般地，把通过某种技术将一个物理实体变为若干个逻辑上的对应物的功能称为”虚拟“。空分复用或时分复用技术见题目6。\n\n（4）异步\n\n在内存中的每个进程，在何时能获得外理机运行，又以怎样的速度向前推进，都是不可预知的。内存中的每个进程有的侧重于计算而较少需要I/0，有的其计算少而I/O多，这样，很可能是先进入内存的作业后完成，而后进入内存的作业先完成。或者说，进程是以不可预知的速度向前推进的，即为进程的异步性。\n\n## 6、时分复用和空分复用技术\n\n（1）时分复用技术\n\n时分复用技术是利用处理机的空闲时间去运行其它程序，提高了处理机的利用率。时分复用技术广泛用于实现虚拟处理机和虚拟设备，使处理机的利用率得以提升。\n\n虚拟处理机技术。利用多道程序设计技术，为每道程序建立至少一个进程，让多道程序并发执行。此时，虽然系统中只有一台处理机，但它能同时为多个用户服务，使每个终端用户都认为是有一个处理机（CPU）在专门为他服务。亦即，利用多道程序设计技术，把一台物理上的处理机虚拟为多台逻辑上的处理机，在每台逻辑处理机上运行一道程序，我们把用户所感觉到的处理机称为**虚拟处理机**。\n\n虚拟设备技术。将一台物理I/O设备虚拟为多台逻辑上的I/O设备，并允许每个用户占用一台逻辑上的I/O设备，这样便可使原来仅允许在一段时间内由一个用户访问的设备（即临界资源），变为允许多个用户“同时”访问的共享设备，即宏观上能“同时”为多个用户服务。例如原来的打印机输入临界资源，而通过虚拟设备技术又可以把它变为多台逻辑上的打印机，供多个用户“同时”打印。\n\n（2）空分复用技术\n\n空分复用技术是利用存储器的空闲空间分区域存放和运行其它程序，提高了内存的利用率。\n\n但是，单纯的空分复用存储器只能提高内存的利用率，并不能实现在逻辑上扩大存储器容量和功能，还必须引入**虚拟存储技术**才能达到此目的，虚拟存储技术在本质上是实现内存的分时复用，即它可以通过分时复用内存的方式，使一道程序仅在远小于它的内存空间中运行。例如，一个100MB的应用程序之所以可以运行在30MB的内存空间，实质上就是每次只把用户程序的一部分调入内存运行，运行完成后将该部分换出，再换入另一部分到内存中运行，通过这样的置换功能，便实现了用户程序的各个部分分时地进入内存运行。\n\n虚拟的实现，可以采用时分复用，也可以采用空分复用。将一台物理设备对应多个N个逻辑设备，如果是利用空分复用方法来实现虚拟，此时一台虚拟设备平均占用的空间必然也等于或低于物理设备所拥有空间的1/N。如果是利用时分复用方法来实现虚拟，则每台虚拟设备的平均速度必然等于或低于物理设备速度的1/N。\n\n## 7、操作系统的主要功能有哪些？\n\n（1）处理机管理功能\n\n在传统的多道程序系统中，处理机的分配和运行都是以进程为基本单位的，因而对处理机的管理可归结为对进程的管理。\n\n主要功能有\n\n- 进程控制：创建和撤销进程\n- 进程同步：为使多个进程余条不紊地运行，可采用进程互斥方式和进程同步方式的协调方式\n- 进程通信：实现进程之间的信息交换\n- 调度：作业调度和进程调度\n\n（2）存储器管理功能\n\n存储器管理的主要任务，是为多道程序的运行提供良好的环境，提高存储器的利用率，方便用户使用，并能从逻辑上扩充内存。\n\n主要功能有\n\n- 内存分配：为每道程序分配内存空间，可采取静态和动态两种方式\n- 内存保护：确保每道用户程序都仅在自己的内存空间内运行，彼此互不干扰\n- 地址映射：将地址空间中的逻辑地址转化为内存空间中与之对应的物理地址\n- 内存扩充：借助虚拟存储技术，从逻辑上扩充内存容量\n\n（3）设备管理功能\n\n设备管理的任务是，完成用户进程提出的I/O请求，为用户进程分配所需的I/O设备，并完成指定的I/O操作，提高CPU和I/O设备的利用率，提高I/O速度。\n\n主要功能有\n\n- 缓冲管理：在I/O设备和CPU之间引入缓冲，可有效缓和CPU和I/O设备速度不匹配的矛盾，提高CPU利用率\n- 设备分配：根据用户进程的I/O请求，为之分配所需的I/O设备\n- 设备处理：实现CPU和设备控制器之间的通信\n\n（4）文件管理功能\n\n文件管理功能的主要任务，是对用户文件和系统文件进行管理以方便用户使用，并保证文件的安全性\n\n主要功能有\n\n- 文件存储空间的管理：由文件系统对诸多文件及文件的存储空间实施统一的管理\n- 目录管理：为每个文件建立一个目录项，目录项包括文件名、文件属性、文件在磁盘上的物理位置等，并对众多的目录项实现按名存取\n- 文件的读/写管理和保护：从外存读取数据，或将数据写入外存，使用存取控制功能对文件进行保护\n\n（5）操作系统与用户之间的接口\n\n为了方便用户使用，操作系统提供了**用户与操作系统的接口**，有两大类：\n\n- 用户接口：用户与操作系统直接交互的接口，便于用户直接或间接地控制自己的作业\n- 程序接口：用户程序与操作系统的接口，方便用户程序在执行中访问系统资源，是用户程序取得操作系统服务的唯一途径\n\n## 8、微内核OS结构\n\n所谓的微内核技术，是指精心设计的、能实现现代OS核心功能的小型内核，其并非是一个完整的OS，只是将操作系统中最基本的部分放入微内核，而将操作系统的绝大部分功能都放在微内核外面的一组服务器中实现的，比如提供进程管理的服务器、提供存储器管理的服务器、提供I/O设备管理的服务器。微内核与服务器之间的消息传递是通过消息传递机制（即网络通信的方式）来实现信息交互的。\n\n在微内核OS中，一般采用“机制与策略分离”的原理。所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上借助于某些参数和算法来实现该功能的优化，或达到不同的功能目标。在传统的OS中，将机制放在OS的内核的较低层，把策略放在内核的较高层次中。在微内核OS中，通常将机制放在OS的微内核，将策略放在微内核外面的一组服务器中。\n\n## 9、进程和程序的区别和联系\n\n（1）程序是指令的集合，是静态的概念。**进程是程序在处理机上的一次执行的过程**，是动态的概念。\n\n（2）当程序没有运行时，程序作为软件资料可长期保存，而进程存在生命周期的，进程只有在运行的时候存在。\n\n（3）一个程序在运行时可能对应多个进程。\n\n## 10、进程的基本状态及转换\n\n进程有三种基本状态：就绪状态、执行状态、阻塞状态\n\n- **就绪状态**：已经获得投入运行所必需的一切资源，一旦分配到CPU，就可以立即执行。\n- **执行状态**：当进程由调度／分派程序分派后，得到CPU控制权，正在CPU上运行着。\n- **阻塞状态**：一个进程正在等待某个事件的发生（如等待 I/O 的完成），而暂停执行。\n\n进程的三种基本状态及其转换图如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126120846.jpg)\n\n上图的四种中间之间过程：\n\n- 就绪到执行：当处理机空闭时，由调度／分派程序从就绪进程队列中选择一个进程占用CPU\n- 执行到就绪： 时间片用完\n- 执行到阻塞：等待某事件的发生（如等待I/O完成）\n- 阻塞到就绪：事件已经发生（如I/O完成）\n\n为了满足进程控制块对数据及操作的完整性要求以及增强管理的灵活性，通常在系统中又为进程进入了两种常见的状态：创建状态和终止状态。\n\n- 创建状态：首先由进程申请PCB，并向PCB填写控制和管理进程的信息；然后，为该进程分配运行时所必须的资源；最后，把该进程转入就绪状态并插入就绪队列之中。如果进程所需的资源尚不得到满足，则创建工作未完成，进程不能被调度，此时进程所处的状态称为创建状态。\n- 终止状态：首先，等待操作系统进行善后处理，最后将其PCB清零，并将PCB空间返还系统。当一个进程达到了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入中止状态的进程在操作系统中依然保留一个记录，其中保存状态码和一些计时统计数据，供其他进程收集。一旦其他进程完成了对其信息的提取之后，操作系统将删除该进程，即将其PCB清零。\n\n进程的五种基本状态及其装换图如下所示：\n\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126115642.png)\n\n\n\n为了系统和用户观察分析进程的需要，许多系统还引入一个对进程的重要操作——挂起操作，与挂起操作对应的操作是激活操作。为了方便操作，也引入了相对应的原语，即挂起原语Suspend和激活原语Active。此时，进程会有**增加**如下状态的转化：\n\n（1）活动就绪->静止就绪：当进程处于未被挂起的状态时，称此为活动就绪状态，此时进程可以接受调度。当用挂起原语Suspend将该进程挂起后，该进程便转为静止就绪状态，此时进程不再被调度执行。\n\n（2）执行->静止就绪：当进程正在执行时，用挂起原语Suspend将该进程挂起后，该进程将暂停执行，进入静止就绪状态。\n\n（3）活动阻塞->静止阻塞：当进程处于未被挂起的阻塞状态时，称它是处于活动阻塞状态。当用挂起原语Suspend将该进程挂起后，进程便转为静止阻塞状态。\n\n（4）静止阻塞->静止就绪：当处于静止阻塞的进程在其所期待的事件出现之后，它将从静止阻塞变为静止就绪状态。\n\n（5）静止就绪->活动就绪：处于静止就绪的进程用激活原语Active激活后，该进程便转为活动就绪状态。\n\n（6）静止阻塞->活动阻塞：处于静止阻塞的进程用激活原语Active激活后，该进程便转为活动阻塞状态。\n\n进程有三种基本状态的中间过程有4个，再加上述6个中间过程，共10个中间过程。\n\n引入挂起和激活操作的进程状态及其装换图如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126150438.png)\n\n## 11、进程控制块PCB中的信息和作用\n\n（1）进程控制块中的信息\n\n- 进程标识符：用于唯一地标识一个进程\n- 处理机状态：处理机的上下文信息，主要是由处理器各种寄存器中的内容组成的\n- 进程调度信息：包括进程的当前状态，进程优先级，引起进程由执行状态变为阻塞状态的事件，进程调度所需的其他信息，如进程调度算法，进程等待CPU时间，进程已执行的时间\n- 进程控制信息：包括程序和数据的地址，进程同步和通信机制，进程运行期间所需的资源清单，已分配到该进程的资源清单，PCB首地址大的链接指针\n\n（2）进程控制块的作用\n\n- 作为独立运行基本单位的标志：PCB是进程存在于系统中的唯一标志\n- 能实现间断性的运行方式：进程被阻塞后，PCB能保留CPU现场信息，再次被调度时，PCB供改进程恢复CPU现场\n- 提供进程管理所需要的信息：操作系统总是根据PCB中的进程控制信息实施对进程的控制和管理\n- 提供进程调度所需要的信息：操作系统根据PCB中的进程调度信息实施进度调度\n- 实现由于其它进程的同步与通信：操作系统根据根据PCB中的进程同步和通信机制实施进程的同步与通信\n\n## 12、理解进程同步机制的基本概念\n\n进程同步机制的任务是，对多个相关进程在执行次序上进行协调，使并发执行的进程能按按照一定的规则共享系统资源，并能很好的合作，从而使程序的执行具有可再现性。**因此同步机制包含进程同步和进程互斥两个概念**。\n\n（1）进程同步和进程互斥\n\n- 进程同步：相互合作的进程能够互通消息、彼此协调运行，比如生产者和消费者问题，生产者生产一个商品后，消费者才能消费。\n- 进程互斥：两个或多个进程访问同一资源，当有一个进程访问时，其他进程不能访问。如生产者和生成者、消费者和消费者。\n\n（2）进程同步机制的两个制约关系\n\n- 间接相互制约：源于资源共享。（进程互斥）\n- 直接相互制约：源于进程间的合作。（进程同步）\n\n可以使用信号量机制实现进程同步和进程互斥。\n\n## 13、理解临界资源、临界区的概念\n\n临界资源：一次仅允许一个进程访问的资源，如打印机、磁带机，都属于临界资源，各个进程间应采用互斥访问方式。\n\n临界区：每个进程中访问临界资源的那段代码称为临界区。显然，若能保证各个进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。\n\n```tex\nwhile(TRUE)\n{\n   进入区\n   临界区\n   退出区\n   剩余区\n}\n```\n\n\n\n## 14、进程同步机制应遵循的规则\n\n所有的同步进制都应遵循下述四条准则：\n\n- **空闲让进**：当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。\n- **忙则等待**：当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。\n- **有限等待**：对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区。\n- **让权等待**：当进程不能进入自己的临界区时，应立即释放处理机。这里的“权”指处理机。\n\n## 15、用信号量机制解决经典进程同步问题\n\n（1）生产者-消费者问题\n\n生产者-消费者问题（多人多缓问题），有多个生产者和多个消费者，生产者向缓冲区中放数据，消费者从缓冲区中取数据。当缓冲区满时，生产者不能再产生数据，当缓冲区空时，消费者不能从缓冲区中取走数据。缓冲池是临界资源，**同一时刻只能有一个进程进入缓冲区**，可以利用互斥信号量mutex实现诸进程对缓冲池的互斥作用；利用信号量empty和full分别表示缓冲区中空缓冲区和满缓冲区的数量。只要缓冲区未满，生产者可将数据放入缓冲区，只要缓冲区非空，消费者便可从缓冲区中取走一个数据。其中，生产者和生产者之间、消费者和消费者之间是互传进程，生产者和消费者是同步进程。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126152544.png)\n\n\n\n```c\n/*生产者-消费者问题（多人多缓问题）伪代码*/\n// semaphore指信号量的类型\nsemaphore Sbuf=n, Sdata =0；\nsemaphore mutex=1;\nitem buffer[n]；\nint in=0, out=0；\n\nproceducer( ) {\n　　do{\n\t\tproducer an item nextp；\n\t\tP(Sbuf)；\n\t\tP(mutex)；\n\t\tbuffer[in]=nextp；\n\t\tin=(in+1) % n；\n\t\tV(mutex)；\n\t\tV(Sdata)；\n\t\t\n\t}while(TRUE);\n}\n \nconsumer( ) {\n　　do{\n\t\tP(Sdata)； \n\t\tP(mutex)；\n\t\tnextc=buffer[out]；\n\t\tout=(out+1) % n；\n\t\tV(mutex)；\n\t\tV(Sbuf)；\n\t\t\n\t}while(TRUE);\n}\n\nvoid main(){\n       cobegin\n         proceducer( ); consumer( ) ;\n       coend\n}\n\n```\n\n（2）读者-写者问题\n\n读者写者( Reader- Writer)问题也是一个著名的进程同步问题。一个数据文件或记录可被多个进程共享。把只要求\n读该文件的进程称为“读进程”，修改文件的进程称为“写进程”。有如下要求：\n\n- 允许多者读\n- 不允许多者写\n- 不允许读/写并进\n\n```c\n/*读者-写者问题伪代码*/\nsemaphore wmutex=1；\nsemaphore rmutex=1；\nint readcount=0；\nReader( ){\n  do{ \n\t\tP(rmutex);　　\n\t\tif (readcount==0)  P(wmutex)； \n\t\tV(rmutex)；\n\t\tperform read operation；\n\t\tP(rmutex);　\n\t\treadcount--;\n\t\tif (readcount==0)  V(wmutex)；\n\t\tV(rmutex)；\n\t\t\n\t}while(TRUE);\n}\n\nWriter( ){\n　do{\n\t\tP(wmutex)；\n　　　   perform write operation；\n　　　   V(wmutex)；\n\n\t}while(TRUE);\n}\n\nvoid main(){\n       cobegin\n         Reader( ); Writer( ) ;\n       coend\n}\n```\n\n在读者-写者问题中，写进程与写进程是互斥进程，读进程与写进程是互斥进程，可以看到，上面代码中声明了两个互斥信号量，并没有声明同步信号量，即读者-写者并没有同步进程。\n\n那么，如何判断两个进程是互斥或同步的呢？我认为，判断是否同步或互斥要看这两个进程对资源的使用情况，如果两个进程共享同一临界资源，那么肯定是互斥的，如果一个进程所需的资源依赖于另一个进程的输出，那么这两个进程是同步的。\n\n另外，常见的进程同步问题还有奇偶数问题、黑白棋子问题、和尚提水问题，限于篇幅，这里就不具体介绍了。\n\n## 16、理解进程通信及其方式\n\n进程通信：指进程之间的信息交换，其所交换的信息量，少者是一个状态或数值，多者则是成千上万个字节。由于进程的同步与互斥也要在进程间交换一定的信息，故也称进程通信，但它们是低级进程通信，因为它们信号量机制实现进程通信，通信效率低，信息量少。\n\n另外，有一种基于共享数据结构的通信方式，它要求诸进程共用某些数据结构，借以实现诸进程间的信息交换。如在生产者—消费者问题中，就是用有界缓冲区这种数据结构来实现通信的。这里，公用数据结构的设置及对进程间同步的处理，都是程序员的职责。这种通信方式是低效的，只适于传递相对少量的数据，也属于低级通信。 \n\n**进程的高级通信可以实现进程间大量数据的传送**，具体的高级通信方式有共享存储器系统、管道通信系统、消息传递系统、客户机/服务器系统。\n\n- 基于共享存储区的通信方式：为了传输大量数据，在存储器中划出了一块共享存储区，诸进程可通过对共享存储区中数据的读或写来实现通信，属于高级通信。\n- 管道通信系统：建立在文件系统基础上，适用于大量变化着的信息交换。所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名pipe文件。向管道(共享文件)提供输入的发送进程(即写进程)，以字符流形式将大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。为了协调双方的通信，管道机制必须提供三种协调能力，即互斥、同步、确定对方是否存在。\n- 消息传递系统：在该机制中，进程间的数据交换是以格式化的消息(message)为单位的；在计算机网络中，又把message称为报文。消息传递系统因其实现方式的不同，可进一步分为两类：\n  a. 直接通信方式：发送进程利用OS提供的发送原语，直接把消息发送给目标进程。\n  b. 间接通信方式：进程之间通过一个作为共享数据结构的中间实体（称为邮箱）的方式进行消息的发送和接收。\n- 客户机/服务器系统：通过计算机网络进行通信。\n\n## 17、进程与线程的区别与联系\n\n（1）在传统的OS中，进程是一个独立拥有资源，能够独立运行，同时又是可独立调度和分派的基本单位。\n\n（2）在OS引入线程之后，把线程一个独立调度和分派的基本单位，线程本身并不拥有系统资源，仅有一点不可缺少的、能保证独立运行的资源。引入线程的目的是减少程序在并发执行时带来的时空开销，\n\n（3）同一个进程中，线程的切换不会引起进程的切换，但从一个线程切换到另一个进程中的线程时，必然会引起进程的切换。线程的上下文切换比进程的上下文切换带来的开销小得多。\n\n（4）一个进程中含有若干个相对独立的线程，多个线程可并发执行。在多线程OS中，所谓进程的执行状态，实际上是指该进程中的某些线程正在执行。\n\n## 18、作业调度的概念及其调度算法\n\n作业调度（又称高级调度）是指根据某种算法，决定将外存上处于后备队列中的哪几个作业调入内存，为它们创建进程、分配必要的资源，并将它们放入就绪队列。作业调度主要用于多道批处理系统中，而在分时和实时系统中不设置这种调度。\n\n作业调度算法有：\n\n（1）先来先服务(FCFS)调度算法\n\n按照作业到达的先后次序来进程调度，该调度算法也适用于进度调度\n\n（2）短作业优先(SJF)调度算法\n\n根据作业的长短来计算优先级，作业越短，其优先级越高\n\n（3）优先级调度算法(PSA)\n\n对于先来先服务算法，作业的等待时间就是作业的优先级；对于短作业优先调度算法，作业的长短就是作业的优先级。\n\n（4）高响应比优先（HRRN）调度算法\n\n既考虑了作业的等待长度，又考虑了运行时间的调度算法，是一个动态的优先级，响应比=优先级=(等待时间+要求服务时间)/要求服务时间\n\n## 19、进程调度的概念及其调度算法\n\n进程调度（又称低级调度）是指，根据某种算法，**决定就绪队列中的哪个进程应获得处理机**，并由分派/调度程序将处理机分配给被选中的进程。在多道批处理系统、分时系统和实时系统中，都必须配置这种调度。除了高级调度和低级调度之外，还有中级调度，它实际上是完成内外存的换入和换出，提高内存的利用率。\n\n进程调度算法有：\n\n（1）轮转(RR)调度算法\n\n系统将所有的就绪进程按FCFS策略排成一个就绪队列，系统可设每隔一定时间(如30ms)便产生一次中断，按照队列中的顺序，把CPU分给进程，并令其执行一个时间片。\n\n（2）优先级调度算法\n\n把处理机分配给就绪队列中优先级最高的进程。\n\n（3）多级反馈队列调度算法\n\n设置多个队列，为每个队列设置不同的优先级，第一个队列优先级最高，第二个次之，最后一个队列优先级最小。\n\n每个队列都采用FCFS算法，当新进程进入内存后，首先将它放入第一队列的末尾，按照FCFS算法调度。当轮到该进程执行时，如果它能在该时间片内完成，便可撤离系统，否则，将它放入第二个队列的末尾，依次类推。当进程被降到最后一个队列后，便采取RR方式进行调度。\n\n队列间按照优先级调度。首先调度最高优先级队列中的各个进程，仅当第一队列空闲才调度第二队列中的进程运行。\n\n多级反馈队列示意图如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126165210.png)\n\n\n\n（4）基于公平原则的调度算法\n\n以上的几种进程调度算法保证的只是优先级运行，并不能保证占用了多少处理机时间，而基于公平原则的调度算法考虑的是调度的公平性，常见有两种相对公平的调度算法。\n\n- 保证调度算法：让每个进程都获得相同的处理机时间。\n- 公平分享调度算法：让每个用户获得相同的处理机时间。\n\n\n\n## 20、实时调度及其调度算法\n\n（1）实现实时调度的基本条件\n\n- 提供必要的信息：就绪时间、开始截止时间和完成截止时间、处理时间、资源要求、优先级。\n- 系统处理能力强：在实时系统中，若处理机的处理能力不够强，则有可能因处理机忙不过，而致使某些实时任务不能得到及时处理，从而导致发生难以预料的后果。\n- 采用抢占式调度机制：在含有HRT（硬实时任务）的实时系统中，广泛采用抢占机制。这样便可满足HRT任务对截止时间的要求。\n- 具有快速切换机制：对中断的快速响应能力、快速的任务分派能力。\n\n（2）实时调度算法的分类\n\n  ① 根据实时任务性质，可将实时调度的算法分为硬实时调度算法和软实时调度算法；② 按调度方式，则可分为非抢占调度算法和抢占调度算法。\n\n**非抢占式调度算法**：\n\n- 非抢占式轮转调度算法：用于要求不太严格的实时控制系统。\n- 非抢占式优先调度算法：用于有一定要求的实时控制系统。\n\n**抢占式调度算法**：\n\n- 基于时钟中断的抢占式优先级调度算法：时钟中断发生时才抢占处理机，可用于大多数的实时系统。\n- 立即抢占的优先级调度算法：能获得非常快的响应。\n\n（3）两种常见的实时调度算法\n\n①**最早截止时间优先EDF（Earliest Deadline First）算法** \n\n算法根据任务的截止时间来确定任务的优先级。截止时间愈早，其优先级愈高。该算法要求在系统中保持一个实时任务就绪队列，该队列按各任务截止时间的早晚排序。算法既可用于抢占式调度，也可用于非抢占式调度方式中。 \n\n② **最低松弛度优先LLF（Least Laxity First）算法**\n\n该算法在确定任务的优先级时，根据的是任务的紧急(或松弛)程度。任务紧急程度愈高，赋予该任务的优先级就愈高，以使之优先执行。**该算法主要用于可抢占调度方式中**。 \n\n\n\n\n\n\n\n## 21、作业平均周转时间和平均带权周转时间\n\n（1）平均周转时间短\n\n作业的周转时间包含四个部分：作业在外存后备队列上等待(作业)调度的时间，进程在就绪队列上等待进程调度的时间，进程在CPU上执行的时间，以及进程等待I/O操作完成的时间。其中的后三项在一个作业的整个处理过程中，可能发生多次。\n\nn个作业的平均周转时间=n个作业的周转时间之和/n。\n\n（2）带权周转时间\n\n作业的周转时间T与系统为它提供服务的时间$T_s$之比，即$W=T/T_s$\n\n（3）平均带权周转时间\n\n平均带权周转时间可表示为：$W{\\rm{ = } }\\frac{1}{n}\\sum\\limits_{i = 1}^n {\\frac{ { {T_i} } }{ { {T_s} } } }$\n\n## 22、CPU利用率和CPU最小时钟周期\n\n（1）CPU利用率\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126171358.png)\n\n（2）CPU最小时钟周期\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126171425.png)\n\n**时钟发生器发出的脉冲信号做出周期变化的最短时间称之为震荡周期**，也称为 CPU 时钟周期，它是计算机中最基本的、最小的时间单位。每一次震荡周期到来，芯片内的晶体管就改变一次状态，让整个芯片完成一定任务。也就是说在一个时钟周期内，**CPU仅完成一个最基本的动作**，一条指令的执行可能需要好几个时钟周期。由此，更小的时钟周期就意味着更高的工作频率。CPU时钟周期的倒数就是时钟频率。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126171621.png)\n\n## 23、死锁及死锁产生的条件\n\n如果一组进程中的每一个进程都在等待仅由该组进程中的其它进程才能引发的事件，那么该组进程是是死锁的。\n\n产生死锁必须具备四个条件，只要任一条件不成立，死锁就不会发生。它们分别是互斥条件、请求和保持条件、不可抢占条件，循环等待条件。\n\n- 互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求该资源，则请求者只能等待，直至占有该资源的进程用毕释放。\n- 请求和保持条件：指进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。\n- 不可抢占条件：指进程已获得的资源在未使用完之前不能被抢占，只能在使用完时由自己释放。\n- 循环等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，…，Pn}中的P0正在等待一个P1占用的资源； P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。\n\n## 24、处理死锁的方法\n\n目前处理死锁的方法可归结为四种：\n\n（1）预防死锁。一种较简单和直观的事先预防方法。该方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来预防发生死锁。\n（2）避免死锁。在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。同样是属于事先预防的策略，但它并不是事先采取各种限制措施，去破坏死锁的四个必要条件。\n\n（3）检测死锁。允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及时地检测出死锁的发生，然后采取适当的措施，把进程从死锁中解脱出来。\n\n（4）解除死锁。这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。\n\n为了更清楚理解处理死锁四种方法，下面对这四种方法采取的具体措施进行介绍：\n\n（1）预防死锁\n\n预防死锁的方法是通过破坏产生死锁的四个必要条件中的一个或几个，以预防发生死锁。由于互斥条件是非共享设备所必须的，不仅不能改变，还应加以保证，因此主要是破坏产生死锁的后三个条件。  \n\n**破坏“请求和保持” 条件（静态分配资源法）**\n该方法规定，所有进程在开始运行之前，必须一次性地申请其在整个运行过程中所需的全部资源。如果系统有足够资源，则分配，破坏了“请求”条件；如果资源不足，则一个资源也不分配，破坏了“保持”条件。\n\n**破坏“不可抢占” 条件（剥夺式分配资源法）**\n进程是逐个地提出对资源的要求的。当一个已经保持了某些资源的进程，再提出新的资源请求而不能立即得到满足时，必须释放它已经保持了的所有资源，待以后需要时再重新申请。这意味着某一进程已经占有的资源，在运行过程中会被暂时地释放掉，也可认为是被抢占了，从而破坏了“不可抢占”条件。\n\n**破坏“循环等待” 条件（按序分配资源法）**\n按顺序分配资源，比如规定每个进程必须按序号递增的顺序请求资，这样，在所形成的资源分配图中，不可能再出现环路，因而破坏了“循环等待”条件。\n\n（2）避免死锁\n\n在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁，但它并不是事先采取各种限制措施。\n\n由于在资源动态分配的过程中，要确保系统始终处于安全状态，可以利用**银行家算法**避免死锁。\n\n银行家算法：当进程在请求一组资源时，首先确定系统中是否有足够的资源分配给他。若有，再进一步计算系统分配这些资源给该进程后，是否会出现不安全状态(是否满足产生死锁的条件)，如果不满足产生死锁的条件，才将资源分配给它。\n\n（3）检测死锁\n\n用资源分配图检测死锁\n\n圆圈代表进程，方框代表资源一类资源，方框中的点代表这一类资源中的一个资源，由进程出发的边是资源请求边，由资源出发的边是资源分配边。**寻找既不阻塞又非独立的进程节点**Pi，如果Pi能够获取所需的资源，则消去Pi的请求边和分配边，依次类推，直到所有的进程节点都是孤立这点，则称该图是可完全简化图。\n\n一个资源分配图中的进程产生**死锁的**充分条件是：当且仅当该资源分配图是不可完全简化图。\n\n例如，下面的资源分配图\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126181401.png)\n\n首先，找到寻找既不阻塞又非独立的进程节点P1，消去P1的请求边和分配边，P1释放资源后，便可使P2获得资源而继续运行，直至P2完成后又释放出它所占有的全部资源，再消去P2的请求边和分配边，此时资源分配图中所有的进程结点都成为孤立结点，该图是可完全简化的，不会发生死锁。\n\n用资源分配图检测死锁更详细的过程可参考[死锁检测-资源分配图的简化](https://blog.csdn.net/qq_39328436/article/details/111123779)\n\n（4）解除死锁\n\n主要有两种方法解决死锁，分别是抢占资源和终止（撤消）进程的方式。\n\n- 抢占资源。从其它进程抢占足够数量的资源给死锁进程，以解除死锁状态。\n- 终止（撤消）进程。终止（或撤销）系统中的一个或多个死锁进程，直至打破循环环路，使系统从死锁状态中解脱出来。\n\n## 25、存储器的多层结构\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126182822.png)\n\n存储器分为三个层次，分别是CPU寄存器、主存、辅存。\n\n- CPU寄存器：寄存器具有与处理机相同的速度，完全能与CPU协调工作，但价格十分昂贵。\n- 主存：包括高速缓存、主存储器、磁盘缓存 。\n  高速缓存：介于寄存器和主存贮器之间，主要用于备份主存中常用的数据，以减少处理机对主存储器的访问次数。\n  主存储器：简称主存或内存，用于保存进程运行时的程序和数据。\n  磁盘缓存：为了缓和磁盘的I/O和主存访问速度的不匹配，从而设置磁盘缓存。\n- 辅存：磁盘，可移动存储介质。\n\n## 26、程序装入内存转变为可以执行程序的过程\n\n用户程序要在系统中运行，必须先将它装入内存，然后再将其转变为一个可以执行的程序，通常要经过以下步骤：编译、 链接、 装入。\n\n（1）编译：由编译程序对用户源程序进行编译，形成若干个**目标模块**。\n\n（2）链接：由链接程序将编译后形成的一组目标模块以及它们需要的库函数链接在一起，形成一个完整的装入模块(可执行目标程序)。\n\n（3）装入：由装入程序将装入模块装入内存。\n\n这三步的示意图如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126183251.png)\n\n\n\n\n\n## 27、程序的装入和链接方式有哪些？\n\n（1）程序的装入\n\n为了阐述方便，先介绍无需进行链接的单个目标模块的装入过程。该目标模块也就是装入模块。在将一个转入模块装入内存时，可以有如下装入方式：\n\n- 绝对装入方式。当计算机系统很小，且仅能运行单道程序时，完全有可能知道程序将驻留在内存的什么位置。此时可以采用绝对装入方式。用户程序经编译后，将产生绝对地址(即物理地址)的目标代码。 装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完全相同，故不须对程序和数据的地址进行修改。\n- 可重定位装入方式（静态重定位）。**所谓的重定位是指，在装入时对目标程序中指令和数据的修改过程，即地址变换。**可重定位装入方式的地址变换通常是在装入时一次完成的，以后不再改变，故称为静态重定位。\n- 动态运行时的装入方式（动态重定位）。当把装入程序装入内存后，并不立即把装入模块中的逻辑地址转换为物理地址（即不立即进行地址变换），而是把这种地址变换推迟到程序真正要执行时才进行。因此，装入内存后所有的地址都仍是逻辑地址。\n\n（2）程序的链接\n\n源程序经过编译后，可得到一组目标模块。链接程序的功能是将这组目标模块以及它们所需要的函数库装配成一个完成的装入模块。在对目标模块进行链接时，根据链接的时间不同，可把链接分成如下三种：\n\n- 静态链接(Static Linking)方式：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。\n- 装入时动态链接(Load-time Dynamic Linking)：这是指将用户源程序编译后所得到的一组目标模块，在装入内存时，采用边装入边链接的链接方式。\n- 运行时动态链接(Run-time Dynamic Linking)：这是指对某些目标模块的链接，是在程序执行中需要该(目标)模块时，才对它进行的链接。\n\n## 28、存储器（内存）的管理策略或方式\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126212226.png)\n\n## 29、连续分配存储管理方式\n\n连续分配存储管理方式是指为某一程序分配连续的内存空间，程序在内存中的逻辑地址相邻，体现在内存空间分配时物理地址相邻。连续分配方式可分为四类：\n\n（1）单一连续分配（单用户连续分配）\n\n用于单用户、单任务OS中。把内存分为系统区和用户区两部分，系统区仅提供给OS使用，它通常是放在内存的低址部分。而在用户区内存中，仅装有一道用户程序，即整个内存的用户空间由该程序独占。程序装入时一般采用静态重定位的方式。\n\n（2）固定分区分配\n\n在多道程序系统出现以后，为了能在内存中装入多道程序，且使这些程序之间又不会发生相互干扰，于是将整个用户空间划分为若干个固定大小的区域，在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的种可运行多道程序的分区式存储管理方式。如果在内存中有四个用户分区，便允许四个程序并发运行。当有一空闲分时，便可以再从外存的后备作业队列中选择一个适当大小的作业，装入该分区。当该作业结束时，又可再从后备作业队列中找出另一作业调入该分区。\n\n对于分区的划分，可以大小相等(指所有的内存分区大小相等)，也可以分为若干大小不等的分区。\n\n为了便于内存分配，通常将分区按其大小进行排队，并为之建立一张分区使用表，其中各表项包括每个分区的起始地址、大小及状态(是否已分配)，如下图所示。当有一用户程序要装入时，由内存分配程序依据用户程序的大小检索该表，从中找出一个能满足要求的、尚未分配的分区，将之分配给该程序，然后将该表项中的状态置为“已分配”。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126214010.png)\n\n每个分区只能装一个作业，作业不一定占满分区，所以会产生碎片、零头。需要注意的是，固定分区分配在程序装入内存时采用的也是静态重定位的方式。\n\n（3）动态分区分配（可变分区分配）\n\n动态分区分配是根据进程的实际需要，动态地为之分配内存空间。其分区的大小可以改变。\n\n为了实现动态分区分配，系统中必须配置相应的数据结构，用以描述空闲分区和己分配分区的情况，为分配提供依据。常用的数据结构有以下两种形式：①空闲分区表，在系统中设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括分区号、分区大小和分区始址等数据项，如下图所示。②空闲分区链。为了实现对空闲分区的分配和链接，在每个分区的起始部分设置一些用于控制分区分配的信息以及用于链接各分区所用的前向指针，在分区尾部则设置一后向指针。通过前、后向链接指针，可将所有的空闲分区链接成一个双向链，如下图所示。为了检索方便，在分区尾部重复设置状态位和分区大小表目。当分区被分配出去以后。把状态位由“0”改为“1”，此时，前、后向指针已无意义。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126215149.png)\n\n在动态分区管理中，主要的操作是分配内存和回收内存。\n\n**分配内存**：设请求的分区大小为u.size，表中每个空闲分区的大小可表示为m.size，而size是事先规定的不在切割的剩余分区的大小。 分配内存的流程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126220559.png)\n\n**回收内存**：\n\n- 回收区与插入点的前一个空闲分区F1相邻接。应将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区F1的大小。\n- 回收分区与插入点的后一空闲分区F2相邻接。可将两分区合并，形成新的空闲分区，但用回收区的首址作为新空闲区的首址，大小为两者之和。\n- 回收区同时与插入点的前、后两个分区邻接。此时将三个分区合并，使用F1的表项和F1的首址，取消F2的表项，大小为三者之和。\n- 回收区既不与F1邻接，又不与F2邻接。这时应为回收区单独建立一个新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126220856.png)\n\n**动态分区分配采用的是动态重定位的方式。**\n\n（4）动态可重定位分区分配\n\n连续分配方式的一个重要特点是，一个系统或用户程序必须被装入一片连续的内存空间中。当一台计算机运行了一段时间后，它的内存空间将会被分割成许多小的分区，而缺乏大的空闲空间。即使这些分散的许多小分区的容量总和大于要装入的程序，但由于这些分区不相邻接，也无法把该程序装入内存。\n\n如下图所示，图a中示出了在内存中现有四个互不邻接的小分区，它们的容量分别为10KB、30KB、14KB和26KB，其总容量是80KB。但如果现在有一个作业到达，要求获得40KB的内存空间，**由于必须为它分配一个连续空间**，故此作业无法装入。这种不能被利用的小分区即是前已提及的“碎片”，或称为“零头“。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126230014.png)\n\n若想把大作业装入，可采用的一种方法是：将内存中的所有作业进行移动，使它们全都相邻接。这样，即可把原来分散的多个空闲小分区拼接成一个大分区，可将一个作业装入该区。这种通过移动内存中作业的位置，把原来多个分散的小分区拼接成一个大分区的方法,称为“拼接”或“紧凑”，如上图b所示。\n\n虽然“紧凑”能获得大的空闲空间，但也带来了新的问题，即经过紧凑后的用户程序在内存中的位置发生了变化，此时若不对程序和数据的地址加以修改(变换)，则程序必将无法执行。为此，在每次“紧凑”后，都必须对移动了的程序或数据进行重定位。为了提高内存的利用率，系统在运行过程中是经常需要进行“紧凑”的。每“紧凑”一次，就要\n对移动了的程序或数据的地址进行修改，这不仅是一件相当麻烦的事情，而且还大大地影响到系统的效率，下面要介绍的动态重定位方法将能很好地解决此问题。\n\n**动态重定位**\n\n在前面所介绍的**动态运行时装入的方式**中，作业装入内存后的所有地址仍然都是相对(逻辑)地址，而将相对地址转换为绝对(物理)地址的工作被推迟到程序指令要真正执行时进行。为使地址的转换不会影响到指令的执行速度，必须有硬件地址变换机构的支持，即须在系统中增设一个重定位寄存器，用它来存放程序(数据)在**内存中的起始地址**。程序在执行时，真正访问的内存地址是相对地址与重定位寄存器中的地址相加而形成的。下图显示出了动态重定位的实现原理。地址变换过程是在程序执行期间，随着对每条指令或数据的访问自动进行的，故称为**动态重定位**。当系统对内存进行了“紧凑”，而使若干程序从内存的某处移至另一处时，不需对程序做任何修改，只要用该程序在内存的新起始地址去置换原来的起始地址即可。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126231200.png)\n\n**动态重定位分区分配算法**\n\n**动态重定位分区分配算法与动态分区分配算法基本上相同**，差别仅在于：在动态重定位分区分配算中，增加了紧凑的功能。通常，当该算不能找到一个足够大的空闲分区以满足用户需求时，如果所有小的空闲分区的容量总和大于用户的要求，这时便须对内存进行“紧凑”，将经“紧凑”后所得到的大空闲分区分配给用户。如果所有小的空闲分区的容量总和仍小于用户的要求，则返回分配失败信息。下图是动态分区分配算法流程图：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126231750.png)\n\n\n\n## 30、常见的动态分区分配算法\n\n（1）基于顺序搜索的动态分区分配算法\n\n①首次适应(first fit，FF)算法\n\nFF算法要求空闲分区链以**地址递增**的次序链接。\n\n在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要求的空闲分区为止。然后再按照作业的大小，从该分区中划出一块内存空间，分配给请求者，余下的空闲分区仍留在空闲链中。\n\n②循环首次适应(next fit，NF)算法（下次适应）\n\nNF算法要求空闲分区链以**地址递增**的次序链接成循环链。\n\n算法是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区，从中划出一块与请求大小相等的内存空间分配给作业。\n\n③最佳适应(best fit，BF)算法\n\nBF算法要求空闲分区链以**容量大小递增**的次序链接。\n\n为一作业选择分区时总是寻找其大小最接近于作业大小的存储区域。\n\n④最坏适应(worst fit，WF)算法\n\nWF算法要求空闲分区链以**容量大小递减**的次序链接。\n\n在为作业选择存储区域时，总是挑选一个最大的空闲区。在划分后剩下的空闲区也是最大的，对以后的分配很可能是有用的。\n\n（2）基于索引搜索的动态分区分配算法\n\n①快速适应(quick fit)算法（分类搜索法）\n\n将空闲分区根据其**容量大小进行分类**，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，这样系统中存在多个空闲分区链表。\n\n空闲分区的分类是根据进程常用的空间大小进行划分，如2 KB、4 KB、8 KB等，对于其它大小的分区，如7 KB这样的空闲区，既可以放在8 KB的链表中，也可以放在一个特殊的空闲区链表中。\n\n在分配内存时，根据进程的长度，寻找到能容纳它的最小空闲区链表，并取下第一块进行分配即可。\n\n②伙伴系统(buddy system)\n\n该算法规定，无论已分配分区或空闲分区，其大小均为2的k次幂，k为整数，1≤k≤m，其中：$2^1$表示分配的最小分区的大小，$2^m$表示分配的最大分区的大小，通常$2^m$是整个可分配内存的大小。 \n\n假设系统的可利用空间容量为$2^m$个字，则系统开始运行时，整个内存区是一个大小为$2^m$的空闲分区。在系统运行过程中，由于不断地划分，将会形成若干个不连续的空闲分区，将这些空闲分区按分区的大小进行分类。对于具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表，这样，不同大小的空闲分区形成了k个空闲分区链表。\n\n设分配一个长度为n的存储空间，首先计算一个i值，使$2^{i-1}<n\\le 2^i$。在空闲分区大小为$2^i$的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。\n\n否则，在分区大小为$2^{i+1}$的空闲分区链表中寻找。若找到，则把该空闲分区分为相等的两个分区，这两个分区称为**一对伙伴**，其中的一个分区用于分配，而把另一个加入分区大小为$2^i$的空闲分区链表中。\n\n若大小为$2^{i+1}$的分区也不存在，则需要查找大小为$2^{i+2}$的空闲分区，若找到则对其进行两次分割。若仍然找不到，则继续查找大小为$2^{i+3}$的空闲分区，依此类推。\n\n在最坏的情况下，可能需要对2k的空闲分区进行k次分割才能得到所需分区。\n\n在回收内存时，一次回收也可能要进行多次合并，如回收大小为$2^i$的空闲分区时，若已存在$2^i$的空闲分区时，则应将其与伙伴分区合并大小为$2^{i+1}$的闲分区；若已存在$2^{i+1}$的空闲分区时，又应继续与其伙伴分区合并为大小为$2^{i+2}$的空闲分区，依此类推。\n\n（3）哈希算法\n\n在快速适应算法和伙伴系统算法中，都是将空闲分区根据分区大小进行分类，对于每一类空闲分区，设立一个空闲分区链表。在为进程分配空间时，需要在一张管理索引表中查找到所需空间大小所对应的表项，从中得到对应的空闲分区链表表头指针，从而通过查找得到一个空闲分区。\n\n哈希算法是利用哈希快速查找的优点，建立哈希函数，构造一张**以空闲分区大小为关键字**的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。　　\n\n当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算，即得到在哈希表中的位置，从中得到相应的空闲分区链表，实现最佳分配策略。\n\n## 31、分页存储管理方式的基本概念\n\n我们知道，离散分配方式分为分页存储管理方式、分段存储管理方式、段页式存储管理方式。这一题介绍分页存储管理方式。\n\n**（1）引入分页的好处**\n\n①没有外碎片，每个内碎片不超过页面大小。\n\n②一个程序的页面不必连续存放\n\n③以页面作为内存分配的基本单位，能有效地提高内存利用率\n\n**（2）分页存储管理方式**\n\n分页存储管理方式是指将**用户程序的地址空间**分为若干个固定大小的区域，称为页或页面（典型大小一般为4KB）。相应地，也将内存空间分为若干个物理块，页和块的大小相同，这样可将用户程序的任一页放入一物理块中，实现离散分配。分页的地址结构包含页号和页内地址。分页地址结构如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127102037.png)\n\n*图中地址长度为32位，其中0~11位为页内地址，即每页大小为4KB；12~31位页号，地址空间最多允许有1M页，即2的20次方个页面*\n\n在分页系统中，允许将进程的各个页离散地存储在内存的任一物理块中，为保证进程仍然能够正确地运行，即能在内存中找到每个页面所对应的物理块，**系统为每个进程建立了一张页面映像表**，简称**页表**，从而实现从页号到物理块号的地址映射。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126233741.png)\n\n（3）**分页存储管理方式中的地址变换机构**\n\n为了实现进程从逻辑地址到物理地址的变换功能，在系统设置了页表寄存器，用于存放页表在内存中的始址和页表的长度，当进程要访问某个逻辑地址中的数据时，地址变换机构会先将要访问的页号与页表长度进行比较，如果页号大于页表长度，则表示本次所访问的地址已超越进程的地址空间，将产生地址**越界中断**。如果未出现越界错误，则**将页号与页表项长度相乘再和页表始址相加**，便得到该表项在页表中的位置，于是可从中得到该页的物理块号，再与页内地址拼接，得到物理地址，再根据物理地址获取所需数据。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126235007.png)\n\n（4）**具有快表的地址变换机构**\n\n由于页表是存放在内存中的，这使CPU在每存取一个数据时，都要两次访问内存。第一次是访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量W拼接，以形成物理地址。第二次访问，才是从第一次所得地址中获得所需数据(或向此地址中写入数据)。\n\n为了提高地址变换速度，可增加一个快表(寄存器)，先从快表读出该页所对应的物理块号。如果未在快表中找到所对应的表项，则再从页表中去寻找。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210126235222.png)\n\n\n\n（5）**两级和多级页表**\n\n现代的计算机系统中，都支持非常大的逻辑地址空间。例如，对于一个具有32位逻辑地址空间的分页系统，规定页面大小为4KB即$2^{12}$B，在每个进程页表中的页表数最大可达$2^{20}$个即1M个，又因为每个页表项在内存中占一个字节，故每个进程仅仅其页表就要占用1MB的内存空间（分页中的页表在内存中占据一片连续的空间），而且还要求是连续的，多个进程情况下，这简直就是灾难。显然这是不现实的，为此可以将页表的存储也采用离散分配方式，即：\n\n①对于页表所需的内存空间，采用离散分配方式，以解决难以找到一块连续的大内存空间的问题。\n\n②只将当前需要的部分**页表项**调入内存，其余的**页表项**仍驻留在磁盘上，需要时再调入。\n\n**两级页表**\n\n针对难于找到大的连续的内存空间来存放页表的问题，可利用将页表进行分页，并离散地将各个页面分别存放在不同的物理块中的办法来加以解决，即两级页表的方式。下图是两级页表的结构\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127000147.png)\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127000217.png)\n\n\n\n具有两级页表的地址变换机构\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127000319.png)\n\n**多级页表**\n\n在二级页表基础上再将页表进行分页，即采用三级页表结构。依次类推，可进行多级分页。\n\n## 32、分段存储管理方式的基本概念\n\n我们知道，离散分配方式分为分页存储管理方式、分段存储管理方式、段页式存储管理方式。这一题介绍分段存储管理方式。\n\n**（1）为什么要引入分段**\n\n一方面是由于通常的程序都可分为若干个段，如主程序段、子程序段A、子程序段B、…、数据段以及栈段等，每\n个段大多是一个相对独立的逻辑单位；另一方面，实现和满足信息共享、信息保护、动态链接以及信息的动态增长等需要，也都是以段为基本单位的。所以，要引入分段存储管理方式。\n\n**（2）分段存储管理方式**\n\n分段存储管理方式把用户程序的地址空间分为若干个大小**不同**的段，每段定义一组相对完整的信息，(内存空间)分配时以段为单位进行分配。分段的地址结构包含段号和段内地址。分段的地址结构如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127104958.png)\n\n*在该地址结构中，允许一个作业最长有64K个段，每个段最大长度为64KB*\n\n分段存储管理方式为使程序能正常运行，亦即，能从物理内存中找出每个逻辑段所对应的位置，应像分页系统那样，**在系统中为每个进程建立一张段映射表**，简称**段表**，从而实现从逻辑段到物理内存区的映射。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127105313.png)\n\n\n\n（3）**分段存储管理方式中的地址变换机构**\n\n为了实现进程从逻辑地址到物理地址的变换功能，在系统设置了段表寄存器，用于存放段表在内存中的始址和段表的长度，在进行地址变换时，会先将要访问的段号与段表长度进行比较，如果段号大于段表长度，则表示本次所访问的地址已超越进程的地址空间（逻辑空间），将产生地址**越界中断**。如果未出现越界错误，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址。然后，再检查段内地址是否超过该段的段长。若超过，同样发生越界中断。若未越界，则将该段的基址与段内地址相加，即可得到要访问的内存的物理地址。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127112132.png)\n\n（4）**具有快表的地址变换机构**\n\n像分页系统一样，当段表放在内存中时，每访问一个数据，都须**访问两次内存**，从而极大地降低了计算机的速率。解决的方法也和分页系统类似，再增设一个联想存储器（**快表**），用于保存最近常用的段表项。由于一般段比页大，因而段表项的数目比页表项的数目少，其所需的联想存储器也相对较小，便可以显著地减少存取数据的时间，比起没有地址变换的常规存储器的存取速度来仅慢约10%～15%。\n\n## 33、分页和分段的主要区别\n\n（1）页是信息的物理单位，分页是由于系统管理的需要。段则是信息的逻辑单位，分段的目的是为了能更好地满足用户的需要。\n\n（2） 页的大小固定且由系统决定，在系统中只能有一种大小的页面；而段的长度却不固定，决定于用户所编写的程序。\n\n（3）分页的用户程序地址空间（逻辑空间）是一维的。由于分页完全是系统的行为，故在分页系统中，用户程序的地址是属于单一的线性地址空间，程序员只需利用一个记忆符即可表示一个地址。而分段是用户的行为，故在分段系统中，用户程序的地址空间是二维的，程序员在标识一个地址时，既需给出段名，又给出段内地址。\n\n## 34、段页式存储管理方式的基本概念\n\n我们知道，离散分配方式分为分页存储管理方式、分段存储管理方式、段页式存储管理方式。这一题介绍段页式存储管理方式。\n\n（1）为什么要引入段页式\n\n分页系统以页面作为内存分配的基本单位，能有效地提高内存利用率，而分段系统以段作为内存分配的基本单位，它能够更好地满足用户多方面的需要。如果能对两种存储管理方式“各取所长”，则可形成一种新的存储器管理方式——段页式存储管理方式。这种新的系统既具有分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点，又能像分页系统那样，很好地解决内存的外部碎片问题。\n\n（2）段页式存储管理方式\n\n段页式存储管理方式是分段和分页原理结合的产物，即先将用户程序分为若干个段，再把每个段分成若干个页，并为每个段赋予一个段名。段页式的地址结构包含段号和段内页号以及页内地址。段页式的地址结构如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127133546.png)\n\n*在该地址结构中，允许一个作业最多有256个段，每段最多有4K个页，每页大小为4KB*\n\n（3）段页式存储管理方式中的地址变换\n\n在段页式系统中，为了实现从逻辑地址到物理地址的变换，**系统中需要同时配置段表和页表**。**段表的内容不再是内存始址和段长，而是页表始址和页表长度**。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127134135.png)\n\n地址变换过程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127134213.png)\n\n其实就是先进行分段的地址变换，根据段号从段表中找到对应的页表，再进行分页的地址变换，根据页号从页表中找到相应页面在内存中的起始地址（即物理块号），最后再结合页内地址，找到在内存中的物理地址，\n\n（4）具有快表的地址变换机构\n\n**在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中，取出指令或数据。**\n\n为了提高执行速度，在地址变换机构中增设一个联想存储器（快表）。\n\n\n\n## 35、虚拟存储器系统的基本概念\n\n存储器（内存）的管理策略除了连续分配方式、离散分配方式之外，还有虚拟存储系统。\n\n（1）为什么要引入虚拟存储器\n\n前面所介绍的各种存储器管理方式有一个共同的特点，即**它们都要求将一个作业全部装入内存后方能运行**。于是，出现了下面这样两种情况：\n\n①有的作业很大，其所要求的内存空间超过了内存总容量，作业不能全部被装入内存，致使该作业无法运行。\n\n②有大量作业要求运行，但由于内存容量不足以容纳所有这些作业，只能将少数作业装入内存让它们先运行，而将其它大量的作业留在外存上等待。\n\n出现上述两种情况的原因都是由于内存容量不够大。一个显而易见的解决方法是从物理上增加内存容量，但这往往会受到机器自身的限制，而且无疑要增加系统成本，因此这种方法是受到一定限制的。另一种方法是从逻辑上扩充内存容量，这正是虚拟存储技术所要解决的主要问题。\n\n（2）局部性原理\n\n局部性原理是指，在一个较短的时间内，程序的执行仅局限于**某个部分**，相应地，它所访问的存储空间也局限于某个区域。\n\n局限性表现在时间局限性和空间局限性。\n\n①时间局限性。 如果程序中的某条指令被执行，则不久以后该指令可能再次执行；如果某数据被访问过，则不久以后该数据可能再次被访问。 产生时间局限性的典型原因是在程序中存在着大量的循环操作。\n\n②空间局限性。 一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，其典型情况便是程序的顺序执行。\n\n（3）虚拟存储器\n\n**基于局部性原理可知，应用程序在运行之前没有必要将之全部装入内存**，而仅须将那些当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它所要访问的页(段)已调入内存，便可继续执行下去；但如果程序所要访问的页(段)尚未调入内存(称为缺页或缺段)，便发出**缺页(段)中断请求**，此时OS将利用**请求调页(段)功能**将它们调入内存，以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)，OS还须再利用**页(段)的置换功能**，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的页(段)调入内存，使程序继续执行下去。这样，便可使一个大的用户程序在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。\n\n总结一下，所谓虚拟存储器，是指具有**请求调入功能和置换功能**，**能从逻辑上**对内存容量加以扩充的一种存储器系统。其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。\n\n虚拟存储器的实现方法有：请求分页存储管理方式、请求分段存储管理方式、请求段页式存储管理方式。这些将在后面的题目中介绍。\n\n## 36、请求分页存储管理方式\n\n请求分页系统是建立在基本分页基础上的，为了能支持虚拟存储器功能，而增加了**请求调页功能和页面置换功能**。相应地，每次调入和换出的基本单位都是长度固定的页面，这使得请求分页系统在实现上要比请求分段系统简单(后者在换进和换出时是可变长度的段)。因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式\n\n为了实现请求分页，系统必须提供一定的硬件支持。计算机系统除了要求一定容量的内存和外存外，还需要有**请求页表机制、缺页中断机构以及地址变换机构**。\n\n（1）请求页表机制\n\n为了满足页面换进换出的需要，在**请求页表**中又增加了四个字段。这样，在请求分页系统中的每个页表应含以下诸项：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127142533.png)\n\n- 状态位P：用于指示该页是否已调入内存。\n- 访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问。\n- 修改位M：表示该页在调入内存后是否被修改过。\n- 外存地址：用于指出该页在外存上的地址，通常是**磁盘块号**，供调入该页时参考。 \n\n（2）缺页中断机构\n\n缺页中断是一种特殊的中断，它与一般的中断相比，有着明显的区别：\n\n-  在指令执行期间产生和处理中断信号。而一般中断是在一条指令执行完后，检查是否有中断请求到达。\n- 一条指令在执行期间可能产生多次缺页中断。\n\n缺页中断就是要访问的页不在主存中，需要操作系统将页调入主存后再进行访问，此时会暂时停止指令的执行，产生一个缺页中断异常，对应的异常处理程序就会从选择一页调入到内存，调入内存后之前被中断的的异常指令就可以继续执行。\n\n缺页中断的处理过程如下：\n\n1. 如果内存中有空闲的物理块，则分配一物理块，然后转第4步，否则转第2步；\n2. 选择某种页面置换算法，选择一个将被替换的物理块，它所对应的页面号为q，将q页面换出，如果该页在内存期间被修改过，则需把它写回到外存；\n3. 将q所对应的页表项进行修改，把其状态位P置为0；\n4. 将需要访问的页装入到空闲的物理块中；\n5. 修改访问的页所对应的页表项的内容，把状态位P位置1，物理块号置为该页装入的物理块所对应的块号，访问字段A加1，外存地址置为访问的页在外存的磁盘块号；\n6. 重新运行被中断的指令。\n\n（3）地址变换机构\n\n请求分页系统中的地址变换机构是在分页系统地址变换机构的基础上，为实现虚拟存储器，再增加了某些功能所形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等等，具体过程如下图所示：\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127144617.png)\n\n## 37、请求分页存储管理方式的页面置换算法\n\n（1）最佳置换算法\n\n最佳置换算法是一种理论上的算法，其所选择的被淘汰页面将是以后永不使用的，或许是在最长(未来)时间内不再被访问的页面。\n\n（2）先进先出(FIFO)页面置换算法\n\n先进先出(FIFO)页面置换算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。\n\n（3）LRU(Least Recently Used)最近最久未使用置换算法\n\nLRU算法利用“最近的过去”作为“最近的将来”的近似，因此，LRU置换算法是选择最近最久未使用的页面予以淘汰。\n\n（4）最少使用(Least Frequently Used，LFU)置换算法\n\n在采用最少使用置换算法时，应为在内存中的**每个页面设置一个移位寄存器**，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。\n\n（5）Clock置换算法\n\n为每页设置一位访问位，再**将内存中的所有页面都通过链接指针链接成一个循环队列**。当某页被访问时，其访问位被置1。\n\nClock置换算法在选择一页淘汰时，检查页的访问位。**如果是0，就选择该页换出**；若为1，则重新将它置0，暂不换出，再按照循环队列次序检查下一个页面。\n\n（6）页面缓冲算法（Page Buffering Algorithm PBA）\n\n页面缓冲算法建立了一个已修改换出页面的链表，对每一个要被换出的页面(已修改)，系统暂不把它们写回磁盘，而是将它们挂在已修改换出页面的链表上，仅当换出页面数目达到一定值时，再将它们**一起写回磁盘上**。\n\n## 38、“抖动”发生原因及预防方法\n\n每个进程在运行时，频繁地出现缺页，造成每个进程的大部分时间都用于页面的换进/换出，而几乎不能再去做任何有效的工作，从而导致发生处理机的利用率急剧下降并趋于0的情况。称此时的进程是处于“抖动”状态。\n\n预防抖动的方法：\n\n（1）采取局部置换策略\n\n当某进程发生缺页时，只能在分配给自己的内存空间里进行置换，不允许它从别的进程空间获得新的物理块，这样即使本进程发生了“抖动”，也不会对其它进程产生影响。\n\n（2）把工作集融入到处理机调度中\n\n调度程序从外存调入作业之前，必须检查每个进程在内存的驻留页面是否足够多。\n\n（3）利用“L=S”准则调节缺页率\n\n其中L是缺页之间的平均时间，S是平均缺页服务时间，即用于置换一个页面所需的时间。如果是L远比S大，说明很少发生缺页，磁盘的能力尚未得到充分的利用；反之，如果是L比S小，则说明频繁发生缺页，缺页的速度已超过磁盘的处理能力。只有当L与S接近时，磁盘和处理机都可达到它们的最大利用率。\n\n（4）选择暂停某些进程，释放它们的物理块。\n\n## 39、什么是工作集\n\n所谓工作集，是指在某段时间间隔Δ里，进程实际所要访问页面的集合。**由于进程发生缺页率的时间间隔与进程所获得的物理块数有关**，虽然程序只需要少量的几页在内存便可运行，但为了较少地产生缺页，应将程序的全部工作集装入内存中。\n\n缺页率与物理块数之间的关系如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127150640.png)\n\n\n\n然而无法事先预知程序在不同时刻将访问哪些页面，即无法事先预知程序的工作集，故仍只有像页面置换算法那样，用程序的过去某段时间内的行为作为程序在将来某段时间内行为的近似。\n\n## 40、请求分段存储管理方式\n\n在分页基础上建立的请求分页式虚拟存储器系统，是以页面为单位进行换入、换出的。而在分段基础上所建立的请求分段式虚拟存储器系统，则是以分段为单位进行换入、换出的。在请求分段系统中,程序运行之前，只需先调入少数几个分段(不必调入所有的分段)便可启动运行，当所访问的段不在内存中时，可请求OS将所缺的段调入内存。像请求分页系统一样，为实现请求分段存储管理方式，同样需要一定的硬件支持和相应的软件。\n\n与请求分页系统相似，在请求分段系统中所需的硬件支持有**段表机制**、**缺段中断机构**,以及**地址变换机构**。\n\n（1）段表机制\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127151614.png)\n\n- 存取方式：用于标识本分段的存取属性是只执行、只读，还是允许读/写。\n- 访问字段A：其含义与请求分页的相应字段相同，用于记录该段被访问的频繁程度。\n- 修改位M：用于表示该段在进入内存后是否已被修改过，供置换段时参考。\n- 存在位P：指示本段是否已调入内存，供程序访问时参考。\n- 增补位：是请求分段式管理中所特有的字段，用于表示本段在运行过程中是否做过动态增长。\n- 外存始址：指示本段在外存中的起始地址，即起始盘块号。\n\n（2）缺段中断机构\n\n与缺页中断机构类似，缺段中断机构同样需要在一条指令的执行期间产生和处理中断，以及在一条指令执行期间，可能产生多次缺段中断。\n但由于分段是信息的逻辑单位，因而不可能出现一条指令被分割在两个分段中，和一组信息被分割在两个分段中的情况。\n\n请求分段系统中的中断处理过程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127151944.png)\n\n（3）地址变换机构\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127152058.png)\n\n## 41、I/O系统的基本功能\n\n（1）隐藏物理设备的细节\n\nI/O系统通过对I/O设备进行抽象，以隐藏物理设备的实现细节，用户只需通过I/O系统提供的读、写命令就可以操作相应的I/O设备。\n\n（2）与设备的无关性\n\n与设备无关的基本含义：应用程序中所用的设备，不局限于使用某个具体的物理设备。比如，当用户要输出打印时，只须提供读/写命令和逻辑设备名，不必指名是哪一台打印机。另一方面，也可以有效提高OS的可移植性和易适应性，对于OS而言，应允许在不需要将整个操作系统进行重新编译的情况下，增添新的设备驱动程序。如Windows中，系统可以为新I/O设备自动安装和寻找驱动程序，从而做到即插即用。\n\n引入该层的目的：为了方便用户和提高OS的可适应性和可扩展性。\n\n（3）提高处理机和I/O设备的利用率\n\nI/O系统的第三个功能是要尽可能地让处理机和I/O设备并行操作，以提高它们的利用率。为此，一方面要求处理机能快速响应用户的I/O请求，使I/O设备尽快地运行起来；另一方面，也应尽量减少在每个I/O设备运行时处理机的干预时间。\n\n（4）对I/O设备进行控制\n\n对I/O设备进行控制是驱动程序的功能。目前对I/O设备有四种控制方式：①采用轮询的可编程I/O方式；②采用中断的可编程I/O方；③直接存储器访问方式；④I/O通道方式。后面的题目会具体介绍这四种方式。\n\n（5）确保对设备的正确共享\n\n从设备的共享属性上，可将系统中的设备分为如下两类:\n①独占设备，进程应互斥地访问这类设备，即系统一旦把这类设备分配给了某进程后，便由该进程独占，直至用完释放。典型的独占设备有打印机、磁带机等。\n②共享设备，是指在一段时间内允许多个进程同时访问的设备。典型的共享设备是磁盘，当有多个进程需对磁盘执行读、写操作时，可以交叉进行，不会影响到读、写的正确性。\n\n（6）错误处理\n\n从处理的角度，可将错误分为临时性错误和持久性错误。对于临时性错误，可通过重试操作来纠正，只有在发生了持久性错时，才需要向上层报告。例如，在磁盘传输过程中发生错误，系统并不认为磁盘发生了故障，而是可以重新再传，一直要重传多次后，若仍有错，才认为磁盘发生了故障。**由于多数错误是与设备紧密相关的**，因此对于错误的处理，应该尽可能在接近硬件的层面上进行，即**在低层软件能够解决的错误就不向上层报告，因此高层也就不能感知；只有底层软件解决不了的错误才向上报告，请求高层软件解决**。\n\n## 42、I/O系统的层次结构\n\n为使十分复杂的I/O软件能具有清晰的结构、更好的可移植性和易适应性，目前已普遍采用**层次式结构**的I/O系统。这是将系统中的**设备管理模块**分为若干个层次，每一层都是利用其下层提供的服务，完成输入输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务。\n\nI/O软件的层次结构如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127201122.png)\n\nI/O系统中各模块之间的层次视图如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127202038.png)\n\n与前面的I/O软件组织的层次结构相对应，I/O系统本身也可分为如下三个层次:\n\n（1）**中断处理程序**\n\n它处于I/O系统的底层，直接与硬件进行交互。当有I/O设备发来中断请求信号时，在中断硬件做了初步处理后，便转向中断处理程序。它首先保存被中断进程的CPU环境，然后转入相应设备的中断处理程序进行处理，在处理完成后，又恢复被中断进程的CPU环境，返回断点继续运行。\n\n（2）**设备驱动程序**\n\n它处于I/O系统的次底层，是进程和设备控制器之间的通信程序，其主要功能是，将上层发来的抽象I/O请求转换为对I/O设备的具体命令和参数，并把它装入到设备控制器中的命令和参数寄存器中，或者相反。由于设备之间的差异很大，每类设备的驱动程序都不相同，故必须由设备制造厂商提供，而不是由OS设计者来设计。\n\n（3）**设备独立性软件**\n\n现代OS中的I/O系统基本上都实现了与设备无关性，也称为与**设备无关的软件**。其基本含义是：I/O软件独立于具体使用的物理设备。由此带来的最大好处是，提高了I/O系统的可适应性和可扩展性，使它们能应用于许多类型的设备，而且在每次增加新设备或替换老设备时，都不需要对I/O软件进行修改，这样就方便了系统的更新和扩\n展。设备独立性软件的内容包括**设备命名、设备分配、数据缓冲**和数据高速缓冲一类软件等。\n\n另外，用户层软件实现与用户交互的接口，用户通过该层发出I/O命令与I/O系统接口交互，从而操作相应的I/O设备。\n\n## 43、I/O系统接口的类型有哪些\n\n根据设备类型的不同，I/O系统接口进一步分为块设备接口、流设备接口和网络接口。\n\n（1）块设备接口\n\n快设备接口是块设备管理程序与高层之间的接口。\n\n所谓块设备，数据的存取和传输都是以数据块为单位的设备。典型的块设备是磁盘，该设备的基本特征是传输速率较高，通常每秒钟为数MB到数十MB。另一特征是可寻址，即能指定数据的输入源地址及输出的目标地址，可随机地读门写磁盘中任一块；磁盘设备的I/O常采用DMA方式。\n\n（2）流设备接口\n\n流设备接口是流设备管理程序与高层之间的接口，该接口又称为字符设备接口。\n\n所谓字符设备，是指数据的存取和传输是以字符为单位的设备，如键盘、打印机等，字符设备的基本特征是传输速率较低，通常为每秒几个字节至数千字节。另一特征是不可寻址，即不能指定数据的输入源地址及输出的目标地址，字符设备在输入/输出时，常采用中断驱动方式。\n\n（3）网络通信接口\n通过网络进行通信，接入该接口的设备成为通信设备。\n\n## 44、设备控制器的基本功能\n\n设备控制器的主要功能是，控制一个或多个I/O设备，以实现I/O设备和计算机之间的数据交换。它是CPU与I/O设备之间的接口，接收从CPU发来的命令，去控制I/O设备工作，使处理机能够从繁杂的设备控制事务中解脱出来。设备控制器是一个可编址的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；若控制器可连接多个设备，则应含有多个设备地址，每一个设备地址对应一个设备。\n\n设备控制器的基本功能如下：\n\n- 接收和识别处理机发来的命令\n- 实现CPU与控制器之间、控制器与设备之间的数据交换\n- 标识和报告I/O设备的状态\n- 识别其所控制的每个I/O设备的地址\n- 提供主机与I/O设备之间的数据缓冲\n- 对I/O设备传来的数据进行差错控制\n\n\n\n## 45、I/O通道基本概念和常用类型\n\n（1）为什么要引入I/O通道\n\n虽然在CPU与I/O设备之间增加了设备控制器后，已能大大减少CPU对I/O的干预，但当主机所配置的外设很多时，CPU的负担仍然很重。为此，在CPU和设备控制器之间又增设了I/O通道，其主要目的是为了建立独立的I/O操作，不仅使数据的传送能独立于CPU，而且也希望有关对I/O操作的组织、管理及其结束处理尽量独立，以保证CPU有更多的时间去进行数据处理；或者说，其目的是使一些原来由CPU处理的I/O任务转由通道来承担，从而把CPU从繁杂的I/O任务中解脱出来。在设置了通道后，CPU只需向通道发送一条I/O指令。通道在收到该指令后，便从内存中取出来本次要执行的通道程序，然后执行该通道程序，仅当通道完成了规定的I/O任务后，才向CPU发中断信号。\n\n（2）什么是I/O通道\n\nI/O通道是一种特殊的处理机，它具有执行I/O指令的能力，并通过执行通道(I/O)程序来控制I/O操作。\nI/O通道与一般的处理机不同：\n\n- 指令类型单一。其所能执行的命令主要局限于与I/O操作有关的指令。\n- 通道没有自己的内存。通道所执行的通道程序是放在主机的内存中的，即通道与CPU共享内存。\n\n（3）I/O通道的类型\n\n根据信息交换方式的不同，可把通道分为以下三种类型：\n\n①字节多路通道(Byte Multiplexor Channel)\n\n这是一种按字节交叉方式工作的通道。它通常都含有许多非分配型子通道，其数量可从几十到数百个，每一个子通道连接一台I/O设备，并控制该设备的I/O操作。这些子通道按时间片轮转方式共享主通道。字节多路通道的原理图如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127205934.png)\n\n② 数组选择通道(Block Selector Channel)\n\n这种通道虽然可以连接多台高速设备，但由于它只含有一个分配型子通道，在一段时间内只能执行一道通道程序，控制一台设备进行数据传送。\n\n③ 数组多路通道(Block Multiplexor Channel)\n\n数组多路通道是将数组选择通道传输速率高和字节多路通道能使各子通道(设备)**分时并行**操作的优点相结合而形成的一种新通道。它含有多个非分配型子通道，用于连接多台高、中速的外围设备，其数据传送是按数组方式进行的。 \n\n这里，不得不提由于通道而引发的**“瓶颈问题”**。由于通道加个昂贵，致使机器中所设置的通道数量势必较少，这往往由使它成了I/O的瓶颈，进而造成整个系统吞吐量的下降。单通道I/O系统如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127210619.png)\n\n解决瓶颈问题最有效的方法，便是增加设备到主机间的通路而不增加通道，如下图所示。换言之，就是把一个设备连接到多个控制器上，而一个控制器又连接到多个通道上。多通路方式不仅解决了瓶颈问题，而且提高了系统的可靠性，因为个别通道或控制器的故障不会使设备和存储器之间没有通路。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127210958.png)\n\n## 46、中断(interrup)和陷入阱(trap)的区别\n\n（1）中断\n中断是指CPU对I/O设备发来的中断信号的一种响应。CPU暂停正在执行的程序，保留CPU环境后，自动地转去执行该I/O设备的中断处理程序。执行完后，再回到断点，继续执行原来的程序。I/O设备可以是字符设备，也可以是块设备、通信设备等，由于中断是由外部设备引起的，故又称**外中断**。\n（2）陷入\n另外还有一种由CPU内部事件所引起的中断，例如进程在运算中发生了上溢或下溢，又如程序出错，如非法指令、地址越界，以及电源故障等。通常把这类中断称为**内中断或陷入(tuap)**。与中断一样，若系统发现了有陷入事件，CPU也将暂停正在执行的程序，转去执行该陷入事件的处理程序。**中断和陷入的主要区别是信号的来源，即是来自CPU外部，还是CPU内部。**\n\n## 47、软中断与硬中断的区别\n\n（1）软中断是软件实现的中断，也就是程序运行时其他程序对它的中断；而硬中断是硬件实现的中断，是程序运行时外接设备对它的中断。\n（2）软中断是程序安排好的，不具有随机行。硬中断是由外部事件引起的，具有随机性和突发性。\n（3）软中断并不会直接中断CPU，接收软中断的进程只有在得到处理机之后才会产生软中断。由于处理硬中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。\n（4）软中断的中断信号由中断指令直接发出的，是不可屏蔽的；硬中断的中断信号是由中断控制器提供的，是可屏蔽的。\n\n## 48、对I/O设备的控制方式有哪些\n\n（1）使用轮询的可编程I/O方式（程序I/O方式）\n\n在处理机向控制器发出一条I/O指令，启动输入设备输入数据时，要同时把状态寄存器中的忙/闲标志busy置为1，然后便不断地循环测试busy(称为轮询)。当busy=1时，表示输入机尚未输完一个字（符），处理机应继续对该标志进行测试，直至busy=0，表明输入机已将输入数据送入控制器的数据寄存器中。于是处理机将数据寄存器中的数据取出，送入内存指定单元中，这样便完成了个字(符)的I/O。\n\n它的特点是：\n\n- CPU和I/O设备串行\n-  每次传送一个字（节）\n\n（2）使用中断的可编程I/O方式（中断驱动I/O方式）\n\n当某进程要启动某个I/O设备工作时，便由CPU向相应的设备控制器发出一条I/O命令，然后立即返回继续执行原来的任务。设备控制器于是按照该命令的要求去控制指定I/O设备。此时，CPU与I/O设备并行操作。例如，在输入时，当设备控制器收到CPU发来的读命令后，便去控制相应的输入设备读数据。一旦数据进入数据寄存器，控制器便通过控制线应CPU发送一中断信号，由CPU检查输入过程中是否出错。若无，便向控制器发送取走数据的信号，然后再通过控制器及数据线，将数据写入内存指定单元中。\n\n（3）直援存储器访问方式（DMA方式）\n\n为了进一步减少CPU对I/O的干预，引入了直接存储器访问方式，该方式的特点是：\n\n- 数据传输的基本单位是数据块，即在CPU与I/O设备之间，每次传送至少一个数据块。\n- 所传送的数据是从设备直接送入内存的，或者相反。\n- 仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在控制器的控制下完成的。可见，DMA方式较之中断驱动方式又进一步提高了CPU与I/O设备的并行操作程度。\n\n它的特点是：\n\n- CPU和I/O设备并行。\n- 每次传送一个至少一个数据块。所传送的多个数据块是连续的，从设备直接送入内存，或者相反。\n\n（4）I/O通道控制方式\n\n虽然DMA方式比起中断方式来已经显著地减少了CPU的干预，即已由以字(节)为单位的干预减少到以数据块为单位的干预，但CPU每发出一条I/O指令，也只能去读(或写)一个连续的数据块。而当我们需要一次去读多个数据块且将它们分别传送到不同的内存区域，或者相反时，则须由CPU分别发出多条I/O指令及进行多次中断处理才能完成。\n\nI/O通道方式是DMA方式的发展，它可进一步减少CPU的干预，即把对一个数据块的读(或写)为单位的干预，减少为对一组数据块的读(或写)及有关的控制和管理为单位的干预。同时，又可实现CPU、通道和I/O设备三者的并行操作，从而更有效地提高整个系统的资源利用率。例如，当CPU要完成一组相关的读(或写)操作及有关控制时，只需向I/O通道发送一条I/O指令，以给出其所要执行的通道程序的首址和要访问的I/O设备，通道接到该指令后，通过执行通道程序便可完成CPU指定的I/O任务。\n\n它的特点是：\n\n-  CPU、通道、I/O设备并行。\n- 每次传送多个不同方向且不连续的数据块。\n\n##  49、什么是假脱机(Spooing)技术？\n\n当系统中引入了多道程序技术后，完全可以利用其中的一道程序，来模拟脱机输入时的外围控制机功能，把低速I/O设备上的数据传送到高速磁盘上。再用另一道程序模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速I/O设备上。 这样，便可在主机的直接控制下，实现以前的脱机输入、输出功能。我们把这种在联机情况下利用多道程序实现数据输入和输出的技术称为 SPOOLing（Simultaneaus Periphernal Operating OnLine)技术，或称为假脱机技术。\n\n## 50、磁盘的访问时间有哪些\n\n磁盘设备在工作时以恒定速率旋转。为了读或写，磁头必须能移动到所指定的磁道上，并等待所指定的扇区的开始位置旋转到磁头下，然后再开始读或写数据。故可把对磁盘的访问时间分成以下三部分：\n\n- **寻道时间**：把磁头移动到指定磁道上所经历的时间\n- **旋转延迟时间** ：指定扇区移动到磁头下面所经历的时间\n- **传输时间** ：数据的传输时间（数据读出或写入的时间）\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127225002.png)\n\n## 51、常见的磁盘调度算法\n\n为了减少对文件的访问时间，应采用一种最佳的磁盘调度算法，**以使各进程对磁盘的平均访问时间最小**。**由于在访问磁盘的时间中主要是寻道时间**，因此，磁盘调度的目标是使磁盘的平均寻道时间最少。目前常用的磁盘调度算法有先来先服务、最短寻道时间优先及扫描等算法。\n\n（1）先来先服务(FCFS)\n根据进程请求访问磁盘的先后次序进行调度。\n（2）最短寻道时间优先(SSTF)\n该算法选择的进程，其要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短。\n（3）扫描(SCAN)算法（电梯调度算法）\n该算法不仅考虑到欲访问的磁道与当前磁道间的距离，更优先考虑的是磁头当前的移动方向。这是典型电梯调度算法。\n（4）循环扫描(CSCAN)算法\n电梯调度算法的改进，即将最小磁道号紧接着最大磁道号构成循环，进行循环扫描。\n（5）NStepSCAN算法\n“**磁臂粘着**”(Armstickiness)：前几种算法中，如果有一个或几个进程对某一磁道频率进行I/O操作，从而垄断了整个磁盘设备。我们把这一现象称为磁臂粘着。\nN步SCAN算法是将磁盘请求队列分成若干个长度为N的子队列，磁盘调度将按FCFS算法依次处理这些子队列。而每处理一个队列时又是按SCAN算法。当系统（磁盘调度）正在处理某子队列的请求时，如果又出现新的磁盘I/O请求，便将新请求进程放入其他队列，这样就可避免出现粘着现象。\n（6）FSCAN算法\nFSCAN算法是N步SCAN算法的简化，即FSCAN只将磁盘请求队列分成两个子队列。一个是由当前所有请求磁盘I/O的进程形成的队列，由磁盘调度按SCAN算法进行处理。在扫描期间，将新出现的所有请求磁盘I/O的进程，放入另一个等待处理的请求队列。\n\n## 52、文件系统中的三级数据组织形式\n\n在文件系统中，通常把数据分为数据项、记录和文件三级。\n\n（1）数据项\n\n最低级的数据组织形式，分为：\n\n- 基本数据项：原子数据，最小逻辑单位，即数据元素、字段。如学号、姓名\n- 组合数据项：由若干个基本数据项组成，简称组项。如工资（基本工资、奖励工资）\n\n数据项的型和值：型指数据项名字和类型，实体在数据项上的数据则称为值。\n\n（2）记录\n\n一组相关数据项的集合，用于描述一个对象在某方面的属性。一个记录应包含哪些数据项，取决于需要描述对象的哪个方面。由于对象所处的环境不同可把他作为不同的对象。例如，一个学生，当把他作为班上的一名学生时，对他的描述应使用学号、姓名、年龄及所在系班，也可能还包括他所学过的课程的名称、成绩等数据项。但若把学生作为个医疗对象时，对他描述的数据项则应使用诸如病历号、姓名、性别、出生年月、身高、体重、血压及病史等项。\n在诸多记录中，为了能唯一地标识一个记录，必须在一个记录的各个数据项中确定出一个或几个数据项，把它们的集合称为关键字(key)。或者说，关键字是唯一能标识一个记录的数据项。通常，只需用一个数据项作为关键字。例如，前面的病历号或学号便可用来从诸多记录中标识出唯一的一个记录。然而有时找不到这样的数据项，只好把几个数据项定为能在诸多记录中唯一地标识出某个记录的关键字。\n\n（3）文件\n\n文件是指由创建者者所定义的、具有文件名的一组相关元素的集合，可分为有结构文件和无结构文件两种。在有结的文件中，文件由若干个相关记录组成，而无结构文件则被看成是一个字符流。文件在文件系统中是一个最大的数据单位，它描述了一个**对象集**。例如，可以将一个班的学生记录作为一个文件。\n\n文件、记录和数据项之间的层次关系如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127230905.png)\n\n## 53、文件系统模型的三个层次\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127231021.png)\n\n**文件系统接口(最高层)**：命令接口和程序接口。命令接口是指用户与文件系统直接交互的接口，程序接口是**用户程序**与文件系统的接口。\n\n**对对象操纵和管理的软件集合(中间层)**：对文件读写的管理、对文件的保护和共享、对文件目录的管理、对存储空间的管理。\n\n对象及属性(最底层)：对象有文件、目录、磁盘存储空间。\n\n## 54、文件的逻辑结构和物理结构\n\n（1）文件的逻辑结构\n\n文件的逻辑结构：从用户角度出发所看到的文件组织形式，是**用户可以直接处理**的数据及其结构。\n\n文件的逻辑结构有：\n\n①按有无结构可分为有结构文件和无结构文件两种。在有结构的文件中，文件有若干个相关记录组成，而无结构文件则被看成是一个字符流。\n\n②按文件的组织方式分类可分为顺序文件、索引文件、索引顺序文件。\n\n- 顺序文件：按照某种顺序排列所形成的文件，其记录可以是定长记录或可变长记录。\n- 索引文件：（定长记录可以通过简单计算，实现随机查找）当记录为可变长时，通常为之建立一张索引表，并**为每一个记录设置一个表项**，以加快检索记录的速度。\n- 索引顺序文件：这是顺序文件和索引文件相结合的产物，这里，在为每个文件建立一张索引表时，并不是为每一个记录建立一个索引表项，而是**为每一组记录中的第一个记录设置一个表项**。\n\n（2）文件的物理结构\n\n文件在外存上的存储组织形式，又称为文件的存储结构**。文件在外存上的存储组织形式可分为以下形式**：\n\n①连续组织方式\n为每个文件分配相邻的物理块（盘块/扇区），将分配给文件的首物理块的地址登记在它的文件目录项内，这样的文件结构是顺序式的文件结构。\n②链接组织方式\n通过每个盘块上的链接指针，将同一个文件的多个离散的盘块链接成一个链表，这样的文件结构是链接式文件结构。\n③索引组织方式\n通过给每个文件的盘块建立索引，形成的是索引式文件结构。\n\n## 55、文件目录和目录文件\n\n通常，在现代计算机系统中，都要存储大量的文件，为了能对这些文件实施有效的管理，必须对它们加以妥善组织，这主要是通过**文件目录**实现的。文件目录也是一种数据结构，用于标识系统中的文件及其物理地址，供检索时使用。对目录管理的要求如下：\n（1）实现“按名存取”。用户只须向系统提供所需访同文件的名字，便能快速准确地找到指定文件在外存上的存储位置。这是目录管理中最基本的功能。\n（2）提高对目录的检索速度。通过合理地组织目录结构加快对目录的检索速度，从而提高对文件的存取速度。\n（3）文件共享，在多用户系统中,应允许多个用户共享一个文件，这样就只须在外存中保留一份该文件的副本供不同用户使用，以节省大量的存储空间，并方便用户和提高文件利用率。\n（4）允许文件重名。系统应允许不同用户对不同文件采用相同的名字，以便于用户按照自己的习惯给文件命名和使用文件。\n\n文件控制块(FCB，File Controller Block)：为正确存取文件，而为文件设置的用于描述和控制文件的数据结构。文件与文件控制块一一对应。\n**文件控制块的有序集合构成文件目录。**\n**文件目录以文件的形式存放，所以叫做目录文件。**\n\n## 56、文件的链接组织形式\n\n前面也提到了，文件的物理结构也即文件在外存上的存储组织形式，又称为文件的存储结构。文件在外存上的存储组织形式有连续组织方式、链接组织方式、索引组织方式，这里介绍文件的链接组织方式。\n\n链接组织方式：通过每个盘块上的链接指针，将同一个文件的多个离散的盘块链接成一个链表，这样的文件结构是链接式文件结构。可分为隐式链接和显式链接两种方式。\n\n（1）隐式链接\n\n将一文件离散地存放在外存上，并将下一个物理块（磁盘块）的地址登记在分配给它的前一个物理块中。\n\n磁盘空间的链接式分配如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127234257.png)\n\n（2）显式链接\n\n将文件离散地存放，并将链接各个物理块的指针显式地登记在内存的一张文件分配表FAT(File Allocation Table)中。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127234450.png)\n\n## 57、文件分配表FAT技术\n\n在MS-DOS中，最早使用的是12位的FAT12，后来为16位的FAT16。在Windows 95和Windows 98操作系统中升级为32位的FAT32，Windows NT/2000/XP及以后的操作系统中又进一步发展为新技术文件系统NTFS。 \n\n在FAT中引入了“卷”的概念，支持将一个物理磁盘分成四个逻辑磁盘，每个逻辑磁盘就是一个**卷**(也称为**分区**)，也就是说每个卷都是一个能够被单独格式化和使用的逻辑单元，供文件系统分配空间时使用。一个卷中包含了文件系统信息、一组文件以及空闲空间。每个卷都专门划出一个单独区域来存放自己的目录和FAT表，以及自己的逻辑驱动器字母。通常对仅有一个硬盘的计算机，最多可将其硬盘分为“C:”、“D:”、“E:\"、“F:”四个卷。需要指出的是。在现代OS中，一个物理磁盘可以划分为多个卷，一个卷也可以由多个物理磁盘组成。\n\n（1）FAT12 \n\nFAT12是以盘块为基本分配单位的，每个盘块大小一般为512B，即0.5K，最多能够存放$2^{12}$方个盘块。为了安全起见，**在每个分区中**都配有两张相同的文件分配表FAT1和FAT2。在FAT的每个表项中存放下一个盘块号，实际上用于盘块之间链接的指针，**通过它可以将一个文件的所有盘块链接起来**。FAT12技术将文件的第一个盘块号放在自己的文件控制块(FCB)中。\n\n为了适应磁盘容量不断增大的需要，在进行盘块分配时，不再以盘块而是以**簇**(cluster)为基本单位，簇是一组连续的扇区，大小一般盘块的整数倍。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210127235301.png)\n\n（2）FAT16\n\n具有16位表宽的FAT表称为FAT16，最大表项数将增至65536 ($2^{16}$)个，可以存放更多的盘块。\n\n（3）FAT32\n\n具有32位表宽的FAT表称为FAT32，FAT12一般以簇为基本分配单位的，FAT32的每个簇都固定为4 KB，管理的最大磁盘空间可达4KB*$2^{32}$，即16TB。FAT32有最小管理空间的限制，不支持容量小于512M的分区，并且FAT32的单个文件长度不能大于4GB。\n\n## 58、NTFS的文件组织方式\n\nNTFS(New Technology File System)是一个专门为Windows NT开发的、全新的文件系统，并适用于Windows 2000/XP及后续的Windows OS。\n\n（1）NTFS磁盘组织\n\nNTFS是以簇作为磁盘空间分配和回收的基本单位的。一个文件占用若干个簇，一个簇只属于一个文件。这样，在为文件分配磁盘空间时，就无须知道盘块的大小，只要根据不同的磁盘容量，选择相应大小的簇，即使NTFS具有了与磁盘物理块大小无关的独立性。\n\n在NTFS文件系统中，把卷上簇的大小称为“**卷因子**”，卷因子是在磁盘格式化时确定的，其大小也是物理磁盘扇区的整数倍。簇的大小可由格式化命令按磁盘容量和应用需求来确定，可以为512B、1KB、…，最大可达64KB。对于小磁盘(≤512MB)，默认簇大小为512字节；对于1GB磁盘，默认簇大小为1KB；对于2GB的磁盘，则默认簇为4KB。事实上，为了在传输效率和簇内碎片之间进行折中，NFS在大多数情况下都是使用4KB。\n\n（2）NTFS文件的组织\n\n在NTFS中，**以卷为单位**，将一个卷中的所有文件信息、目录信息以及可用的未分配空间信息，都以文件记录的方式记录在一张**主控文件表 MFT**(Master File Table)中，该表是NTFS卷结构的中心，从逻辑上讲，卷中的每个文件作为一条记录，在MFT表中占有一行，其中还包括MFT自己的这一行。每行大小固定为1 KB，每行称为该行所对应文件的**元数据**(metadata)，也称为文件控制字。\n\n在MFT表中，每个元数据都将其所对应文件的所有信息(包括文件的内容等)组织在所对文件的一组属性中。由于文件大小相差悬殊，其属性所需空间大小也相差很大。当文件较小时，其属性值所占空间也较小，可以将文件的所有属性直接记录在元数据中。而当文件较大时，元数据仅能记录文件的一部分属性，其余属性，如文件的内容等，只好记录到卷中的其它可用簇中，并将这些簇按其所记录文件的属性进行分类，分别链接成多个队列，并将指向这些队列的指针保存在元数据中。\n\n例如，对于一个真正的数据文件，即属性为DATA的文件，如果很小，就直接将其存储在MFT表中对应的元数据中，这样对文件数据的访问仅需要对MFT表进行访问即可，减少了磁盘访问次数，显著地提高了对小文件存取的效率。如果文件较大，则文件的真正数据往往保存在其它簇中。此时通过元数据中指向文件DATA属性的队列指针，可以方便地查找到这些簇，完成对文件数据的访问。\n\nNTFS使用64位磁盘地址，并且支持长文件名，单个文件名限制在255个字符以内。它和FAT技术一样，也是链接组织形式的一种。\n\n## 59、文件存储空间的管理\n\n文件在外存上的存储组织形式有连续组织方式、链接组织方式、索引组织方式。为了实现任何一种文件组织方式，都需要为文件分配盘块，**因此必须知道磁盘上哪些盘块是可用于分配的**。**故在为文件分配磁盘时，除了需要文件分配表外，系统还应为可分配存储空间设置相应的数据结构**，即设置一个磁盘分配表 (Disk Allocation Table)，用于\n记住可供分配的存储空间情况。此外，还应提供对盘块进行分配和回收的手段。不论哪种分配和回收方式，存储空间的基本分配单位都是磁盘块而非字节。下面介绍几种常用的文件存储空间的管理方法：\n\n（1）空闲表法\n\n属于连续分配方式，为每个文件分配一块连续空间。系统为外存上的所有区建立一张空闲表，每个空闲区对应一个空闲表项，每个表项包括表项序号、空闲区的第一个盘块号和空闲区的盘块数。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128113805.png)\n\n**分配与回收**\n\n空闲盘区的分配与内存的分区(动态)分配类似，同样是采用首次适应算法和最佳适应算法等。\n\n系统在对用户所释放的存储空间进行回收时，也采取类似于内存回收的方法，即要考虑回收区是否与空闲表中插入点的前区和后区相邻接，对相邻接者应予以合并。\n\n优点：空闲区分配与回收容易。\n缺点：空闲表也会浪费很大存储空间。\n\n（2）空闲链表法\n\n将文件存储空间中的所有空闲区拉成一条空闲链表。根据构成链所用基本元素的不同，可以把链表分为两种形式：空闲盘块链和空闲盘区链。\n\n①空闲盘块链：将磁盘上所有空闲空间，以盘块为单位拉成一条链。\n\n优点：分配和回收一个盘块的过程简单。\n缺点：空闲盘块链可能很长。分配盘块时，可能要重复操作多次。\n\n②空闲盘区链：将磁盘上所有空闲盘区拉成一条链。和空闲表法类似。\n\n（3）位示图法\n\n利用二进制的一位来表示文件存储空间中的一个盘块的使用情况。其值为0表示空闲，为1表示分配，这样由所有盘块所对应的位构成一个集合，称为位示图。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128114835.png)\n\n在盘块分配时，将相应位置1，在回收时，将相应位置0。\n\n（4）成组链接法\n\n①空闲盘块的组织\n\n将一个文件卷的所有空闲盘块分成固定大小的组（如100个盘块），将每一组的盘块号和盘块数记入前一组的最后一个盘块中，第一组的盘块数和盘块号记入空闲盘块号栈中。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128120327.png)\n\n②空闲盘块的分配\n\n首先检查空闲盘块号栈是否上锁，如未上锁，便从栈顶取出一空闲盘块号，将与之对应的盘块分配给用户，然后将栈顶指针下移一格。把栈中的空闲盘块数减1。\n\n若该盘块号已是栈底，即S.free(0)，这是当前栈中最后一个可分配的盘块号。调用磁盘读过程，将栈底盘块号所对应盘块的内容读入栈中，作为新的盘块号栈的内容，并把原栈底对应的盘块分配出去(其中的有用数据已读入栈中)。\n\n③空闲盘块的回收\n\n将回收盘块的盘块号记入空闲盘块号栈的顶部，并执行空闲盘块数加1操作。\n\n当栈中空闲盘块号数目已达100时，表示栈已满，便将现有栈中的100个盘块号记入新回收的盘块中，再将其盘块号作为新栈底。空闲盘块数记为1。\n\n## 60、廉价磁盘冗余阵列（RAID)\n\n人们于1987年开发出由多个小磁盘组成一个大容量的康价碰盘冗余阵列( Redundant Array of Inexpensive Disk,RAID)，该系统是利用一台磁盘阵列控制器来统一管理和控制一组(几台到几十台)磁盘驱动器组成一个大型磁盘系统。RAID不仅是大幅度地增加了磁盘的容量，而且也极大地提高了磁盘的I/O速度和整个磁盘系统的可靠性。故该系统一经推出便很快被许多大型系统所采用。\n\n（1）并行交叉存取\n\n把在大、中型机中，用于提高访问内存速度的并行交叉存取技术应用到磁盘存储系统中，以提高对磁盘的I/O速度。在该系统中，有多台磁盘驱动器，系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的**相同位置**上。以后当要将一个盘块的数据传送到内存时，采取并行传输方式，将各个盘块中的子盘块数据同时向内存中传输，从而使传输时间大大减少。 \n\n磁盘并行交叉存取方式如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128122310.png)\n\n（2）RAID的分级\n\n- RAID 0级。仅提供了并行交叉存取。 无冗余校验功能。\n- RAID 1级。具有磁盘镜像功能。\n- RAID 3级。具有并行传输功能的磁盘阵列。利用其中一台磁盘做奇偶校验盘完成数据的校验功能。\n- RAID 5级。具有独立传送功能的磁盘阵列。每个磁盘都有自己独立的数据通路，独立地进行读/写，无专门的校验盘。\n- RAID 6级和RAID 7级。RAID 6级的阵列中，设置了一个专用的、可快速访问的异步校验盘，该盘有独立的数据访问同路。RAID 7级是对RAID 6级的改进，在该阵列中的所有磁盘，都具有较高的传输速率和优异的性能，是目前最高档次的磁盘阵列。 \n\n## 61、常见的磁盘容错技术\n\n磁盘容错技术，又称系统容错技术SFT(System Fault Tolerance)，主要通过设置冗余部件来提高磁盘系统可靠性。SFT常被分为 低、中、高三个级别。第一级是低级磁盘容错技术；第二级是中级磁盘容错技术；第三级是系统容错技术，它基于集群技术实现容错。\n\n（1）第一级容错技术SFT-Ⅰ\n\n主要用于防止因磁盘表面缺陷所造成的数据丢失。它包含双份目录和双份文件分配表、热修复重定向、写后读校验等措施。\n\n①双份目录和双份文件分配表\n\n可在不同的磁盘上或在磁盘的不同区域中，分别建立(双份)目录表和FAT。其中，一份被称为主目录及主FAT； 把另一份称为备份目录及备份FAT。 \n\n②热修复重定向\n\n系统将磁盘的一部分作为热修复重定向区，用于存放当发现磁盘有缺陷时的待写入数据，并对写入该区的数据进行登记，以便以后对数据进行访问。\n\n③写后读校验\n\n在每次从内存缓冲区向磁盘中写入数据块后，又立即读出该磁盘块，并送至另一缓冲区与内存中的数据进行比较，若一致则认为写入成功。\n\n（2）第二级容错技术SFT-Ⅱ\n\n第二级容错技术主要用于防止由磁盘驱动器和磁盘控制器故障所导致的系统不能正常工作，它具体分为磁盘镜像和磁盘双工。\n\n①磁盘镜像(Disk Mirroring)\n\n为了避免磁盘驱动器发生故障而丢失数据，便增设了磁盘镜像功能。为实现该功能，须在同一磁盘控制器下，再增设一个完全相同的磁盘驱动器。 \n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128123550.png)\n\n②磁盘双工(Disk Duplexing)\n\n即将两台磁盘驱动器分别接到两个磁盘控制器上，同样使这两台磁盘机镜像成对。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128123650.png)\n\n（3）第三级容错技术——基于集群技术的容错功能\n\n主要工作模式有三种：热备份模型、互为备份模式和公用磁盘模式。\n\n①双机热备份模式\n\n系统中备有两台服务器，两者的处理能力通常是完全相同的，一台作为主服务器，另一台作为备份服务器。 \n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128124108.png)\n\n②双机互为备份模式\n\n两台服务器均为在线服务器，它们各自完成自己的任务。例如，一台作为数据库服务器，另一台作为电子邮件服务器，为了实现两者互为备份的功能，在两台服务器之间，应通过某种专线将其连接起来。如果希望两台服务器之间能相距较远，最好利用FDDI单模光纤来连接两台服务器。在此情况下，最好再通过路由器将两台服务器互连起来，作为备份通信线路。下图是双机互为备份系统的情况：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210128124142.png)\n\n在互为备份的模式中，最好在每台服务器内都配置两台硬盘，一个用于装载系统程序和应用程序，另一个用于接收由另一台服务器发来的备份数据，作为该服务器的镜像盘。在正常运行时，镜像盘对本地用户是锁死的，这样就较易于保证在镜像盘中数据的正确性。如果仅有一个硬盘，则可用建立虚拟盘的方式或分区方式来分别存放系统程序和应用程序以及另一台服务器的备份数据。\n\n③公用磁盘模式\n\n为了减少信息复制的开销，可以将多台计算机连接到一台公共的磁盘系统上去。该公共磁盘被划分为若干个卷。每台计算机使用一个卷。如果某台计算机发生故障，此时系统将重新进行配置，根据某种调度策略来选择另一台替代机器，后者对发生故障的机器的卷拥有所有权，从而可接替故障计算机所承担的任务。\n\n## 62、特权指令和非特权指令、管态和目态\n\n（1）特权指令和非特权指\n\n**特权指令**是指不允许用户程序中直接使用的指令，是关系到系统全局的指令。其对内存空间的访问范围基本不受限制，不仅能访问用户存储空间，也能访问系统存储空间。包括I/O指令、设置系统时钟时间、关中断、清主存、修改存储器管理寄存器、执行停机指令、转换执行状态等。 \n\n**非特权指令**只能完成一般性的操作和任务，不能对系统中的硬件和软件直接进行访问，其对内存的访问范围也局限于用户空间。 \n\n（2）管态和目态\n\n**管态（系统态、核心态）**：当CPU处于管态时可执行包括特权指令在内的一切机器指令。当**OS程序**占用中央处理器时应让CPU在管态工作。\n\n**目态（用户态）**：不允许执行特权指令。当**应用程序**占用中央处理器时应让CPU在目态工作。\n\n\n\n## 63、什么是系统调用？和库函数调用有何区别？\n\n（1）系统调用是操作系统提供的一组用于实现各种系统功能的子程序(过程)，并将它们提供给应用程序调用。库函数调用可以认为是系统调用的封装（并不是所有的库函数都是），有可能包含一个系统调用，有可能包含几个系统调用，也有可能不包含系统调用。\n（2）系统调用是面向硬件的，调用速度明显快于库函数，但是缺乏移植性。库函数的调用是面向开发的，虽然速度要慢于系统调用，但是解决了一致性的问题。\n（3）系统调用发生在内核空间，如果一般应用程序使用系统调用来进行文件操作，会有用户态到系统态切换的开销。事实上，如果使用库函数调用进行文件操作也会有系统调用带来的开销，但是使用库函数可以大大减少系统调用的次数。因为由于双缓冲的存在(双缓冲区肯定比单个缓冲区强)，在用户态和内核态，都应用了缓冲技术，当用户使用fwrite()写文件，都是先将内容写到用户空间缓冲区，当用户空间缓冲去写满或者写操作结束时，才将用户缓冲区的内容写到内核缓冲区，同样的道理，当内核缓冲区写满或者写结束时才将内核缓冲区的内容写到文件对应的硬件媒介上。\n\n## 64、系统调用和一般的过程调用的区别\n\n(1) 运行在不同的系统状态。系统调用中，调用程序是运行在用户态，而被调用程序是运行在系统态。一般的过程调用，其调用程序和被调用程序都运行在相同的状态——系统态或用户态。\n\n (2) 状态的转换。系统调用中，涉及到**由用户态到系统态的转换**。而一般的过程调用并不涉及到系统状态的转换。\n\n(3) 返回问题。系统调用中，在被调用过程执行完后，不一定返回原进程执行，而是重新做进程优先级分析，当原进程仍具有最高优先级时，才返回到调用程序继续执行。但一般的过程调用仍返回原进程。\n\n(4) 嵌套调用。系统调用中，每个系统对嵌套调用的深度都有一定的限制，例如最大深度为6。但一般的过程对嵌套的深度则没有什么限制。\n\n##  65、逻辑地址空间和物理地址空间\n\n程序经过编译后，每个目标模块都是从0号单元开始编址，称为目标模块的相对地址(或逻辑地址)。当链接程序将各个目标模块链接成一个完整的可执行目标程序时，依次按各个模块的相对地址构成一个统一的**从0号单元开始编址的逻辑地址空间**。\n\n物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数据都要通过物理地址从主存中获取。当装入程序(Loader)将可执行目标程序装入内存时，必须通过地址转换将逻辑地址转换成物理地址(因为要分配内存空间)，这个过程称为**地址重定位**，这样形成的地址空间就是**物理地址空间**。\n\n\n\n> 如需转发请联系本人同意，谢谢！","tags":["操作系统","面经"],"categories":["知识储备"]},{"title":"使用HybridSN进行高光谱图像分类","url":"/2021/01/05/173233/","content":"\n\n\n## 一、前言\n\n高光谱图像（Hyperspectral image，以下简称HSI）分类广泛应用于遥感图像的分析，随着深度学习和神经网络的兴起，越来越多的人使用二维CNN对HSI进行分类，而HSI分类性能却高度依赖于空间和光谱信息，由于计算复杂度增加，很少有人将三维CNN应用于HSI分类中。这篇 [Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification](https://ieeexplore.ieee.org/document/8736016)构建一种混合网络(HybridSN)解决了HSI分类所遇到的问题，它首先用三维CNN提取空间-光谱的特征，然后在三维CNN基础上进一步使用二维CNN学习更多抽象层次的空间特征，这与单独使用三维CNN相比，混合的CNN模型既降低了复杂性，也提升了性能。经实验证明，使用HybridSN进行HSI分类，能够获得非常不错的效果。\n\n\n\n<!-- more -->\n\n\n\n## 二、高光谱图像\n\n在进行高光谱图像分类之前，我认为有必要了解什么是高光谱图像。从计算机的角度来说，高光谱图像（Hyperspectral image）就是由多通道（几十甚至几百个）的数组构成的图像，每个像素点都有很多的数来描述，**单个通道上的“灰度值”反映了被拍摄对象对于某一波段的光的反射情况。**\n\n我们知道，常见的RGB彩色图像只有三个通道，而高光谱图像有几十甚至几百个通道，所以高光谱图像包含包含更多的目标信息，利用高光谱图像进行目标的分类识别也必然比采用RGB图像具有更高的准确度。如下图所示，利用高光谱相机可以拍摄出由不同波长组成的空间立方体图像（即高光谱图像），用一个光谱曲线将其显示出来，横轴表示波长，纵轴表示反射系数，由于同一物体对不同波长的光反射因子不一样，因此利用高光谱图像更能反映出不同物体的差异性。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210103152030.png)\n\n其实高光谱成像技术在很早以前就已经被广泛应用了，天上的卫星拍摄到的就是高光谱图像，通过分析每个像素点的光谱曲线，可以把不同地面目标对应的像素点分类，从而在高光谱图像中把地面、建筑物、草坪、江河等等区分开。\n\n\n\n## 三、HybridSN模型\n\n对于HSI分类问题，我们在提取空间信息的同时，也希望能获取到不同波长的光谱信息，而二维CNN是无法处理光谱信息的，也就无法提取到更具有判别性的特征图。幸运的是，三维CNN能够同时提取光谱和空间的特征，但代价是增加计算复杂度。为了充分发挥二维和三维CNN的优势，Swalpa Kumar Roy等人提出了HSI分类模型HybridSN，其模型图如下图所示，它由三个三维卷积、一个二维卷积和三个全连接层组成。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210103230613.png)\n\n在HybridSN模型中，三维卷积核的尺寸分别为`8×3×3×7×1`(即图中$K_1^1$=3 ，$K_2^1$=3 ，$K_3^1$=7)、`16×3×3×5×8`(即图中$K_1^2$=3 ，$K_2^2$=3 ，$K_3^2$=5)和`32×3×3×3×16`(即图中$K_1^3$=3 ，$K_2^3$=3 ，$K_3^3$=3），分别位于第一、第二和第三卷积层中。其中，`16×3×3×5×8`表示输入特征图的个数为8，输出特征图个数为16，三维卷积核大小为`3x3x5`，可理解为有两个空间维度和一个光谱维度。**二维卷积在flatten之前被应用一次，它能有效的判别空间信息，也不会大量损失光谱信息，这是对HSI数据非常重要**。\n\n模型的详细参数配置如下表所示，可以看出，第一个FC层（即dense1)参数量最多，最后一个全连接层（dense3）的输出为16，这是因为Indian Pines (IP)数据集的类别数为16。HybridSN中可训练的权重参数总数为5122176，所有参数都是随机初始化的，使用Adam优化器，交叉熵损失函数，学习率为0.001，batch大小为128，训练100个epoch。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210103232652.gif)\n\n\n\n下面是我实现的HybridSN模型：\n\n```python\nclass_num = 16\nclass HybridSN(nn.Module):  \n  def __init__(self, in_channels=1, out_channels=class_num):\n    super(HybridSN, self).__init__()\n    self.conv3d_features = nn.Sequential(\n        nn.Conv3d(in_channels,out_channels=8,kernel_size=(7,3,3)),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5,3,3)),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3,3,3)),\n        nn.ReLU()\n    )\n\n    self.conv2d_features = nn.Sequential(\n        nn.Conv2d(in_channels=32 * 18, out_channels=64, kernel_size=(3,3)),\n        nn.ReLU()\n    )\n\n    self.classifier = nn.Sequential(\n        nn.Linear(64 * 17 * 17, 256),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(256, 128),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(128, 16)\n    )\n \n  def forward(self, x):\n    x = self.conv3d_features(x)\n    x = x.view(x.size()[0],x.size()[1]*x.size()[2],x.size()[3],x.size()[4])\n    x = self.conv2d_features(x)\n    x = x.view(x.size()[0],-1)\n    x = self.classifier(x)\n    return x\n```\n\n带有Batch Normalization的HybridSN模型：\n\n```python\nclass HybridSN_BN(nn.Module):  \n  def __init__(self, in_channels=1, out_channels=class_num):\n    super(HybridSN_BN, self).__init__()\n    self.conv3d_features = nn.Sequential(\n        nn.Conv3d(in_channels,out_channels=8,kernel_size=(7,3,3)),\n        nn.BatchNorm3d(8),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5,3,3)),\n        nn.BatchNorm3d(16),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3,3,3)),\n        nn.BatchNorm3d(32),\n        nn.ReLU()\n    )\n\n    self.conv2d_features = nn.Sequential(\n        nn.Conv2d(in_channels=32 * 18, out_channels=64, kernel_size=(3,3)),\n        nn.BatchNorm2d(64),\n        nn.ReLU()\n    )\n\n    self.classifier = nn.Sequential(\n        nn.Linear(64 * 17 * 17, 256),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(256, 128),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(128, 16)\n    )\n \n  def forward(self, x):\n    x = self.conv3d_features(x)\n    x = x.view(x.size()[0],x.size()[1]*x.size()[2],x.size()[3],x.size()[4])\n    x = self.conv2d_features(x)\n    x = x.view(x.size()[0],-1)\n    x = self.classifier(x)\n    return x\n```\n\n上面我实现了两种模型，一种是原始的HybridSN模型，另一种是带有Batch Normalization的HybridSN模型，下面还会再实现另外两种模型。\n\n## 四、注意力机制\n\n为了提升HSI分类模型的性能，我也实现了带有注意力机制的HybridSN模型进行训练，这里我采用[CBAM: Convolutional Block Attention Module](https://arxiv.org/pdf/1807.06521.pdf)的空间注意力和通道注意力机制。\n\n（1）Channnel attetion module(通道注意力模块)\n\n通道注意力模是解决**look what**的问题，主要是探索不同通道之间特征图的关系，通过分配各个卷积通道上的资源，使模型更应该注意哪一部分特征。通道注意力的过程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210104232604.png)\n\n1. 首先使用MaxPool和AvgPool聚合两个空间维度上的特征，实现时可以用`AdaptiveAvgPool2d`和`AdaptiveMaxPool2d`保证尺寸不变\n2. 然后通过共享的MLP层，即FC+Relu+FC层，学习每个通道的权重，再将两个特征图相加，后接一个sigmoid函数。\n3. 最后将结果与未经channel attention的原始输入相乘，从而得到的新的特征图。\n\nChannnel attetion module实现如下：\n\n```python\n# 参考 https://github.com/luuuyi/CBAM.PyTorch\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc1   = nn.Conv2d(in_planes, in_planes // 16, 1, bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2   = nn.Conv2d(in_planes // 16, in_planes, 1, bias=False)\n\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n```\n\n（2）Spatial attention module(空间注意力模块)\n\n空间注意力模块解决的是**look where**的问题，通过对特征图每个位置进行二维调整（即attention调整），使模型关注到值得更多关注的区域上。空间注意力的过程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210104222745.png)\n\n1. 首先对不同特征图上相同位置的像素值进行全局的MaxPooling和AvgPooling操作，分别得到两个spatial attention map。\n2. 将这两个特征图concatenate，通过7\\*7的卷积核对这个feature map进行卷积操作，后接一个sigmoid函数。\n3. 最后把得到的空间注意力特征图与未经Spatial attention的原始输入相乘，得到的新的特征图。\n\nSpatial attention module实现如下：\n\n```python\n# 参考 https://github.com/luuuyi/CBAM.PyTorch\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n        padding = 3 if kernel_size == 7 else 1\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n```\n\n**加上注意力机制的HybridSN模型如下：**\n\n```python\nclass_num = 16\nclass HybridSN_Attention(nn.Module):  \n  def __init__(self, in_channels=1, out_channels=class_num):\n    super(HybridSN_Attention, self).__init__()\n    self.conv3d_features = nn.Sequential(\n        nn.Conv3d(in_channels,out_channels=8,kernel_size=(7,3,3)),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5,3,3)),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3,3,3)),\n        nn.ReLU()\n    )\n\t# 通道和空间注意力\n    self.ca = ChannelAttention(32 * 18)\n    self.sa = SpatialAttention()\n\n    self.conv2d_features = nn.Sequential(\n        nn.Conv2d(in_channels=32 * 18, out_channels=64, kernel_size=(3,3)),\n        nn.ReLU()\n    )\n\n    self.classifier = nn.Sequential(\n        nn.Linear(64 * 17 * 17, 256),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(256, 128),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(128, 16)\n    )\n \n  def forward(self, x):\n    x = self.conv3d_features(x)\n    x = x.view(x.size()[0],x.size()[1]*x.size()[2],x.size()[3],x.size()[4])\n\n    x = self.ca(x) * x\n    x = self.sa(x) * x\n\n    x = self.conv2d_features(x)\n    x = x.view(x.size()[0],-1)\n    x = self.classifier(x)\n    return x\n```\n\n**加上Batch Normalization、注意力机制的HybridSN模型如下：**\n\n```python\nclass HybridSN_BN_Attention(nn.Module):  \n  def __init__(self, in_channels=1, out_channels=class_num):\n    super(HybridSN_BN_Attention, self).__init__()\n    self.conv3d_features = nn.Sequential(\n        nn.Conv3d(in_channels,out_channels=8,kernel_size=(7,3,3)),\n        nn.BatchNorm3d(8),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5,3,3)),\n        nn.BatchNorm3d(16),\n        nn.ReLU(),\n        nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3,3,3)),\n        nn.BatchNorm3d(32),\n        nn.ReLU()\n    )\n\n    self.ca = ChannelAttention(32 * 18)\n    self.sa = SpatialAttention()\n\n    self.conv2d_features = nn.Sequential(\n        nn.Conv2d(in_channels=32 * 18, out_channels=64, kernel_size=(3,3)),\n        nn.BatchNorm2d(64),\n        nn.ReLU()\n    )\n\n\n    self.classifier = nn.Sequential(\n        nn.Linear(64 * 17 * 17, 256),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(256, 128),\n        nn.ReLU(),\n        nn.Dropout(p=0.4),\n        nn.Linear(128, 16)\n    )\n \n  def forward(self, x):\n    x = self.conv3d_features(x)\n    x = x.view(x.size()[0],x.size()[1]*x.size()[2],x.size()[3],x.size()[4])\n\n    x = self.ca(x) * x\n    x = self.sa(x) * x\n\n    x = self.conv2d_features(x)\n    x = x.view(x.size()[0],-1)\n    x = self.classifier(x)\n    return x\n```\n\n\n\n## 五、开始实验\n\n上面，我共实现了四种HybridSN模型，分别是：\n\n- 原始的HybridSN模型\n- 加上Batch Normalization的HybridSN模型：HybridSN_BN\n- 加上通道和空间注意力机制的HybridSN模型：HybridSN_Attention\n- 加上Batch Normalization、通道和空间注意力机制的HybridSN模型：HybridSN_BN_Attention\n\n下面我将分别用这四种模型测试Indian Pines数据集，并分析结果。(考虑到篇幅，下面我只写出了主要的方法，全部实现过程请看我的colab)\n\n\n\n### 5.1 下载数据集\n\nIndian Pines 是最早的用于HSI分类的数据集，该数据集有尺寸为145×145 的空间图像和224个波长范围为400～2500nm的光谱反射谱带，由于第 104~108、150-163 和第 220 个波段不能被水反射，因此一般使用的是剔除了这 20 个波段后剩下的 200 个波段作为测试的对象。该数据集共有16类庄稼，用不同的颜色标出。可通过如下方式下载数据集：\n\n```python\n! wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n! wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n! pip install spectral\n```\n\n### 5.2 PCA降维\n\n可以把HSI数据立方体表示为$I\\ \\in R^{M \\times N \\times D}$ ，其中*I*为原始输入，*M*为宽度，*N*为高度，*D*为光谱带数（即深度）。**I**中的每一个HSI像素都包含*D个*光谱量，并形成一个one-hot 标签向量，$Y = ({ {\\rm{y}}_1},{ {\\rm{y} }_2}, \\cdots ,{ {\\rm{y} }_C}) \\in {R^{1 \\times 1 \\times C} }$，其中，C表示谱带覆盖类别（land-cover categories）。然而，高光谱像素谱带覆盖类别的混合特性，使得类内差异性和类间相似性较高，这对任何模型来说都具有很大的挑战，为了消除光谱冗余，我们采用主成分分析(PCA)的方法将谱带的数量从*D*减少到*B*，同时保持相同的空间尺寸（即宽度*M*和高度*N*）。因为只减少了光谱带的数量，从而保留了空间信息，这对识别任何物体都是非常重要的。这里将PCA降维后的数据表示为$X \\in {R^{M \\times N \\times B}}$， 其中X为PCA后的修正输入，*M*为宽度，*N*为高度，*B*为PCA后的谱带数。\n\n为了更好的进行HSI分类，下面将HSI数据立方体划分为一个个小的有重叠的3D-patch，其真值由中心像素的标签决定。对于上面**X**中的3D neighboring patches $P \\in {R^{S \\times S \\times B}}$ ，其空间位置的中心为$(\\alpha ,\\beta )$，覆盖S×S窗口或空间范围和所有*B*谱段。因此，在位置$(\\alpha ,\\beta )$处的3D-patch，用${P_{\\alpha ,\\beta }}$表示，涵盖了宽度从$\\alpha  - (S - 1)/2$ 到 $\\alpha  + (S - 1)/2$ ，高度从$\\beta  - (S - 1)/2$ 到 $\\beta  + (S - 1)/2$，以及PCA降维后的数据立方体*X*的所有*B*谱段。\n\n下面是PCA降维及3D-patch的实现过程：\n\n```python\n# 对高光谱数据 X 应用 PCA 变换\ndef applyPCA(X, numComponents):\n    newX = np.reshape(X, (-1, X.shape[2]))\n    pca = PCA(n_components=numComponents, whiten=True)\n    newX = pca.fit_transform(newX)\n    newX = np.reshape(newX, (X.shape[0], X.shape[1], numComponents))\n    return newX\n\n# 对单个像素周围提取 patch 时，边缘像素就无法取了，因此，给这部分像素进行 padding 操作\ndef padWithZeros(X, margin=2):\n    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n    x_offset = margin\n    y_offset = margin\n    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n    return newX\n\n# 在每个像素周围提取 patch ，然后创建成符合 keras 处理的格式\ndef createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n    # 给 X 做 padding\n    margin = int((windowSize - 1) / 2)\n    zeroPaddedX = padWithZeros(X, margin=margin)\n    # split patches\n    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n    patchIndex = 0\n    for r in range(margin, zeroPaddedX.shape[0] - margin):\n        for c in range(margin, zeroPaddedX.shape[1] - margin):\n            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n            patchesData[patchIndex, :, :, :] = patch\n            patchesLabels[patchIndex] = y[r-margin, c-margin]\n            patchIndex = patchIndex + 1\n    if removeZeroLabels:\n        patchesData = patchesData[patchesLabels>0,:,:,:]\n        patchesLabels = patchesLabels[patchesLabels>0]\n        patchesLabels -= 1\n    return patchesData, patchesLabels\ndef splitTrainTestSet(X, y, testRatio, randomState=345):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState, stratify=y)\n    return X_train, X_test, y_train, y_test\n```\n\n然后，创建数据集加载类：\n\n```python\n\"\"\" Training dataset\"\"\"\nclass TrainDS(torch.utils.data.Dataset): \n    def __init__(self):\n        self.len = Xtrain.shape[0]\n        self.x_data = torch.FloatTensor(Xtrain)\n        self.y_data = torch.LongTensor(ytrain)        \n    def __getitem__(self, index):\n        # 根据索引返回数据和对应的标签\n        return self.x_data[index], self.y_data[index]\n    def __len__(self): \n        # 返回文件数据的数目\n        return self.len\n\n\"\"\" Testing dataset\"\"\"\nclass TestDS(torch.utils.data.Dataset): \n    def __init__(self):\n        self.len = Xtest.shape[0]\n        self.x_data = torch.FloatTensor(Xtest)\n        self.y_data = torch.LongTensor(ytest)\n    def __getitem__(self, index):\n        # 根据索引返回数据和对应的标签\n        return self.x_data[index], self.y_data[index]\n    def __len__(self): \n        # 返回文件数据的数目\n        return self.len\n```\n\n\n\n### 5.3 训练模型\n\n为了更高效的分析训练结果，我创建了一个训练和测试的方法，然后将上面提到的四种模型作为参数进行训练。\n\n（1）训练方法\n\n```python\ndef train(net):\n  current_loss_his = []\n  current_Acc_his = []\n\n  best_net_wts = copy.deepcopy(net.state_dict())\n  best_acc = 0.0\n\n  criterion = nn.CrossEntropyLoss()\n  optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n  # 开始训练\n  total_loss = 0\n  for epoch in range(100):\n      net.train()  # 将模型设置为训练模式\n      for i, (inputs, labels) in enumerate(train_loader):\n          inputs = inputs.to(device)\n          labels = labels.to(device)\n          # 优化器梯度归零\n          optimizer.zero_grad()\n          # 正向传播 +　反向传播 + 优化 \n          outputs = net(inputs)\n          loss = criterion(outputs, labels)\n          loss.backward()\n          optimizer.step()\n          total_loss += loss.item()\n\n      net.eval()   # 将模型设置为验证模式\n      current_acc = test_acc(net)\n      current_Acc_his.append(current_acc)\n\n      if current_acc > best_acc:\n        best_acc = current_acc\n        best_net_wts = copy.deepcopy(net.state_dict())\n\n      print('[Epoch: %d]   [loss avg: %.4f]   [current loss: %.4f]  [current acc: %.4f]' %(epoch + 1, total_loss/(epoch+1), loss.item(), current_acc))\n      current_loss_his.append(loss.item())\n\n  print('Finished Training')\n  print(\"Best Acc:%.4f\" %(best_acc))\n\n  # load best model weights\n  net.load_state_dict(best_net_wts)\n\n  return net,current_loss_his,current_Acc_his\n\n```\n\n（2）测试方法\n\n```python\ndef test_acc(net):\n  count = 0\n  # 模型测试\n  for inputs, _ in test_loader:\n      inputs = inputs.to(device)\n      outputs = net(inputs)\n      outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n      if count == 0:\n          y_pred_test =  outputs\n          count = 1\n      else:\n          y_pred_test = np.concatenate( (y_pred_test, outputs) )\n\n  # 生成分类报告\n  classification = classification_report(ytest, y_pred_test, digits=4)\n  index_acc = classification.find('weighted avg')\n  accuracy = classification[index_acc+17:index_acc+23]\n  return float(accuracy)\n```\n\n### 5.4 可视化结果\n\nHybridSN、HybridSN_BN、HybridSN_Attention、HybridSN_BN_Attention的训练结果如下：\n\n（1）四种模型的Loss下降曲线\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210104232504.png)\n\n（2）四种模型的Accuracy变化曲线\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20210104232720.png)\n\n（3）四种模型最佳Precision、Recall、F1-Score\n\n|         模型          | Accuracy | Recall | F1-Score |\n| :-------------------: | :------: | :----: | :------: |\n|       HybridSN        |  0.9790  | 0.9788 |  0.9786  |\n|      HybridSN_BN      |  0.9897  | 0.9888 |  0.9888  |\n|  HybridSN_Attention   |  0.9807  | 0.9806 |  0.9805  |\n| HybridSN_BN_Attention |  0.9885  | 0.9884 |  0.9884  |\n\n\n\n### 5.5 分析结论\n\n从收敛速度上看，HybridSN_BN和HybridSN_BN_Attention远快于另外两种模型，说明加上Batch Normalization之后，模型的收敛速度大大提升，而HybridSN_BN和HybridSN_BN_Attention的收敛速度几乎一致，说明Attention并没有提升收敛速度的作用。四种模型大约在25个epoch以后就不怎么收敛了，说明HybridSN本身的收敛速度还是很快的，只不过加了BN以后这种效果更明显了。\n\n从准确度上看，HybridSN_BN、HybridSN_Attention、HybridSN_BN_Attention均高于HybridSN，说明Attention和Batch Normalization都有提升模型分类准确度的作用，相比HybridSN_Attention而言，HybridSN_BN提升的效果更明显，这就说明了BN不仅提升收敛速度方面效果显著，在提升准确度方面也是很不错的。但是，HybridSN_BN_Attention相比HybridSN_BN，无论是Precision、Recall还是F1-Score，都下降了，说明了BN和Attention这两种机制并不搭配，在下面的思考中，我也给出了为什么会出现这种情况个人理解。\n\n可以看到，HybridSN模型的收敛速度很快，能在25个epoch内实现，准确度也很高，四种模型的准确度都达到了97%以上，说明采用三维和二维卷积的混合网络，是非常有助于解决高光谱图像分类问题的。\n\n## 六、思考\n\n（1）二维卷积和三维卷积的区别\n\n二维卷积是最常见、用途最广泛的卷积，主要用于提取空间特征，对于一张图片来说，可以根据设定的卷积核的不同，提取不同的特征，如数字图像处理中模糊、锐化、去噪操作都是用特定卷积核实现的。在CNN中，二维卷积的卷积核权重是可学习的，再加上激活函数的非线性变换，几乎可以拟合出任何想要的模型。三维卷积的卷积核可以看作一个数据立方体，因此三维卷积处理的对象是一个立方体图像（或其它相似的数据），三维卷积的思想与二维卷积相同，只不过多了一个维度，所以三维卷积不仅提取处理空间特征，也可以提取除了空间特征以外的另一维度的特征。由于高光谱图像不仅有空间信息，还有不同波长的光谱信息，因此使用三维卷积来提取高光谱图像的特征就再好不过了，但是三维卷积有一个致命的缺点，就是计算复杂度太高，参数量也比二维卷积多出了一维维度的倍数，所以采用三维和二维卷积的混合网络即降低了模型的复杂性，也提升了模型的性能。\n\n\n\n（2）为什么Batch Normalization能够加快收敛速度\n\nBatch Normalization，顾名思义，以进行学习时的batch为单位，按batch进行规范化。具体而言，把每层神经网络任意神经元输入值的分布强行拉回到均值为0方差为1的标准正态分布，用数学式表示的话，如下所示：\n\n![img](https://img-blog.csdnimg.cn/2020072322071327.png)\n\n*m代表batch的大小，$μ_B$为批处理数据的均值，$σ^2_B$为批处理数据的方差。*\n\nBN层可以让激活函数(非线性变化函数)的输入数据落入比较敏感的区域，缓解了梯度消失问题，加速了网络收敛速度。同时，BN层将每一个batch的均值与方差引入到网络中，由于每个batch的这两个值都不相同，可看做为训练过程增加了随机噪音，可以起到一定的正则效果，防止过拟合。\n\n\n\n（3）为什么多测试几次网络会发现每次分类的结果都不一样？\n\n我认为导致网络每次测试的结果都不一样原因是：没有使用net.eval()将模型切换至测试模式。我们知道，dropout的本质通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。比如，以概率 p=0.6 随机将神经元置0，就相当于在10个神经元选4个神经元输出(4个神经元在工作，另外6神经元置0)，这时我们就相当于训练了 $C_{10}^4$ 个模型，只是每个模型的参数量更少了。如果测试时仍处理训练模式，那么也会随机将神经元置为0，这就带来了不确定的结果，而在测试模式下，**dropout层会让所有的激活单元都通过**，最后的输出再乘以 (1-p) 作为模型的测试结果，这样得到的数据就是确定的了。同样的，是否处于测试模式也会影响BN层的工作机制，从而影响测试的结果。因此，合理的运用model.train()和model.eval()对测试的结果是至关重要的。\n\n（4）如果想要进一步提升高光谱图像的分类性能，可以如何使用注意力机制？\n\n在上述实验中，给HybridSN加上注意力机制后模型的性能有了提升，我也尝试了把注意力机制加在HybridSN模型不同位置上作比较（结果没有在上面呈现），发现把Attention加在第三个三维卷积后，二维卷积之前比加在二维卷积后效果更好。我认为这是因为高光谱图像经过二维卷积之后会损失一部分光谱信息，如果将注意力机制加在二维卷积之后，那么Attention抽取关键信息的效果就不明显了（会忽略少部分光谱信息的关键区域），所以应该把Attention加在第三个三维卷积后，这样会保留更多的光谱信息，从而进一步提升高光谱图像的分类性能。从上面的结果中也看到了，加上Attention之后，模型的Precision、Recall、F1-Score都提升了。\n\n（5）为什么HybridSN_BN_Attention的性能不如HybridSN_BN？\n\n我刚开始也很疑惑，为什么两个被公认性能优越的模块加在一起后性能反而下降了呢？我想了很久，得出了自己的一点理解：因为BN是固定每一次输入Batch的分布，把每层神经网络任意神经元输入值的分布强行拉回到均值为0方差为1的标准正态分布，而Attention是为了获取更加显著的区域，经过Attention后显著的区域会变得更为突出，这在一定程度上打乱了原来输入的分布，从这方面来讲，这两个模块似乎是一种相互互斥的存在，效果自然就下降了。这相当于一个精通python的人认为python是世界上最好的语言，而另一个精通java的人认为java是最好世界上的语言，当一个人即会java也会python时，它可能任何一个都不精通。当然，得到这样的结果也可能是如下原因造成：\n\n- 由于Indian Pines数据集自身特点，模型对其分类性能的评估并没有广义性，可能在另外一个数据集上BN+Attenion的性能又比只有BN的模型好了\n- 模型本身的结果可能就存在问题，如果调整一下各个模块的顺序，改变各个模块内卷积核的参数，结果会不会更好呢？\n\n由于时间原因及个人知识水平的限制，并没有做更多的探索，还望见谅。\n\n\n\n## 七、结语\n\nHybridSN是一种用于HSI分类的混合网络模型，以三维和二维卷积结合的方式既提升了模型的性能，也降低了复杂度。另外，分别加上BN、Attention之后，模型的性能都有了提升，BN提升更加明显，但是把BN和Attention一起加在HybridSN中，会发现HybridSN_BN_Attention的性能虽然比原始的HybridSN有所提升，但不如HybridSN_BN，我认为这是因为两个模块是一种互斥的存在，从而导致HybridSN_BN的性能降低，上面也给出了自己的解释。这次实验让我学到了很多，不仅熟练掌握了HSI分类，也对BN和Attention的印象更加深刻，更明白了不是所有优秀的模块组合起来就能取得好的结果，只有不断的分析、实践、思考，才能更好的理解其本质。\n\n\n\n最后，附上本文在colab的实现过程：[https://colab.research.google.com/drive/12QbZqcxfplFEm7yp3X9wgi7jYXmqRjz9?usp=sharing](https://colab.research.google.com/drive/12QbZqcxfplFEm7yp3X9wgi7jYXmqRjz9?usp=sharing)\n\n\n\n【参考文档】\n\n[HybridSN: Exploring 3-D–2-D CNN Feature Hierarchy for Hyperspectral Image Classification](https://ieeexplore.ieee.org/document/8736016)\n\n[CBAM: Convolutional Block Attention Module](https://github.com/luuuyi/CBAM.PyTorch)\n\n[高光谱数据集](https://blog.csdn.net/qq_38290648/article/details/80596543)\n\n[高光谱图像](https://www.sohu.com/a/308158769_394987)\n\n\n\n","tags":["HybridSN"],"categories":["神经网络"]},{"title":"SalBiNet360-Saliency Prediction on 360° Images with Local-Global Bifurcated Deep Network","url":"/2020/12/23/111602/","content":"\n> 这是我第一篇精读的IEEE2020论文，**我认为这一篇论文非常有意义，因为它是目前为止最先进显著性预测模型**，在理解论文过程中，我查阅了许多相关资料，其中一些放在文章最后的补充概念部分，这对理解SalBiNet360的原理非常重要。另外，如果翻译过程中有什么不妥之处，欢迎在评论区留言指正。\n\n英文名称：SalBiNet360: Saliency Prediction on 360° Images with Local-Global Bifurcated Deep Network\n\n中文名称：基于局部-全局二叉式深度网络的360°全景图显著性预测\n\n论文会议：2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\n\n论文地址：[https://ieeexplore.ieee.org/abstract/document/9089519](https://ieeexplore.ieee.org/abstract/document/9089519)\n\n<!-- more -->\n\n# 摘要\n\n随着虚拟现实应用的发展，在360°全景图上预测人类的**视觉注意**对理解用户的行为至关重要。基于360°全景图全局和局部视觉显著性的特点，论文提出了一个用于360°全景图显著性检测的框架(**SalBiNet360**)。在全局深度子网络中，利用多个多尺度的上下文模块和一个多级解码器来整合网络中层和深层的特征。在局部深层子网络中，只利用一个多尺度上下文模块和一个单级解码器来减少局部显著性特征的冗余。最后利用线性组合方法，结合全局和局部显著图的特点，生成最终的融合显著图。在两个公开数据集上进行的定性和定量实验表明，**SalBiNet360的性能优于当前最先进的方法，特别是能够更好地预测低显著性区域和图像左右边界附近的区域**。\n\n关键词： 360°度全景图，SalBiNet360，虚拟现实 (VR)\n\n> 关于视觉注意及视觉显著性检测见本文最后的补充概念\n\n# 1 引言\n\n360°全景图在VR技术中扮演着至关重要的角色。与2D图像不同，360°全景图允许观察者从各个方向观察场景，因此其特性吸引了研究者更多的兴趣。此外，预测观察者在360°图像上的视觉注意力，可以帮助研究人员了解观察者佩戴VR设备时的行为，它还可以应用在计算机视觉的各个方面，如图像压缩和图像裁剪。\n\n**显著性模型是在人类没有明确意图的情况下，观察图像所注意的物体或区域**。随着神经网络的兴起和发展，对传统二维图像上的显著性预测模型进行了深入的研究。许多优秀的模型已经出现，并建立了大量的数据集，如MIT Saliency Benchmark（一个显著性预测框架）。然而，到目前为止，关于360°全景图的显著性预测的研究还比较少，尤其是以神经网络为框架的研究。一般情况下，我们通常会通过**ERP投影**的方式将360°全景图投射到一个平面上，但这种投影方式会使360°全景图对应球面的两个极点被转换为上界和下界，从而导致图像过度变形。\n\n> 关于ERP投影见本文最后的补充概念\n\n如果将传统二维图像上的显著性预测模型直接应用于ERP图像上，效果将不理想。图1(c)显示了在传统二维图像上，由显著性模型预测的全局ERP显著图。与ground truth（图1（b））相比，全局显著图大致预测了显著性区域（赤道区域）。但是对于其它低显著性的区域（观察者不太关注的区域），传统模型无法预测它们。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223124655.gif)\n\n*图1：(a)ERP图像，(b)ground truth显著图，(c)(d)分别是全局和局部的显著图，(e)-(j)通过立方体投影的直线显著图。*\n\n为了解决这个问题，利用**立方体投影**将360°全景图投射到立方体的六个面，每个面的视场角（FOV）为90°，显示六个方向的景物，而且比ERP图像失真小，这些立方体图被命名为rectilinear  images，我将其译为**直线图像**。图1(e)-(j)说明了这六张直线显著图，而图1(d)则说明了由这些直线显著图重新投影出来的局部显著图。与全局显著图相比，局部显著图可以精细地预测显著性区域，即使是一些显著性较低的区域也可以预测。（这里全局和局部特征我理解为：如果从整张ERP图片提取特征就是全局特征，如果从立方体投影的六个面分别提取特征，再重新投影到一张图上，那么得到的就是局部特征）\n\n> 关于立方体投影及视场角（FOV）见本文最后的补充概念\n\n然而，在预测缺乏全局性的直线显著图时，模型增强了低显著性区域，**甚至一些不被人类关注的区域也被错误地预测出来**。在图1(i)和图1(j)中，除了云层和坑洞，几乎没有什么物体，它们显然是突出的。所以在局部显著性图（图 1(d)）中，这两类物体很容易被预测出来。但是预测整幅图像时，在其它物体的存在下，云层和坑洞就显得不那么突出了。因此，模型对云层和坑洞的敏感度较低，所以，在缺乏全局性的直线图像中，模型对低显著性的区域是很敏感的。\n\n为了解决上述问题，作者提出了一种基于360全景图的全局和局部显著性预测的新框架（SalBiNet360）。这是一个包含全局和局部显著性预测子网络的（二叉式）深度网络框架。在全局深度子网络中，我们利用多个多尺度的上下文模块从网络的中层和深层提取上下文特征，然后，这些特征由一个多级解码器整合，预测全局显著性图。对于局部深层子网络，为了降低网络对一些低显著性区域的敏感性，只利用一个多尺度上下文模块，然后利用单级解码器来还原图像的分辨率，生成直线显著图。最后，将多张直线显著图重新投影成局部显著图（如图1（d）），利用线性组合策略将全局显著图与局部显著图融合。综上所述，我们做出了以下贡献：\n\n- 本文提出了一种全新的二叉式深度网络，该网络有两个子网络，分别预测360°全景图的全局和局部显著性特征，通过线性组合将全局显著图和局部显著图融合生成最终的显著图。\n- 提出了一种新的多尺度上下文模块，以提取360°全景图多尺度的上下文特征。\n- 采用全局子网络中的多级解码器，以减小不同层网络的判别特征之间的差距。\n- 在两个公开可用的数据集上进行的广泛实验说明，所提出的SalBiNet360优于经过测试的最先进的方法。\n\n\n\n# 2 相关工作\n\n到目前为止，大多数360°全景图的显著性预测模型都是在传统二维图像模型基础上改进的（所谓的传统二维图像模型是指用二维图形训练和测试的模型），主要有三个研究方向，分别是赤道偏移、凝视位置的数据映射和投影变换。\n\n赤道偏移。当观察者观看VR全景图像时，他们往往会更多地关注赤道附近的内容，这被命名为赤道偏移。Battisti等人利用这一特性，将360°全景图划分为多个区域，每个区域赋予它们不同的显著性权重，区域越靠近图像的赤道，权重越大。Ding等人从图像层面细化到像素层面，利用高斯分布模型来模拟赤道偏差，从而提高了精度。但他们都只是基于360°全景图的全局属性设计模型，并没有考虑到局部的显著性。\n\n凝视位置的数据映射。一些显著性预测方法，是基于凝视位置的数据映射，就是利用观察者的凝视位置数据来建立显著图。这类方法将观察者有限的注视位置扩展为一般的显著图。Upenik等人利用头部运动轨迹来预测显著性，根据头部角度速度来确定观察者观察图像某些区域时所花费的时间。Abreu等人根据观察者的固定时间来区分观察者的视觉注意（即根据观察者看某一部分区域的大概时间来区分显著性区域）。\n\n对于投影变换，最常用的方法是ERP投影。为了解决ERP图像的边界失真问题，Lebreton等人将几个不同经度边界的ERP投影的显著图均匀地整合在一起，从而得到最终的显著图。但是，他们没有解决图像上下边界附近发生严重失真的问题。Startsev等人将360°全景图投射到ERP图像和反ERP图像上，然后对这两幅图像进行预测，并将其融合，解决了等ERP图像左右边界不连续的问题。此外，他们还单独预测了图像上下边界附近的显著性。但是他们直接使用了预训练的显著性模型，而不是通过360°全景图来训练它们，所以这些模型无法提取360°全景图的具体特征。而球面投影则是将360°全景图投射到球面上，使图像具有连续性，图像上的景物不易失真，可以提高模型的精度。但是，应用这些模型预测立体空间中的图像是复杂的。Bogdanova等人提出了一个基于球面投影的显著模型，构建球形金字塔模块，从而输出球面显著图。\n\n除以上几种投影变换方法外，还有立方体、八面体、正金字塔投影等。立方体投影是比较常用的，Maugey等人提出了双立方体投影法，以解决立方体投影中的边界畸变和不连续问题。该方法将360°全景图投影到两个水平和垂直相差45°的立方体上，然后通过旋转将两个显著图融合。虽然它可以精细地预测局部的显著图，但由于直线图像缺乏全局性，导致一些低显著性的区域被错误地预测。Chao等人提出的SalGAN360在上述方法基础上扩展到多立方投影，也分别预测了全局和局部的显著图。但是，它始终利用SalGAN预测全局和局部的显著性特征，而没有考虑到360°全景图的全局和局部属性，以提高网络。\n\n本文根据360°全景图的全局和局部属性，将提出的网络分为两个不同的深度子网络，分别预测全局和局部的显著性特征，通过融合得到最终的显著图。\n\n\n\n# 3 方法\n\n在本节中，构建了包含全局和局部深度子网络的二叉式网络（SalBiNet360）。在全局深度子网络中，生成了一个全局的显著图，可以检测所有方向的视觉注意力。在局部深度子网络中，生成了一个以精细方式检测视觉注意力的局部显著图。最后，通过与全局和局部显著图的线性组合，生成融合的显著图。\n\n## 3.1 SalBiNet360机制\n\n### 3.1.1 Framework\n\n所提出的模型框架如图2所示，它利用ResNet50作为骨架。ResNet50有四个卷积块（输入层还有一个卷积）。对于一个输入图像，在第四个卷积块中，分辨率降低了32倍。这里从网络中第二个卷积块的最后一层开始，我们将网络分成两个深度子网络，其中一个子网络预测全局的显著性，而另一个子网络预测局部的显著性。这两个子网络都有ResNet50最后两个卷积块。图2蓝色的方块就是ResNet50的convBlock块，一个convBlock包含多个卷积操作，若想对ResNet50有更深的理解，[ResNet残差网络及变体详解](https://blog.csdn.net/qq_37555071/article/details/108258862?ops_request_misc=%25257B%252522request%25255Fid%252522%25253A%252522160870193316780308367044%252522%25252C%252522scm%252522%25253A%25252220140713.130102334.pc%25255Fblog.%252522%25257D&request_id=160870193316780308367044&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-1-108258862.pc_v1_rank_blog_v1&utm_term=resnet)，相信会让你有所收获。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223134214.gif)\n\n\n\n*图2：SalBiNet360的框架。该网络分为全局和局部深度子网络，分别用来预测360°图像的全局和局部显著性特征。*\n\n在全局显著性预测中，将整个ERP图像纳入全局子网络，输出全局显著性图。一般来说，神经网络的第一个卷积块会提取一些低级特征，如形状、纹理、轮廓等，但这些特征对显著性预测的贡献较小。此外，不同尺度的卷积层可以保留精细的上下文信息，尤其是中间*的特征图的尺度相对较大，这使得更多的全局信息得以保留。因此，将最后三个卷积块的特征被提取出来，分别输入到三个相同的多尺度上下文模块(MCM)中，然后生成三个不同层次的特征图。之后，采用多级解码器对三个特征图进行整合，生成全局显著图。\n\n在局部显著性预测中，首先通过立方体投影将360°全景图投射到立方体的六个面上，每个面的FOV为90°，可以得到多个直线图像。然后，把这些直线图像输入到局部子网络，局部子网络输出相应的直线显著图。最后，ResNet50的后三个卷积块的特征也在局部子网络中被提取出来。如果在局部子网络中加入多个多尺度的上下文模块（就像全局子网络的架构一样），会增加局部显著图的冗余度。在图3中，沟渠和灯具是ground truths中显著性较低的对象，与只有一个多尺度上下文模块的局部子网络相比，有多个多尺度上下文模块的局部子网络会错误地将这些显著性较低的对象预测为高显著性的对象。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223135821.gif)\n\n*图3：具有一个和多个多尺度上下文模块的地面真相和局部显著图的视觉比较。(\"MCM\"表示多尺度上下文模块)*\n\n因此，与全局子网络中的操作不同，局部子网络的最后三个卷积块中的特征图是连在一起的，只是输入到一个多尺度的上下文模块中。之后，采用卷积-上采样操作的单级解码器，将多尺度上下文模块输出的结果恢复到与输入的分辨率一样的大小。然后，利用重投影法将这些直线显著图重新投影成多个ERP显著图，通过使用平均法将所有的ERP显著图重叠，得到局部显著图。\n\n最后，将全局和局部的显著图进行线性组合融合，得到融合的显著图。多尺度上下文模块和多级解码器的具体内容将在3.2节和3.3节中介绍。\n\n\n\n### 3.1.2 预训练\n\n在没有360°全景图的大型数据集的情况下，SalBiNet360必须由SALICON进行预训练(SALICON是一个显著性检测数据集)。该数据集包含20 000张二维图像以及相应的显著图，其中10,000张用于训练，5,000张用于验证，5 000张用于测试。将二维图像放入模型中，相应地同时生成两张预测的二维显著图，一个是来自全局子网络，另一个是来自局部子网络。然后利用 ground truth的显著图，根据**二元交叉熵损**失来监督这两个子网络的训练。\n\n### 3.1.3 微调\n\n在使用SALICON预训练模型后，将全局和局部深度子网络进行联合微调。做法是将训练的直线图像分别放入模型中，相应地同时生成两个预测的直线显著图，一个是来自全局子网络，另一个是来自局部子网络。在360°全景图显著性预测模型中，经常使用皮尔逊相关系数（Pearson’s Correlation Coefficient，简称CC） 和归一化扫描路径显著性（Normalized Scanpath Saliency，简称NSS）这两个指标来衡量模型的有效性。因此，在二元交叉熵中加入这两个指标来优化模型训练的过程。对于全局子网络，损失可以定义如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223141413.png)\n\n其中，ܵ$S_g$、$S_{sal}$、$S_{fix}$ 分别是全局子网络预测的直线显著图、ground truth的直线显著图和二元直线定点图，$\\mu_{BCE}$和$\\sigma_{BCE}$表示SalBiNet360对预测的二维图像计算出的$L_{BCE}$的平均值和标准差，$L_{BCE}$表示二元交叉熵损失，$L_{normal}$是CC和NSS的归一化函数。\n\n$L_{BCE}$定义如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223142528.png)\n\n其中*N*为像素数，*j*为像素坐标。\n\n$L_{normal}$定义如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223142732.png)\n\n其中$L^{CC}_{metric}$是CC的评价指标，$L^{NSS}_{metric}$是NSS的评价指标。$\\mu_{CC}$、$\\sigma_{CC}$、$\\mu_{NSS}$、$\\sigma_{NSS}$表示SalBiNet360对预测的二维图像计算的这两个指标（即CC和NSS）的平均值和标准差。\n\n对于局部子网络来说，$lossL_L$与全局子网络中的损失相同，只是用局部子网络预测的直线显著图$S_l$代替了$S_g$。因此，SalBiNet360的总损失定义为：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223143234.png)\n\n在微调步骤中，我们首先固定Resnet50网络的权重。然后，我们对SalBiNet360中其他部分的权重进行微调。最后，随机初始化两个解码器的最后两个卷积层的权重（我认为这两个卷积层的权重占比很小，虽然进行随机初始化了，也影响不了整个模型的性能，也提高了模型的鲁棒性）。这样在微调的过程中就可以充分提取360°全景图的特征。\n\n\n\n\n\n\n\n### 3.1.4 测试\n\n在测试步骤中，预测局部显著性时，首先将直线图像放入模型中，在局部子网络中生成直线显著图（忽略全局子网络中的输出）。然后，将直线显著图重新投影为ERP格式，得到局部显著图图。\n\n在预测全局显著性特征时，将ERP图像放入模型中，模型直接在全局子网络中生成全局显著图（忽略局部子网络中的输出）。虽然网络是由失真较小的直线图像进行微调，但在预测全局显著性时，由于赤道附近的区域失真较小，所以模型在等ERP图像的赤道附近区域可以很好地预测。另外，**利用Fused Saliency Method（FSM，融合显著性方法）作为后处理方法，解决了360°全景图左右边界不连续的问题，在这个方法中四个全局显著图分别赋予0.25的权重**。\n\n最后，将全局和局部显著图进行线性组合融合，得到融合后的显著图。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223143752.png)\n\n其中，$\\alpha$和$\\beta$分别是全局和局部显著图的权重，且$\\alpha$+$\\beta$=1\n\n> 我第一次看到FSM方法，非常疑惑，作者文中并没有过多的解释，我查阅了其引用的论文，才理解了具体用到的方法，见本文最后的补充概念。\n\n\n\n## 3.2 多尺度上下文模块\n\n当360°全景图通过ERP投影到一个平面上时，图像上不同尺度的上下文信息是不同的。如图 4 所示，**360°全景图比传统的二维图像尺寸大得多，可以捕捉到更多的场景信息**，在此基础上，设计了多尺度的上下文模块，有效地提取不同尺度的上下文特征。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223145815.gif)\n\n*图4：多尺度上下文模块的架构。*\n\n如图4所示，所提出的多尺度上下文模块共包含四个分支{$b_n$，n=1,2,3,4}。每个分支都有不同大小的卷积核，可以在不同尺度的360°全景图上进一步提取更多的上下文特征。最初，在每个分支中利用1X1卷积层来减少特征图的通道数。对于݊n>1的分支，我们分别增加一个卷积层，其内核大小为（2n-1)x(2n-1)，然后，在四个分支中分别增加一个3x3卷积层，再将每个分支的特征图Concatenate，再做一次3x3卷积操作。最后，将提取的判别特征与原始特征通过shortcut与Relu激活函数结合，从而得到不同尺度的判别特征。\n\n\n\n## 3.3 多层解码器\n\n在全局子网络中，利用多尺度的上下文模块，得到三个判别性特征图{$f_i$，i=2,3,4}。**为了缩小这些特征之间的差距，采用多级解码器**。如图5所示，在这个解码器中有四层（c=1,2,3,4)，$f_i^c$示 c 层中的第 i 个特征图，$f_i$在第二层中更新了以下内容公式：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223154812.png)\n\n其中Up是对特征图进行因子为$2^{k-2}$的上采样操作，Conv是3X3卷积层。 圈表示元素化的乘积（点积）。\n\n> 我认为这里每一层的特征图从2开始是应该方便些公式，如上面的$2^{k-2}$，k从2开始，第一幅特征图上采样因子就是2\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223150711.gif)\n\n*图5：多级解码器的架构。图中顶部的\"c\"表示第c层。*\n\n对于$f_4^2$，作者设置$f_4^2$ = $f_4^1$，对于$f_2^3$，作者设置$f_2^3$=$f_2^2$（即这些位置的特征图采用一样的上采样和卷积操作）。至于$f_3^3$ 和 $f_2^4$，作者采用upsampling-convolution-concatenation策略来整合多个特征，公式如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223151427.png)\n\n其中，Up为上采样因子为2的操作，Conv是3x3卷积层，Concat是两个特征图的通道连接。最终，通过对 $f_2^4$使用upsampling-convolution策略，解码器生成与输入的ERP图像大小相同的全局显著图。\n\n至于单层解码器，主要由5个3×3卷积层和1个填充层以及5个系数为2的双线性上采样层组成（就是图2的那五个橙色方块）。\n\n\n\n# 4 实验\n\n## 4.1 实验配置\n\n### 4.1.1评估数据集\n\nSalBiNet360是在两个公开的数据集上进行评估的：Salient360! 和Grand Challenge\n\nSalient360! 是国际会议ICME2017的360°全景图显著性预测挑战赛数据集，由65张360°全景图组成，观察者的头部和眼部运动被记录下来，其中40张图像用于训练，25张用于测试。\n\nVR Saliency是虚拟现实全景图显著性预测数据集，由22张图像组成，观察者的头部动作被记录下来。\n\n两个数据集中的图像都由室内和室外场景内容组成。\n\n### 4.1.2 评价指标\n\nSalBiNet360的性能是通过四个常用的指标来评估的：KL、CC、NSS、AUC。KL和CC评价的是两个显著图之间的**显著性密度分布**（主要是面向局部信息的），NSS和AUC评价的是显著图和二元定点图之间的眼动位置分布（主要是面向全局信息的）。\n\n> 关于KL、CC、NSS、AUC四个指标，作者并没有详细介绍，我查阅了许多资料，大致知道其具体的衡量标准，见见本文最后的补充概念部分。\n\nSalient360! 数据集的性能是在KL、CC、NSS和AUC上评估的，而对于VR Saliency数据集，只采用CC来评估性能，如下所述。在下面的小节中，每个实验的最佳结果以红色粗体显示。\n\n\n\n### 4.1.3 实施细节\n\n**网络结构** 。在全局子网络中，对于多尺度上下文模块，每个分支的特征图通道减少到32个。在局部子网中，经过多尺度上下文模块的处理，特征图的通道减少到256个。\n\n**微调与测试**。Salient360!数据集中40幅训练图像分为30幅用于微调，10幅用于验证。在立方体投影中，立方体在水平和垂直方向上每45°旋转一次，可以得到2×2=4种旋转方式。因此，每幅360°全景图有4×6=24幅直线图像，完全可以生成30×24=720幅直线图像用于微调，10×24=240幅用于验证。在测试SalBiNet360模型时，为了使重新投影后的局部显著图更加平滑，每隔10度旋转一个立方体，因此会产生9×9×6×25=12150张整线图像（每次转10度，即水平方向9次，垂直方向9次，一次360°全景图有6张直线图像，Salient360!共25张360全景测试图）。当预测全局显著性时，预测25个ERP图像得到全局显著图。当预测局部显著性时，预测12150张直线图像，并重新投影为25张局部显著性图。最后，通过融合这些全局和局部的显著图，可以得到25个融合的显著图。\n\n对于VR Saliency，根据其实验设置，用SALICON数据集预训练模型后直接测试22张360°全景图。同样，立方体也是每10°旋转一次，就会产生9x9x6x22=10692个直线图像。预测全局和局部的显著图和Salient360!中的一样。\n\n在预训练和微调步骤中，所提出的模型均采用Adam优化器进行训练，初始学习率为$10^{-4}$，batch size为10。此外，当损失下降到一定程度时，学习率会下降10%。SalBiNet360基于PyTorch框架，部署在GeForce GTX1080Ti GPU上。源代码可在https://github.com/githubcbob/SalBiNet360（访问404，可能是作者删了，哈哈）\n\n\n\n## 4.2 SalBiNet360的分析\n\n### 4.2.1 融合策略中权重的选择\n\n在融合全局与局部显著图时，我们做了多组全局和局部权重选择的实验。表1说明了在测试步骤中，两个数据集上不同权重的融合结果。可以看出，随着$\\alpha$的增加( $\\beta$减少)，SalBiNet360的指标得分在两个数据集上都出现了先增加后减少的现象。当全局权重 $\\alpha$设置为0.55时Salient360!表现最佳，$\\alpha$在上设置为0.50时VR Saliency表现最佳。因此，在下面的实验中，我们在Salient360!上的融合策略中设置 $\\alpha$=0.55($\\beta$=0.45)，在VR Saliency上设置 $\\alpha$=0.50($\\beta$=0.50)。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223154513.png)\n\n*表1：两个数据集上不同权重选择的比较。*\n\n\n\n### 4.2.2 多尺度上下文模块的有效性\n\n在下面的实验中，**将SalBiNet360的两个子网络中的多尺度上下文模块全部去掉**，以测试多尺度上下文模块对显著性预测的影响。表2显示了SalBiNet360在有上下文模块和无上下文模块的两个数据集上测试的量化结果。显然，带有多尺度上下文模块的SalBiNet360的性能优于不带有多尺度上下文模块的SalBiNet360，这说明带有多尺度上下文模块的SalBiNet360能够有效地预测360°图像上的显著性。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223154733.png)\n\n*表2：SalBiNet360在两个数据集上有无上下文多尺度模块（\"MCM\"表示多尺度上下文模块）的比较。*\n\n### 4.2.3 全局、局部和融合显著性预测的表现\n\n为了研究全局、局部和融合的显著性预测对SalBiNet360整体性能的影响，我们分别在两个数据集上做了两个子网络和融合策略的显著性预测实验。从表3中可以看出，全局显著性在NSS和AUC上的表现都优于局部显著性，而局部显著性在KL和CC上的表现都优于全局显著性。这说明全局显著图对图像凝视点（gaze points）的识别能力优于局部显著图，而局部显著图在减少显著性信息的丢失上效果更好。此外，融合后的显著图在NSS和AUC上都优于全局图和局部图，而在其他两个指标上略逊于局部图。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223155102.png)\n\n*表3：全局、局部和融合的显著性在两个数据集上的比较。*\n\n图6和图7通过箱形图说明了全局、局部和融合显著性在两个数据集上的得分分布。很明显，在Salient360!数据集上，融合显著性在KL和CC上的得分分布与局部显著性相似，NSS和AUC的得分分布与全局显著性相似。但在VR Saliency上，融合显著性的得分分布普遍大于全局和局部显著性的得分分布。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223155431.gif)\n\n*图6：全局、局部和融合显著性在Salient 360上的得分分布对比*\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223155530.gif)\n\n*图7：全局、局部和融合显著性在VR Saliency上的得分分布对比*\n\n图8和图9显示了全局、局部和融合的显著图在两个数据集上的一些可视化结果。可以观察到全局子网络预测的显著性区域大致集中在图像的赤道部分，局部显著性预测可以精细地预测一些显著对象，如阶梯。但是，由于缺乏全局性，某些物体被错误地预测为高显著性（如坐具和树木）。结合全局和局部显著图的特性，融合后的显著图可以恰到好处地预测这些显著性区域，从而提高SalBiNet360的预测质量。在VR Saliency上，融合的显著图的效果稍差（因为模型没有进行微调就直接测试，主要是由于其数据集很少，只有22张图片），但融合的显著图也可以削弱一些物体的显著性。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223155754.gif)\n\n*图8：Salient 360上的全局、局部、融合的显著图和ground truths 的视觉对比*\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223155853.gif)\n\n*图9：VR Saliency上的全局、局部、融合的显著图和ground truths 的视觉对比*\n\n\n\n## 4.3 与最新技术的比较\n\n表4显示了SalBiNet360与现有的7种经过测试的最先进的显著性模型在Salient360!上的量化结果，包括GBVS360、SalNet360、Maugey、Startsev、SJTU、CDSR和SalGAN360。很明显，SalBiNet360在大多数情况下优于所有其他方法。只有SalGAN360获得了与SalBiNet360相同的AUC分数。值得注意的是，与CC、NSS和AUC相比，SalBiNet360在KL方面有明显的提高，这说明SalBiNet360在减少**显著性密度分布**的信息损失方面效果更好。表5是VR Saliency中的量化比较。比较的三种模型（EB、SalNet+EB、ML-Net+EB）的性能结果，可以看出，SalBiNet360得到的性能最好。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223160455.png)\n\n*表4：不同方法在Salient360!上的比较。*\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223160542.png)\n\n*表5：不同方法在VR Saliency上的比较。*\n\nSalient360!上一些案例的视觉对比如图10所示。与SalGAN360相比，SalBiNet360不仅可以精细预测图像赤道附近的显著性区域，还可以预测一些SalGAN360忽略的低显著性区域（如树木和地板）。此外，SalBiNet360还可以预测图像左右边界附近的显著性区域，从而减少了显著性密度分布中的信息损失。这与表4中SalBiNet360在KL得分上有所提高的结果是一致的。这一现象可以解释为利用多尺度的上下文模块从多个尺度中提取上下文特征，包括边界的特征。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223160909.gif)\n\n*图10：SalBiNet360和最先进的模型在Salient360!的视觉对比*\n\n\n\n图11是SalBiNet360在VR Saliency上的视觉效果。在不对网络进行微调的情况下，SalBiNet360只能大概的做到预测一些显著性区域。但图像左右边界附近的显著性区域还是可以预测的。 它证明了SalBiNet360能够有效地解决等角ERP图像左右边界的不连续视觉信息问题。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223161046.gif)\n\n*图11：SalBiNet360对VR Saliency的视觉效果*\n\n## 4.4 讨论\n\n在两个360°全景图数据集上的大量实验表明，提出的SalBiNet360实现了具有竞争力的性能。它是一个包含全局和局部显著性预测子网络的二叉式深度网络。该网络仅通过直线图像进行联合微调。如果将这两个子网络作为两个独立的分支分别进行微调，则可能会浪费很多时间。\n\n在缺乏大的360°图像saliency数据集的情况下，必须利用失真较小的直线图像和相应的ground truths来微调模型，这样可以忽略ERP图像上下边界的尺度和严重失真。显然，在测试步骤中，由于等角图像的赤道附近失真较小，全局子网络可以很好地预测赤道附近的显著性（如图8、9中的\"全局显著性图\"）。**但是，两极的预测效果并不好。因此，需要将其与局部显著性相结合，以弥补全局显著性的不足。**\n\n与表4和表5中的其他模型相比，SalBiNet360构建了两个子网络，分别适合预测360°图像的全局和局部显著性。**全局子网络可以大致预测360°全景图的赤道附近和左右边界的显著性区域，而局部子网络可以精细地预测一些显著性高的区域和观察者不太关注的区域，从而弥补了全局显著性的劣势**。SalBiNet360的分叉架构可以应用于其他利用360°全景图的全局和局部显著性的显著性模型。\n\n# 5 总结\n\n本文提出了一种全新的360°全景图的显著性预测框架，命名为SalBiNet360。所提出的框架在ResNet50的第二个卷积块之后分为两个深度子网络，这两个子网络分别预测全局和局部的显著图。在全局深度子网络中，上下文特征从网络的中层和深层中提取，**并由三个多尺度的上下文模块和一个多层次的解码器进行整合**。而在局部深度子网络中，为了减少图像低显著性区域的冗余，**只利用一个多尺度的上下文模块和一个单层解码器来生成局部显著图**。最后，通过线性组合融合全局和局部显著图，生成最终的显著图。在两个可用的数据集上进行了广泛的实验表明，SalBiNet360的性能优于已测试的最先进的方法。\n\n\n\n\n\n# 补充概念\n\n为了更好的理解本文，我查阅了许多资料，补充了文章中的作者所提到一些术语和概念：\n\n（1）**视觉显著性检测**(Visual saliency detection)指通过智能算法模拟人的视觉特点，提取图像中的显著区域***(***即人类感兴趣的区域)。\n\n（2）**视觉注意机制**(Visual Attention Mechanism，VA)，即面对一个场景时，人类自动地对感兴趣区域进行处理而选择性地忽略不感兴趣区域，这些人们感兴趣区域被称之为显著性区域。如下图所示，当看到这幅图像时，图中的四个人最能引起人的注意，而其它区域（如地面）就不会引起人们注意。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223123107.png)\n\n*来源：https://www.cnblogs.com/ariel-dreamland/p/8919541.html*\n\n（3）**ERP**全称equirectangular projection，又可以称为equidistant cylindrical projection，中文译为等距柱状投影。这种投影方式将经线映射为恒定间距的垂直线，将纬线映射为恒定间距的水平线，映射关系相对简单，但既不是等面积的也不是保角的，引入了相当大的失真。下图是一幅用ERP方式投影的360全景图，长宽比为2:1，可以明显看出，两极区域拉伸严重，造成了极大的冗余，增加了编码负担。 \n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223124401.png)\n\n*来源：https://blog.csdn.net/lin453701006/article/details/71173090*\n\n（4）**立方体投影**就是将360°全景图被投影到各面都是正方形的六面体上（面积未保持不变），经线和纬线都是直线，在纬度 +45° 和 -45° 之间，东南西北方向是准确的，但常规方向不准确。在极面上，由中心确定的方向是真实的。在纬度 +45° 到 -45° 之间，比例尺是正确的。如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223125906.png)\n\n*来源：https://desktop.arcgis.com/zh-cn/arcmap/10.7/map/projections/cube.htm*\n\n（5）**视场角（FOV）**。在光学仪器中，以光学仪器的镜头为顶点，以被测目标的物像可通过镜头的最大范围的两条边缘构成的夹角，称为视场角。如下图。 视场角的大小决定了光学仪器的视野范围，视场角越大，视野就越大。通俗地说，目标物体超过这个角就不会被收在镜头里，就只能看到局部物体。 \n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223130328.png)\n\n*来源：http://www.colorspace.com.cn/kb/2013/02/24/fov/*\n\n（6）**Fused Saliency Maps**（FSM，融合显著性方法）。其作者认为（引用论文的作者），在传统情况下，摄影师倾向于将感兴趣的对象定格在赤道近旁，对于边界的区域其实是不敏感的，因此，使用传统图像训练显著性模型很可能不包含这些区域的特征，尤其是基于深度神经网络的模型。为了解决显著性模型的中心先验限制，提出了Fused Saliency Maps（FSM）方法，该方法过程如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223144925.png)\n\n\n\n1. 首先，输入ODI图像（omnidirectional images，全向图像，球面投影产生的图像）。\n2. 将其随机翻译成不同的版本，具体做法是将里面的场景、物体随机移动、随机拼接，这里的T即翻译的版本数，可根据实际情况设置。\n3. 用相应的显著性模型预测这T幅图像的显著性图\n4. 采用线性组合的方式将3产生的T幅显著性图融合，其中$W_1$、$W_2$、$W_3$、$W_4$为这4幅图的权重。\n\nFSM方法可以解决全景图左右边界不连续的问题。\n\n*来源：Look around you: Saliency maps for omnidirectional images in VR applications. Ninth International Conference on Quality of Multimedia Experience (QoMEX). IEEE, 1-6, 2017*\n\n（7）Kullback-Leibler Divergence，简称**KL散度**，通常用来衡量两个分布之间的距离， KL散度越小说明，两个分布之间的距离越小，该模型检测性能越好。\n\n（8）Pearson’s Correlation Coefficient（**CC**）是指皮尔逊相关系数，用来评价预测的眼关注点显著图和ground truth之间的线性相关性，其值越大，相关性越强，算法性能越好，值为正表示正相关，值为负表示负相关。下面是其一个公式（CC有很多变种）：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201223152740.png)\n\n\n\n（9）Normalized Scanpath Saliency （**NSS**）是指标准化扫描路径显着性，用来评价预测的人眼凝视位置与ground truth之间的差异性，NSS越大说明差异越小，模型性能越好。\n\n（10）Area Under Curve（**AUC**），显示了模型预测人眼注视点的能力大小，最理想的预测对应的score是1，AUC越大说明算法检测性能越好。\n\n*参考：https://www.cnblogs.com/hSheng/archive/2012/12/05/2803424.html*\n\n","categories":["论文精读"]},{"title":"破解DeePL翻译ppt后下载下来的加密文件","url":"/2020/12/20/163913/","content":"\n在DeePL中把ppt翻译后再下载下来不能进行编辑，只能以只读方式打开，只有输入密码后才能进行编辑，这里破解密码，步骤如下：\n\n<!-- more -->\n\n\n\n1、首先将ppt的名称加上.zip，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201220164232.png)\n\n2、解压缩后，打开文件夹，进入ppt文件夹下并打开presentation.xml文件，如下图：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201220164425.png)\n\n3、删除里面``cy=\"10058400\" /></p:presentation>`之间的内容，如下图：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201220164546.png)\n\n\n\n4、全选下图这些文件压缩为zip文件文件\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201220164853.png)\n\n\n\n5、然后再把压缩后的zip文件后面`.zip`删除，再次打开ppt，即可进行编辑了\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201220164748.png)","categories":["工具"]},{"title":"使用matplotlib绘制各种图像","url":"/2020/11/25/125802/","content":"\n最近由于论文的需要，要用到matplotlib绘制图像，这里顺便总结一下！\n\n<!-- more -->\n\n\n\n> 我是用cv2读取图片，最近发现了一个奇异的问题，在一个目录下用相对路径读取读片（相对路径没有英文），新建一个notebook文件可以读取，但是把别的地方的notebook文件拷贝过来就不行了，一直返回None，虽然不知道是什么原因，但以后需要注意啊！！！\n\n\n\n\n\n## 1. 基本matplotlib设置\n\n```python\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# 设置中文字体为黑体\nplt.rcParams['font.sans-serif'] = ['SimHei']\n# 用来正常显示负号\nplt.rcParams['axes.unicode_minus'] = False\ndef BGRTORGB(img):\n    return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\ndef BGRTOGRAY(img):\n    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n```\n\n\n\n## 2. 同时显示多个图像\n\n因为matplotlib显示是从小到大排列，比如要显示10张图像，并分2为行显示，显示的子图序号是`251`、`252`、...、`2510`，这是不行的，因为`2510`不被识别，因此采用这种方式显示图片有个数限制。\n\n所以，用虽然用下面的方法可以同时显示多个图像，但是最多不超过10张。\n\n\n\n```python\n# 同时显示多个图像\n\"\"\"\nimgs 源图片列表，类型为list（或numpy数组）\nnames 源图片标题，类型为list（或numpy数组）\nuse_color 是否彩色显示，None为全部灰度显示，如果指定某一张图片彩色显示，也可以设置，例如[False,True,False]，即执行第二种图片彩色显示\ntfigsize 整个画布的尺寸\nrow 显示的行数，行数一定要被图片数整除\n\"\"\"\ndef show_mutli_img(imgs,names,use_color=None,tfigsize=(10,10),row=1):\n    if use_color is None :\n        use_color = [False]*len(imgs)\n    plt.figure(figsize=tfigsize)\n    show_len=len(imgs)\n    gird=int(str(row)+str(show_len//row))*10;\n    r,i,c=0,0,0;\n    for r in range(row):\n        for i in range(show_len//row):       \n            plt.subplot(gird+c+1)\n            if use_color[i]:\n                plt.imshow(imgs[c])\n            else: plt.imshow(imgs[c],cmap='gray')\n            plt.title(names[c])\n            c = c+1\n    plt.show()\n```\n\n\n\n## 3. 同时显示多个图像（无个数限制）\n\n```python\n\"\"\"\nplt.subplot2grid创建子图\nrow,col分别为行、列，类型为int\ndata_img为存储图片的数组列表（或numpy数组），必须是(row,col)大小\ndata_title为存储对应图片的标题列表（或numpy数组），大小同上\n\"\"\"\ndef show_data_img(data_img,data_title,row,col,tfigsize=(12,5)):\n    plt.figure(figsize=tfigsize)\n    plots = []\n    for i in range(row):\n        for j in range(col):\n            ax = plt.subplot2grid((row,col), (i,j))\n            ax.imshow(data_img[i][j],cmap='gray')\n            ax.set_title(data_title[i][j])\n    plt.show()   \n```\n\n\n\n## 4. 多个大小不同的图像\n\n```python\n# 显示不同级别的小波图像\n\"\"\"\n使用plt.subplot2grid来创建多小图\n- grid 表示将整个图像窗口分成几行几列，类型为tuple\n- pos 表示从第几行几列开始作图，类型为list\n- spans 表示这个图像行列跨度，类型为list\n- titles 表示子图的标题，类型为list\n\"\"\"\ndef show_levelImg(show_imgs,grid,pos,spans,titles,tfigsize=(10,10)):\n    plt.figure(figsize=tfigsize)\n    i = 0;\n    for i in range(len(pos)):\n        #行，列\n        trowspan,tcolspan = spans[i]\n        ax1 = plt.subplot2grid(grid, pos[i], rowspan=trowspan, colspan=tcolspan);\n        ax1.imshow(show_imgs[i],cmap='gray');ax1.set_title(titles[i]);ax1.axis('off')\n```\n\n可以运行一下看看效果：\n\n```python\n# len(imgs) =7\ngrid = (4,4)\npos = [(0, 2),(2,0),(2,2),(0,0),(0,1),(1,0),(1,1)]\nspans = [(2,2),(2,2),(2,2),(1,1),(1,1),(1,1),(1,1)]\ntitles = ['person1','person2','person3','person4','person5','ca1','car2']\nshow_levelImg(imgs,grid,pos,spans,titles)  \n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201125140304.png)\n\n\n\n\n\n\n\n## 5. 直方图\n\n```python\n# 读取图像\nimg = cv2.imread(\"resource/lina.jpg\")\nimg = BGRTORGB(img)\ngray_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\nplt.hist(gray_img.ravel(), 256);plt.title(\"直方图\")\nplt.show()\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201125140529.png)\n\n\n\n```python\ndef show_hist_quantized(histogram_quantized):\n    plt.figure(figsize=(7,7))\n    plt.title(u\"等分量化后的直方图\")\n    plt.xlabel(u\"等分index\")\n    plt.ylabel(u\"nums\")\n    plt.bar(x=list(range(len(histogram_quantized))), height=histogram_quantized)\n    plt.show()\nhistogram_quantized = [50,40,30,60,70]    \nshow_hist_quantized(histogram_quantized)\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201125141415.png)\n\n\n\n\n\n## 6. 坐标轴为整数的折线图\n\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nplt.title(u\"a plot\")\nplt.xlabel(u\"xxx\")\nplt.ylabel(u\"yyy\")\ndata = [13.4,4.6,7.8,9.9,5.5]\nplt.xticks(range(len(data)))\nplt.plot(data)\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201125141022.png)\n\n","tags":["matplotlib"],"categories":["python"]},{"title":"C++学习笔记——函数提高","url":"/2020/11/25/105331/","content":"\n本文讲解了C++函数的各种用法，如函数的默认参数、占位参数、函数重载等。\n\n<!-- more -->\n\n\n\n## 1 函数默认参数\n\n在C++中，函数的形参列表中的参数是可以有默认值大的\n语法：`返回值类型 函数名 (参数= 默认值){ }`\n\n示例：\n\n```cpp\n#include<iostream>\nusing namespace std;\n\n//函数默认参数\n//如果我们自己传入数据，就用自己的数据，如果没有，那么用默认值\nint func(int a, int b=50, int c=70) {\n\treturn a + b + c;\n}\n\n//注意事项\n//1、如果某个位置已经有了默认参数，那么从这个位置往后，从左到右都必须有默认值\n//int func2(int a, int b = 50, int c) {\n//\treturn a + b + c;\n//}\n//2、如果函数声明有默认参数，函数实现就不能有默认参数\n//准确的说，是声明和实现只能有一个有默认参数，否则，可能会二义性\nint func2(int a, int b);\n\nint func2(int a=20, int b=20) {\n\treturn a + b;\n}\n\nint  main() {\n\t//cout << func(10, 20, 30) << endl;\n\t//cout << func(10,20) << endl;\n\t//cout << func(10) << endl;\n\tcout<<func2(10, 10)<<endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n## 2 函数占位参数\nC++中函数的形参列表里可以有占位参数，用来做占位，调用函数时必须填补该位置\n\n语法：`返回值类型 函数名 (函数类型){}`\n\n在现阶段函数的占位参数存在意义不大，但是以后可能会用到该技术\n\n示例：\n```cpp\n//占位参数\n//目前阶段占位参数，我们还用不到，以后可能会用到\n\nvoid func(int a,int) {\n\tcout << \"this is func\" << endl;\n}\n//占位参数 还可以有默认参数\nvoid func1(int a, int = 10) {\n\tcout << \"this is func1\" << endl;\n}\nint  main() {\n\tfunc(10,10);\n\tfunc1(10);\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 3 函数重载\n### 3.1 函数重载概述\n\n**作用**：函数名可以相同，提高复用性\n\n函数重载满足条件：\n- 同一作用域下\n- 函数名称相同\n- 函数参数**类型不同** 或者 **个数不同** 或者 **顺序不同**\n\n**注意**：函数的返回值不可以作为函数重载的条件\n\n示例：\n\n```cpp\n//函数重载\n//可以让函数名相同，提高复用性\n\n//函数重载的满足条件1\n//1、同一作用域下\n//2、函数名称相同\n//3、函数参数类型不同，或者个数不同，或者顺序不同\n\nvoid func() {\n\tcout << \"func 调用\" << endl;\n}\nvoid func(int a) {\n\tcout << \"func(int a) 调用\" << endl;\n}\nvoid func(double a) {\n\tcout << \"func(double a) 调用\" << endl;\n}\nvoid func(int a,double b) {\n\tcout << \"func(int a,double b) 调用\" << endl;\n}\nvoid func(double a, int b ) {\n\tcout << \"func(double a, int b ) 调用\" << endl;\n}\n//注意事项\n//函数的返回追不可以作为函数重载的条件\n//int func(double a, int b) {\n//\tcout << \"func(double a, int b ) 调用\" << endl;\n//}\nint  main() {\n\n\t//func();\n\t//func(1);\n\t//func(10.0);\n\t//func(1, 10.0);\n\tfunc(10.0, 1);\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n### 3.2 函数重载注意事项\n\n- 引用作为重载条件\n- 函数重载碰到函数默认参数\n\n示例：\n\n```cpp\n//函数重载的注意事项\n//1、引用作为重载的条件\nvoid func(int &a) {// int &a=10;不合法的，因为这个字面量10放在常量区里面，不可写\n\tcout << \"fun(int &a) 调用\" << endl;\n}\nvoid func(const int &a) {//const int &a=10 只读的引用，是合法的\n\tcout << \"fun(const int &a) 调用\" << endl;\n}\n\n//2、函数重载碰到默认参数\nvoid func2(int a,int b=10) {\n\tcout << \"func2(int a,int b)的调用\" << endl;\n}\nvoid func2(int a) {\n\tcout << \"func2(int a)的调用\" << endl;\n}\n\nint  main() {\n\t//int a = 10;\n\t//const引用也可以重载\n\t//func(a);//调用无const函数\n\t//func(10);//调用有const函数\n\n\tfunc2(10);//当函数重载碰到默认参数，出现二义性，报错，尽量避免这种情况\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n\n\n","tags":["c++"],"categories":["c&c++"]},{"title":"C++学习笔记——引用","url":"/2020/11/25/105203/","content":"\n\n引用作为c++的一个重要功能，起到了不可忽视的作用，那么，就让我们一起来看看吧！\n\n<!-- more -->\n\n\n\n## 1 引用的基本使用\n\n- **作用**：给变量起别名\n- **语法**：`数据类型 &别名 = 原名`\n- 注意：引用的数据类型要和原类型一样\n\n原理图：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20201004193426381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n示例：\n\n```cpp\n#include<iostream>\n\nusing namespace std;\n\n\nint  main() {\n\n\tint a = 10;\n\t//创建引用\n\tint &b = a;\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\n\tb = 100;\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 2 引用的注意事项\n- 引用必须初始化\n- 引用在初始化后，不可以改变\n\n原理图：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20201004194926459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n示例：\n\n```cpp\nint  main() {\n\tint a = 10;\n\n\t//1、引用必须初始化\n\tint &b=a;//错误，必须要初始化\n\n\t//2、引用在初始化后，不可以改变\n\tint c = 20;\n\tb = c;//赋值操作，而不是更改引用,即这里只是把b指向的内置赋值成20\n\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\tcout << \"b = \" << b << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 3 引用做函数参数\n- 作业：函数传参时，可以利用引用的技术让形参修饰实参\n- 优点：可以简化指针修改实参\n\n示例：\n\n```cpp\n//交换函数\n//1、值传递\nvoid mySwap01(int a, int b) {\n\tint temp = a;\n\ta = b;\n\tb = temp;\n\t//cout << \"mySwap01 a = \" << a << endl;\n\t//cout << \"mySwap01 b = \" << b << endl;\n}\n//2、地址传递\nvoid mySwap02(int *a, int *b) {\n\tint temp = *a;\n\t*a = *b;\n\t*b = temp;\n\n}\n//3、引用传递\nvoid mySwap03(int &a, int &b) {\n\tint temp = a;\n\ta = b;\n\tb = temp;\n}\n\nint  main() {\n\tint a = 10;\n\tint b = 20;\n\t//mySwap01(a, b);//值传递，实参不会改变\n\tmySwap02(&a, &b);//地址传递，实参会改变\n\tmySwap03(a, b);//地址传递，实参会改变\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n> 总结：通过引用参数产生的效果同地址传递是一样的。引用的语法更清楚简单\n\n## 4 引用做函数返回值\n\n作用：引用是可以作为函数的返回值存在的\n\n注意：**不要返回局部变量的引用**\n用法：函数调用作为左值\n\n示例：\n\n```cpp\n//引用做函数的返回值\n//1、不要返回局部变量的引用\nint& test01() {\n\tint a = 10;//局部变量存放在四区中的栈区\n\treturn a;\n}\n\n//2、函数的调用可以作为左值\nint& test02() {\n\tstatic int a = 10;//静态变量，存放在全局区，全局区上的数据在程序结束后由系统释放\n\treturn a;\n}\n\n\nint  main() {\n\n\tint &ref = test01();\n\n\t//cout << \"ref = \" << ref << endl;//第一次结果正确，是因为编译器做了保留\n\t//cout << \"ref = \" << ref << endl;//第二次结果错误，是因a的内存已经释放\n\n\tint &ref2 = test02();\n\tcout << \"ref2 = \" << ref2 << endl;\n\tcout << \"ref2 = \" << ref2 << endl;\n\ttest02() = 1000;//如果函数的返回值是引用，这个函数调用可以作为左值\n\tcout << \"ref2 = \" << ref2 << endl;\n\tcout << \"ref2 = \" << ref2 << endl;\n\tcout << \"ref2 = \" << ref2 << endl;\n\n\n\t//这个就不是变量的引用了，这里相对于直接在新的内存copy函数的返回值\n\tint ref3 = test02();\n\tcout << \"ref3 = \" << ref3 << endl;\n\tcout << \"ref3 = \" << ref3 << endl;\n\ttest02() = 999;\n\tcout << \"ref3 = \" << ref3 << endl;\n\tcout << \"ref3 = \" << ref3 << endl;\n\tcout << \"ref3 = \" << ref3 << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 5 引用的本质\n\n本质：**引用的本质在c++内部实现是一个指针常量**，即指针的指向不可以修改，指针指向的值是可以修改的\n\n\n示例：\n\n```cpp\n//发现是引用，转换为int* const ref = &a;\nvoid func(int &ref) {\n\tref = 100;//ref是引用，转换为*ref = 100;\n}\n\nint  main() {\n\n\tint a = 10;\n\n\t//自动转化为int *const ref = &a;指针常量是指针的指向不可以改，也说明为什么引用不可更改\n\tint &ref = a;\n\tref = 20; //内部发现ref是引用1，自动帮我们转换为：*ref = 20;\n\n\tcout << \"a = \" << a << endl;\n\tcout << \"ref = \" << ref << endl;\n\n\tfunc(a);\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n原理图：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20201004204328249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n> 结论：C++推荐用引用技术，因为语法方便，引用本质是指针常量，但是所有的指针操作编译器都帮我们做了\n\n## 6 常量引用\n\n作用：常量引用主要用来修饰形参，防止误操作\n\n在函数形参列表中，可以加==const修饰形参==，防止形参改变实参\n\n示例：\n\n```cpp\n//打印数据\nvoid showValue(const int &val) {//加上const就不能修改了\n\t//val = 1000;\n\tcout << \"val = \" << val << endl;\n}\n\nint  main() {\n\t//常量引用\n\t//使用场景：用来修饰形参，防止误操作\n\t//int a=10;\n\t//int &ref = 10;//错误，引用必须引一块合法的内存空间，可以是栈区，也可以是堆区，所以这里字面量是不可以的\n\tconst int &ref = 10;//加上const之后，编译器将代码修改为 int temp = 10; const int &ref = temp;\n\t//ref = 20;//加入const之后变为只读，不可以修改\n\n\tint a = 100;\n\tshowValue(a);\n\tcout << \"a = \" << a << endl;\n\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n","tags":["c++"],"categories":["c&c++"]},{"title":"C++学习笔记——程序的内存模型","url":"/2020/11/25/105031/","content":"\n本文带来C++的内存模型，干货多多！\n\n<!-- more -->\n\n\n\n## 1 内存分区模型\n\nC++程序在执行时，将内存大方向划分为4个区域\n- 代码区：存放函数体的二进制代码，由操作系统进行管理的（所有的代码及注释）\n- 全局区：存放全局变量和静态变量以及常量\n- 栈区：由编译器自动分配释放，存放函数的参数值，局部变量等\n- 堆区：有程序员分配和释放，若程序员不释放，程序结束时由操作系统回收\n\n\n**内存四区的意义**：\n不同区域存放的数据，赋予不同的生命周期，给我们更大的灵活编码\n\n### 1.1 程序运行前\n在程序编译后，生成了exe可执行程序，**未执行该程序前**分为两个区域：代码区和全局区\n\n\n**代码区：**\n- 存放CPU执行的机器指令（就是你写的代码）\n- 代码区是**共享的**，共享的目的是对于频繁被执行的程序，只需要在内存中有一份代码即可\n- 代码区是**只读的**，使其只读的原因是防止程序意外地修改了它的指令\n\n**全局区：**\n- 全局变量和静态变量存放在此\n- 全局区还包含了常量区，字符串常量和其他常量（const修饰的变量即常量）也存放在此\n- ==该区域的数据在程序结束后由操作系统释放==\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020092320063968.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\n//全局变量\nint g_a = 10;\nint g_b = 10;\n\n//const修饰的全局变量，即全局常量，全局常量在常量区\nconst int c_g_a = 10;\nconst int c_g_b = 10;\n\nint main() {\n\n\t// 全局区\n\t// 全局变量、静态变量、常量（字符串常量和全局常量）\n\n\t//创建普通局部变量\n\tint a = 10;\n\tint b = 10;\n\tcout << \"局部变量a的地址为：\" << (int)&a << endl;\n\tcout << \"局部变量b的地址为：\" << (int)&b << endl;\n\tcout << \"全局变量g_a的地址为：\" << (int)&g_a << endl;\n\tcout << \"全局变量g_b的地址为：\" << (int)&g_b << endl;\n\n\t// 静态变量 在普通变量前面加static，数据静态变量\n\tstatic int s_a = 10;\n\tstatic int s_b = 10;\n\tcout << \"静态变量s_a的地址为：\" << (int)&s_a << endl;\n\tcout << \"静态变量s_b的地址为：\" << (int)&s_b << endl;\n\t\n\t//常量\n\t//字符串常量\n\tcout << \"字符串常量hello地址为：\" << (int)&\"hello\" << endl;\n\tcout << \"字符串常量world地址为：\" << (int)&\"world\" << endl;\n\n\t//const修饰的变量\n\t//const修饰的全局变量，const修饰的局部变量\n\tcout << \"全局常量c_g_a的地址为：\" << (int)&c_g_a << endl;\n\tcout << \"全局常量c_g_b的地址为：\" << (int)&c_g_b << endl;\n\n\t//const修饰的局部变量，即局部常量,局部常量不在常量区，也不在全局区\n\t//局部常量存放在栈区\n\tconst int c_l_a = 10;// c - const g - global  l - local\n\tconst int c_l_b = 10;\n\tcout << \"局部常量c_l_a的地址为：\" << (int)&c_l_a << endl;\n\tcout << \"局部常量c_l_b的地址为：\" << (int)&c_l_b << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n\n```\n\n总结：\n- c++中在程序运行前分为全局区和代码区\n- 代码区特点是共享和只读\n- 全局区中存放全局变量、静态变量、常量\n- 常量区中存放const修饰的全局常量和字符串常量\n- const修饰的局部常量放在栈区（同普通局部变量一个位置）\n\n### 1.2 程序运行后\n**栈区：**\n- 由编译器自行分配和释放，存放函数的参数值，局部变量等\n- 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自行释放（在函数执行完后自行释放）\n\n```cpp\n//栈区数据注意事项 -- 不要返回局部变量的地址\n//栈区的数据由编译器管理开辟和释放\n\n\nint * func(int b) {//形参数据也会放在栈区\n\tb = 100;\n\tint a = 10;//局部变量存放在栈区，存放在栈区，栈区的数据在函数执行完后自行释放\n\treturn &a;//返回局部变量的地址\n}\n\nint main() {\n\t//接受func函数的返回值\n\tint * p = func(1);\n\n\tcout << *p << endl;//第一次可以打印正确的数字，是因为编译器给我们做了一次保留\n\tcout << *p << endl;//第二次这个数据就不再保留了\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n**堆区：**\n- 由程序员分配释放，若程序员不释放，程序运行期间，该内存不会被释放，程序结束时由操作系统回收\n- 在C++中利用new在堆区开辟内存\n\n```cpp\nint * func() {\n\t//利用new关键字，可以将数据开辟到堆区\n\t//指针 本质也是变量，放在栈上，指针保存的数据是放在堆区\n\tint * p = new int(10);//返回的是地址\n\treturn p;\n}\n\nint main() {\n\t\n\t//在堆区开辟数据\n\tint * p = func();//得到func返回的地址，保存在main函数区部变量中（也在堆区），当main函数运行结束后，这个func返回的局部变量地址才会消除\n\tcout << *p << endl;\n\tcout << *p << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923205713998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n总结：\n- 堆区数据由程序员管理开辟和释放\n- 堆区数据利用new关键字进行开辟内存\n\n### 1.3 new操作符\n- C++中利用==new==操作符在堆区开辟数据\n- 堆区开辟的数据，由程序员手动开辟，手动释放，释放利用操作符==delete==\n\n语法：`new 数据类型`\n利用new创建的数据，会返回该数据对应的类型的指针\n\n```cpp\n//1、new的基本语法\nint * func() {\n\t//在堆区创建整型数据\n\t//new返回的是 该数据类型的指针\n\tint * p = new int(10);\n\treturn p;\n}\n\nvoid test01() {\n\tint * p = func();\n\tcout << *p << endl;\n\tcout << *p << endl;\n\t//堆区的数据 由程序员管理开辟，程序员管理释放\n\t//如果释放堆区的数据，利用关键字delete\n\tdelete p;\n\tcout << *p << endl; //内存已经被释放，再次访问就是非法操作，会报错\n}\n\n//2、在堆区利用new开辟数组\nvoid test02() {\n\t//创建10整型数据的数组，在堆区\n\tint * arr = new int[10];//10代表数组有10个元素\n\tfor (int i = 0; i < 10; i++)\n\t\tarr[i] = i + 100;\n\tfor (int i = 0; i < 10; i++)\n\t\tcout << arr[i] << endl;\n\t//释放堆区数组\n\t//释放数组的时候，要加[]才可以\n\tdelete[] arr;\n}\n\nint main() {\n\t\n\t//test01();\n\ttest02();\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 2 几个重要结论\n### 2.1 结论1\n结论1：当调用函数时，其实就相当于对传入实参进行了拷贝，存放在栈中（局部变量），具体如下（见示例1）：\n- 当传入值时，拷贝值存放在栈中\n- 当传入指针时，拷贝指针的地址存放在栈中\n- 当传入引用时，和传入指针原理是一样的，因为引用本身是由指针常量实现的（即指针的指向不可以修改，指针指向的值是可以修改的）\n\n\n另外，需要注意的是：**简短的赋值操作不属于拷贝，赋值操作只是把原有内存空间换成了别的值，所以拷贝只是在函数调用时存在**，可以看下面的实例2.\n\n示例1：\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\nvoid func(int a) {\n\tcout << \"func(int a)中a的地址：\" << (int)&a << endl;\n}\nvoid func1(int *a) {\n\tcout << \"func1(int *a)中a的地址：\" << (int)a << endl;\n\tcout << \"func1(int *a)中指针a本身存放的地址：\" << (int)&a << endl;\n\n}\nvoid func2(int &a) {\n\tcout << \"func2(int &a)中a的地址：\" << (int)&a << endl;\n}\n\nint g_a = 10;\nint main() {\n\tcout << \"（全局区）全局变量g_a的地址：\" << (int)&g_a << endl;\n\tint l_a = 10;\n\tcout << \"（栈区）局部变量l_a的地址：\" <<(int)&l_a<< endl;\n\tfunc(g_a);\n\tfunc(l_a);\n\tfunc1(&l_a);\n\tfunc2(l_a);\n\t/*\n\t结论1：当调用函数时，其实就相当于对传入实参进行了拷贝，存放在栈中（局部变量），具体有以下情况：\n\t- 当传入值时，拷贝值存放在栈中\n\t- 当传入指针时，拷贝指针的地址存放在栈中\n\t- 当传入引用时，和传入指针原理是一样的，因为引用本身是由指针常量实现的（即指针的指向不可以修改，指针指向的值是可以修改的）\n\t*/\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n示例2：\n\n```cpp\nint main() {\n\n\t//下面赋值前后a的地址是一样的\n\tint a = 10;\n\tcout << \"a的地址为：\" << (int)&a << endl;\n\n\ta = 20;\n\tcout << \"值更改后a的地址为：\" << (int)&a << endl;\n\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n### 2.2 结论2\n结论2，**全局区中全局变量和静态变量在一个区域，全局常量和字符串常量在一个区域。全局变量和静态变量可以读写（即可以更改），全局常量和字符串常量只能读，不能写。在全局区的常量区（全局常量和字符串常量）中，数值只存在一份，而全局变量区（全局变量和静态变量），相同数值可以有多个（方法是多创建几个数值相同的变量）。见示例1**\n\n除了作用域外，全局变量区（全局变量和静态变量）和局部变量区（栈区）是一样的，都可以读写，多个值相同的变量拥有**不同**的内存空间。\n\n另外，**所有的字面量（包括字符串字面量和其他字面量）都是常量，存放在全局区中的常量区中，不能进行写操作，而引用是为了给变量其别名，为了对变量的内存空间进行读写操作（必须有一个合法的内存空间，可以读写的空间都可以，堆区，栈区，全局变量区），所以把变量赋给引用，而不能是字面量。如果是只读的引用，则把字面量赋给引用也是合法的，见示例2**。\n\n**要记住，创建一个局部变量（指针变量、数值变量，后面结论3会更详细说），存放在栈区，而引用只是给变量起别名，不是创建变量，所以引用的右侧位置只能放变量**\n\n```cpp\n// 全局区\n// 全局变量、静态变量、常量（字符串常量和全局常量）\n\n//全局变量\nint g_a = 10;\nint g_b = 10;\n\n//const修饰的全局变量，即全局常量\nconst int c_g_a = 10;\nconst int c_g_b = 10;\nint main() {\n\n\tcout << \"全局区变量地址为：\" << endl;\n\tcout << \"全局变量g_a的地址为：\" << (int)&g_a << endl;\n\tcout << \"全局变量g_b的地址为：\" << (int)&g_b << endl;\n\n\tstatic int s_a = 10;\n\tstatic int s_b = 10;\n\tcout << \"全局区静态变量地址为：\" << endl;\n\tcout << \"静态变量s_a的地址为：\" << (int)&s_a << endl;\n\tcout << \"静态变量s_b的地址为：\" << (int)&s_b << endl;\n\n\n\tcout << \"全局区普通常量地址为：\" << endl;\n\tcout << \"全局常量c_g_a的地址为：\" << (int)&c_g_a << endl;\n\tcout << \"全局常量c_g_b的地址为：\" << (int)&c_g_b << endl;\n\n\tcout << \"全局区字符串常量地址为：\" << endl;\n\tcout << \"字符串常量hello地址为：\" << (int)&\"hello\" << endl;\n\tcout << \"字符串常量world地址为：\" << (int)&\"world\" << endl;\n\tcout << \"字符串常量hello地址为：\" << (int)&\"hello\" << endl;\n\n\t//结论2，全局区中全局变量和静态变量在一个区域，全局常量和字符串常量在一个区域。\n\t//全局变量和静态变量可以读写（即可以更改），全局常量和字符串常量只能读，不能写\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n示例2：\n\n```cpp\nint main() {\n\t//int &p = 10;//读写的引用，不合法的，因为这个字面量10放在常量区里面，不可以进度写\n\t//只读的引用，合法的\n\tconst int &c = 10;\n\n\tint a = 10;\n\t//引用右侧放变量，合法\n\tint &b = a;\n\n\tcout << b << endl;\n\tcout << c << endl;\n\t\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n\n\n### 2.3 结论3\n**结论3（很重要）**：\n- 所有的局部变量(一般为指向一片内存空间的指针的内存地址)存放在栈区，当然数据型局部变量也在栈区\n- 所有的全局变量(一般为指向一片内存空间的指针的地址)存放在全局变量区，当然数据型全局变量也在全局变量区\n- 如果在局部作用域中new一个数据(数值或数组），new出来的数据的内存空间在堆区，而指向该内存空间的指针的地址在栈区\n- 如果在全局作用域中new一个数据(数值或数组），new出来的数据的内存空间在堆区，而指向该内存空间的指针的地址在全局变量区\n- 在局部作用域中用如`char * s = \"hello\"`创建出来的字符串，该字符串的内存空间在全局常量区，而指向该字符串内存空间的指针的地址(即s的地址)在栈区，故该字符串的内存空间是只读不可写的，而指向该字符串内存空间的指针的地址是可以被重新写入的（即重新赋值，看结论1的注意事项）\n- **在局部作用域中用如`char arr[] = \"hello\"`创建出来的数组字符串，该字符串的内存空间在栈区，该字符串内存空间的指针的地址(即arr的地址)也在栈区**，这个是需要注意的地方，所以，该字符串的内存空间是**可读可写的**，并且内存空间由编译器自动释放。\n- 在局部作用域中用如`char *newarr = new char[6]`创建的数组，该数组的内存空间在堆区，而指向数组内存空间的指针的地址在栈区，该数组的内存空间需要由程序员释放，指向数组内存空间的指针的地址(内存空间)由编译器自动释放。\n- 在全局作用域用如`int * global_newArr = new int[20]`创建的数组，该数组的内存空间在堆区，而指向数组内存空间的指针的地址在全局变量区，该数组的内存空间需要由程序员释放，指向数组内存空间的指针的内存空间由编译器自动释放。\n\n示例：\n\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\nint * global_newArr = new int[20];\n\nint main() {\n\n\t//int型局部变量\n\tint a = 10;\n\tcout << \"栈区的地址为：\" << (int)&a << endl;\n\n\tcout << \"全局常量区的地址为：\" << (int)&\"hello\" << endl;\n\t\n\n\tint * p = new int(10);\n\tcout << \"堆区的地址为：\" << (int)p << endl;\n\tcout << \"指向堆区内存空间的指针(变量)的地址为：\" << (int)&p << endl;\n\n\n\tchar * s = \"hello\";\n\tcout << \"字符串的地址为：\" << (int)s << endl;\n\tcout << \"指向该字符串内存空间的指针的地址为：\" << (int)&s << endl;\n\t//s[3] = 'z'; 报错，全局常量区只能读，不能写\n\n\tchar arr[] = \"hello\";\n\tcout << \"数组字符串的地址为：\" << (int)arr << endl;\n\tcout << \"指向该数组字符串内存空间的指针的地址为：\" << (int)&arr << endl;\n\t//arr[3] = 'z';不报错，数组字符串存放在堆区，可读可写\n\n\n\tchar *newarr = new char[6];\n\tcout << \"new数组的地址为：\" << (int)newarr << endl;\n\tcout << \"指向new数组内存空间的指针的地址为：\" << (int)&newarr << endl;\n\n\tcout << \"global_newArr的地址为：\" << (int)global_newArr << endl;\n\tcout << \"指向global_newArr内存空间的指针的地址为：\" << (int)&global_newArr << endl;\n\n\tdelete p;\n\tdelete[] newarr;\n\tdelete[] global_newArr;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n### 2.4 结论4(sizeof统计空间大小)\n\n**关于数组字符串和指针字符串所占空间大小**，无论指针字符串长度多少，使用`sizeof`统计的大小始终为4个字节，因为统计的是指针的大小。而对于数组字符串，使用`sizeof`统计的是整个字符串空间的大小。\n\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\nint main() {\n\tchar * a = \"abcefg\";\n\tchar b[] = \"abcefg\";\n\tcout << \"a:\" << sizeof(a) << endl;\n\tcout << \"b：\" << sizeof(b) << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n","tags":["c++"],"categories":["c&c++"]},{"title":"C++学习笔记——结构体","url":"/2020/11/25/104732/","content":"\n## 1. 结构体基本概念\n\n结构体属于用户==自定义的数据类型==，允许用户存储不同的数据类型\n\n<!-- more -->\n\n## 2. 结构体定义和作用\n\n语法：`struct 结构体名 { 结构体成员列表 };`\n通过结构体创建变量的方式有三种：\n- struct 结构体名变量名\n- struct 结构体名 = {成员1值，成员2值...}\n- 定义结构体时顺便创建变量\n\n示例：\n\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\n// 1、创建学生数据类型：学生包括(姓名，年龄，分数)\n// 语法 struct 类型名称 {成员列表}\nstruct Student {\n\n\t//成员列表\n\tstring name;\n\tint age;\n\tint score;\n\n} s3;//顺便常见结构体变量\n\n// 2、通过学生类型创建具体学生\n\nint main() {\n\n\t// 2.1 struct Student s1\n\t//struct 关键字可以省略\n\tStudent s1;\n\ts1.age = 20;\n\ts1.name = \"张三\";\n\ts1.score = 100;\n\tcout << \"姓名：\" << s1.name << \"\\t年龄：\" << s1.age << \"\\t分数：\" << s1.score << endl;\n\t// 2.2 struct Student s2 = {...}\n\tstruct Student s2 = { \"李四\",21,101 };\n\tcout << \"姓名：\" << s2.name << \"\\t年龄：\" << s2.age << \"\\t分数：\" << s2.score << endl;\n\t// 2.3 在定义结构体时顺便创建结构体变量 （不建议）\n\ts3.age = 22;\n\ts3.name = \"王五\";\n\ts3.score = 102;\n\tcout << \"姓名：\" << s3.name << \"\\t年龄：\" << s3.age << \"\\t分数：\" << s3.score << endl;\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n> - 总结1：定义结构体时的关键字是struct，不可省略\n> - 总结2：创建结构体变量时，关键字struct可以省略\n> - 总结3：结构体变量利用操作符\".\"访问成员\n\n## 3. 结构体数组\n\n作用：将自定义的结构体放入到数组中方便维护\n语法：`struct 结构体名 数组名[元素个数]={ {} , {} , {} , ... , {}}`\n示例：\n\n```cpp\n#include<iostream>\n#include<string>\nusing namespace std;\n\nstruct Student {\n\n\tstring name;\n\tint age;\n\tint score;\n\n};\n\nint main() {\n\n\tstruct Student stus[3] = { {\"张三\",20,100},{\"李四\",21,101},{\"王五\",22,102} };\n\tfor (int i = 0; i < 3; i++)\n\t\tcout << \"名字：\" << stus[i].name << \"\\t年龄：\" << stus[i].age << \"\\t分数：\" << stus[i].score << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 4. 结构体指针\n\n作用：通过指针访问结构体中的成员\n\n- 利用操作符`->`可以通过结构体指针访问结构体属性\n\n示例：\n\n```cpp\nstruct Student {\n\n\tstring name;\n\tint age;\n\tint score;\n\n};\n\nint main() {\n\n\t//1、创建结构体变量\n\tstruct Student s = { \"张三\",18,100 };\n\n\t//2、通过指针指向结构体变量（struct可以省略）\n\tstruct Student * p = &s;\n\n\t//3、通过指针访问结构体变量中的数据\n\t\n\tcout << \"名字：\" << p->name << \"\\t年龄：\" << p->age << \"\\t分数：\" << p->score << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 5. 结构体嵌套结构体\n\n作用：结构体中的成员可以是另一结构体\n例如：每个老师辅导一个学员，一个老师的结构体中，记录一个学生的结构体\n\n```cpp\nstruct Student {\n\tstring name;\n\tint age;\n\tint score;\n\n};\nstruct Teacher {\n\tint id;\n\tstring name;\n\tint age;\n\tstruct Student stu;\n};\n\nint main() {\n\tstruct Teacher t;\n\tt.id = 1000;\n\tt.name = \"老王\";\n\tt.age = 50;\n\tt.stu.name = \"小王\";\n\tt.stu.age = 20;\n\tt.stu.score = 60;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 6. 结构体做函数参数\n\n作用：将结构体作为参数向函数中传递\n\n传递方式有两种：\n- 值传递\n- 地址传递\n\n```cpp\n// 定义学生结构体\nstruct Student {\n\tstring name;\n\tint age;\n\tint score;\n\n};\n\n\n//打印学生信息的函数\n//1、值传递 不会改变实参的值\nvoid printStudent1(struct Student s) {\n\ts.age = 100;\n\tcout << \"值传递函数打印 姓名：\" << s.name << \" 年龄：\" << s.age << \" 分数：\" << s.score << endl;\n}\n\n//2、地址传递 会改变实参的值\nvoid printStudent2(struct Student * p) {\n\tp->age = 200;\n\tcout << \"地址传递函数打印 姓名：\" << p->name << \" 年龄：\" << p->age << \" 分数：\" << p->score << endl;\n}\n\nint main() {\n\t//结构体做函数参数\n\t//将学生传入到一个参数中，打印学生身上的所有信息\n\t\n\t//创建结构体变量\n\tstruct Student s;\n\ts.name = \"张三\";\n\ts.age = 20;\n\ts.score = 85;\n\t\n\t//printStudent1(s);\n\tprintStudent2(&s);\n\n\tcout << \"main函数打印 姓名：\" << s.name << \" 年龄：\" << s.age << \" 分数：\" << s.score << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 7. 结构体中const使用场景\n\n作用：用const来防止误操作\n\n```cpp\n// const使用场景\n\n// 定义学生结构体\nstruct Student {\n\tstring name;\n\tint age;\n\tint score;\n\n};\n\n// 将函数中的形参改为指针，可以减少内存空间，而且不会复制新的副本出来\n// 传入指针，只占4个字节，比值传递大幅节省空间\nvoid printStudent(const struct Student * s) {\n\t//s->age = 150; 加入const之后，只能读不能写，一旦有修改的操作就会报错，可以防止我们误操作\n\tcout << \"值传递函数打印 姓名：\" << s->name << \" 年龄：\" << s->age << \" 分数：\" << s->score << endl;\n}\n\nint main() {\n\n\t//创建结构体变量\n\tstruct Student s;\n\ts.name = \"张三\";\n\ts.age = 20;\n\ts.score = 85;\n\t\n\tprintStudent(&s);\n\n\tcout << \"main函数打印 姓名：\" << s.name << \" 年龄：\" << s.age << \" 分数：\" << s.score << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n","tags":["c++"],"categories":["c&c++"]},{"title":"C++学习笔记——指针","url":"/2020/11/25/100029/","content":"\n## 1. 指针的基本概念\n\n指针的作用：可以通过指针**间接访问**内存，**指针就是一个地址**\n\n- 内存编号是从0开始记录的，一般用十六进制数字表示\n- **可以利用指针变量保存地址**\n\n<!-- more -->\n\n## 2. 指针变量的定义和使用\n\n指针变量定义语法：`数据类型 * 变量名`\n\n\n实例如下：\n```cpp\n#include<iostream>\nusing namespace std;\n\nint main() {\n\t//1.定义zhizhen\n\tint a = 10;\n\t// 指针定义的语法：数据类型 * 指针变量名\n\tint * p;\n\t// 让指针记录变量a的地址\n\tp = &a;\n\tcout << \"a的地址为：\" << &a << endl;\n\tcout << \"指针p为：\" << p << endl;\n\n\t//2.使用指针\n\t//可以通过解引用的方式来找到指针指向的内存\n\t// 指针前加 * 代表解应用，找到指针指向内存中的数据，然后进行读和写的操作\n\t*p = 1000;\n\tcout << \"a = \" << a << endl;\n\tcout << \"*p = \" << *p << endl;\n\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n示意图：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923150324142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n## 3. 指针所占用内存空间\n\n- 在32位操作系统下，指针是占4个字节空间大小，不管是什么类型\n- 在64位操作系统下，指针是占8个字节空间大小\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923145719788.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n实例：\n\n```cpp\n#include<iostream>\nusing namespace std;\n\nint main() {\n\n\t//指针所占用内存空间\n\tint a = 10;\n\tint * p = &a;\n\n\t// 在32位操作系统下，指针是占4个字节空间大小，不管是什么类型\n\t// 在64位操作系统下，指针是占8个字节空间大小\n\t// sizeof(p)和sizeof(int *)一样\n\tcout << \"sizeof （int *) = \" << sizeof(int *) << endl;\n\tcout << \"sizeof （float *) = \" << sizeof(float *) << endl;\n\tcout << \"sizeof （double *) = \" << sizeof(double *) << endl;\n\tcout << \"sizeof （char *) = \" << sizeof(char *) << endl;\n\tsystem(\"pause\");\n\treturn 0;\n}\n\n```\n\n## 4. 空指针和野指针\n\n- **空指针**：指针变量指向内存中编号为0的空间\n- 用途：初始化指针变量\n- 注意：空指针指向的内存是不可以访问的\n\n示例1：空指针\n\n```cpp\nint main() {\n\n\t//空指针\n\t// 1、空指针用于给指针变量进行初始化\n\tint * p = NULL;\n\t// 2、空指针是不可以进行访问的\n\t// 0~255之间的内存编号是系统占用的，因此不可以访问\n\t*p = 100;\n\t// 会报错\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n- **野指针**：指针变量指向非法的内存空间\n\n示例2：野指针\n\n```cpp\nint main() {\n\n\t//野指针\n\t// 在程序中，尽量避免出现野指针\n\n\t// 指针变量p指向内存地址编号为0x1100的空间\n\tint * p = (int *)0x1100;\n\t\n\t// 访问野指针报错\n\tcout << *p << endl;\n\t// 引发了异常: 读取访问权限冲突。因为你没有申请这个地址所指向的内存空间，却又访问它\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n> 总结：空指针和野指针都不是我们申请的空间，因此不要访问，否则会出错。\n\n## 5. const修饰指针\n\nconst修饰指针三种情况：\n1. const修饰指针 ---常量指针\n2. const修饰常量 ---指针常量\n3. const即修饰指针，又修饰常量\n\n示例1：常量指针（红线标注的是错误的方式）\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923153102951.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n示例2：指针常量（红线标注的是错误的方式）\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923153331852.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n示例3：const即修饰指针，又修饰常量（红线标注的是错误的方式）\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020092316462361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n示例：\n\n```cpp\nint main() {\n\t// 1、const修饰指针\n\tint a = 10;\n\tint b = 10;\n\n\tconst int * p = &a;\n\t// 指针指向的值不可以改，指针的指向可以改\n\t// *p = 20; 错误\n\tp = &b; //正确\n\n\t// 2、const修饰常量 指针常量\n\tint * const p2 = &a;\n\t*p2 = 100; //正确\n\t// p2 = &b; //错误，指针的指向不可以改\n\t// 3、const修饰指针和常量\n\tconst int * const p3 = &a;\n\t// 指针的指向和指针指向的值 都不可以改\n\t// *p3 = 100; //错误\n\t// p3 = &b; //错误\n}\n```\n\n> 技巧：看const右侧紧跟着的是指针还是常量，是指针就是常量指针，是常量就是指针常量\n\n## 6. 指针和数组\n\n- 作用：利用指针访问数据数据中元素\n\n示例：\n\n```cpp\nint main() {\n\t//指针和数组\n\t//利用指针访问数组中的元素\n\n\tint arr[10] = { 1,2,3,4,5,6,7,8,9,10 };\n\tcout << \"第一个元素为：\" << arr[0] << endl;\n\tint * p = arr;//arr就是数组首地址\n\tcout << \"利用指针访问第一个元素：\" << *p << endl;\n\t//p++不是把地址加1，是指针偏移一个单位，在32位下是偏移4个字节，在64位下，偏移8个字节\n\tp++;\n\tcout << \"利用指针访问第二个元素：\" << *p << endl;\n\tsystem(\"pause\");\n\treturn 0;\n}\n```\n\n## 7. 指针和函数\n\n作用：利用指针作函数参数，可以修改实参的值\n\n\n\n\n\n```cpp\n#include<iostream>\nusing namespace std;\n\n\nvoid swap01(int a, int b) {\n\tint temp = a;\n\ta = b;\n\tb = temp;\n}\n\nvoid swap02(int *p1, int *p2) {\n\tint temp = *p1;\n\t*p1 = *p2;\n\t*p2 = temp;\n}\n\nint main() {\n\n\t// 指针和函数\n\t//1、值传递 不会改变实参的值\n\tint a = 10;\n\tint b = 20;\n\tswap01(a, b);\n\tcout << \"值传递：\\n\";\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\n\n\t//2、地址传递 会改变实参的值\n\tcout << \"地址传递：\\n\";\n\tswap02(&a, &b);\n\tcout << \"a = \" << a << endl;\n\tcout << \"b = \" << b << endl;\n\n\tsystem(\"pause\");\n\treturn 0;\n}\n\n```\n\n示例图如下\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923160126957.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n## 8. 指针、数组、函数组合案例\n\n案例描述：封装一个函数，利用冒泡排序，实现对整型数组的升序排序\n\n例如数组：int arr[10] = {4,3,6,8,1,2,10,8,7,5}\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200923160823956.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n","tags":["c++"],"categories":["c&c++"]},{"title":"机器学习概述","url":"/2020/11/25/095842/","content":"\n\n在这里将学到：\n- 什么是机器学习\n- 为什么需要机器学习\n- 机器学习中的基本概念：包括**样本、特征、标签、模型、学习算法**\n- 机器学习的三要素：模型、评价准则、优化算法\n- 训练集、测试集、样本集的概念\n\n<!-- more -->\n\n\n\n\n\n\n## 什么是机器学习\n\n通俗地讲， 机器学习 （Machine Learning， ML）让计算机从数据中进行自动学习，得到某种知识，而不是人为指定且明显的去编程。以手写体数字识别为例，我们需要让计算机能自动识别手写的数字，由于每个人的写法都不相同，我们很难总结每个数字的手写体特征，因此设计一套识别算法几乎是一项几乎不可能的任务。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802172618567.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70 =500x300)\n在现实生活中，很多问题都类似于手写体数字识别这类问题，比如物体识别、语音识别等。对于这类问题，我们不知道如何设计一个计算机程序来解决。因此，**人们开始尝试采用另一种思路，即让计算机“看”大量的样本，并从中学习到一些经验，然后用这些经验来识别新的样本**。要识别手写体数字，首先通过人工标注大量的手写体数字图像（即每张图像都通过人工标记了它是什么数字），这些图像作为训练数据，然后通过学习算法自动生成**模型**，并依靠它来识别新的手写体数字。这和人类学习过程也比较类似，我们教小孩子识别数字也是这样的过程。这种通过数据来学习的方法就称为**机器学习**的方法。\n\n机器学习自动生成的**模型**也称为**决策函数$f$**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802190614894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70 =500x300)\n\n\n\n## 机器学习的基本概念\n\n机器学习中的一些基本概念：包括**样本、特征、标签、模型、学习算法**等。以一个生活中的经验学习为例，假设我们要到市场上购买芒果，但是之前毫无挑选芒果的经验，那么我们如何通过学习来获取这些知识？\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802174401531.gif)\n\n\n首先，我们从市场上随机选取一些芒果，列出每个芒果的**特征 (Feature)**，包括颜色，大小，形状，产地，品牌，以及我们需要预测的**标签 (Label)**。标签可以是**连续值**（比如关于芒果的甜度、水分以及成熟度的综合打分），也可以是**离散值**（比如好、坏两类标签）。\n\n一个标记好特征以及标签的芒果可以看作是一个**样本 (Sample)**。一组样本构成的集合称为**数据集 (Data Set)**。一般将数据集分为两部分：训练集和测试集。 **训练集 (Training Set)**中的样本是用来训练模型的，也叫**训练样本**(Training Sample)，而**测试集 (Test Set)**中的样本是用来检验模型好坏的，也叫**测试样本**(Test Sample)。\n\n> 特征也可以称为属性（Attribute），样本（Sample），也叫示例（Instance）。\n\n我们用一个 d 维向量 $X = [x_1, x_2, · · · , x_d]^T$ 表示一个芒果的所有特征构成的向量，称为**特征向量** （Feature Vector），其中每一维表示一个特征。\n\n假设训练集由 N 个样本组成，其中每个样本都是独立同分布 （Identically and Independently Distributed， IID）的，即独立地从相同的数据分布中抽取的，记为\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802191715788.png)\n其中，${X^{ { {\\left( 1 \\right)}^{ } } } }$表示第一个样本的特征向量，${y^{ { {\\left( 1 \\right)}^{ } } } }$第一个样本的标签\n\n给定训练集 $D$，我们希望让计算机自动寻找一个**函数**$f (X; θ)$ 来建立每个样本特性向量 X 和标签 y 之间的映射。对于一个样本 $X$，我们可以通过决策函数来预测其标签的值\n$$\\hat y=f (X; θ)$$\n或标签的条件概率\n$$p(y|X)=f_y(x;θ)$$\n其中 $θ$ 为可学习的参数\n\n通过一个**学习算法** (Learning Algorithm) ${\\rm A}$，在训练集上找到一组参数 $θ^∗$，使得函数 $f (X; θ^*)$ 可以近似真实的**映射关系**。这个过程称为学习 （Learning）或训练 （Training）过程，函数 $f (X; θ)$ 称为**模型** （Model）。\n\n> 在有些文献中，学习算法也叫做学习器 （Learner）。\n\n下次从市场上买芒果（测试样本）时，可以根据芒果的特征，使用学习到的模型 $f (X; θ^*)$ 来预测芒果的好坏。为了评价的公正性，我们还是独立同分布地抽取一组样本作为测试集 $D^′$，并在测试集中所有样本上进行测试，计算预测结果的准确率。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802193511664.png)\n其中 $I (·)$ 为指示函数， $|D^′|$ 为测试集大小。(对于分类，一般是求出总测试集样本的个数和预测正确的个数)\n\n下图给出了机器学习的基本概念。对一个预测任务，输入特征向量为 $X$，输出标签为 $y$，我们选择一个函数 $f (X; θ)$，通过学习算法 ${\\rm A}$ 和一组训练样本 $D$，找到一组最优的参数 $θ^∗$，得到最终的模型 $f (X; θ^*)$。这样就可以对新的输入 $X$ 进行预测。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802194158846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n## 机器学习的三要素\n机器学习方法可以分为三个基本要素：模型、学习准则、优化算法。\n\n### 模型\n> 输入空间默认为样本的特征空间\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802200142159.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n> $R$为实数，$m$为参数的数量，表示有m个实数要学习\n\n**线性模型：**\n\n**线性模型**的假设空间为一个参数化的**线性函数族**，\n$$f (X; θ)=W^T*X+b$$\n\n其中，$X$是特征向量，$W$是权重向量，$b$是偏置\n\n**非线性模型：**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802200931903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n比如，卷积神经网络中的卷积运算本身就是一个可以学习**非线性基函数**\n\n\n## 学习准则\n学习准则就是找到可以评价学习成果好坏的准则，如果用函数表示，则成为**损失函数**\n\n**损失函数**是一个非负实数函数，，用$L(y, f (X; θ))$ 来表示，用来量化模型预测和真实标签之间的差异。\n\n常见回归损失函数有：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200802202112854.png)\n常见分类损失函数有：**交叉熵损失函数 （Cross-Entropy Loss Function）**\n\n## 优化算法\n梯度下降\n\n## 关于验证集的一点补充\n\n将数据分为训练集和测试集对于简单的模型和样本来说就够了，但是对于复杂的模型（如CNN）和样本（如图片），就需要将数据集分类三部分：训练集、验证集、测试集\n\n- 训练集（Training Set）：用来训练模型的\n- 验证集（Validation set）：用于对模型的能力进行初步评估，可以作为调参、选择特征等算法相关的选择的依据。\n- 测试集 （Test Set）：用来评估模最终模型的泛化能力，不能作为调参、选择特征等算法相关的选择的依据\n\n就好比考试一样，我们平时做的题相当于训练集，测试集相当于最终的考试，我们通过最终的考试来检验我们最终的学习能力，将测试集信息泄露出去，相当于学生提前知道了考试题目，那最后再考这些提前知道的考试题目，当然代表不了什么，你在最后的考试中得再高的分数，也不能代表你学习能力强。所以说，如果通过**测试集**来调节模型，相当于不仅知道了考试的题目，学生还都学会怎么做这些题了（因为我们肯定会人为的让模型在测试集上的误差最小，因为这是你调整超参数的目的），那再拿这些题考试的话，人人都有可能考满分，但是并没有起到检测学生学习能力的作用。原来我们通过测试集来近似泛化误差，也就是通过考试来检验学生的学习能力，但是由于**信息泄露**，此时的测试集即考试无任何意义，现实中可能学生的能力很差。所以，我们在学习的时候，老师会准备一些小测试来帮助我们查缺补漏，**这些小测试也就是要说的验证集**。我们通过验证集来作为调整模型的依据，这样不至于将测试集中的信息泄露。\n\n- 训练集-----------学生的课本；学生 根据课本里的内容来掌握知识。\n- 验证集------------作业，通过作业可以知道 不同学生学习情况、进步的速度快慢。\n- 测试集-----------考试，考的题是平常都没有见过，考察学生举一反三的能力。\n\n也就是说我们将数据划分训练集、验证集和测试集。在训练集上训练模型，在验证集上评估模型，一旦找到的最佳的参数，就在测试集上最后测试一次，测试集上的误差作为泛化误差的近似。关于验证集的划分可以参考测试集的划分，其实都是一样的，这里不再赘述。\n\n总结\n\n- 机器学习让计算机从数据中进行自动学习，得到某种知识，而不是人为指定且明显的去编程\n- 之所以机器学习，是因为现实世界的问题都比较复杂，很难通过规则来手工实现\n- 机器学习中的基本概念：包括**样本、特征、标签、模型、学习算法**\n- 机器学习的三要素：模型、评价准则、优化算法\n- 训练集、测试集、样本集的概念\n\n> 声明：本文大部分摘录自神邱老师的《神经网络与深度学习》，加上一小部分个人的理解和其他博客的资料，因此将本文声明为**转载**，本文只做学习和交流使用，如有侵权请联系博主删除。\n\n参考文档\n【神经网络与深度学习-邱锡鹏著】\n[训练集、验证集、测试集以及交验验证的理解](https://blog.csdn.net/kieven2008/article/details/81582591)\n[训练集、验证集和测试集](https://zhuanlan.zhihu.com/p/48976706)\n\n\n\n\n","categories":["机器学习"]},{"title":"hexo复杂latex公式无法显示并报错的问题","url":"/2020/11/24/231533/","content":"\nhexo复杂latex公式无法显示并报错的问题\n\n<!-- more -->\n\n## 问题描述\n\n在写hexo博客的时候，遇到markdown中公式太长太复杂的时候，就老是显示出错，部分错误信息如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124231718.png)\n\n\n\n我报错的地方如下:\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124231907.png)\n\n\n\n## 解决方法\n\n这是一个hexo中的latex公式渲染问题。不能在公式内连续使用两个`左花括号`！，把两个左花括号中间加`空格`分开就行了，即改为：`$\\frac{ {\\partial L} }{ {\\partial W} }$`\n\n你就会看到成功的显示公式啦！！！\n\n另外，用这种方法也可以：[Nunjucks Error: 解决方案](https://blog.csdn.net/weixin_45333934/article/details/108274320)，该方法好像执行`hexo g`速度快一点，可能是心理作用，哈哈！\n\n\n\n参考文档\n\n[hexo复杂latex公式无法显示问题](https://blog.csdn.net/ALexander_Monster/article/details/106178094)","categories":["工具"]},{"title":"Google Colab的一些常用命令","url":"/2020/11/24/224504/","content":"\n在此记录一些我遇到Google Colab常用命令，以便以后查阅！该命令colab在线地址为：[colab的一些常用命令](https://drive.google.com/file/d/1JRO9afK-2PQwvudxaDLqcuawZRxZWT-c/view?usp=sharing)\n\n\n<!-- more -->\n\n\n\n\n\n# 基本操作\n（1）colab挂载drive上的数据文件\n推荐参考我的博客[Google Colab挂载drive上的数据文件](https://blog.csdn.net/qq_37555071/article/details/107544680)，这里不就过多赘述了。\n\n（2）查看当前所在路径\n```bash\n!pwd\n```\n\n（3）切换目录\n```bash\n# 后面为要切换的路径，支持相对、绝对路径\n%cd /content/drive/Colab/   \n```\n\n（4）查看当前目录的所有文件名称\n```bash\n!ls  也可以 ls\n```\n\n（5）拷贝文件\n```bash\n# 前面是要拷贝的文件名，后面是拷贝后的文件目录\n!cp -i /content/drive/cat_dog_result.csv /content/\n```\n\n（6）创建文件或文件夹\n```bash\n# 创建dirabc文件夹\nmkdir dirabc\n# 创建test1、test2、test3文件\ntouch test1.txt test2.txt test3.txt\n```\n\n（7）删除文件\n```bash\n#  删除文件夹或文件，后面跟文件夹或文件名称\n!rm -rf test3.txt\n# 也可以删除多个文件\n!rm -rf test1.txt test2.txt test3.txt\n# 删除除了drive的所有文件\nls | grep -v drive | xargs rm -rf\n```\n\n# 解压缩操作\n（1）解压rar文件\n```bash\n! apt-get install rar\n!apt-get install unrar\n# x参数是保存原来的文件架构，e参数是把里面的文件都解压到当前路径下\n# 注意压缩文件时要右键，添加到xxx.rar，不要添加到压缩文件\n! unrar x cat_dog.rar\n```\n\n（2）压缩rar文件\n```bash\n# !rar 压缩后的文件名 要压缩的文件名或文件夹名\n!rar a 123.rar  wxl.jks\n```\n\n（3）解压zip文件\n```bash\n!unzip FileName.zip \n```\n\n（4）压缩zip文件\n```bash\n# !zip 压缩后的文件名 要压缩的文件名或文件夹名\n!zip FileName.zip DirName \n```\n更多解压缩方式可参考：[Unrar, Unzip in colab](https://colab.research.google.com/drive/17Jtj0Mrs0lgWo4zi8jQoiAKunjR0GzwQ?usp=sharing)\n\n\n# 阻止Colab自动掉线\n在colab上训练代码，页面隔一段时间无操作之后就会自动掉线，之前训练的数据都会丢失。不过好在最后终于找到了一种可以让其自动保持不离线的方法，用一个js程序自动点击连接按钮。代码如下：\n\n```js\nfunction ClickConnect(){\n  console.log(\"Working\"); \n  document\n    .querySelector(\"#top-toolbar > colab-connect-button\")\n    .shadowRoot\n    .querySelector(\"#connect\")\n    .click()\n}\n \nsetInterval(ClickConnect,60000)\n```\n\n使用方式是：按快捷键`ctrl+shift+i`，并选择`Console`，然后复制粘贴上面的代码，并点击回车，该程序便可以运行了，如下所示：\n\n![](https://img-blog.csdnimg.cn/img_convert/a812f4f6edd1c69db0f38e73e2ac11d1.png)\n\n\n参考文档\n[linux下解压命令大全](https://blog.csdn.net/xsfqh/article/details/89448976)","tags":["colab"],"categories":["工具"]},{"title":"为什么MobileNet及其变体（如ShuffleNet）会变快？","url":"/2020/11/24/224323/","content":"\n> 本文是转载文章，转载自[深入剖析：为什么MobileNet及其变体（如ShuffleNet）会变快？](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247506133&idx=2&sn=1082d154907cedb3ebea028df3787d8e&chksm=ec1c352cdb6bbc3af142fe776b2c9ac73d831d946eda8cc45c6abf9cdd6c4abaef82eeb0c250&mpshare=1&scene=1&srcid=0828Av9UvPz9AbUBnyi3wnAc&sharer_sharetime=1599125590114&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=c45d238be947117fcf9d09c202668aad75e244db66c43fc3a6c9ec8bcc9fc50c2cea193203b229ce4e107aea09fe33bfdf0d8528a563618300689838ca76ab39f9ee3393d565a0a091b9713ef47b7273dd8c99b377abc7d00d8cbc662ebffd68d8fafa2b606af324cd1df8fed9a07a6d523be8a08c4323a195123680a9aa8a75&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AcmLpoaSOHY8/ugr1Vi8OdE=&pass_ticket=3cYbF3kWoNM5K54gjR4tlKnJ8nzIvZSHzY/x9JiBuxWbw3Pu9NJ1BcsIB%2byab7wA&wx_header=0)，**删除了文中冗余的部分，加入许多自己的理解，有些部分也通过pytorch进行了实现，并通过引入具体的计算更清晰的反映出轻量级神经网络的本质**。\n\n\n<!-- more -->\n\n\n\n\n\n\n## 前言\n\n从MobileNet等CNN模型的组成部分出发，概述了**高效CNN模型**（如MobileNet及其变体）中**使用的组成部分**（building blocks），并解释了**它们如此高效的原因**。特别地，我提供了关于如何在**空间和通道域**进行卷积的直观说明。\n\n## 高效CNN模型的组成部分\n在解释具体的高效CNN模型之前，我们先检查一下高效CNN模型中使用的组成部分的计算量，看看卷积在空间和通道域中是如何进行的。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903215104929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n假设 H x W 为输出feature map的空间大小，N为输入通道数，K x K为卷积核的大小，M为输出通道数，则标准卷积的计算量为 H\\*W\\*N\\*K\\*K\\*M 。这里重要的一点是，**标准卷积的计算量与(1)输出特征图H x W的空间大小，(2)卷积核K x K的大小，(3)输入输出通道的数量N x M成正比**。当在空间域和通道域进行卷积时，需要上述计算量。通过分解这个卷积，可以加速 CNNs，如上图所示。\n\n## 卷积\n首先，我提供了一个直观的解释，关于空间和通道域的卷积是如何对进行标准卷积的，它的计算量是H\\*W\\*N\\*K\\*K\\*M。\n\n这里连接输入和输出之间的线，以可视化输入和输出之间的依赖关系。直线数量大致表示空间（spatial）和通道（channel）域中卷积的计算量。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903215447602.png#pic_center)\n例如，最常用的卷积——conv3x3，可以如上图所示。我们可以看到，输入和输出在**空间域是局部连接的，而在通道域是全连接的**。你可能看的不太明白，那我们换张图试试，下面是空间域中输入和输出的关系，可以看出空间域确实是局部连接的。**空间域可以想象为，把特征图输入和输出的神经元拉平，然后进行连接，事实上，在计算机内部就是这么做的。**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904092416818.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n下面是通道域中输入和输出的关系（隐藏红线框部分），下图输入通道是3，输出通道是1，输入的3个通道都连接在了输出的1个通道上，这也证明了通道域是全连接的。如果输出通道有多个，也能想象出来吧。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731150746946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n接下来，如上所示用于改变通道数的conv1x1，或pointwise convolution。由于kernel的大小是1x1，所以这个卷积的计算量是 H\\*W\\*N\\*M，（H x W 为输出feature map的空间大小，N为输入通道数，M为输出通道数），计算量比conv3x3降低了1/9。**这种卷积被用来“混合”通道之间的信息**。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903220728682.png#pic_center)\n## 分组卷积（Grouped Convolution）\n分组卷积是卷积的一种变体，将输入的feature map的**通道分组**，对每个分组的通道独立地进行卷积。\n\n假设 G 表示组数，分组卷积的计算量为 H\\*W\\*N\\*K\\*K\\*M/G，计算量变成标准卷积的1/G。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903221031750.png#pic_center)\n举个例子，假如，卷积核大小为3x3，输入通道数为10，输出通道数为20，输出特征图大小为15x15，对于不分组情况下，计算量是`15*15*10*3*3*20=405000`，如果把输入的feature map的通道分为2组，即输入通道数为10分为2组，每组的输入通道数为5，每组输出通道数为10，输出的总通道数为20，则计算量为`15*15*5*3*3*10*2=202500`，可以看到计算量变成标准卷积的1/2。\n\n在conv3x3 而且 G=2的情况。我们可以看到，通道域中的连接数比标准卷积要小，说明计算量更小。\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903222640830.png#pic_center)\n在 conv3x3，G=3的情况下，**连接变得更加稀疏**。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090322265421.png#pic_center)\n在 conv1x1，G=2的情况下，conv1x1也可以被分组。**这种类型的卷积被用于ShuffleNet中**。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903222726588.png#pic_center)\n## 深度卷积（Depthwise Convolution）\n在**深度卷积**中，对每个输入通道分别进行卷积。**它也可以定义为分组卷积的一种特殊情况，其中输入和输出通道数相同，G等于通道数**。不得不提的是，**Depthwise Convolution在通道域上把计算量降低到了极致**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904093441110.png#pic_center)\n如上所示，depthwise convolution 通过省略通道域中的卷积，大大降低了计算量。\n\n## Channel Shuffle\nChannel shuffle是一种操作(层)，它改变 ShuffleNet 中**使用的通道的顺序**。这个操作是通过张量reshape和 transpose 来实现的。\n\n\n假设G表示分组卷积的组数，N表示输入通道的数量，首先将输入通道的维数reshape 为(G, N ')，即G\\*N '=N，然后将(G, N ')转置为(N '， G)，最后将其view成与输入相同的形状。pytorch实现如下：\n\n```python\nimport torch\ndef channel_shuffle(x, groups):\n    batchsize, num_channels, height, width = x.data.size()\n \n    channels_per_group = num_channels // groups\n \n    # reshape\n    x = x.view(batchsize, groups,\n               channels_per_group, height, width)\n \n    # transpose\n    # - contiguous() required if transpose() is used before view().\n    #   See https://github.com/pytorch/pytorch/issues/764\n    x = torch.transpose(x, 1, 2).contiguous()\n \n    # flatten\n    x = x.view(batchsize, -1, height, width)\n\n    return x\n\nx = torch.randn(1,10,224,224)\nx = channel_shuffle(x,2)\nx.size()\n# 输出：torch.Size([1, 10, 224, 224])\n```\n\n虽然Channel Shuffle的操作不能像计算卷积那样来定义计算量，但应该有一些开销。\n\nG=2时的channel shuffle 情况如下，这里无卷积操作，只是改变了通道的顺序。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904111231327.png#pic_center)\n打乱的通道数 G=3，情况如下\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904111255450.png#pic_center)\n\n\n\n\n## 高效的CNN模型\n\n下面，对于高效的CNN模型，我将直观地说明为什么它们是高效的，以及如何在空间和通道域进行卷积。\n\n### ResNet (Bottleneck Version)\nResNet 中使用的**带有bottleneck 架构的残差单元**是与其他模型进行进一步比较的良好起点。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904095643782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n如上所示，具有bottleneck架构的残差单元由conv1x1、conv3x3、conv1x1组成。第一个conv1x1减小了输入通道的维数，降低了随后的conv3x3的计算量。最后的conv1x1恢复输出通道的维数。\n\n### ResNeXt\nResNeXt是一个高效的CNN模型，可以看作是ResNet的一个特例，将conv3x3替换为**成组**的conv3x3。**通过使用有效的分组conv**，与ResNet相比，conv1x1的通道减少率变得适中（可以让conv1x1不用降维那么多，因为用分组conv已经降低了很多计算量了），从而在相同的计算代价下获得更好的精度。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904095826862.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n### MobileNet (Depthwise Separable Conv)\nMobileNet是一个**深度可分离卷积**模块的堆叠，由depthwise conv和conv1x1 (pointwise conv)组成。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090410015854.png#pic_center)\n**深度可分离卷积分别在空间域和通道域独立执行卷积**。这种卷积分解显著降低了计算量，从**H\\*W\\*N\\*K\\*K\\*M** 降低到 **H\\*W\\*N\\*K\\*K**(depthwise) + **H\\*W\\*N\\*M**(conv1x1)=**HWN(K² + M)**。一般情况下，输出通道M远远大于卷积核大小K(如K=3和M≥32)，减小率约为1/8-1/9。\n\n这里你可能对于上述计算比较懵，那我们分解一下吧。\n\n- 假设 H x W 为输出feature map的空间大小，N为输入通道数，K x K为卷积核的大小，M为输出通道数，则标准卷积的计算量为 H\\*W\\*N\\*K\\*K\\*M。\n- depthwise conv可以看做分组卷积的一种特殊情况，其中输入和输出通道数相同，分组数G等于通道数，其计算量为H\\*W\\*N\\*K\\*K\\*N/N=H\\*W\\*N\\*K\\*K。\n- conv1x1的输入通道数是N，输出通道数是M，计算量为H\\*W\\*N\\*M。\n\n### ShuffleNet\nShuffleNet的动机是如上所述，**conv1x1是在空间域上已经把计算量降低到了极致**，所以在空间域上已经没有改进的空间，而**分组conv1x1可以在通道域上再次降低计算量**。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904102338403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n上图说明了用于ShuffleNet的模块。这里重要的使用的组成部分（building blocks）是channel shuffle层，它在分组卷积中对通多在组间的顺序进行“shuffles”。**如果没有channel shuffle，分组卷积的输出在组之间就不会被利用，导致精度下降**。\n\n### MobileNet-v2\nMobileNet-v2采用类似ResNet中带有bottleneck架构残差单元的模块架构；并用深度卷积（depthwise convolution）代替conv3x3，是残差单元的改进版本。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904112511274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n从上面可以看到，与标准的 bottleneck 架构相反，第一个conv1x1增加了通道维度，然后执行depthwise conv，最后一个conv1x1减少了通道维度。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904112551109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n通过如上所述对组成部分（building blocks） 进行重新排序，将其与MobileNet-v1(Depthwise Separable Conv)进行比较，我们可以看到这个体系结构（MobileNet-v2）是如何工作的 (这种重新排序不会改变整个模型体系结构，因为MobileNet-v2是这个模块的**堆叠**，所以不会有影响的)。\n\n也就是说，上述模块可以看作是深度可分离卷积的一个改进版本，其中可分离卷积中的单个conv1x1被分解为两个conv1x1。让T表示通道维数的**扩展因子**，两个 conv1x1 的计算量为 2\\*H\\*W\\*N\\*N/T ，而深度可分离卷积下的conv1x1的计算量为 HWN²。如果T = 6，将 conv1x1 的计算成本降低了3倍(一般为T/2)。\n\n这里可能有人看的不太理解，我们来详细算一下吧（以上图为例子）。\n\n上图中第一个depthwise conv，第二个和第三个为conv1x1，假设第二个Conv1x1的输入通道为N，则第二个Conv1x1输出通道就为N/T，因为第二个Conv1x1是**经过扩展因子扩大了T倍**，则第三个Conv1x1的输入通道是N/T，则第三个Conv1x1的输出通道是N。\n\n这样就可以算出，第二个Conv1x1的计算量为`H*W*N*N/T`，第三个Conv1x1的计算量为`H*W*(N/T)*N`，两个Conv的总计算量为**2\\*H\\*W\\*N\\*N/T**，而深度可分离卷积下的conv1x1的计算量为 HWN²，如果T = 6，成本计算成本就是降低了3蓓。\n\n可能有人要问，PW升维不是增加参数量了么，你这么一算咋减小了？是的，用PW**升维**是增加了一部分参数量，不过正因为是1x1Conv，所以增加的参数量并不多。上面，我们对组成部分（building blocks） 进行重新排序并进行了计算，在**高维度下**两个conv1x1比**低维度下**深度可分离卷积下的conv1x1参数可降低了不少呢！\n\n### FD-MobileNet\n\n最后，介绍 Fast-Downsampling MobileNet (FD-MobileNet)。在这个模型中，与MobileNet相比，下采样在较早的层中执行。这个简单的技巧可以降低总的计算成本。\n\n从VGGNet开始，许多模型采用相同的下采样策略：**执行向下采样，然后将后续层的通道数增加一倍**。对于标准卷积，下采样后计算量不变，因为根据定义得 H\\*W\\*N\\*K\\*K\\*M 。而对于深度可分离卷积，下采样后其计算量减小：由 **HWN(K² + M)** 降为 **(H/2)\\*(W/2)\\* (2N)\\*(K² + 2M)** = HWN(K²/2 + M)。当M不是很大时(即较早的层)，这是相对占优势的。注意：这里的2N和2M是因为执行向下采样后，后续层的通道数了增加一倍。\n\n\n**下面是对全文的总结：**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200905112522639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n","tags":["MobileNet"],"categories":["神经网络"]},{"title":"DenseNet密集卷积网络详解（附代码实现）","url":"/2020/11/24/224154/","content":"\n## 前言\nDenseNet是CVPR2017的最佳论文，由康奈尔大学黄高博士（Gao Huang）、清华大学本科生刘壮（Zhuang Liu）、Facebook 人工智能研究院研究科学家 Laurens van der Maaten 及康奈尔大学计算机系教授 Kilian Q. Weinberger 所作，有兴趣的同学可以结合[原文](https://arxiv.org/pdf/1608.06993.pdf)阅读。\n\n<!-- more -->\n\n\n\n\nResNet通过前层与后层的“**短路连接**”（Shortcuts），加强了前后层之间的信息流通，在一定程度上缓解了梯度消失现象，从而可以将神经网络搭建得很深，具体可以参考[ResNet残差网络及变体详解](https://blog.csdn.net/qq_37555071/article/details/108258862)。更进一步，这次的主角DenseNet最大化了这种前后层信息交流，**通过建立前面所有层与后面层的密集连接，实现了特征在通道维度上的复用，不但减缓了梯度消失的现象，也使其可以在参数与计算量更少的情况下实现比ResNet更优的性能**。连接方式可以看下面这张图：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903105033190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n标准的 L 层卷积网络有 $L$ 个连接，即每一层与它的前一层和后一层相连，而DenseNet将前面所有层与后面层连接，故有 $(1+2+...+L)*L=(L+1)*L/2$ 个连接。这里看完有些摸不着头脑没关系，接下来我们会具体展开。\n\n## Dense Block\nDense Block是DenseNet的一个基本模块，这里我们从一般的神经网络说起：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090311000558.png#pic_center)\n上图是标准神经网络的一个图，输入和输出的公式是$X_l = H_l(X_{l-1})$，其中$H_l$是一个组合函数，通常包括BN、ReLU、Pooling、Conv操作，$X_{l-1}$是第 $l$ 层输入的特征图，$X_{l}$是第 $l$ 层输出的特征图。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903110339759.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n上图则是ResNet的示意图，我们知道ResNet是跨层相加，输入和输出的公式是$X_l = H_l(X_{l-1})+X_{l-1}$\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903110523502.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n而对于DesNet，则是采用跨通道concat的形式来连接，用公式来说则是$X_l = H_l(X_0,X_1,...,X_{l-1}$)，这里要注意所有的层的输入都来源于前面所有层在channel维度的concat，我们用一张动图体会一下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090311071451.gif#pic_center)\n特征传递方式是**直接将前面所有层的特征concat后传到下一层，而不是前面层都要有一个箭头指向后面的所有层**，这与具体代码实现是一致的，后面会具体的实现。\n\n这里要注意，**因为我们是直接跨通道直接做concat，所以这里要求不同层concat之前他们的特征图大小应当是相同的**，所以DenseNet分为了好几个Dense Block，**每个Dense Block内部的feature map的大小相同**，而每个Dense Block之间使用一个Transition模块来进行下采样过渡连接，这个后文会介绍。\n\n## Growth rate\n假如输入特征图的channel为$K_0$，那么第 $l$ 层的channel数就为 $K_0+(l-1)K$，我们将其称之为网络的增长率（growth rate）。因为每一层都接受前面所有层的特征图，即特征传递方式是**直接将前面所有层的特征concat后传到下一层**，所以这个$K$不能很大，要注意这个K的实际含义就是这层新提取出的特征。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903111854807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n## Bottleneck\n\n在刚才Dense Block中的非线性组合函数是指**BN+ReLU+3x3 Conv**的组合，尽管每前进一层，只产生K张新特征图，但还是嫌多，于是**在进行3×3卷积之前先用一个 1×1卷积将输入的特征图个数降低到 4\\*k**，我们发现这个设计对于DenseNet来说特别有效。所以我们的非线性组合函数就变成了**BN+ReLU+1x1 Conv+BN+ReLU+3x3 Conv**的结构，由此形成的网络结构我们称之为**DenseNet-B**。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903164547925.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n**增加了1x1的卷积的Dense Block也称为Bottleneck结构**，实现细节如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903114842520.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n有以下几个细节需要注意：\n\n1. 每一个Bottleneck输出的特征通道数是相同的，例如这里的K=32。同时可以看到，经过concat操作后的通道数是按K的增长量增加的，因此这个K也被称为GrowthRate。\n2. 这里1×1卷积的作用是**固定输出通道数，达到降维的作用**，1×1卷积输出的通道数通常是GrowthRate的4倍。当几十个Bottleneck相连接时，concat后的通道数会增加到上千，如果不增加1×1的卷积来降维，后续3×3卷积所需的参数量会急剧增加。比如，输入通道数64，增长率K=32，经过15个Bottleneck，通道数输出为`64+15*32=544`，再经过第16个Bottleneck时，如果不使用1×1卷积，第16个Bottleneck层参数量是`3*3*544*32=156672`，如果使用1×1卷积，第16个Bottleneck层参数量是`1*1*544*128+3*3*128*32=106496`，可以看到参数量大大降低。\n3. Dense Block采用了激活函数在前、卷积层在后的顺序，即BN-ReLU-Conv的顺序，这种方式也被称为**pre-activation**。通常的模型relu等激活函数处于卷积conv、批归一化batchnorm之后，即Conv-BN-ReLU，也被称为post-activation。作者证明，如果采用post-activation设计，性能会变差。想要更清晰的了解pre-activition，可以参考我的博客[ResNet残差网络及变体详解](https://blog.csdn.net/qq_37555071/article/details/108258862)中的Pre Activation ResNet。\n\n\n\n\n\n\n\n## Transition layer\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903113233261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n两个相邻的Dense Block之间的部分被称为**Transition层**，具体包括BN、ReLU、1×1卷积、2×2平均池化操作。**通过1×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽，从而进一步降低模型复杂度。**\n\n## 压缩因子\n为进一步提高网络的紧密度，我们可以在转换层(transition layers)减少feature-maps的数量。我们引入一个压缩因子$\\theta$，假定上一层得到的feature map的channel大小为$m$，那经过Transition层就可以产生 $\\theta m$ 个特征，其中$\\theta$在0和1之间。在**DenseNet-C**中，我们令$\\theta$=0.5。当模型结构即含瓶颈层，又含压缩层时，我们记模型为DenseNet-BC。\n\n## DenseNet网络结构\nDenseNet网络构成如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903151310711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n上图中，增长率K=32，采用pre-activation，即BN-ReLU-Conv的顺序。\n\n以DenseNet-121为例，看下其网络构成：\n1. DenseNet-121由121层权重层组成，其中4个Dense block，共计2×(6+12+24+16) = 116层权重，加上初始输入的1卷积层+3过渡层+最后输出的全连接层，共计121层；\n2. 训练时采用了DenseNet-BC结构，压缩因子0.5，增长率k = 32；\n3. 初始卷积层有2k个通道数，经过7×7卷积将224×224的输入图片缩减至112×112；Denseblock块由layer堆叠而成，layer的尺寸都相同：1×1+3×3的两层conv（每层conv = BN+ReLU+Conv）；Denseblock间由过渡层构成，过渡层通过1×1卷积层来减小通道数，并使用步幅为2的平均池化层减半高和宽。最后经过全局平均池化 + 全连接层的1000路softmax得到输出。\n\n\n## DenseNet优缺点\nDenseNet的优点主要有3个：\n\n1. **更强的梯度流动**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903151844516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\nDenseNet可以说是一种隐式的**强监督模式**，因为每一层都建立起了与前面层的连接，误差信号可以很容易地传播到较早的层，所以较早的层可以从最终分类层获得直接监管（监督）。\n2. **能够减少参数总量**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903152017839.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n3.**保存了低维度的特征**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903152107501.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n在标准的卷积网络中，最终输出只会利用提取最高层次的特征。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903152120395.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n而**在DenseNet中，它使用了不同层次的特征，倾向于给出更平滑的决策边界**。这也解释了为什么训练数据不足时DenseNet表现依旧良好。\n\n\n\n**DenseNet的不足在于由于需要进行多次Concatnate操作，数据需要被复制多次，显存容易增加得很快，需要一定的显存优化技术。另外，DenseNet是一种更为特殊的网络，ResNet则相对一般化一些，因此ResNet的应用范围更广泛。**\n\n\n## 实验效果\n这里给出DenseNet在CIFAR-100和ImageNet数据集上与ResNet的对比结果，首先来看下**DenseNet与ResNet在CIFAR-100数据集上实验结果**，如下图所示，可以看出，只有0.8M大小的DenseNet-100性能已经超越ResNet-1001，并且后者参数大小为10.2M。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200903181215171.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n下面是**DenseNet与ResNet在ImageNet数据集上的比较**，可以看出，同等参数大小时，DenseNet也优于ResNet网络。其它实验结果见原论文。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020090318171124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n## Pytorch实现DenseNet\n首先实现DenseBlock中的内部结构，这里是BN+ReLU+1x1 Conv+BN+ReLU+3x3 Conv结构，最后也加入dropout层以用于训练过程。\n\n```python\nclass _DenseLayer(nn.Sequential):\n    \"\"\"Basic unit of DenseBlock (using bottleneck layer) \"\"\"\n    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n        super(_DenseLayer, self).__init__()\n        self.add_module(\"norm1\", nn.BatchNorm2d(num_input_features))\n        self.add_module(\"relu1\", nn.ReLU(inplace=True))\n        self.add_module(\"conv1\", nn.Conv2d(num_input_features, bn_size*growth_rate,\n                                           kernel_size=1, stride=1, bias=False))\n        self.add_module(\"norm2\", nn.BatchNorm2d(bn_size*growth_rate))\n        self.add_module(\"relu2\", nn.ReLU(inplace=True))\n        self.add_module(\"conv2\", nn.Conv2d(bn_size*growth_rate, growth_rate,\n                                           kernel_size=3, stride=1, padding=1, bias=False))\n        self.drop_rate = drop_rate\n\n    def forward(self, x):\n        new_features = super(_DenseLayer, self).forward(x)\n        if self.drop_rate > 0:\n            new_features = F.dropout(new_features, p=self.drop_rate)\n        # 在通道维上将输入和输出连结\n        return torch.cat([x, new_features], 1)\n```\n据此，实现DenseBlock模块，内部是密集连接方式（输入特征数线性增长）：\n\n```python\nclass _DenseBlock(nn.Sequential):\n    \"\"\"DenseBlock\"\"\"\n    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n        super(_DenseBlock, self).__init__()\n        for i in range(num_layers):\n            layer = _DenseLayer(num_input_features+i*growth_rate, growth_rate, bn_size,\n                                drop_rate)\n            self.add_module(\"denselayer%d\" % (i+1), layer)\n```\n此外，实现Transition层，它主要是一个卷积层和一个池化层：\n\n```python\nclass _Transition(nn.Sequential):\n    \"\"\"Transition layer between two adjacent DenseBlock\"\"\"\n    def __init__(self, num_input_feature, num_output_features):\n        super(_Transition, self).__init__()\n        self.add_module(\"norm\", nn.BatchNorm2d(num_input_feature))\n        self.add_module(\"relu\", nn.ReLU(inplace=True))\n        self.add_module(\"conv\", nn.Conv2d(num_input_feature, num_output_features,\n                                          kernel_size=1, stride=1, bias=False))\n        self.add_module(\"pool\", nn.AvgPool2d(2, stride=2))\n```\n最后我们实现DenseNet网络：\n\n```python\nclass DenseNet(nn.Module):\n    \"DenseNet-BC model\"\n    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64,\n                 bn_size=4, compression_rate=0.5, drop_rate=0, num_classes=1000):\n        \"\"\"        \n        :param growth_rate: 增长率，即K=32\n        :param block_config: 每一个DenseBlock的layers数量，这里实现的是DenseNet-121\n        :param num_init_features: 第一个卷积的通道数一般为2*K=64\n        :param bn_size: bottleneck中1*1conv的factor=4，1*1conv输出的通道数一般为factor*K=128\n        :param compression_rate: 压缩因子\n        :param drop_rate: dropout层将神经元置0的概率，为0时表示不使用dropout层\n        :param num_classes: 分类数\n        \"\"\"\n        super(DenseNet, self).__init__()\n        # first Conv2d\n        self.features = nn.Sequential(OrderedDict([\n            (\"conv0\", nn.Conv2d(3, num_init_features, kernel_size=7, stride=2, padding=3, bias=False)),\n            (\"norm0\", nn.BatchNorm2d(num_init_features)),\n            (\"relu0\", nn.ReLU(inplace=True)),\n            (\"pool0\", nn.MaxPool2d(3, stride=2, padding=1))\n        ]))\n\n        # DenseBlock\n        num_features = num_init_features\n        for i, num_layers in enumerate(block_config):\n            block = _DenseBlock(num_layers, num_features, bn_size, growth_rate, drop_rate)\n            self.features.add_module(\"denseblock%d\" % (i + 1), block)\n            num_features += num_layers*growth_rate\n            if i != len(block_config) - 1:\n                transition = _Transition(num_features, int(num_features*compression_rate))\n                self.features.add_module(\"transition%d\" % (i + 1), transition)\n                num_features = int(num_features * compression_rate)\n\n        # final bn+ReLU\n        self.features.add_module(\"norm5\", nn.BatchNorm2d(num_features))\n        self.features.add_module(\"relu5\", nn.ReLU(inplace=True))\n\n        # classification layer\n        self.classifier = nn.Linear(num_features, num_classes)\n\n        # params initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.bias, 0)\n                nn.init.constant_(m.weight, 1)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        features = self.features(x)\n        out = F.avg_pool2d(features, 7, stride=1).view(features.size(0), -1)\n        out = self.classifier(out)\n        return out\n```\n\n【参考文档】\n[深入解析DenseNet(含大量可视化及计算)](https://mp.weixin.qq.com/s?__biz=MzUzNzk2ODUyNQ==&mid=2247484110&idx=1&sn=0f415bac7335342fd151cffcd1dc502d&chksm=fadfa82ccda8213aedac938b58dca11ec0e8e0d3a9205f4efca844f77c92f12225920bef741d&mpshare=1&scene=1&srcid=0903APUhFluNU7752uehJ7pM&sharer_sharetime=1599098864114&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=af1f462991b3ae2f73d8edd600c4378b767aff3e954a4656a4eeb460f16939d828393da9cba16ed045c655c8fb207f7dbd13c2de88325f562ff92a6fcd2d95cf6ecbc5a4bccc2a8c973ffd995c75134146c311897ad6086c17c304e1fa2484da63fb4df1767131ed3f1605e2a6917c79b142a52b6737422fdebf716e9939e540&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AW14wywO1LP2LC9IpvKu9xI=&pass_ticket=mWKUrpjSxXDNNq6Wxeq9z%2bpdzjoRwb%2bsOY1LPtVaBwUd%2bbTos55%2bq/sa%2b%2bkvdHSF&wx_header=0)\n[来聊聊DenseNet及其变体PeleeNet、VoVNet](https://mp.weixin.qq.com/s?__biz=MzI0NDYxODM5NA==&mid=2247484785&idx=1&sn=fcfd18eff932853b4d3f7e7cec22d3d6&chksm=e95a4084de2dc992791d204a1232d237800c5e9f8166d000a16d54360bb60aba0fb6f9645f50&mpshare=1&scene=1&srcid=0829OeTUIOQO2urTTN8ArxN1&sharer_sharetime=1598666372095&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=029d4162e347a3ad8256a33675540963e9543dda8391a5f64379beeee4b8e75a04d1c796a2cac2066bb9a0384e2dc86527c3af81fcf09176d74d582e0a638e3d1dd6e86cb094342d867957c69fc56d0eb8f99f62d3df3f0491f44d396211630f7eda98e0645c1a23ee20847187d31d745b19eac23f4bd9d92a2fe5295788d935&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AQTz6sAlVMxA9IAp9ltR15Q=&pass_ticket=VOgSQ7cGMld09vU35rB0cjJS6QZUBmypkhw5kxq/X%2bFElM8Ehh63InCpsqo8aHzC)\n[稠密连接网络（DenseNet）](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter05_CNN/5.12_densenet)\n[深度学习网络篇——DenseNet](https://blog.csdn.net/weixin_43624538/article/details/85227041?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159866029119724825707695%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=159866029119724825707695&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-1-85227041.pc_v1_rank_blog_v1&utm_term=densenet&spm=1018.2118.3001.4187)\n[论文笔记DenseNet](https://blog.csdn.net/ChuiGeDaQiQiu/article/details/79512257)\n[DenseNet：比ResNet更优的CNN模型](https://zhuanlan.zhihu.com/p/37189203)\nDensely Connected Convolutional Networks\n","tags":["DenseNet"],"categories":["神经网络"]},{"title":"细粒度分析与Bilinear CNN model（附代码实现）","url":"/2020/11/24/224009/","content":"\n## 前言\n\n\n有时，我们逛街时看到不同的狗，却不知道其具体品种，看到路边开满鲜花，却傻傻分不清具体是什么花。实际上，类似的问题在实际生活中屡见不鲜，人类尚且如此，更别说人工智能了。为了解决这一问题，研究者们提出了**细粒度分析**（fine-grained image analysis）这一专门研究物体精细差别的方向。\n\n<!-- more -->\n\n\n\n## 细粒度分析\n\n**细粒度分析**任务相较于**通用图像**（general/generic images）任务的区别和难点在于**其图像所属类别的粒度更为精细**。下图为例，通用图像分类其任务诉求是将“袋鼠”和“狗”这两个物体大类（蓝色框和红色框中物体）分开，可见无论从样貌、形态等方面，二者还是能很容易被区分；而细粒度图像分类任务则要求对“狗”类别下细粒度的子类，即分别对“哈士奇”和“爱斯基摩犬”的图像分辨出来。正因同类别物种的不同子类往往仅在耳朵形状、毛色等细微处存在差异，可谓“差之毫厘，谬以千里”。不止对计算机，对普通人来说，细粒度图像任务的难度和挑战无疑也更为巨大。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902104417284.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n近年来，随着AI的发展，深度学习方面的细粒度图像分析任务可分为**细粒度图像分类**（fine-grained image classification）和 **细粒度图像检索**（fine-grained image retrieval）两大经典图像研究方向。\n\n\n**细粒度图像分类**\n\n由于细粒度物体的差异仅体现在细微之处，**如何有效地对图像进行分析检测，并从中发现重要的局部区域信息，成为了细粒度图像分类算法要解决的关键问题**。对细粒度分类模型，可以按照其使用的监督信息的多少，分为“基于强监督信息的分类模型”和“基于弱监督信息的分类模型”两大类。\n\n\n**基于强监督信息的细粒度图像分类模型**\n\n所谓“强监督细粒度图像分类模型”是指，在模型训练时，为了获得更好的分类精度，除了图像的类别标签（label）外，还使用了物体标注框（object bounding box）和 部位标注点（part annotation）等额外的人工标注信息，这点与目标检测（Detection）与图像分割（Segmentation）的含义是相同的，如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902105325386.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n常见的强监督信息细粒度分类的经典模型有Part-based R-CNN、Pose Normalized CNN、Mask-CNN，这里不再详细赘述。\n\n\n**基于弱监督信息的细粒度图像分类模型**\n\n基于强监督信息的分类模型虽然取得了较满意的分类精度，但由于标注信息的获取代价十分昂贵，在一定程度上也局限了这类算法的实际应用。因此，目前细粒度图像分类的一个明显趋势是，希望在模型训练时仅使用**图像级别标注信息**（即图片的label），而不再使用额外的object bounding box和part annotation信息，也能取得与强监督分类模型可比的分类精度，这便是“基于弱监督信息的细粒度分类模型”。思路同强监督分类模型类似，基于弱监督信息的细粒度分类模型也需要借助**全局和局部信息来做细粒度级别的分类**。而区别在于，弱监督细粒度分类希望在不借助object bounding box和part annotation的情况下，**也可以做到较好的局部信息的捕捉**。当然，在分类精度方面，目前最好的弱监督分类模型仍与最好的强监督分类模型存在差距（分类准确度相差约1～2%）。常见的基于弱监督信息的细粒度图像分类模型有Two Level Attention Model、Constellations、Bilinear CNN model。\n\n\n**细粒度图像检索**\n\n图像分析中除监督环境下的分类任务，还有另一大类经典任务——无监督环境下的图像检索。图像检索（image retrieval）按检索信息的形式，分为“以文搜图”（text-based）和“以图搜图”（image-based），这里具体就不介绍了。\n\n\n\n## Bilinear CNN model\n\n**双线性模型**（Bilinear CNN model）是基于弱监督信息的细粒度图像分类模型，在2015与Bilinear CNN Models for Fine-grained Visual Recognition》被提出来用于fine-grained分类。\n\n我们知道，深度学习成功的一个重要精髓，就是将原本分散的处理过程，如特征提取，模型训练与决策等，整合进了一个完整的系统，进行端到端的整体优化训练，不需要人来干预了。并且，对于图像的不同特征，我们常用的方法是进行**连接**（特征图尺寸不变，通道数增加），或者进行**加和**（特征图同一位置像素值相加，通道数不变），或者max-pooling（通道数不变，特征图尺寸变小）。\n\n\n研究者们通过研究人类的大脑发现，人类的视觉处理主要有两条pathway（通路），一条是the ventral stream，对物体进行识别，另一条是the dorsal stream，为了发现物体的位置。作者基于这样的思想，希望能够将两个不同特征进行融合来共同发挥作用，提高细粒度图像的分类效果，即希望两个特征能分别表示图像的位置和对目标进行识别，模型框架如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902112409503.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n> 一种对Bilinear CNN模型的解释是，**网络A的作用是对物体／部件进行定位，即完成物体与局部区域检测工作，而网络B则是用来对网络A检测到的物体位置进行特征提取**。两个网络相互协调作用，完成了细粒度图像分类过程中两个最重要的任务：**物体、局部区域的检测与特征提取**。\n\n两个不同的stream代表着通过CNN得到的不同特征，然后将两个特征进行bilinear操作。一个 bilinear CNN model 由四元组构成，$\\beta=(f_A,f_B,P,C)$，其中$f_A$ 和 $f_B$ 代表特征提取函数，即网络中的A、B，$P$ 是一个池化函数（pooling function），C表示分类器。图像 $I$ 的特征的每一个位置 $l$，进行如下计算：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902160557998.png#pic_center)\n**具体来讲，过程如下：**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902113008719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n就是先把在特征图同一位置上的特征进行矩阵相乘，得到矩阵 $b$ ，对所有位置的 $b$ 进行sum pooling（也可以是 max pooling，但一般采用 sum pooling 以方便进行矩阵运算）得到矩阵 $\\xi$。比如，对于一个CNN来讲，输入的特征图有c个通道数，那么在位置 $I$ 上的特征就是1\\*c 的大小，然后与同一位置上，不用CNN得到的 1\\*c 的矩阵进行乘积，得到c*c矩阵，然后将所有位置上的 c\\*c 的矩阵进行求和（就得到了 $\\xi$ ），再转换成向量的形式就可以得到Bilinear vector，即上图中的$x$  。对 $x$ 进行 $y=sign(x)\\sqrt{|x|}$ 操作，再对得到的 $y$ 进行 L2归一化操作 $z=y/||y||_2$，然后我们就可以把特征 $z$ 用于**细粒度图像分类**（fine-grained image classification）了。\n\n>L2归一化操作具体参考[L2范数归一化](https://blog.csdn.net/geekmanong/article/details/51344732)。\n\n\n上面的解释可能看的很懵，举一个例子来说明吧。如使用VGG Conv5_3 输出特征图维度为12\\*12\\*512（特征图大小12\\*12，有512个通道），则特征图共有12\\*12=144个位置，每个位置的特征维度为1\\*512，将两个特征图同一位置的512\\*1与1\\*512的矩阵相乘，得到该位置特征向量维度为512\\*512。文章中使用**所有位置特征向量之和**对其进行池化，故将144个512\\*512的特征向量相加，最终得到512\\*512的双线性特征。 该过程可以使用矩阵乘法实现，将特征图变形为144\\*512的特征矩阵，之后其转置与其相乘，得到512*512的双线性特征向量。\n\n\n```python\n# 实现方式：pytorch \nx = torch.randn(1,512,12,12)\nbatch_size = x.size(0)\nfeature_size = x.size(2)*x.size(3)\nx = x.view(batch_size , 512, feature_size)\nx = (torch.bmm(x, torch.transpose(x, 1, 2)) / feature_size).view(batch_size, -1)\nx = torch.nn.functional.normalize(torch.sign(x) * torch.sqrt(torch.abs(x) + 1e-10))\n```\n\n>关于torch.bmm参考[torch.bmm()函数解读](https://blog.csdn.net/qq_40178291/article/details/100302375)\n\n\nBilinear CNN model的形式简单，便于梯度反向传播，进而实现端到端的训练。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200902154836140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n另外，值得一提的是，bilinear模型由于其优异的泛化性能，不仅在细粒度图像分类上取得了优异效果，还被用于其他图像分类任务，如行人重检测（person Re-ID）。\n\n\n## 代码实现\n\n通过引用resnet18的特征提取部分，实现Bilinear CNN model，如下所示：\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torchvision.models import resnet18\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.features = nn.Sequential(resnet18().conv1,\n                                     resnet18().bn1,\n                                     resnet18().relu,\n                                     resnet18().maxpool,\n                                     resnet18().layer1,\n                                     resnet18().layer2,\n                                     resnet18().layer3,\n                                     resnet18().layer4)\n        self.classifiers = nn.Sequential(nn.Linear(512**2,14))\n        \n    def forward(self,x):\n        x=self.features(x)\n        batch_size = x.size(0)\n        feature_size = x.size(2)*x.size(3)\n        x = x.view(batch_size , 512, feature_size)\n        x = (torch.bmm(x, torch.transpose(x, 1, 2)) / feature_size).view(batch_size, -1)\n        x = torch.nn.functional.normalize(torch.sign(x)*torch.sqrt(torch.abs(x)+1e-10))\n        x = self.classifiers(x)\n        return x\n```\n\n\n【参考文档】\n1. [「见微知著」——细粒度图像分析进展综述](https://zhuanlan.zhihu.com/p/24738319)\n2. [双线性池化（Bilinear Pooling）详解、改进及应用](https://zhuanlan.zhihu.com/p/62532887)\n3. [bilinear model && bilinear pooling（一）](https://zhuanlan.zhihu.com/p/87650330)\n4. [学习笔记之——Bilinear CNN model](https://blog.csdn.net/gwplovekimi/article/details/91891439)\n5. [Bilinear CNN](https://blog.csdn.net/u013841196/article/details/102730183)\n6. BilinearCNNModelsforFine-grainedVisualRecognition","tags":["细粒度分析"],"categories":["神经网络"]},{"title":"RuntimeError CUDA out of memory（已解决）","url":"/2020/11/24/223828/","content":"\n今天用pytorch训练神经网络时，出现如下错误：\n\n**RuntimeError: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 2.00 GiB total capacity; 1.29 GiB already allocated; 79.00 MiB free; 1.30 GiB reserved in total by PyTorch)**\n\n明明 GPU 0 有2G容量，为什么只有 79M 可用？ 并且 1.30G已经被PyTorch占用了。**这就说明PyTorch占用的GPU空间没有释放，导致下次运行时，出现CUDA out of memory**。\n\n<!-- more -->\n\n\n\n解决方法如下：\n\n（1）新建一个终端\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200901171405531.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（2）输入 `nvidia-smi`，会显示GPU的使用情况，以及占用GPU的应用程序\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200901171522884.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（3）输入`taskkill -PID 进程号 -F ` 结束占用的进程，比如 `taskkill -PID 7392 -F`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200901171704466.png)\n（4）再次输入 `nvidia-smi` 查看GPU使用情况，会发现GPU被占用的空间大大降低，这样我们就可以愉快地使用GPU运行程序了\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200901171827184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n【参考文档】\n\n[CUDA out of memory.(已解决）](https://blog.csdn.net/weixin_43398590/article/details/105383173?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight)\n\n","tags":["pytorch"],"categories":["pytorch"]},{"title":"ResNet残差网络及变体详解（符代码实现）","url":"/2020/11/24/223553/","content":"\n本文通过分析深度网络模型的缺点引出ResNet残差网络，并介绍了几种变体，最后用代码实现ResNet18。\n\n<!-- more -->\n\n\n## 前言\n\nResNet（Residual Network， ResNet）是微软团队开发的网络，它的特征在于具有比以前的网络更深的结构，在2015年的ILSVRC大赛中获得分类任务的第1名。\n\n\n网络的深度对于学习表达能力更强的特征至关重要的。网络的层数越多，意味着能够提取的特征越丰富，表示能力就越强。（越深的网络提取的特征越抽象，越具有语义信息，特征的表示能力就越强）。\n\n\n但是，随着网络深度的增加，所带来的的问题也是显而易见的，主要有以下几个方面：\n1. 增加深度带来的首个问题就是**梯度爆炸/消散**的问题，这是由于随着层数的增多，在网络中反向传播的梯度会随着连乘变得不稳定，变得特别大或者特别小。这其中经常出现的是梯度消散的问题。\n2. 为了克服梯度消散也想出了许多的解决办法，如使用BatchNorm，将激活函数换为ReLu等，但是改善问题的能力有限。\n3. 增加深度的另一个问题就是网络的**degradation**（退化）问题，即随着深度的增加，网络的性能会越来越差。如下所示：![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYwMzkyMC8yMDE5MDMvMTYwMzkyMC0yMDE5MDMyMjA5MTgwNjc4Ny02NDg1NTk0NDUuanBn?x-oss-process=image/format,png#pic_center)\n\n为了让更深的网络也能训练出好的效果，何凯明大神提出了一个新的网络结构——ResNet（Residual Network，残差网络）。通过使用残差网络结构，深层次的卷积神经网络模型不仅避免了出现模型性能退化的问题，并取得了更好的性能。\n\n需要注意的是，**Residual Network不是为了解决过拟合的问题，因为过拟合只是在测试集上错误率很高，而在训练集上错误率很低**，通过上图可以出，随着深度的加深而引起的 **model degradation**（模型退化）不仅在训练集上错误率高，在测试集上错误率也很高。所以说 Residual Network 主要是为了解决因网络加深而导致的模型退化问题（也有效避免了梯度消散问题，下面会讲）。\n\n\n## 模型退化\n\n通常，当我们堆叠一个模型时，会认为效果会越堆越好。因为，网络的层数越多，意味着能够提取到的特征越丰富，特征的表示能力就越强，假设一个比较浅的网络已经可以达到不错的效果，那么再进行叠加的网络如果什么也不做，效果不会变差。\n\n事实上，这是问题所在，**因为“什么都不做”是之前神经网络最难做到的事情之一**。这时因为由于非线性激活函数（Relu）的存在，每次输入到输出的过程都几乎是不可逆的（信息损失），所以很难从输出反推回完整的输入。所以随着深度的加深而引起的 **model degradation**（模型退化）仅通过普通网络模型是无法避免的。\n\nResidual Learning（残差学习）设计的本质，是让**模型的内部结构具有恒等映射的能力，至少让深度网络实现和浅层网络一样的性能，即让深度网络后面的层至少实现恒等映射的作用，这样在堆叠网络的过程中，不会因为继续堆叠而产生退化。**\n\n\n在mobileNetV2论文中，作者说明了使用ReLU的问题，即当使用ReLU等激活函数时，会导致信息丢失，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827170000864.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n低维（2维）的信息嵌入到n维的空间中（即Input的特征经过高维空间进行变换），并通过随机矩阵$T$对特征进行变换，之后再加上ReLU激活函数，之后在通过 $T^{−1}$ （T的逆矩阵）进行反变换。当n=2，3时，会导致比较严重的信息丢失，部分特征重叠到一起了；当n=15到30时，信息丢失程度降低。\n\n\n\n\n## 残差结构\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827170620973.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n在上图中，我们可以使用一个非线性变化函数来描述一个网络的输入输出，即深层的输入为X（X也为浅层的输出），深层的输出为F(x)+x，F通常包括了卷积，激活等操作。\n\n这里需要注意附加的恒等映射关系具有两种不同的使用情况：残差结构的输入数据若和输出结果的维度一致，则直接相加；若维度不一致，必须对x进行升维操作，让它俩的维度相同时才能计算。升维的方法有两种：\n- 直接通过zero padding 来增加维度（channel）；\n- 用1x1卷积实现，直接改变1x1卷积的filters数目，这种会增加参数。\n\n\n\n\n令H(x)=F(x)+x，即H(x)为深层的输出，则 F(x)=H(x)−x。此时残差结构如下图所示，虚线框中的部分就是F(x)，即H(x)−x。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827172706533.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n\n\n当浅层的x代表的特征已经足够成熟（即浅层网络输出的特征x已经达到了最优），再经过任何深层的变换改变特征x都会让loss变大的话，**F(x)会自动趋向于学习成为0**，x则从恒等映射的路径继续传递。这样就在不增加计算成本的情况下实现了目的：**在前向过程中，当浅层的输出已经足够成熟，让深层网络后面的层能够实现恒等映射的作用（即让后面的层从恒等映射的路径继续传递）**，这样就解决了由于网络过深而导致的模型退化的问题。\n\n从另一方面讲，**残差结构可以让网络反向传播时信号可以更好的地传递**，以一个例子来解释。\n\n\n假设非残差网络输出为G(x)，残差网络输出为H(x)，其中H=F(x)+x，输入的样本特征 **x=1**。（注意：这里G和H中的F是一样的，为了区分，用不同的符号）\n\n（1）在某一时刻：\n\n非残差网络G(1)=1.1， 把G简化为线性运算$G(x)=W_g*x$，可以明显看出$W_g=1.1$。\n残差网络H(1)=1.1， H(1)=F(1)+1, F(1)=0.1，把F简化为线性运算$F(x)=W_f*x$，$W_f=0.1$。\n\n（2）经过一次反向传播并更新G和F中的$W_g$与$W_f$后（输入的样本特征x不变，仍为1）：\n\n非残差网络G’(1)=1.2， 此时$W_g=1.2$\n残差网络H’(1)=1.2, H’(1)=F’(1)+1, F’(1)=0.2，$W_f=0.2$\n\n可以明显的看出，F的参数$W_f$就从0.1更新到0.2，而G的参数$W_g$就从1.1更新到1.2，这一点变化对F的影响远远大于G，**说明引入残差后的映射对输出的变化更敏感，对权重的调整作用更大，所以效果更好**。\n\n从另外一方面来说，对于残差网络H=F(x)+x，每一个导数就加上了一个恒等项1，dh/dx=d(f+x)/dx=1+df/dx，此时就算原来的导数df/dx很小，这时候误差仍然能够有效的反向传播，有效避免了非残差网络链式求导连乘而引发的**梯度消散**。\n\n>这里可能要有人问，反向传播不应该是对权重求偏导吗，这里怎么是对x求偏导？\n反向传播的目的是为了更新权重，但是反向传播的过程是用链式法则实现，在这个过程中，网络中间层的x和w都会参与回传。乘法的反向传播会将上游的值乘以正向传播时的输入信号的“翻转值”后传递给下游，加法节点的反向传播将上游的值原封不动地输出到下游。\n\n\n\n\n\n\n\n因此，从上面的分析可以看出，残差模块最重要的作用就是改变了前向和后向信息传递的方式从而很大程度上促进了网络的优化。\n- 前向：当浅层的输出已经足够成熟，让深层网络后面的层能够实现恒等映射的作用（即让后面的层从恒等映射的路径继续传递），解决了由于网络过深而导致的模型退化的问题。\n- 后向：引入残差后的映射对输出的变化更敏感，对权重的调整作用更大，效果更好。\n\n至于为何 shortcut（即附加的恒等映射关系）的输入时X，而不是X/2或是其他形式。kaiming大神的另一篇文章 Identity Mappings in Deep Residual Networks 中探讨了这个问题，对以下6种结构的残差结构进行实验比较，shortcut 是X/2的就是第二种，结果发现还是第一种效果好。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828200641837.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n\n\nResNet的研究者还提出了**能够让网络结构更深的残差模块**，如下图所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828203656416.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n将原来的building block(残差结构)改为bottleneck（瓶颈结构），很好地减少了参数数量，即先用第一个1x1的卷积把256维channel降到64维，第三个1x1卷积又升到256维，总共用参数：1x1x256x64+3x3x64x64+1x1x64x256=69632，如果不使用 bottleneck，参数将是 3x3x256x256x2=1179648，差了16.94倍。\n\n\n总的来说，由于将原来的building block(残差结构)改为bottleneck（瓶颈结构）减少了模型训练的参数量，同时减少整个模型的计算量，并且网络深度得以增加，这使得拓展更深的模型结构成为可能，于是出现了拥有50层、101层、152层的ResNet模型，这不仅没有出现模型性能退化的问题，而且错误率和计算复杂度都保持在很低的程度。\n\n作者最后在Cifar-10上尝试了1202层的网络，结果在训练误差上与一个较浅的110层的相近，但是测试误差要比110层大1.5%。作者认为是采用了太深的网络，发生了过拟合。所以现在的残差结构最多到100多层，不能再深了，后面会讲到如何把残差网络扩展到1000层。\n\n## ResNet网络结构\n我们以VGG作对比介绍ResNet网络。看下图：\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYwMzkyMC8yMDE5MDMvMTYwMzkyMC0yMDE5MDMyMjExNTY1MjA2Ni0xMTE1OTA2MzA0LnBuZw?x-oss-process=image/format,png#pic_center)\n左边为基本的VGGNet，中间为基于VGG作出的扩增至34层的普通网络，右边为34层的残差网络，不同的是每隔两层就会有一个residual模块。对于残差网络（右图），维度匹配的shortcut连接为实线（输入和输出有相同的通道数），反之为虚线。维度不匹配时，同等映射有两种可选方案：全0填充和1x1卷积。\n\n\n\n常用的ResNet有5种常用深度：18，34，50，101，152层。网络分成5部分，分别是：conv1，conv2_x，conv3_x，conv4_x，conv5_x。如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827205445989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n根据上图，ResNet101的层数为3 + 4 + 23 + 3 = 33个building block，每个block为3层，所以有33 x 3 = 99层，再加上第一层的卷积conv1，以及最后的fc层（用于分类），一共是99+1+1=101层。\n\n\n以往模型大多在ImageNet上作测试，所以这里只给出在ImageNet上的成绩，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20181217193440759.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYyNDUzOA==,size_16,color_FFFFFF,t_70#pic_center)\n可以看到，由于使用1×1的卷积层来减少模型训练的参数量，同时减少整个模型的计算量，增加了网络的深度，152层的ResNet相比于其他网络有提高了一些精度。\n\n\n\n## Pre Activation ResNet\n由于ResNet引入了残差模块，很好的解决了网络模型degradation的问题，从而提高了网络深度。由于将原来的building block（残差结构）改为bottleneck（瓶颈结构）减少了模型训练的参数量，同时减少整个模型的计算量，这使得拓展更深的模型结构成为可能，于是出现了拥有50层、101层、152层的ResNet模型，那么，**我们还能不能加深一些呢？100层可以，1000层呢？**\n\n答案是不可以，至少目前的残差模型是不行的，**因为目前的残差块在加和之后会经过一个relu，由于这个激活函数Relu的位置带来的影响**，使得增加的操作虽然在100层中不会有很大的影响，但是在1000层的超深网络里面还是会阻碍整个网络的前向反向传播（具体原因接着往下看），我们需要接着改进。\n\n\n\n当前卷积神经网络的基本模块通常为卷积+归一化+激活函数（conv+bn+relu）的顺序，对于普通的按照这些模块进行顺序堆叠的网络来说，各个模块的顺序没有什么影响，但是对于残差网络来说却不一样。\n\npre activation 和 post activation ，也就是**激活函数Relu的位置，是放在卷积前还是卷积后**。对于一般的网络来说，这是没什么区别的，因为网络是各个模块进行叠加，这个卷积块的激活函数的输出就是另一卷积块的激活函数的输入，总体来看无所谓先后。\n\n但是，残差网络不一样，它的残差分支包含着完整的卷积，归一化，激活函数层，而后这一分支要和原始信号分支进行相加，因此就有了多种方案，如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828155213685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n我们最常见的是图a的形式，即原始信号和残差信号相加之和再经过Relu输出到下一个block，但实际上还有b、c、d、e等形式，它们的性能如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828155347392.png#pic_center)\n\n\n\n图b，将BN拿出来，放到加和函数之后，结果最差，分析原因可能是不应该把原始信号和残差信号一起加和后归一化，改变了原始信号的分布。\n\n图c，将ReLU提到残差分支，结果也不行，因为这样一来，残差分支的信号就是非负的，当然会影响表达能力，结果也就变得更差了。\n\n图a是原始的ResNet模块，我们可以看到原始信号和残差信号相加后需要进入Relu做一个非线性激活，这样一来，相加后的结果永远是非负的，这就约束了模型的表达能力（和图c原理类似），因此需要做一个调整。图d和图e都是讲ReLU提到了卷积之前，但是BN的顺序有所不同。图d在临近输出放了BN，然后再和原始信号相加，**本来BN就是为了给数据一个固定的分布，一旦经过别的操作就会改变数据的分布，会削减BN的作用，在原版本的resnet中就是这么使用的BN，所以，图d效果与原始的ResNet（图a）性能大致相当**。图e在临近输入放了BN，效果大大提升，这应该是来自于BN层的功劳，本来BN层就应该放置在卷积层之前提升网络泛化能力。\n\n我们来看下这两种结构在CIFAR-10和CIFAR-100上的效果吧：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828162419741.png#pic_center)\n原始的ResNet结构增加到1000层错误率反而提高，但是用上Pre Activation unit后把网络增加到1000层，错误率显著降低，值的注意的是**这里所有精度提升都是出自于深度的增加**。\n\n1000层的残差网络和100层的网络之间的计算复杂度基本是线性的，因此从时间和算力的角度而言还是100层的网络更加实用，但是改进后的残差模块证明了1000层的网络的可实现性，实际上现在各大厂每次开会都要拿超深的网络出来吓人，原理就是这个模块。\n\n\n**那么，我们有没有什么其他不是靠深度的办法来增加特征的表征能力呢？如果有的话结合上ResNet的深度，会不会产生很好的效果呢？**\n\n## 其它的ResNet变体\n### Wide ResNet\n\nWide ResNet，就是比普通的残差网络更宽（也就是通道数量更大）的结构，那么它与ResNet有什么不同呢？\n\n首先，看一下几个不同的残差模块的对比，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828164655354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n(a)是普通的残差结构，(b)是使用1*1卷积进行升维和降维的结构，(c) 是直接增加网络的宽度，图中方块的宽度就表示它的残差块的通道数更大。(d)是文章中提出，可以看到相比于基础模块在中间加上了dropout层，这是因为增加了宽度后参数的数量会显著增加，为了防止过拟合使用了卷积层中的dropout，并取得了相比于不用dropout更好的效果。\n\n作者们实验结果表明：16层的改进残差网络就达到了1000层残差网络的性能，而且计算代价更低。\n\n\n\n\nWide ResNet网络结构如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20181217193732589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYyNDUzOA==,size_16,color_FFFFFF,t_70#pic_center)\n\n作者通过实验发现每个残差内部由两个3\\*3卷积层组成可以有最好的效果，上图是改进后模型的基本架构，与ResNet唯一不同的是多了一个k，代表了原始模块中卷积核数量的k倍（也就是通道数量更大），B(3,3) 代表每一个残差模块内由两个3\\*3的卷积层组成。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828170839561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n上图是164层原始残差网络和28层十倍宽度残差网络在CIFAR-10和CIFAR-100数据集上的比较，实线是在测试集上的错误率，虚线是在训练集上的错误率，可以看到，改进后的宽网络无论在测试集上还是在训练集上都有更低的错误率。\n\n\n\n下图是不同宽度的模型之间纵向比较，同深度下，随着宽度增加，准确率增加。深度为22层，宽度为原始8倍的模型比深度为40层的同宽的模型准确率还要高\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20181217193750658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYyNDUzOA==,size_16,color_FFFFFF,t_70#pic_center)\n我们可以得到如下结论：\n\n1. 在同深度情况下，增大宽度可以增加各种深度的残差模型的性能\n2. 宽度和深度的增加就可以使性能提升。\n3. 深度的增加对于模型的提升是有限的，在一定范围内，增加深度可以使模型性能提升，但是一定程度以后，在增加模型的深度，反而有更高的错误率\n4. 从某种意义上来说，宽度比深度增加对于模型的提升更重要。\n\n### Inception v4\n这里推荐看一下我的博客[深入解读GoogLeNet网络结构](https://blog.csdn.net/qq_37555071/article/details/108214680)，可以更好的理解Inception模块。作者在Inceptionv4论文中共提出了3个新的网络：Inceptionv4、Inception-ResNetv1、Inception-ResNetv2，并拿这三个网络加上Inceptionv3一起进行比较。\n\n作者认为，**对于训练非常深的卷积模型，残差连接本质上是必需的**。但似乎发现并**不支持这种观点**，至少对于图像识别来说是的。但是，它可能需要更多的测试数据和更深的模型**来了解残差连接提供的有益方面的真实程度**。在实验部分，作者证明了**在不利用残差连接的情况下训练非常深的网络并不是很困难**。然而，**使用残差连接似乎大大提高了训练速度**，这仅仅是它们使用的一个很好的论据。也就是说**Residual connection并不是必要条件，只是使用了Residual connection会加快训练速度。**\n\n\n\n我们直接来看Inception-ResNet的网络结构吧（下图）。值得注意的是，Inception-ResNetv1计算代价跟Inception-v3大致相同，Inception-ResNetv2的计算代价跟Inception-v4网络基本相同。\n\n![在这里插入图片描述](https://img-blog.csdn.net/20180613075024302?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM4NDExOTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center)\n这里其他模块不介绍了，现在只重点关注Inception的ResNet模块部分。\n\nInception-ResNet-v1和Inception-ResNet-v2对应的Inception-resnet-A模块为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828173646805.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n如上面的图片所示，改进主要有两点。1. 将residual模块加入inception，2. 将各分支的输出通过聚合后通过同一个1*1的卷积层来进行通道的扩增。\n\nInceptionv4比Inceptionv3层次更深、结构更复杂，并且IncpetionV4对于Inception块的每个网格大小进行了统一。Inception-ResNet在Inception块上加了残差连接加快训练速度。Inception-ResNet-v2的整体框架和Inception-ResNet-v1是一致的，只不过v2的计算量更加expensive些（输出的channel数量更多）。它们训练精度如下：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828174215491.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n从上图可以看出，加了Residual模块的模型训练速度明显比正常的Inception模型快一些，而且也有稍微高一些的准确率。最后，Inception-ResNet-v2的Top-5准确率达到了3.1%，如下图所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828175612572.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n想要更详细的了解Inceptionv4，可以参考这两篇博客[Inceptionv4论文详解](https://blog.csdn.net/qq_38807688/article/details/84590291) 和 [卷积神经网络的网络结构——Inception V4](https://blog.csdn.net/u013841196/article/details/80673688)\n\n\n\n### ResNext\nResNeXt基于wide residual和inception，提出了将残差模块中的所有通道分组进行汇合操作会有更好的效果。同时也给inception提出了一个简化的表示方式。\n\n简化的inception如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828191338471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n与原始的Inception相比，简化的Inception将不同尺寸的卷积核和池化等归一化为3\\*3的卷积核，并且每个分支都用 1\\*1 的卷积核去扩展通道后相加就得到了上面的结构，再这个基础上加上shortcut就得到了ResNext模块：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828191427486.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\nResNext包含了32个分支的基模块，每个分支一模一样。每一个框中的参数分别表示输入维度，卷积核大小，输出维度，如256,1x1,64表示当前网络层的输入为256个通道，使用1x1的卷积，输出为64个通道。ResNext通过1x1的网络层，控制通道数先进行降维，再进行升维，然后保证和ResNet模块一样，输入输出的通道数都是256。因此，可以总结如下：\n\n1.  相对于Inception-Resnet，ResNext的每个分支都是相同的结构，相对于Inception，网络架构更加简洁。\n2. Inception-Resnet中的先各分支输出并concat，然后用1 \\* 1卷积变换深度的方式被先变换通道数后单位加的形式替代。\n3. 因为每个分支的相同结构，**可以提出除了深度和宽度之外的第三维度cardinality，即分支的数量**。\n\n\nResNext结构对比普通的ResNet结构，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020082818095390.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n从另外一个角度，ResNext是也可以看做一个增加了分组的残差模块，对于上图的ResNet结构的第一个卷积模块，输入为256维，输出为64维。右侧包含了32个同样的支路，每一个支路的输入为256维，输出为4维。不过两者的参数量是相当的，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828191955481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n**类比Wide Residual的配置图，二者一个是改变了卷积核的倍数，一个增加了分组，但都是在残差模块做工作。** 不同深度、不同宽度、不同分组的网络对比如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200828192913658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n可以看到，相对于100层的残差网络，用深度，宽度，和cardinality三种方式增大了两倍的复杂度，相同复杂度下，**分组更多即C更大的模型性能更好，这说明cardinality是一个比深度和宽度更加有效的维度**。而且，ResNext的计算速度更快，因为ResNext的结构本来就非常适合硬件并行处理。\n\n\n\n## ResNet18的实现\n\n残差块的实现如下。它可以设定输出通道数、是否使用额外的 1×1 卷积层来修改通道数以及卷积层的步幅。\n\n```python\nimport time\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nclass Residual(nn.Module):  \n    def __init__(self, in_channels, out_channels, use_1x1conv=False, stride=1):\n        super(Residual, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        # 1x1conv来升维\n        if use_1x1conv:\n            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        # 1x1conv对浅层输入的X升维\n        if self.conv3:\n            X = self.conv3(X)\n        return F.relu(Y + X)\n```\n下面我们来查看输入和输出形状一致的情况：\n\n```python\nblk = Residual(3, 3)\nX = torch.rand((4, 3, 6, 6))\nblk(X).shape # torch.Size([4, 3, 6, 6])\n```\n我们也可以在增加输出通道数的同时减半输出的高和宽。\n\n```python\nX = torch.rand((4, 3, 6, 6))\nblk = Residual(3, 6, use_1x1conv=True, stride=2)\nblk(X).shape # torch.Size([4, 6, 3, 3])\n```\n\nResNet的**前两层**跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7×7卷积层后接步幅为2的3×3的最大池化层。不同之处在于ResNet每个卷积层后增加的批量归一化层。\n\n```python\nresnet_18 = nn.Sequential(\n        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n        nn.BatchNorm2d(64), \n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n```\n\nGoogLeNet在后面接了4个由Inception块组成的模块。**ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。第一个模块的通道数同输入通道数一致**。由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。之后的每个模块在**第一个残差块**里将上一个模块的通道数翻倍，并将高和宽减半。\n\n下面我们来实现这个模块。注意，这里对第一个模块做了特别处理。\n\n```python\ndef resnet_block(in_channels, out_channels, num_residuals, first_block=False):\n    if first_block:\n        assert in_channels == out_channels # 第一个模块的通道数同输入通道数一致\n    blk = []\n    for i in range(num_residuals):\n        if i == 0 and not first_block:\n            blk.append(Residual(in_channels, out_channels, use_1x1conv=True, stride=2))\n        else:\n            blk.append(Residual(out_channels, out_channels))\n    # 解包迭代器，从而传入多个模块\n    return nn.Sequential(*blk)\n```\n接着我们为ResNet加入所有残差块。这里每个模块使用两个残差块。\n\n```python\nresnet_18.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\nresnet_18.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\nresnet_18.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\nresnet_18.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n```\n最后，与GoogLeNet一样，加入全局平均池化层后接上全连接层输出。\n\n```python\nclass GlobalAvgPool2d(nn.Module):\n    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n    def __init__(self):\n        super(GlobalAvgPool2d, self).__init__()\n    def forward(self, x):\n        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n    \nclass FlattenLayer(torch.nn.Module):\n    def __init__(self):\n        super(FlattenLayer, self).__init__()\n    def forward(self, x): # x shape: (batch, *, *, ...)\n        return x.view(x.shape[0], -1)\n        \nresnet_18.add_module(\"global_avg_pool\", GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, 512, 1, 1)\nresnet_18.add_module(\"fc\", nn.Sequential(FlattenLayer(), nn.Linear(512, 10))) \n```\n这里每个模块里有4个卷积层（不计算1×1卷积层），加上最开始的卷积层和最后的全连接层，共计18层。这个模型通常也被称为ResNet-18。通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。虽然ResNet的主体架构跟GoogLeNet的类似，但ResNet结构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。\n\n我们来观察一下输入形状在ResNet不同模块之间的变化。\n\n```python\nX = torch.rand((1, 1, 224, 224))\nfor name, layer in resnet_18.named_children():\n    X = layer(X)\n    print(name, ' output shape:\\t', X.shape)\n\"\"\"\n# 前面四层是 7x7conv、BN、nn.ReLU、MaxPool2d\n# 输出\n0  output shape:\t torch.Size([1, 64, 112, 112])\n1  output shape:\t torch.Size([1, 64, 112, 112])\n2  output shape:\t torch.Size([1, 64, 112, 112])\n3  output shape:\t torch.Size([1, 64, 56, 56])\nresnet_block1  output shape:\t torch.Size([1, 64, 56, 56])\nresnet_block2  output shape:\t torch.Size([1, 128, 28, 28])\nresnet_block3  output shape:\t torch.Size([1, 256, 14, 14])\nresnet_block4  output shape:\t torch.Size([1, 512, 7, 7])\nglobal_avg_pool  output shape:\t torch.Size([1, 512, 1, 1])\nfc  output shape:\t torch.Size([1, 10])\n\"\"\"\n```\n\n另外，本文用到的论文我上传到百度云上了，有需要的请自提，链接：https://pan.baidu.com/s/1cParM5EEOz3QOQgjAZt9jA 提取码：ngvb 。包含如下三个论文：\n- Identity Mappings in Deep Residual Networks\n- Wide Residual Networks\n- AggregatedResidualTransformationsforDeepNeuralNetworks\n\n\n【参考文档】\n[深度学习网络篇——ResNet](https://blog.csdn.net/weixin_43624538/article/details/85049699)\n[resnet中的残差连接，你确定真的看懂了？](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029645&idx=1&sn=75b494ec181fee3e8756bb0fa119e7ce&chksm=87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07&mpshare=1&scene=1&srcid=0826sj1X99iidGol2vOYXoyL&sharer_sharetime=1598412745177&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=92bd8fadcb6a4858933403615d2b1a972f5118c4a09c232aef7f191fe77f564ecd8fcee532326e67d272b0451ccad5d44c0586df1184bd3170c632e98c86f33bc664bca4603775cab14cca0fe4739d5170a3f0b4fa71418da0597ca52322b9008de5cda1b2746ea23f0d96b8a0720c48fc50cf26ae7c16982bfd6f2aad9addf8&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AS/my8QJbD1iVlhaLq6mPl4=&pass_ticket=YcCsKQUoka0nj/P%2b0pwrfYVeXAi9wdtnOBln8h11m8ftsr1WLiJ5a6KMsypN6fsD)\n[残差网络（ResNet）](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter05_CNN/5.11_resnet)\n[残差网络ResNet笔记](https://www.cnblogs.com/alanma/p/6877166.html)\n[CNN 经典网络之-ResNet](https://www.cnblogs.com/yanshw/p/10576354.html)\n深度学习之Pytorch实战计算机视觉-唐进民著\n\n","tags":["ResNet"],"categories":["神经网络"]},{"title":"深入解读GoogLeNet网络结构（附代码实现）","url":"/2020/11/24/223407/","content":"\n\n\n## 前言\n\n> 七夕了，看着你们秀恩爱，单身狗的我还是做俺该做的事吧！\n\n\n![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hsZXIvYmxvZ2ltZy9yYXcvbWFzdGVyL2ltZ3MvMjAyMDA4MDMxMDQ1MzcuZ2lm)\n\n\n在上一篇文章中介绍了[VGG网络结构](https://blog.csdn.net/qq_37555071/article/details/108199352)，VGG在2014年ImageNet 中获得了定位任务第1名和分类任务第2名的好成绩，而同年分类任务的第一名则是**GoogleNet** 。GoogleNet是Google研发的深度网络结构，之所以叫“GoogLeNet”，是为了向“LeNet”致敬，有兴趣的同学可以看下原文[Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf)。\n\n\n\n<!-- more -->\n\n\n\n\n与VGGNet模型相比较，GoogleNet模型的网络深度已经达到了22层（ 如果只计算有参数的层，GoogleNet网络有22层深 ，算上池化层有27层），而且在网络架构中引入了Inception单元，从而进一步提升模型整体的性能。虽然深度达到了22层，但大小却比AlexNet和VGG小很多，GoogleNet参数为500万个（ 5M ），VGG16参数是138M，是GoogleNet的27倍多，而VGG16参数量则是AlexNet的两倍多。\n\n## Inception单元结构\n\n我们先来看一下模型中的Inception单元结构，然后在此基础上详细分析GoogleNet网络结构，这里推荐看一下我的这篇博客[从Inception到Xception，卷积方式的成长之路](https://blog.csdn.net/qq_37555071/article/details/107835402)，可以对下面的内容有更好的理解。\n\nInception 最初提出的版本主要思想是**利用不同大小的卷积核实现不同尺度的感知**，网络结构图如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806113406524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nInception Module基本组成结构有四个成分。1\\*1卷积，3\\*3卷积，5\\*5卷积，3\\*3最大池化。最后对四个成分运算结果进行通道上组合，这就是Naive Inception的核心思想：利用不同大小的卷积核实现不同尺度的感知，最后进行融合，可以得到图像更好的表征。\n\n下面通过一个具体的实例来看看整个Naive Inception单元的详细工作过程，假设在上图中Naive  Inception单元的前一层输入的数据是一个32×32×256的特征图，**该特征图先被复制成4份并分别被传至接下来的4个部分**。我们假设这4个部分对应的滑动窗口的步长均为1，其中，1×1卷积层的Padding为0，滑动窗口维度为1×1×256，要求输出的特征图深度为128；3×3卷积层的Padding为1，滑动窗口维度为3×3×256，要求输出的特征图深度为192；5×5卷积层的Padding为2，滑动窗口维度为5×5×256，要求输出的特征图深度为96；3×3最大池化层的  Padding为1，滑动窗口维度为3×3×256。**这里对每个卷积层要求输出的特征图深度没有特殊意义，仅仅举例用**，之后通过计算，分别得到这4部分输出的特征图为32×32×128、32×32×192、32×32×96  和  32×32×256，最后在合并层进行合并，得到32×32×672的特征图，合并的方法是将各个部分输出的特征图相加，最后这个Naive  Inception单元输出的特征图维度是32×32×672，总的参数量就是`1*1*256*128+3*3*256*192+5*5*256*96=1089536`。\n\n但是Naive  Inception有两个非常严重的问题：**首先，所有卷积层直接和前一层输入的数据对接，所以卷积层中的计算量会很大；其次，在这个单元中使用的最大池化层保留了输入数据的特征图的深度，所以在最后进行合并时，总的输出的特征图的深度只会增加，这样增加了该单元之后的网络结构的计算量**。于是人们就要想办法减少参数量来减少计算量，在受到了模型 “Network in Network”的启发，开发出了在GoogleNet模型中使用的Inception单元（Inception V1），这种方法可以看做是一个额外的1\\*1卷积层再加上一个ReLU层。如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806113747780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n这里使用1x1 卷积核主要目的是进行**压缩降维，减少参数量**，从而让网络更深、更宽，更好的提取特征，这种思想也称为**Pointwise Conv**，简称PW。\n\n\n举个例子来论证下吧。假设新增加的  1×1 的卷积的输出深度为64，步长为1，Padding为0，其他卷积和池化的输出深度、步长都和之前在Naive  Inception单元中定义的一样（即上面例子中定义的一样），前一层输入的数据仍然使用同之前一样的维度为32×32×256的特征图，通过计算，分别得到这  4  部分输出的特征图维度为32×32×128、32×32×192、32×32×96  和32×32×64，将其合并后得到维度为32×32×480的特征图，将这4部分输出的特征图进行相加，最后Inception单元输出的特征图维度是32×32×480。新增加的3个  1×1 的卷积参数量是`3*1*1*256*64=49152`，原来的卷积核参数量是`1*1*256*128+3*3*64*192+5*5*64*96=296960`，总的参数量就是`49152+296960=346112`。\n\n在输出的结果中，32×32×128、32×32×192、32×32×96  和之前的Naive  Inception  单元是一样的，**但其实这三部分因为1×1卷积层的加入，总的卷积参数数量已经大大低于之前的Naive  Inception单元**，**而且因为在最大池化层之前也加入了1×1的卷积层，所以最终输出的特征图的深度也降低了，这样也降低了该单元之后的网络结构的计算量**。\n\n## GoogLeNet模型解读\n\nGoogleNet网络结构（Inception V1）的网络结构如下：\n\n\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X2pwZy94bkJGSGNSNDE4cUM4TE9zN1R0dnJOTDRLRllpYkRIMmtpYzluQjhweXowbXFIdU0yUVk4WjZtNXNJQzlwZDRJRmJ4MlZLbWttYm1wVlg0N2lidE1VaWMwdXcvNjQw?x-oss-process=image/format,png)\n\nGoogLeNet网络有22层深（包括pool层，有27层深），在分类器之前，采用Network in Network中用Averagepool（平均池化）来代替全连接层的思想，而在avg pool之后，还是添加了一个全连接层，是为了大家做finetune（微调）。而无论是VGG还是LeNet、AlexNet，在输出层方面均是采用连续三个全连接层，全连接层的输入是前面卷积层的输出经过reshape得到。**据发现，GoogLeNet将fully-connected layer用avg pooling layer代替后，top-1 accuracy 提高了大约0.6%；然而即使在去除了fully-connected layer后，依然必须dropout。**\n\n由于全连接网络参数多，计算量大，容易过拟合，所以GoogLeNet没有采用VGG、LeNet、AlexNet三层全连接结构，直接在Inception模块之后使用Average Pool和Dropout方法，不仅起到降维作用，还在一定程度上防止过拟合。\n\n**在Dropout层之前添加了一个7×7的Average Pool，一方面是降维，另一方面也是对低层特征的组合。我们希望网络在高层可以抽象出图像全局的特征，那么应该在网络的高层增加卷积核的大小或者增加池化区域的大小，GoogLeNet将这种操作放到了最后的池化过程，前面的Inception模块中卷积核大小都是固定的，而且比较小，主要是为了卷积时的计算方便。**\n\n\n\nGoogLeNet在网络模型方面与AlexNet、VGG还是有一些相通之处的，它们的主要相通之处就体现在卷积部分，\n\n- AlexNet采用5个卷积层\n- VGG把5个卷积层替换成5个卷积块\n- GoogLeNet采用5个不同的模块组成主体卷积部分\n\n用表格的形式表示GoogLeNet的网络结构如下所示：\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9zYnphQnhDRXJManBpYzBtaWNaOVFkZ3FTcjhXZ01WdEV2NGhvaFh2bWpxdHBxZlVKWGxIVWliSDZXaWFxWjNicW85NEJrazFCanBGaWNTd28yNkd6dDRLRlhBLzY0MA?x-oss-process=image/format,png#pic_center)\n上述就是GoogLeNet的结构，可以看出，和AlexNet统一使用5个卷积层、VGG统一使用5个卷积块不同，GoogLeNet在主体卷积部分是**卷积层与Inception块混合使用**。另外，需要注意一下，在输出层GoogleNet采用**全局平均池化**，得到的是高和宽均为1的卷积层，而不是通过reshape得到的全连接层。\n\n需要注意的是，上图中 “＃3×3reduce” 和 “＃5×5reduce” 表示在3×3和5×5卷积之前，使用的**降维层**中的1×1滤波器的数量。pool proj代表max-pooling后的投影数量（即先max-pooling，再PW降维），所有的reductions（降维）和projections（投影）也都使用激活函数ReLU。\n\n\n下面就来详细介绍一下GoogLeNet的模型结构。\n\n**输入**\n\n原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）\n\n**第一模块**\n\n第一模块采用的是一个单纯的卷积层紧跟一个最大池化层。\n\n卷积层：卷积核大小7*7，步长为2，padding为3，输出通道数64，输出特征图尺寸为`(224-7+3*2)/2+1=112.5(向下取整)=112`，输出特征图维度为112x112x64，卷积后进行ReLU操作。\n\n池化层：窗口大小3*3，步长为2，输出特征图尺寸为`((112 -3)/2)+1=55.5(向上取整)=56`，输出特征图维度为56x56x64。\n\n关于卷积和池化中的特征图大小计算方式，可以参考我的博客[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)\n\n**第二模块**\n\n第二模块采用**2个卷积层**，后面跟一个最大池化层。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825150804453.png#pic_center)\n\n**卷积层：**\n1. 先用64个1x1的卷积核（3x3卷积核之前的降维）将输入的特征图（56x56x64）变为56x56x64，然后进行ReLU操作。参数量是`1*1*64*64=4096`\n2. 再用卷积核大小3*3，步长为1，padding为1，输出通道数192，进行卷积运算，输出特征图尺寸为`(56-3+1*2)/1+1=56`，输出特征图维度为56x56x192，然后进行ReLU操作。参数量是`3*3*64*192=110592`\n\n第二模块卷积运算总的参数量是`110592+4096=114688`，即`114688/1024=112K`。\n\n\n**池化层：** 窗口大小3*3，步长为2，输出通道数192，输出为`((56 - 3)/2)+1=27.5(向上取整)=28`，输出特征图维度为28x28x192。\n\n**第三模块(Inception 3a层)**\n\nInception 3a层，分为四个分支，采用不同尺度，图示如下：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/202008251231252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n再看下表格结构，来分析和计算吧：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825151846422.png#pic_center)\n\n1. 使用64个1x1的卷积核，运算后特征图输出为28x28x64，然后RuLU操作。参数量`1*1*192*64=12288`\n2. 96个1x1的卷积核（3x3卷积核之前的降维）运算后特征图输出为28x28x96，进行ReLU计算，再进行128个3x3的卷积，输出28x28x128。参数量`1*1*192*96+3*3*96*128=129024`\n3. 16个1x1的卷积核（5x5卷积核之前的降维）将特征图变成28x28x16，进行ReLU计算，再进行32个5x5的卷积，输出28x28x32。参数量`1*1*192*16+5*5*16*32=15872`\n4. pool层，使用3x3的核，输出28x28x192，然后进行32个1x1的卷积，输出28x28x32.。总参数量`1*1*192*32=6144`\n\n将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256。总的参数量是`12288+129024+15872+6144=163328`，即`163328/1024=159.5K`，约等于159K。\n\n**第三模块(Inception 3b层)**\n\nInception 3b层，分为四个分支，采用不同尺度。\n\n1. 128个1x1的卷积核，然后RuLU，输出28x28x128\n2. 128个1x1的卷积核（3x3卷积核之前的降维）变成28x28x128，进行ReLU，再进行192个3x3的卷积，输出28x28x192\n3. 32个1x1的卷积核（5x5卷积核之前的降维）变成28x28x32，进行ReLU，再进行96个5x5的卷积，输出28x28x96\n4. pool层，使用3x3的核，输出28x28x256，然后进行64个1x1的卷积，输出28x28x64\n\n将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480。\n\n**第四模块(Inception 4a、4b、4c、4e)**\n\n与Inception3a，3b类似\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825153012306.png#pic_center)\n**第五模块(Inception 5a、5b)**\n\n与Inception3a，3b类似\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825153237754.png#pic_center)\n\n\n**输出层**\n\n前面已经多次提到，在输出层GoogLeNet与AlexNet、VGG采用3个连续的全连接层不同，GoogLeNet采用的是全局平均池化层，得到的是高和宽均为1的卷积层，然后添加丢弃概率为40%的Dropout，输出层激活函数采用的是softmax。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825153225724.png#pic_center)\n\n**激活函数**\n\nGoogLeNet每层使用的激活函数为ReLU激活函数。\n\n**辅助分类器**\n\n根据实验数据，发现**神经网络的中间层也具有很强的识别能力，为了利用中间层抽象的特征，在某些中间层中添加含有多层的分类器**。如下图所示，红色边框内部代表添加的辅助分类器。**GoogLeNet中共增加了两个辅助的softmax分支，作用有两点，一是为了避免梯度消失，用于向前传导梯度。反向传播时如果有一层求导为0，链式求导结果则为0。二是将中间某一层输出用作分类，起到模型融合作用**。最后的loss=loss_2 + 0.3 \\* loss_1 + 0.3 \\* loss_0。实际测试时，这两个辅助softmax分支会被去掉。\n\n\n\n\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9QbjRTbTBSc0F1aWEwRUlYWE5zb1h1SHZqN241YmVTNHpWMmNLSXVZTWlibmliTHB2bWYxY3ZodkJuOUppYm51YnBjc04xeUZ2cDJuVThaRjY1WWljN0NBN3FBLzY0MA?x-oss-process=image/format,png#pic_center)\n\n## GoogLeNet其他版本\n上面介绍的GoogLeNet模型是Inception v1版本，还有Inception v2，v3，v4版本\n\n**Inception V2**\n\n1. 学习VGGNet的特点，用两个3*3卷积代替5*5卷积，可以降低参数量。\n2. 提出BN算法。BN算法是一个正则化方法，可以提高大网络的收敛速度。就是每一batch的输入分布标准化处理，使得规范化为N(0,1)的高斯分布，收敛速度大大提高。详情可以参考我的博客[Batch Normalization：批量归一化详解](https://blog.csdn.net/qq_37555071/article/details/107549047)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806130828579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n**Inception V3**\n\n学习Factorization into small convolutions的思想，在Inception V2的基础上，将一个二维卷积拆分成两个较小卷积，例如将7\\*7卷积拆成1\\*7卷积和7\\*1卷积，这样做的好处是降低参数量。该paper中指出，通过这种非对称的卷积拆分比对称的拆分为几个相同的小卷积效果更好，可以处理更多，更丰富的空间特征，这就是Inception V3网络结构。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080613330515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n**Inception V4**\n\n借鉴了微软的ResNet网络结构思想，后面写到Resnet再介绍吧。\n\n\n## GoogLeNet测试样本处理\n1. 对于一个测试样本，将图像的短边缩放成4种尺寸，分别为256，288，320，352。\n2. 从每种尺寸的图像的左边，中间，右边（或者上面，中间，下面）分别截取一个方形区域，共三块方形区域。\n3. 对于每一个方形区域，我们取其四角和中心，裁切出5个区域，再将方形区域缩小到224×224，共6快区域，加上它们的镜像版本（将图像水平翻转），一共得到4×3×6×2=144张图像。这样的方法在实际应用中是不必要的，可能存在更合理的修剪方法。下图展示了不同修剪方法和不同模型数量的组合结果：\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825155701819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n*上表中，通过改变模型数量以及切分数量，展示几种测试策略对于图片进行预测的效果，所有数据报告基于验证数据集,以避免测试集上的过拟合。*\n\n\n使用多个模型时，每个模型的Softmax分类器在多个修剪图片作为输入时都得到多个输出值，然后再对所有分类器的softmax概率值求平均。\n\n\n**效果如下所示：**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200825155830735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n可以看到，GoogLeNet在验证集和测试集上top-5的错误率都降到了6.67%，在当年参赛者中排名第一。\n\n\n  \t\n\n\n\n\n## GoogleNet代码实现\n\n**Inception实现**\n\n```python\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nclass Inception(nn.Module):\n    # c1 - c4为每条线路里的层的输出通道数\n    def __init__(self, in_c, c1, c2, c3, c4):\n        super(Inception, self).__init__()\n        # 线路1，单1 x 1卷积层\n        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n        # 线路2，1 x 1卷积层后接3 x 3卷积层\n        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n        # 线路3，1 x 1卷积层后接5 x 5卷积层\n        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n        # 线路4，3 x 3最大池化层后接1 x 1卷积层\n        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n \n    def forward(self, x):\n        p1 = F.relu(self.p1_1(x))\n        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n        p4 = F.relu(self.p4_2(self.p4_1(x)))\n        return torch.cat((p1, p2, p3, p4), dim=1)  # 在通道维上连结输出\n```\n\n**GlobalAvgPool2d与FlattenLayer**\n\n```python\nclass GlobalAvgPool2d(nn.Module):\n    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现\n    def __init__(self):\n        super(GlobalAvgPool2d, self).__init__()\n    def forward(self, x):\n        return F.avg_pool2d(x, kernel_size=x.size()[2:])\n    \nclass FlattenLayer(torch.nn.Module):\n    def __init__(self):\n        super(FlattenLayer, self).__init__()\n    def forward(self, x): # x shape: (batch, *, *, ...)\n        return x.view(x.shape[0], -1)\n```\n\n**GoogLeNet实现**\n\n```python\nclass GoogLeNet(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(GoogLeNet, self).__init__()\n        \n        self.b1 = nn.Sequential(nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n                           nn.ReLU(),\n                           nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n        self.b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n                           nn.Conv2d(64, 192, kernel_size=3, padding=1),\n                           nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n        self.b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n                           Inception(256, 128, (128, 192), (32, 96), 64),\n                           nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n        self.b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n                           Inception(512, 160, (112, 224), (24, 64), 64),\n                           Inception(512, 128, (128, 256), (24, 64), 64),\n                           Inception(512, 112, (144, 288), (32, 64), 64),\n                           Inception(528, 256, (160, 320), (32, 128), 128),\n                           nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n\n        self.b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n                           Inception(832, 384, (192, 384), (48, 128), 128),\n                           GlobalAvgPool2d())\n        self.output=nn.Sequential(FlattenLayer(),\n                                  nn.Dropout(p=0.4),\n                                  nn.Linear(1024, 1000))\n        \n        def forward(self, x):\n            x=b1(x)\n            x=b2(x)\n            x=b3(x)\n            x=b4(x)\n            x=b5(x)\n            x=output(x)\n            return x\n```\n**测试输出**\n\n```python\nnet = GoogLeNet()\nX = torch.rand(1, 3, 224, 224)\n# 可以对照表格看一下各层输出的尺寸\nfor blk in net.children(): \n    X = blk(X)\n    print('output shape: ', X.shape)\n\"\"\"\n# 输出：\noutput shape:  torch.Size([1, 64, 56, 56])\noutput shape:  torch.Size([1, 192, 28, 28])\noutput shape:  torch.Size([1, 480, 14, 14])\noutput shape:  torch.Size([1, 832, 7, 7])\noutput shape:  torch.Size([1, 1024, 1, 1])\noutput shape:  torch.Size([1, 1000])\n\"\"\"\n```\n\n\n\n【参考文档】\n1. [GoogLeNet中的inception结构，你看懂了吗](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029565&idx=1&sn=330e398a4007b7b24fdf5203a5bf5d91&chksm=871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd&scene=21#wechat_redirect)\n2. [GoogleNet 论文解析及代码实现](https://mp.weixin.qq.com/s?__biz=MzI1ODEzMDQ3OQ==&mid=2247484578&idx=1&sn=4e41b5304664aa3f8020faec9454747a&chksm=ea0d93e2dd7a1af4556b3852a00961615d0df3605d98dcd8c23acb37b22626455d11e6a90adf&mpshare=1&scene=1&srcid=08253WfHcIkpm3iCO1ICf58x&sharer_sharetime=1598319287371&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=19019e2f1359b2de084edfb643f43e91654d68635120cbf885413ba7afc22639d7757ea0d526f323ce679a5040343d9eb6f254294fee1ea2f991310ee5e25bbe884660b311ce10d0b531a684dd82ac14da5d51f7d6d5a73fc4ca5ec88189890b2fa1c86131d2bd1ec69398222799856c8b6c9890d64acdf0fe0410292c1a2d83&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AVxFjJhoCwO8UI1HylAlShI=&pass_ticket=vFUwXThz6nwuqDXBu8RFZMPKZjXMC0vxTeL29D9KIAj11S9RDOH70u14fPZeWLU0)\n3. [带你快速学会 GoogLeNet 神经网络](https://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&mid=2650725770&idx=4&sn=34c148f1c5dd80115fea9c38215973cb&chksm=bea6ac5989d1254f8c8015ec27e0647f03099d5989d296fecf0fa5de78f205d3e3170f77e9ef&mpshare=1&scene=1&srcid=0825UnHhIih8vnQgNvChrWBQ&sharer_sharetime=1598319794600&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=b6de4a213a64b7292bca947a43a1bd9735df46270820810bf2af4d69d20c297f9f436989b6c839ca238cf07eb05b11f019b360e19c055a4b568a103b9d929516059f43875a73dd44f83eef760bb9e85c6573653e1a2a81124fcf925747d30ff106c8bdde5229391fea5028c415b8c87debb59134f8fce4f621ea9467cd5419dc&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=Afibu8%2bcZCDn182XsPwKq8g=&pass_ticket=vFUwXThz6nwuqDXBu8RFZMPKZjXMC0vxTeL29D9KIAj11S9RDOH70u14fPZeWLU0)\n4. [卷积神经网络之GoogLeNet](https://mp.weixin.qq.com/s?__biz=MzI0NTM1MzA2Mw==&mid=2247484704&idx=1&sn=6b75e56ee317922b536b9eca119dc06d&chksm=e94e9a28de39133ed340f38e332f064a3c0fe42d81842d93d7bec309222bc3270f49482b3513&mpshare=1&scene=1&srcid=082568MV7VsEDOmvSikHDyM6&sharer_sharetime=1598319942128&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=92bd8fadcb6a48589b9f7f2db79c9d66ee5708a8ce35f046f5ea2617868dda3dd5719d48310f524f62e09bd966f8f620da4a78c6b2d2a77c933ce7ea10befa64250913ac4bb5c84423d846f996f3c11eb5e10ca6830c919daaaca0e77e2060d642d0bb739722a44aa9e27ea068df75fb26003f530bda9c9eadfd72210c0fca94&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=ASSsmXagqLOuBFd%2byPqfM6s=&pass_ticket=vFUwXThz6nwuqDXBu8RFZMPKZjXMC0vxTeL29D9KIAj11S9RDOH70u14fPZeWLU0)\n5. [GoogLeNet学习笔记](https://zhuanlan.zhihu.com/p/27124535)\n6. [GoogLeNet模型](https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter05_CNN/5.9_googlenet?id=_592-googlenet%E6%A8%A1%E5%9E%8B)\n7. 深度学习之pytorch计算机视觉-唐进民著\n8. Going Deeper with Convolutions, CVPR 2014\n\n我把GoogLeNet的论文上传到百度云上了，有需要请自提，链接：https://pan.baidu.com/s/1Tcg6-s1pHCE2WZ9TBaQ90A  提取码：ivft","tags":["GoogLeNet"],"categories":["神经网络"]},{"title":"深入解读VGG网络结构（附代码实现）","url":"/2020/11/24/223242/","content":"\nVGGNet由牛津大学的视觉几何组（Visual  Geometry  Group）提出，并在2014年举办的ILSVRC（ImageNet 2014比赛）中获得了定位任务第1名和分类任务第2名的好成绩，（GoogleNet 是2014 年的分类任务第1 名）。虽然VGGNet在性能上不及GoogleNet，但因为VGG结构简单，应用性强，所以很多技术人员都喜欢使用基于VGG 的网络。VGG论文[Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)，有兴趣的同学可以看下。\n\n<!-- more -->\n\n\n\n\n**VGG 最大的特点就是通过比较彻底地采用 3x3 尺寸的卷积核来堆叠神经网络，这样也加深整个神经网络的深度。这两个重要的改变对于人们重新定义卷积神经网络模型架构也有不小的帮助，至少证明使用更小的卷积核并且增加卷积神经网络的深度，可以更有效地提升模型的性能。**\n\n\n\nVGG 选择的是在 AlexNet 的基础上加深它的层数，但是它有个很显著的特征就是持续性的添加 3x3 的卷积核。而AlexNet 有 5 层卷积层，从下面的网络结构图我们可以看出来，VGG 就是针对这 5 层卷积层进行改造，共进行了 6 种配置。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824151316119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n这六种配置的参数量：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152012157.png#pic_center)\n\n这六种配置的效果展示图：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020082415194940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n从上面的效果图中，我们发现VGG19是最好的。但是，VGG-19 的参数比 VGG-16 的参数多了好多。由于VGG-19需要消耗更大的资源，因此实际中VGG-16使用得更多。而且VGG-16网络结构十分简单，并且很适合迁移学习，因此至今VGG-16仍在广泛使用，下面我们主要来讨论一下VGG16的网络结构，也就是图中的类型D。（VGG19即上面的E类型）\n\nVGG16相比AlexNet的一个改进是采用连续的3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5），如下图中所示，共有13个卷积层，3个全连接层。其**全部采用3\\*3卷积核，步长统一为1，Padding统一为1，和2\\*2最大池化核，步长为2，Padding统一为0**。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152348459.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n那么，就让我们一层一层来分析吧！\n\n（1）INPUT层：VGG16卷积神经网络默认的输入数据必须是维度为224×224×3的图像，和  AlexNet一样，其输入图像的高度和宽度均为224，而且拥有的色彩通道是R、G、B这三个。\n（2）**CONV3-64**：使用的卷积核为`(3*3*3)*64`（卷积核大小为3\\*3，输入通道为3，输出通道为64），步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为224，即$224=\\frac{224-3+2}{1}+1$   ，最后输出的特征图的维度为224×224×64。卷积通用公式参考我的博客[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)中卷积中的特征图大小计算方式。\n（3）**CONV3-64**：使用的卷积核为`(3*3*64)*64`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为224，即$224=\\frac{224-3+2}{1}+1$   ，最后输出的特征图的维度为224×224×64。\n（4）Max pool：池化核大小为2×2，步长为2。通过套用池化通用公式，可以得到最后输出的特征图的高度和宽度均为112，即 $112=\\frac{224-2}{2}+1$   ，最后得到的输出的特征图的维度为112×112×64。\n（5）**CONV3-128**：使用的卷积核为`(3*3*64)*128`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为112，即$112=\\frac{112-3+2}{1}+1$   ，最后输出的特征图的维度为112×112×128。\n（6）**CONV3-128**：使用的卷积核为`(3*3*128)*128`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为112，即$112=\\frac{112-3+2}{1}+1$   ，最后输出的特征图的维度为112×112×128。\n（7）Max pool：池化核大小为2×2，步长为2。通过套用池化通用公式，可以得到最后输出的特征图的高度和宽度均为56，即 $56=\\frac{112-2}{2}+1$   ，最后得到的输出的特征图的维度为56×56×128。\n（8）**CONV3-256**：使用的卷积核为`(3*3*128)*256`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为56，即$56=\\frac{56-3+2}{1}+1$   ，最后输出的特征图的维度为56×56×256。\n（9）**CONV3-256**：使用的卷积核为`(3*3*256)*256`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为56，即$256=\\frac{256-3+2}{1}+1$   ，最后输出的特征图的维度为56×56×256。\n（10）**CONV3-256**：经过`(3*3*256)*256`卷积核，生成featuremap为`56*56*256`。\n（11）Max pool：  经过`（2*2）`maxpool，生成featuremap为`28*28*256`。\n（12）**CONV3-512**：经过`（3*3*256）*512`卷积核，生成featuremap为`28*28*512`。\n（13）**CONV3-512**：经过`（3*3*512）*512`卷积核，生成featuremap为`28*28*512`。\n（14）**CONV3-512**：经过`（3*3*512）*512`卷积核，生成featuremap为`28*28*512`。\n（15）Max pool：经过`（2*2）`maxpool,生成featuremap为`14*14*512`。\n（16）**CONV3-512**：经过`（3*3*512）*512`卷积核，生成featuremap为`14*14*512`。\n（17）**CONV3-512**：经过`（3*3*512）*512`卷积核，生成featuremap为`14*14*512`。\n（18）**CONV3-512**：经过`（3*3*512）*512`卷积核，生成featuremap为`14*14*512`。\n（19）Max pool：经过`2*2`卷积，生成featuremap为`7*7*512`。\n（20）**FC-4096**：输入为`7*7*512`，和AlexNet模型一样，都需要对输入特征图进行扁平化处理以得到1×25088的数据，输出数据的维度要求是1×4096，所以需要一个维度为25088×4096的矩阵完成输入数据和输出数据的全连接，最后得到输出数据的维度为1×4096。\n（21）**FC-4096**：输入数据的维度为1×4096，输出数据的维度要求是1×4096，所以需要一个维度为4096×4096的矩阵完成输入数据和输出数据的全连接，最后得到输出数据的维度为1×4096。\n（22）**FC-1000**：输入数据的维度为1×4096，输出数据的维度要求是1×1000，所以需要一个维度为4096×1000的矩阵完成输入数据和输出数据的全连接，最后得到输入数据的维度为1×1000。\n\n上面加粗的层即带有可训练参数的层，共16 weight layers。\n\nVGG16的参数一共是多少呢，现在来计算吧！\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824164009624.png#pic_center)\nVGG16（即上图D）总参数量是138M，具体如下：\n第1层：`1792 = 3*3*3*64+64`\n第2层：`36928 = 3*3*64*64+64`\n第3层：`73856 = 3*3*64*128+128`\n第4层：`147584 = 3*3*128*128+128`\n第5层：`295168 = 3*3*128*256+256`\n第6层：`590080 = 3*3*256*256+256`\n第7层：`590080 = 3*3*256*256+256`\n第8层：`1180160 = 3*3*256*512+512`\n第9层：`2359808 = 3*3*512*512+512`\n第10层：`2359808 = 3*3*512*512+512`\n第11层：`2359808 = 3*3*512*512+512`\n第12层：`2359808 = 3*3*512*512+512`\n第13层：`2359808 = 3*3*512*512+512`\n第14层：`102764544 = 7*7*512*4096+4096`\n第15层：`16781312 = 4096*4096+4096`\n第16层：`4097000 = 4096*1000+1000`\n\n总计：138357544个  （138M）\n\n\n\n\n**总结：**\n\n1. VGG16相比AlexNet的一个改进是采用连续的3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）\n2. 加深结构都使用ReLU激活函数：提升非线性变化的能力\n3. VGG16 **全部采用3\\*3卷积核，步长统一为1，Padding统一为1，和2\\*2最大池化核，步长为2，Padding统一为0**\n4. VGG19比VGG16的区别在于多了3个卷积层，其它完全一样\n5. VGG16基本是AlexNet（AlexNet是8层，包括5个卷积层和3个全连接层）的加强版，深度上是其2倍，参数量大小也是两倍多。\n\n我们已经知道，VGG16相比AlexNet的一个改进是采用连续的3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5），现在，来思考几个问题吧。\n\n\n**Thinking1：使用3x3卷积核替代7x7卷积核的好处？**\n- 2 个 3x3 的卷积核叠加，它们的感受野等同于 1 个 5x5 的卷积核，3 个叠加后，它们的感受野等同于 1 个 7x7 的效果。用2个3x3的卷积核代替原来的 5x5卷积核如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152851501.png#pic_center)\n- 由于感受野相同，3个3x3的卷积，使用了3个非线性激活函数，增加了非线性表达能力，从而可以提供更复杂的模式学习。\n- 使用3x3卷积核可以减少参数，假设现在有 3 层 3x3 卷积核堆叠的卷积层，输出和输出通道数都是C，那么它的参数总数是 3x(3x3xCxC)=27xCxC 。同样和它感受野大小一样的一个卷积层，卷积核是 7x7 的尺寸，假如输出和输出通道数都是C，那么它的参数总数就是 7x7xCxC=49xCxC。而且通过上述方法网络层数还加深了。三层3x3的卷积核堆叠参数量比一层7x7的卷积核参数链还要少。\n- 总的来说，使用3x3卷积核堆叠的形式，既增加了网络层数又减少了参数量。\n\n\n**Thinking2：多少个3x3的卷积核可以替代原来11x11的卷积核？**\n\n(11-1)/2=5，故5个3x3的卷积核可以替代原来11x11的卷积核，即n-11+1=n+(-3+1)\\*5\n\n\n**Thinking3：VGG的C网络结构使用了1x1卷积核，1x1卷积核的主要好处?**\n\n- 使用多个1x1卷积核，在保持feature map 尺寸不变（即不损失分辨率）的前提下，可以大幅增加非线性表达能力，把网络做得很deep。\n- 进行卷积核通道数的降维和升维。\n- 1x1卷积相当于线性变换，非线性激活函数起到非线性作用。\n- 总结就是：1x1 卷积核的好处是不改变感受野的情况下，进行升维和降维，同时也加深了网络的深度。\n\n\n\nVGG16和VGG19都在pytorch封装好了，如下所示：\n\n```python\ntorchvision.models.vgg16(pretrained=False)\ntorchvision.models.vgg19(pretrained=False)\n```\n\n\n代码实现：\n\n```python\nimport torch\nimport torch.nn as nn\n# 带BN层的vgg16\nclass VGG16_bn(torch.nn.Module):\n\n    def __init__(self, num_classes):\n        super(VGG16_bn, self).__init__()\n        \n        self.block_1 = nn.Sequential(\n                nn.Conv2d(in_channels=3,\n                          out_channels=64,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=64,\n                          out_channels=64,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(64),\n                nn.ReLU(inplace=True),\n            \n                nn.MaxPool2d(kernel_size=2,\n                             stride=2)\n        )\n        \n        self.block_2 = nn.Sequential(\n                nn.Conv2d(in_channels=64,\n                          out_channels=128,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=128,\n                          out_channels=128,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(128),\n                nn.ReLU(inplace=True),\n            \n                nn.MaxPool2d(kernel_size=2,\n                             stride=2)\n        )\n        \n        self.block_3 = nn.Sequential(\n                nn.Conv2d(in_channels=128,\n                          out_channels=256,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=256,\n                          out_channels=256,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=256,\n                          out_channels=256,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(256),\n                nn.ReLU(inplace=True),\n            \n                nn.MaxPool2d(kernel_size=2,\n                             stride=2)\n        )\n        \n          \n        self.block_4 = nn.Sequential(\n                nn.Conv2d(in_channels=256,\n                          out_channels=512,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=512,\n                          out_channels=512,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=512,\n                          out_channels=512,\n                          kernel_size=3,\n                          stride=1,\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n\n                nn.MaxPool2d(kernel_size=2,\n                             stride=2)\n        )\n        \n        self.block_5 = nn.Sequential(\n                nn.Conv2d(in_channels=512,\n                          out_channels=512,\n                          kernel_size=(3, 3),\n                          stride=(1, 1),\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=512,\n                          out_channels=512,\n                          kernel_size=(3, 3),\n                          stride=(1, 1),\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n            \n                nn.Conv2d(in_channels=512,\n                          out_channels=512,\n                          kernel_size=(3, 3),\n                          stride=(1, 1),\n                          padding=1),\n                nn.BatchNorm2d(512),\n                nn.ReLU(inplace=True),\n\n                nn.MaxPool2d(kernel_size=(2, 2),\n                             stride=(2, 2))\n        )\n        \n        #自适应平均池化，见https://www.zhihu.com/question/282046628\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        \n        self.classifier = nn.Sequential(\n                nn.Linear(512 * 7 * 7, 4096),\n                nn.ReLU(True),\n                nn.Dropout(),\n                nn.Linear(4096, 4096),\n                nn.ReLU(True),\n                nn.Dropout(),\n                nn.Linear(4096, num_classes),\n        )\n        \n         \n        # 初始化权重\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                # VGG采用了Kaiming initialization\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)            \n    \n        \n    def forward(self, x):\n\n        x = self.block_1(x)\n        x = self.block_2(x)\n        x = self.block_3(x)\n        x = self.block_4(x)\n        x = self.block_5(x) \n        x = self.avgpool(x)\n        # 拉平     \n        x = torch.flatten(x, 1)      \n        x = self.classifier(x)\n        # 一般不用softmax\n        # x = F.softmax(x, dim=1)\n        return x\n```\n\n```python\n# 拿一个数据测试下吧！\nif __name__ == \"__main__\":\n    a=torch.randn(3,224,224)\n    a=a.unsqueeze(0)\n    print(a.size())\n    net = VGG16_bn(10)\n    x=net(a)\n    print(x.size())\n\"\"\"\n# 输出\ntorch.Size([1, 3, 224, 224])\ntorch.Size([1, 10])\n\"\"\"\n```\n\n【参考文档】\n1. [【卷积神经网络结构专题】经典网络结构之VGG(附代码实现)](https://mp.weixin.qq.com/s?__biz=MzU2NDExMzE5Nw==&mid=2247487630&idx=2&sn=77d0bcef8452741823081ac8a0e4ed44&chksm=fc4eaacccb3923da09e61e26f4950a860881b07fb619f8f9d3b0ee61f17a3a76c2cba7aa75e9&scene=158#rd)\n2. [【模型解读】从LeNet到VGG，看卷积+池化串联的网络结构](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029512&idx=1&sn=a46fc10de7daba25694bda75a916aa91&chksm=871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187&mpshare=1&scene=1&srcid=0804y5ewJsTSJKBSVaMNmvrm&sharer_sharetime=1596532567452&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=92bd8fadcb6a4858b2c5b0a38954321b0f8c3dc80d539d1fc2a0778dc107c45ce2aca8614afc433452f4fd83aba02ddb6a1be7e244027038c09196c4dc62cca07dafbdb87d527756f0a49d5105425e85&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AZ6oMa1fen0omFBd4MdcdrU=&pass_ticket=bfbIoM7yRmV2MGkwcfISFD0R1Uc2EfrGFv2CzbEqH1kNmM/wiobhHOk806C/dvoE)\n3.    [深度学习之基础模型-VGG](https://blog.csdn.net/whz1861/article/details/78111606)\n4. 【深度学习之pytorch计算机视觉】-唐进民著\n\n\n","tags":["VGG"],"categories":["神经网络"]},{"title":"array，list，tensor，Dataframe，Series之间互相转换总结","url":"/2020/11/24/223046/","content":"\n\n本文转载自：[【串讲总结】array, list, tensor，Dataframe，Series之间互相转换总结](https://blog.csdn.net/qq_33431368/article/details/107581604?utm_medium=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight)\n\n## 一、前言\n对于在Deep Learning的学习中总会有几个数据类型的转换，这次想把这些常用的转换做一个总结，方便以后看。\n\n<!-- more -->\n\n\n\n\n\n这些主要包括：`Dataframe、Series(pandas), array(numpy), list, tensor(torch)`\n\n## 二、定义\n\n### 2.1 Dataframe和Series\n\n这里简单介绍一下这两个结构。Dataframe创建的方式有很多种，这里不赘述了。以下举个例子，因为我们这里要讲的是和array等的转换，这里全都用数字型的元素。\n\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9GSXpPRWliOFZRVXBPczdPeU9INkxtSjRrcTdIcksxVVdtV3lRenpleUFQQzRXSDBkc2xDQjdOcDdobldxbllpYk50aWJmYzBSajNMb1pWR0N6cXNEekY1QS82NDA?x-oss-process=image/format,png)\n对于dataframe来说，我们打印出来，结构类似于一个二维矩阵格式，只是每一列和每一个行都有个index，这并且这些结构之间有很多方便的操作，在读入结构化数据的时候尤为方便，所以平时做偏结构化数据的时候， 比如excel、pickle等等，pandas的使用是绕不开的。\n\n而其中的series相当于dataframe的一个元素，如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081320193186.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nSeries只有row index，**有点类似于一个一维向量**。\n\n\n而DataFrame既有行索引也有列索引，它也可以被看做由Series组成的字典（共同用一个索引）\n\n\n### 2.2 array\n\n数组结构是由不同维度的list转换来的，用array的原因主要在于有更多的矩阵操作，数据使用起来更方便，比如转置、矩阵相乘、reshape等等。\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813204916515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n### 2.3 tensor\n张量是在深度学习框架中的一个数据结构，把数据喂进模型中需要把数据转换为tensor结构，等我们再取出来做框架以外的操作，比如保存成文件，用plot画图，都需要重新转换为array或list结构。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813204952507.png)\n## 三、互相转换\n\n先用一个例子直观举例下\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081320501214.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813205228508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n## 四、详细总结\n### 4.1 Dataframe到Series\n挑一列的index取出\n\n```python\nSeries = Dataframe['column']\n```\n\n### 4.2 Series到list\n\n```python\nlist = Series.to_list()\n```\n\n### 4.3 list 转 array\n\n```python\narray = np.array(list)\n```\n\n### 4.4 array 转 torch.Tensor\n\n```python\ntensor = torch.from_numpy(array)\n```\n\n### 4.5 torch.Tensor 转 array\n\n```python\narray = tensor.numpy()\n# gpu情况下需要如下的操作\narray = tensor.cpu().numpy()\n```\n\n### 4.6 torch.Tensor 转 list\n\n```python\n# 先转numpy，后转list\nlist = tensor.numpy().tolist()\n```\n\n### 4.7 array 转 list\n\n```python\nlist = array.tolist()\n```\n\n### 4.8 list 转 torch.Tensor\n\n```python\ntensor=torch.Tensor(list)\n```\n\n### 4.9 array或者list转Series\n\n```python\nseries = pd.Series({'a': array})\nseries2 = pd.Series({'a': list})\n```\n\n之后这里的操作就多了，看你具体需求了，也可以多个series拼成一个dataframe, 如下， 其他操作不一一赘述了\n\n```python\ndf = pd.DataFrame({'aa': series, 'bb': series2})\n```\n\n原文链接：[https://blog.csdn.net/qq_33431368/article/details/107581604?utm_medium=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight](https://blog.csdn.net/qq_33431368/article/details/107581604?utm_medium=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-OPENSEARCH-1.edu_weight)\n","tags":["python"],"categories":["python"]},{"title":"【超详细】对比10种优化函数BGD、SGD、mini-batch GD、Momentum、NAG、Adagrad、RMSProp、Adadelta、Adam、AMSgrad","url":"/2020/11/24/222922/","content":"\n在实践中常用到一阶优化函数，典型的一阶优化函数包括 BGD、SGD、mini-batch GD、Momentum、Adagrad、RMSProp、Adadelta、Adam 等等，**一阶优化函数在优化过程中求解的是参数的一阶导数**，这些一阶导数的值就是模型中参数的微调值。另外，近年来二阶优化函数也开始慢慢被研究起来，二阶方法因为计算量的问题，现在还没有被广泛地使用。\n\n<!-- more -->\n\n\n\n深度学习模型的优化是一个**非凸函数优化**问题，这是与**凸函数优化**问题对应的。对于凸函数优化，任何局部最优解即为全局最优解。几乎所有用梯度下降的优化方法都能收敛到全局最优解，损失曲面如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811103153430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n而非凸函数优化问题则可能存在无数个局部最优点，损失曲面如下，可以看出有非常多的极值点，有极大值也有极小值。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811103348878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n本文将从原理、公式、代码、loss曲线图、优缺点等方面详解论述：\n@[TOC]( )\n\n\n## 一、BGD/SGD/mini-batch GD\n梯度下降算法主要有BGD、SGD、mini-batch GD，后面还有梯度下降算法的改进，即Momentum、Adagrad 等方法\n### 1.1 BGD\n\n**BGD**（Batch gradient descent，批量梯度下降），是拿所有样本的loss计算梯度来更新参数的，更新公式如下：\n$$\\theta=\\theta-\\eta· \\nabla_\\theta J(\\theta)$$\n\n> 在有的文献中，称GD是拿所有样本的loss计算梯度来更新参数，也就是全局梯度下降，和这里的BGD是一个意思\n\n其中，$\\theta$为要更新的参数，即weight、bias；$\\eta$ 为学习率；$J$为损失函数，即 loss function ；$\\nabla_\\theta J(\\theta)$ 是指对 loss function 的 $\\theta$ 求梯度。\n\n令$\\Delta\\theta_t=-\\eta· \\nabla_\\theta J(\\theta)$，则$\\theta_{t+1}=\\theta_{t}+\\Delta\\theta_t$，$\\theta_{1}$ 即初始化的weight、bias。\n\n写成伪代码如下：\n\n```python\n# all_input和all_target是所有样本的特征向量和label\nfor i in range(epochs):\n    optimizer.zero_grad()\n    output = model(all_input)\n    loss = loss_fn(output,all_target)\n    loss.backward()\n    optimizer.step()\n```\n\n\n\n在loss的等值线图中，随着 weight 的变化loss降低的曲线走向（红线）如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811100747627.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n其中 x1是纵轴，x2是横轴 ；$weight=[x1,x2]$ ，即两个坐标轴对应的点；$X_i=[x1_i,x2_i]$，即weight不同时刻的取值；$X_0=[x1_0,x2_0]$是weight的初始化值。\n\n从上图中可以看出，**BGD的loss曲线走向相对平滑，每一次优化都是朝着最优点走**。\n\n\n由于BGD在每次计算损失值时都是针对整个参与训练的样本而言的，所以会出现**内存装不下，速度也很慢的情况**。能不能一次取一个样本呢？于是就有了随机梯度下降（Stochastic gradient descent），简称 sgd。\n\n### 1.2 SGD\n\n**SGD**（Stochastic gradient descent，随机梯度下降）是**一次拿一个样本的loss计算梯度来更新参数**，其更新公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811105800214.png)\n其中，$x^{(i)}$ 是第一个样本的特征向量，$y^{(i)}$ 是第i个样本的真实值。\n\n也可以写成如下形式：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811110014943.png)\n其中，$g_{t,i}$ 是第i个样本的梯度。\n\n写成伪代码如下：\n\n```python\nfor i in range(epochs):\n    # batch=1,每次从dataset取出一个样本\n    for input_i,target_i in dataset:\n        optimizer.zero_grad()\n        output = model(all_input)\n        loss = loss_fn(output,all_target)\n        loss.backward()\n        optimizer.step()\n```\n\n在loss的等值线图中，随着 weight 的变化loss降低的曲线走向如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200811111504701.jpg)\n从上图中可以看出，**SGD的loss曲线走向是破浪式的，相对于BGD的方式，波动大，在非凸函数优化问题中，SGD可能使梯度下降到更好的另一个局部最优解，但从另一方面来讲，SGD的更新可能导致梯度一直在局部最优解附近波动**。\n\n> SGD的不确定性较大，可能跳出一个局部最优解到另一个更好的局部最优解，也可能跳不出局部最优解，一直在局部最优解附近波动\n\n由于同一类别样本的特征是相似的，因此某一个样本的特征能在一定程度代表该类样本，所以SGD最终也能够达到一个不错的结果，但是，SGD的更新方式的波动大，更新方向前后有抵消，存在浪费算力的情况。于是，就有了后来大家常用的小批量梯度下降算法（Mini-batch gradient descent）。\n\n### 1.3 Mini-batch GD\nMini-batch GD（Mini-batch gradient descent，小批量梯度下降）是**一次拿一个batch的样本的loss计算梯度来更新参数**，其更新公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812152612762.png)\n其中，batch_size=n。\n\n写成伪代码如下：\n\n```python\nfor i in range(epochs):\n    # batch_size=n,每次从dataset取n个样本\n    for input,target in dataset:\n        optimizer.zero_grad()\n        output = model(all_input)\n        loss = loss_fn(output,all_target)\n        loss.backward()\n        optimizer.step()\n```\n在loss的等值线图中，随着 weight 的变化loss降低的曲线走向如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812153352680.png)\n\n从上图可以看出，mini-batch GD 的loss走向曲线在BGD和SGD之间，mini-batch GD 既解决了SGD更新方式波动大的问题，又可以尽量去计算多个样本的loss，提高参数的更新效率。\n\n### 1.4 GD法的缺点\n梯度下降算法虽然取得了一定的效果，但是仍然有以下缺点：\n- 学习率大小比较难缺难确定，需要反复去试\n- 学习率不够智能，对每个参数的各个维度一视同仁\n- mini-batch GD算法中，虽然一定程度上提高参数的更新效率，并没有完全解决SGD中的问题，即更新方向仍然前后有抵消，仍然有浪费算力的情况\n- SGD和mini-batch GD由于每次参数训练的样本是随机选取的，模型会受到随机训练样本中噪声数据的影响，又因为有随机的因素，所以也容易导致模型最终得到局部最优解。\n\n\n\n## 二、Momentum/NAG\n知道了GD法的缺点，动量法通过之前积累梯度来替代真正的梯度从而避免GD法浪费算力的缺点，加快更新速度，我们现在来看**动量法**（momentum）和其改进方法NAG吧。\n### 2.1 Momentum\n在使用梯度下降算法的时，刚开始的时候梯度不稳定，波动性大，导致做了很多无用的迭代，浪费了算力，**动量法**（momentum）解决SGD/mini-batch GD中参数更新震荡的问题，**通过之前积累梯度来替代真正的梯度，从而加快更新速度**，其更新公式如下：\n$$\\begin{array}{l}\n\\upsilon_t=\\gamma\\upsilon_{t-1}+\\eta· \\nabla_\\theta J(\\theta)\\\\        \n\\theta=\\theta-\\upsilon_t\n\\end{array}$$\n其中，$\\theta$是要更新的参数即weight，$\\nabla_\\theta J(\\theta)$是损失函数关于weight的梯度，$\\gamma$为动量因子，通常设为0.9；$\\eta$ 为学习率。这里新出现了一个变量 $\\upsilon$，对应物理上的速度。\n也可以写成下面的形式（不常用）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812161157101.png)\n其中，$\\rho$为动量因子，通常设为0.9；$\\alpha$为学习率。\n\n只看公式可能不好理解，我们来代入计算下吧。\n\n假设 $\\eta$ 学习率为0.1，用 g 表示损失函数关于weight的梯度，则可计算如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812164126220.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n**动量法**（momentum）更新示意图如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812161702116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n这样， 每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值。当某个参数在最近一段时间内的梯度方向不一致时， 其真实的参数更新幅度变小，增加稳定性； 相反， 当在最近一段时间内的梯度方向都一致时， 其真实的参数更新幅度变大， 起到加速作用。\n\n一般而言， 在迭代初期， 梯度方向都比较一致， 动量法会起到加速作用， 可以更快地到达最优点。**在迭代后期， 梯度方向会不一致， 在收敛值附近振荡， 动量法会起到减速作用， 增加稳定性**。动量法也能解决稀疏梯度和噪声问题，这个到Adam那里会有详细解释。\n\n\n\n### 2.2 NAG\n**NAG**（Nesterov Accelerated Gradient，Nesterov加速梯度）是一种对动量法的改进方法， 也称为 Nesterov 动量法（Nesterov Momentum）。其公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812162552828.png)\n其中，$\\nabla_\\theta J(\\theta-\\gamma\\upsilon_{t-1})$是损失函数关于下一次（提前点）weight的梯度。\n\n也可以写为（不常用）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812164820951.png)\n\n**NAG**更新示意图如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812165251355.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n由于momentum刚开始时梯度方向都比较一致，收敛较快，但是到后期，由于momentum惯性的存在，很可能导致在loss极值点的附近来回震荡，而**NAG向前计算了一次梯度，当梯度方向快要改变的时候，它提前获得了该信息，从而减弱了这个过程，再次减少了无用的迭代，并保证能顺利更新到loss的极小值点**。\n\n\n\n\n\n\n## 三、Adagrad/RMSProp/Adadelta\n在神经网络的学习中，学习率$\\eta$的值很重要。学习率过小，会导致学习花费过多时间；反过来，学习率过大，则会导致学习发散而不能正确进行。\n\n在关于学习率的有效技巧中，有一种被称为学习率衰减（learning rate decay）的方法，即随着学习的进行，使学习率逐渐减小。实际上，一开始“多”学，然后逐渐“少”学的方法，**在神经网络的学习中经常被使用。逐渐减小学习率的想法，相当于将“全体”参数的学习率值一起降低**。而AdaGrad进一步发展了这个想法，针对“一个一个”的参数，赋予其“定制”的值，现在我们来看Adagrad/RMSProp/Adadelta吧。\n\n\n\n### 3.1 Adagrad\nAdaGrad（Adaptive Grad，自适应梯度）为参数的每个参数自适应地调整学习率，让不同的参数具有不同的学习率，其公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812173130536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n其中，W表示要更新的权重参数，$\\frac{ {\\partial L} }{ {\\partial W} }$表示损失函数关于W的梯度，$\\eta$表示学习率，这里新出现了变量$h$，它保存了以前的所有梯度值的平方和，$\\odot$表示对应矩阵元素的乘法。然后，在更新参数时，通过乘以 $\\frac{1}{\\sqrt h}$，就可以调整学习的尺度。这意味着，**参数的元素中变动较大（被大幅更新）的元素的学习率将变小。也就是说，可以按参数的元素进行学习率衰减，使变动大的参数的学习率逐渐减小**。\n\nAdagrad公式也可以写为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812192420580.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n其中， $g_\\tau \\in R$ 是第$\\tau$次迭代时的梯度，$\\alpha$为初始的学习率，$\\varepsilon$是为了保持数值稳定性而设置的非常小的常数， 一般取值 $e^{−7}$ 到 $e^{−10}$，此外， 这里的开平方、 除、 加运算都是按元素进行的操作。\n\n由于Adagrad学习率衰减用了所有的梯度，如果在经过一定次数的迭代依然没有找到最优点时，累加的梯度幅值是越来越大的，导致学习率越来越小， 很难再继续找到最优点，为了改善这个问题，从而提出RMSProp算法。\n\n\n### 3.2 RMSProp\n与AdaGrad不同，**RMSProp（Root Mean Square Propagation，均方根传播） 方法并不是将过去所有的梯度一视同仁地相加，而是逐渐地遗忘过去的梯度，在做加法运算时将新梯度的信息更多地反映出来，这种操作从专业上讲，称为“指数移动平均”，呈指数函数式地减小过去的梯度的尺度**。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812192541768.png)\n\n\n其中，$\\beta$ 为衰减率， 一般取值为 0.9，$\\alpha$为初始的学习率， 比如 0.001。\n\n从上式可以看出， RMSProp 算法和 AdaGrad 算法的区别在于 $G_t$ 的计算由累积方式变成了指数衰减移动平均。在迭代过程中， 并且，**每个参数的学习率并不是呈衰减趋势， 既可以变小也可以变大**（把$\\beta$设的更小些，每个参数的学习率就呈变大趋势）。\n\n> 这里不得不提一下RProp，Rprop可以看做 RMSProp的简单版，它是依据符号来改变学习率的大小：当最后两次梯度符号一样，增大学习率，当最后两次梯度符号不同，减小学习率。\n\n\n\n### 3.3 AdaDelta \nAdaDelta 与 RMSprop 算法类似， AdaDelta 算法也是通过**梯度平方的指数衰减移动平均来调整学习率**。此外， **AdaDelta 算法还引入了每次参数更新差值Δ𝜃 的平方的指数衰减权移动平均**。\n\n第 t 次迭代时， 参数更新差值 Δ𝜃 的平方的指数衰减权移动平均为\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081218193921.png)\nAdaDelta 算法的参数更新公式为：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812192717500.png)\n\n\n其中 $G_t$ 的计算方式和 RMSprop 算法一样 ， $\\Delta X_{t - 1}^2$ 为参数更新差值 Δ𝜃 的指数衰减权移动平均。\n\n从上式可以看出， **AdaDelta 算法将 RMSprop 算法中的初始学习率 𝛽 改为动态计算的 $\\sqrt {\\Delta X_{t - 1}^2}$ ，在一定程度上平抑了学习率的波动**。除此之外，AdaDelta连初始的学习率都不要设置了，提升了参数变化量的自适应能力。\n\n除此之外，AdaDelta公式还有一个常用的表示方法：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812193957164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n## 四、Adam\\AMSgrad\n现在来介绍比较好用的方法Adam和其改进方法AMSgrad。\n### 4.1 Adam\n**Adam** 算法 （Adaptive Moment Estimation Algorithm）可以看作动量法和 RMSprop 算法的结合， **不但使用动量作为参数更新方向， 而且可以自适应调整学习率**。\n\n\nAdam 算法一方面计算梯度平方 $g^2_t$ 的指数衰减移动平均（和 RMSprop 算法类似）, 另一方面计算梯度 $g_t$ 的指数衰减移动平均 （和动量法类似），如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812194548127.png)\n\n\n其中 $\\beta_1$ 和 $\\beta_2$ 分别为两个移动平均的衰减率， 通常取值为 $\\beta_1$ = 0.9，$\\beta_2$ = 0.999。 **我们可以把 $M_t$ 和 $G_t$ 分别看作梯度的均值（一阶矩估计）和未减去均值的方差（二阶矩估计）**。其中，$M_t$ 来自momentum，用来稳定梯度，$G_t$ 来自RMSProp，用来是梯度自适应化。\n\n对$M_t$ 和 $G_t$偏差进行修正：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812210354974.png)\n\n\nAdam 算法的参数更新公式为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081220485436.png)\n\n\n\n其中，其中学习率 $\\alpha $ 通常设为 0.001， 并且也可以进行衰减， 比如 $\\alpha_t=\\frac{\\alpha_{0}}{\\sqrt t}$ 。\n\n\nAdam， 结合了 动量法 和 RMSProp 算法最优的性能，它还是能提供解决**稀疏梯度和噪声问题**的优化方法，在深度学习中使用较多。这里解释一下为什么Adam能够解决**稀疏梯度和噪声问题**：稀疏梯度是指梯度较多为0的情况，由于adam引入了动量法，在梯度是0的时候，还有之前更新时的梯度存在（道理跟momentum一样），还能继续更新；噪声问题是对于梯度来说有一个小波折（类似于下山时路不平有个小坑）即多个小极值点，可以跨过去，不至于陷在里面。\n\n\nAdam 算法是 RMSProp 算法与动量法的结合， 因此一种自然的 Adam 算法的改进方法是引入 Nesterov 加速梯度， 称为**Nadam** 算法\n\n**这里思考一个问题：为什么对Adam偏差进行修正？**\n\n网上没找到好的解释，那来看一下原文吧！\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812211001933.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n大致意思是说：刚开始，我们任意初始化了一个 $m_0$（注意：一般$m_0$初始化为0，在Momentum算法中也是），并且根据公式$m_t=\\beta m_{t-1}+(1-\\beta)g_t$更新公式，得到 $m_1$，可以明显的看到，第一步更新严重依赖初始化的$m_0$，这样可能会造成严重的偏差。\n\n为了纠正这个，我们需要移除这个初始化$m_0$（偏置）的影响，例如，可以把$m_1=\\beta m_{0}+(1-\\beta)g_1$中的$\\beta m_{0}$从$m_1$移除（即$m_1-\\beta m_0$），并且除以（$1-\\beta$），这样公式就变为了 $\\hat{m}=\\frac{m_1-\\beta m_0}{1-\\beta}$，当$m_0$=0时，$\\hat{m_t}=\\frac{m_t}{1-\\beta^t}$。同理，对于$G_t$也是如此。\n\n总的来说，在迭代初期，$M_t$ 和 $G_t$的更新严重依赖于初始化的$M_0=0$、$G0=0$，当初始化$M_t$ 和 $G_t$都为0时，$M_t$ 和 $G_t$都会接近于0，这个估计是有问题的，可能会造成严重的偏差（即可能使学习率和方向与真正需要优化的学习率和方向严重偏离），所以，我需要移除这个初始化的$M_0$ 和 $G0$（偏置）的影响， 故需要对偏差进行修正。\n\n\n**上面说了这么多理论，分析起来头头是道，各种改进版本似乎各个碾压 SGD 算法。但是否真的如呢？此外，Adam看起来都这么厉害了，以后的优化函数都要使用Adam吗？**\n\n来看一下下面的实验：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813163800385.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n所有方法都采用作者们（原文）的默认配置，并且进行了参数调优，不好的结果就不拿出来了。\n- nesterov 方法，与 sgd 算法同样的配置。\n- adam 算法，m1=0.9，m2=0.999，lr=0.001。\n- rms 算法，rms_decay=0.9，lr=0.001。\n- adagrad，adadelta 学习率不敏感。\n\n\n看起来好像都不如 SGD 算法，实际上这是一个很普遍的现象，各类开源项目和论文都能够印证这个结论。总体上来说，改进方法降低了调参工作量，只要能够达到与**精细调参的 SGD** 相当的性能，就很有意义了，这也是 Adam 流行的原因。但是，**改进策略带来的学习率和步长的不稳定还是有可能影响算法的性能**，因此这也是一个研究的方向，不然哪来这么多Adam 的变种呢。\n\n这里引用一位清华博士举的例子：很多年以前，摄影离普罗大众非常遥远。十年前，傻瓜相机开始风靡，游客几乎人手一个。智能手机出现以后，摄影更是走进千家万户，手机随手一拍，前后两千万，照亮你的美（咦，这是什么乱七八糟的）。但是专业摄影师还是喜欢用单反，孜孜不倦地调光圈、快门、ISO、白平衡……一堆自拍党从不care的名词。技术的进步，使得傻瓜式操作就可以得到不错的效果，但是在特定的场景下，要拍出最好的效果，依然需要深入地理解光线、理解结构、理解器材。优化算法大抵也如此，大家都是殊途同归，只是相当于在SGD基础上增加了各类学习率的主动控制。如果不想做精细的调优，那么Adam显然最便于直接拿来上手。\n\n原文在[Adam那么棒，为什么还对SGD念念不忘 (2)—— Adam的两宗罪](https://zhuanlan.zhihu.com/p/32262540)\n\nAdam那么棒，也不是没有缺点，继续往下面看！\n\n### 4.2 AMSgrad\nICLR 2018 最佳论文提出了 AMSgrad 方法，研究人员观察到 Adam 类的方法之所以会不能收敛到很好的结果，是因为在优化算法中广泛使用的指数衰减方法会使得梯度的记忆时间太短。\n\n在深度学习中，每一个 mini-batch 对结果的优化贡献是不一样的，有的产生的梯度特别有效，但是也一视同仁地被时间所遗忘。\n\n具体的做法是使用过去平方梯度的最大值来更新参数，而不是指数平均。其公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813161546652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n## 五、不同优化函数比较\n\n（1）不同优化函数的loss下降曲线如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812201908590.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（2）不同优化函数在 MNIST 数据集上收敛性的比较（学习率为0.001， 批量大小为 128）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200812220337887.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（3）不同优化函数配对比较\n![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9waWMyLnpoaW1nLmNvbS84MC92Mi0zOWM1ZGYxNjczZDk4MzFlOWJjMTBjOWU5YzRmMTJhOF8xNDQwdy5qcGc?x-oss-process=image/format,png)\n横纵坐标表示降维后的特征空间，区域颜色则表示目标函数值的变化，红色是高原，蓝色是洼地。他们做的是配对儿实验，让两个算法从同一个初始化位置开始出发，然后对比优化的结果。可以看到，几乎任何两个算法都走到了不同的洼地，他们中间往往隔了一个很高的高原。这就说明，不同算法在高原的时候，选择了不同的下降方向。\n\n这里参考 [Adam那么棒，为什么还对SGD念念不忘 (3)—— 优化算法的选择与使用策略述](https://zhuanlan.zhihu.com/p/32338983)\n\n## 六、pytorch不同优化函数的定义\n\n这里介绍几种常用优化函数的参数定义和解释\n\n（1）**torch.optim.SGD**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813093551803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n重要参数解释：\n- lr 学习率，用于控制梯度更新的快慢，如果学习速率过快，参数的更新跨步就会变大，极易出现震荡；如果学习速率过慢，梯度更新的迭代次数就会增加，参数更新、优化的时间也会变长，所以选择一个合理的学习速率是非常关键的。\n- momentum 动量因子，介于[0,1]之间，默认为0，一般设为0.9，当某个参数在最近一段时间内的梯度方向（即与动量$\\upsilon$方向）不一致时， 其真实的参数更新幅度变小，增加稳定性； 相反， 当在最近一段时间内的梯度方向都一致时， 其真实的参数更新幅度变大， 起到加速作用。\n- weight_decay 权重衰减（L2惩罚），默认为0，来看下原文吧：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813101331216.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n大致意思是说：为了避免过拟合，在这里增加了一个L2惩罚项，推到如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813101959248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n其中，$\\eta$为学习率，而$\\eta\\ \\lambda$ 就是weight_decay，不过pytorch让用户可以自由设置，有了更大的自由度\n- nesterov，布尔类型，默认为False，设为True，可使用NAG动量\n\n**使用方式：**\n```python\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\nfor i in range(epochs):\n    # batch_size=n,每次从dataset取n个样本\n    for input,target in dataset:\n        optimizer.zero_grad()\n        output = model(all_input)\n        loss = loss_fn(output,all_target)\n        loss.backward()\n        optimizer.step()\n```\n（2）**torch.optim.Adagrad**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020081310322668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n主要参数详解：\n- lr-decay 学习率衰减，学习率衰减公式如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813103611835.png)\n其中，$lr_i$为第i次迭代时的学习率，$lr_start$为原始学习率，decay为一个介于[0.0, 1.0]的小数。可以看到，decay越小，学习率衰减地越慢，当decay = 0时，学习率保持不变。decay越大，学习率衰减地越快，当decay = 1时，学习率衰减最快。\n- eps，相当于$\\varepsilon$，是为了保持数值稳定性而设置的非常小的常数， 一般取值 $e^{−7}$ 到 $e^{−10}$\n\n（3）**torch.optim.Adam**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200813160557807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n- betas，默认值（0.9,0.999），即Adam里的$\\beta_1$、$\\beta_2$\n- amsgrad，是否启用Adam的改进方法AMSgrad，默认为False\n\n这里只介绍了需要注意的几个优化函数，更多函数定义，请查阅[pytorch官方文档](https://pytorch.org/docs/stable/index.html)\n\n\n【参考文档】\n神经网络与深度学习-邱锡鹏著\n有三AI-深度学习视觉算法工程师指导手册\n深度学习入门：基于pytorch的理论与实现-陆宇杰译\n深度学习之pytorch实战计算机视觉-唐进民著\n[optim.sgd学习参数](https://blog.csdn.net/apsvvfb/article/details/72536495?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.edu_weight)\n\n","tags":["优化函数"],"categories":["神经网络"]},{"title":"在Windows10中使用 Jupyter Notebook 运行C++","url":"/2020/11/24/222744/","content":"\n在Windows10中使用 Jupyter Notebook 运行C++ ！\n\n<!-- more -->\n\n\n\n## 一、安装Linux子系统\n（1）**开启Subsystem-Linux服务**\n\n鼠标右键开始，选中Windows PowerShell(管理员)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080719424473.png)\n输入 `Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux` 开启服务，**需要重启电脑**\n\n（2）**安装Linux 发行版本**\n鼠标右键开始，选中设置->系统->关于，查看当前Windows10版本，需要 16215 之后的版本才能安装Linux子系统，\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807194800357.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**打开 Microsoft Store 搜索 Linux，选中Ubuntu**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080719495371.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**点击获取：**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807195043302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**大约432M：**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807195111220.png)\n\n（3）**开始初始化Linux**\n\n下载完成后，点击启动，首次启动需要几分钟\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807195315132.png)\n输入账号和密码\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807195530167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n你也可以右键开始，点击运行，输入 `bash` 运行Linux：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807200039210.png)\n**两种方法都可以进入Linux，但是进入的根目录不一样，输入 `pwd` 查看当前的目录**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080720022272.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n`/homw/wxl` 是Linux 系统的用户路径，`/mnt/c/Users/wang1` 是Linux 系统挂载的 Windows 盘符，即C盘。\n\n（4）**更新和升级发行版的软件包**\nLinux默认源是国外的站，所以访问速度可能比较慢，换成阿里的源，步骤如下：\n\n1. 备份之前的源 `sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup`\n2. 打开源文件 `sudo vim /etc/apt/sources.list`\n3. 复制中科大源或阿里云源：\n\n**中科大源：**\n```bash\ndeb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse\ndeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiverse\ndeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse\ndeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse\ndeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiverse\ndeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse\n```\n**阿里云源：**\n```bash\ndeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse\ndeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\n```\n注意：vim，`i` 是编辑模式，可以添加和删除内容，`Esc键` 命令模式（刚进入Vim就是命令模式，命令模式下才可以输入各种命令），`:wq` 是保存并退出。`%d` 删除文件中所有内容的方法：(要切换到命令模式输入)\n\n\n**如下所示**：![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080720164568.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n4.输入如下命令更新软件包\n```bash\nsudo apt update\nsudo apt upgrade\n```\n到这里Linux子系统就安装完成了\n\n## 二、安装 Miniconda\n在Linux命令行输入如下命令安装 Miniconda：\n\n```bash\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n```\n也可以复制`https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh`到浏览器里下载，除非你能科学上网，否则这里下载特别慢，我把下载好的Miniconda3-latest-Linux-x86_64.sh上传到百度云上了，请自行提取，链接：https://pan.baidu.com/s/16US_Jt-UjYC-ox4Siql5vw 提取码：cc0b\n\n先将下载好的Miniconda3-latest-Linux-x86_64.sh文件手动拷贝到windows  `C:\\Users\\wang1` 目录下（wang1是你的用户名），执行`cp /mnt/c/Users/wang1/Miniconda3-latest-Linux-x86_64.sh  /homw/wxl`就拷贝到了Linux 系统的用户路径下，然后执行 `bash Miniconda3-latest-Linux-x86_64.sh`，就可以安装了，中间需要输入两个`yes`，成功界面如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200807212151891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n推荐用Ubuntu启动的方式安装，我用 `bash` 启动的方式安装失败了，然后用这种方式就成功了。\n\n**到这一步，关闭 Ubuntu 重新打开，会发现原来的用户名前面有一个（base），说明安装成功。**\n\n## 三、安装 Jupyter notebook\n输入如下命令安装Jupyter notebook\n\n```bash\npip install jupyter -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com\n```\n注意：我用 `conda install jupyter` 安装之后不能用，我也搞不清楚为什么，大家要留意这个坑。\n\n安装之后，输入 `jupyter notebook` 就可以启动notebook，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808132036301.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n复制划线的地址即可访问，可以看到，报错了，但是不影响访问，如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808132158195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n点击右上角new，只有python核，按`Ctrl + Z或Ctrl + C`关闭notebook，现在我们就安装C++内核吧。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808132305885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n## 四、安装C++内核\n安装c++d的内核插件 `xeus-cling`，这里要用conda安装，pip无法安装。\n\n先设置conda国内源\n\n```bash\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\nconda config --set show_channel_urls yes\n```\n**下面的步骤一定要注意（此处很重要），我就因为这里的坑浪费了一天的时间，没错，就是一天的时间**\n\n\n**本人安装了很多次xeus-cling都因为下载速度太慢而以失败告终，后来发现是因为安装xeus-cling时，我们想通过指定channel加快访问速度时，conda反而会优先访问默认源而非镜像。**\n\n可以通过 `conda config --show` 看到 默认情况下的 `channel_alias` 值是 `https://conda.anaconda.org/` ，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080821212859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**说明，在conda还是优先访问默认源而非镜像，输入如下命令修改默认源：**\n\n```bash\nconda config --set channel_alias https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud\n```\n可以看到，修改之后默认源就变了\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808212254993.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n然后输入下面命令愉快的安装c++内核插件吧，中间需要输入y确认\n\n```bash\nconda install -c conda-forge xeus-cling\n```\n看到这里就安装成功啦\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808212454653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n## 五、使用notebook写C++程序\n\n安装c++内核插件后，再次输入`jupyter notebook` 命令，可以看到右上角多了`C++11、C++14、C++17`，这是不同版本的C++。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808212624883.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n新建一个 C++14 notebook，输入一些 C++ 代码，Shift + Enter 可以得到运行结果，没有报错就大功告成了！\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808212749224.png)\n也可以输入`?cout 或 ?std::cout` 查看cout函数的帮助文档，其他的一些用法可以在 [xeus-cling 的文档](https://xeus-cling.readthedocs.io/en/latest/) 中查看\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808212933561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n**如果我们需要在某个文件夹中保存下 notebook，在要保存的文件夹下按住 shift 单击右键，选择“在此处打开 Linux shell”，这样打开的 Jupyter notebook 的目录就是该目录，新建的 notebook 也自动保存在了当前目录，而不会在 Linux 系统里。**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808213342832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n按`Ctrl+z`关闭notebook，为notebook安装左侧导航插件吧：\n\n```bash\npip install jupyter_nbextensions_configurator jupyter_contrib_nbextensions -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com \njupyter contrib nbextension install --user\njupyter nbextensions_configurator enable –user\n```\n这样左侧就出现导航啦\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808222228505.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n可以再安装 Jupyter lab，比 Jupyter notebook 好看，文件管理也方便，直接安装就可以和 Jupyter notebook 一样使用：\n\n```bash\nconda install -c conda-forge jupyterlab\n\n安装完成后...\n\njupyter lab\n```\n打开 jupyter lab 界面如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808225255441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n**到这里就都大功告成了，留下一个问题，这里为什么报错（如下所示），我还没解决，虽然不影响使用，但是作为强迫症，总想把它去掉，拜托请留言，谢谢了**：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200808235538521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n## 六、Linux常用命令\n\n在linux下，必然要经常和linux打交道，一些简单的linxu命令\n\n1、vim 命令：\n`vim 文件名` 用vim打开文件。vim中，`i` 是编辑模式，可以添加和删除内容，`Esc键` 命令模式（刚进入Vim就是命令模式，命令模式下才可以输入各种命令），`:wq` 是保存并退出。`%d` 删除文件中所有内容的方法：(要切换到命令模式输入)\n\n2、删除文件：\n- `rm 文件名`  \n\n3、删除整个文件夹及文件夹里的文件：\n`rm -rf /var/log/httpd/access` 将会删除/var/log/httpd/access目录以及其下所有文件、文件夹\n说明：\n-r 就是向下递归，不管有多少级目录，一并删除\n-f 就是直接强行删除，不作任何提示的意思\n\n4、拷贝文件：\n\n（1）`cp -rv A B` 拷贝A文件夹到B目录\n（2）如果你正在B目录下,可以这样:  `cp -rv A ./`\n（3）`cp -v A/A1 ./` 拷贝A文件下的A1文件\n\n\n5、赋予权限\n`sudo chmod -R 777` 文件夹\n参数-R是递归的意思\n777表示开放所有权限\n\n`chmod +x 某文件`\n\n如果给所有人添加可执行权限：chmod a+x 文件名；\n如果给文件所有者添加可执行权限：chmod u+x 文件名；\n如果给所在组添加可执行权限：chmod g+x 文件名；\n如果给所在组以外的人添加可执行权限：chmod o+x 文件名；\n\n6、`cd ~` 进入用户根目录\n\n7、查看历史命令\n`history`\n\n8、卸载软件\n`sudo apt-get remove nodejs` 卸载nodejs\n\n9、安装nodejs\n参考 https://blog.csdn.net/qq_41204927/article/details/83537207\n（1）去官网下载最新版nodejs https://nodejs.org/en/download/current/\n（2）卸载已安装的Node和npm，这一点很重要，要不你装好了 node -v 还是原来的版本\n```bash\nsudo apt remove npm  //卸载npm\nsudo apt remove node //卸载node\n\ncd /usr/local/bin   //进入该目录中，若有node或者npm文件，将他删除删除\n```\n\n（3）下载完成后通过XFtp 或者其他类似软件传到服务器上，然后解压到opt目录下\n`tar -xJf /mnt/c/Users/wang1/node-v14.7.0-linux-x64.tar.xz  -C /opt`\n（4）建立链接到 /usr/local/bin/ 目录（但是我试了/usr/bin/成功）\n`sudo ln -s /opt/node-v8.5.0-linux-x64/bin/node /usr/local/bin/node`\n输入`node -v`成功\n`sudo ln -s /opt/node-v14.7.0-linux-x64/bin/node /usr/local/bin/node`或`sudo ln -s /opt/node-v14.7.0-linux-x64/bin/node /usr/bin/node`\n不知道为什么，输入`npm -v`均不成功\n（5）设置淘宝镜像\n```bash\nsudo npm config set registry https://registry.npm.taobao.org   //设置淘宝镜像\nsource ~/.bashrc       //使修改立即生效\n```\n\n【参考文档】\n[在 Win10 中使用 Jupyter notebook 运行 C++ 详细教程](https://blog.csdn.net/qq_20084101/article/details/89494474)\n[Windows 10 安装 Linux 子系统（Windows Subsystem for Linux）](https://blog.csdn.net/qq_20084101/article/details/82316263)\n[windows下使用 Jupyter notebook 运行 C++](https://zhuanlan.zhihu.com/p/84753836)","categories":["工具"]},{"title":"从Inception到Xception，卷积方式的成长之路！","url":"/2020/11/24/222612/","content":"\n2014年Google提出了多尺度、更宽的**Inception**网络结构，不仅比同期的VGG更新小，而且速度更快。Xception则将Inception的思想发挥到了极致，解开了**分组卷积**和大规模应用的序幕。\n\n本文将详细讲述\n- Inception v1的多尺度卷积和Pointwise Conv\n- Inception v2的小卷积核替代大卷积核方法\n- Inception v3的卷积核非对称拆分\n- Bottleneck卷积结构\n- Xception的Depthwise Separable Conv深度可分离卷积\n\n<!-- more -->\n\n\n\n\n\n## 多尺度卷积\nInception 最初提出的版本主要思想是**利用不同大小的卷积核实现不同尺度的感知**，网络结构图如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806113406524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nInception Module基本组成结构有四个成分。1\\*1卷积，3\\*3卷积，5\\*5卷积，3\\*3最大池化。最后对四个成分运算结果进行通道上组合，这就是Inception Module的核心思想：利用不同大小的卷积核实现不同尺度的感知，最后进行融合，可以得到图像更好的表征。\n\n\n使用了多尺度卷积后，我们的网络更宽了，同时也提高了对于不同尺度的适应程度。\n\n## Pointwise Conv\n使用了多尺度卷积后，我们的网络更宽了，虽然提高了对于不同尺度的适应程度，但是计算量也变大了，所以我们就要想办法减少参数量来减少计算量，于是在 **Inception v1** 中的**最终版本**加上了 1x1 卷积核，网络结构图如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806113747780.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*图a与图b的区别就是是否使用了 1x1 卷积进行压缩降维*\n\n使用1x1 卷积核主要目的是进行**压缩降维，减少参数量**，这就是**Pointwise Conv**，简称PW。\n\n\n\n举个例子，假如输入的维度是 96 维，要求输出的维度是 32 维，二种计算方式：\n- 第一种：用3x3的卷积核计算，参数量是`3*3*96*32=27648`（为了方便计算，这里忽略偏置bias，后面的计算均如此）\n- 第二种：先用1x1卷积核将输出通道降维到32，参数量是`1*1*96*32=3072`，再用3x3卷积计算输出，参数量是`3*3*32*32=9216`，总的参数量是`3072+9216=12288`\n\n从结果`12288/27648=0.44`可以看到，第二种方式的参数量是第一种方式的0.44倍，大大减少了参数量，加快训练速度。\n\n\n由Inception Module组成的GoogLeNet（Inception V1）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806125450803.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n> Inception V1 的主要思想是利用不同大小的卷积核实现了不同尺度的感知，再加上1x1 卷积的大量运用，模型比较精简，比VGG更深但是却更小\n\n也有用**Pointwise Conv**做升维的，在 MobileNet v2 中就使用 Pointwise Conv 将 3 个特征图变成 6 个特征图，丰富输入数据的特征。\n\n## 卷积核替换\n\n就算有了Pointwise Conv，**由于 5x5 卷积核直接计算参数量还是非常大，训练时间还是比较长**，于是Google学习VGGNet的特点，提出了**使用多个小卷积核替代大卷积核的方法**，这就是 **Inception V2**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806130828579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n在Inception V2中，使用两个 3x3 卷积核来代替 5x5 卷积，不仅使参数量少了，深度也变深了，提升了神经网络的效果，可谓一举多得。\n> 为什么提升了网络深度，可以提升神经网络效果？\n> 因为多层非线性层(每一层都加了relu)可以提供更复杂的模式学习，而且参数量更少 => 采用堆积的小卷积核优于采用大卷积核（相同感受野的情况下）\n\n现在来计算一下参数量感受下吧！\n\n假设输入 256 维，输出 512 维，计算参数量：\n- 使用 **5x5 卷积核**，参数量为`5*5*256*512=3276800`\n- 使用**两个 3x3 卷积核**，参数量为`3*3*256*256+3*3*256*512=1769472`\n\n\n从结果`1769472/3276800=0.54`可以看到，第二种方式的参数量是第一种方式0.54倍，大大的减少了参数量，加快训练速度。\n\n## 卷积核拆分\n\n在使用多个小卷积核替代大卷积核的方法后，参数量还是比较大，于是Google学习Factorization into small convolutions的思想，在Inception V2的基础上，将一个二维卷积拆分成两个较小卷积，例如将7\\*7卷积拆成1\\*7卷积和7\\*1卷积，这样做的好处是降低参数量。该paper中指出，**通过这种非对称的卷积拆分比对称的拆分为几个相同的小卷积效果更好**，可以处理更多，更丰富的空间特征。这就是**Inception V3**网络结构：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080613330515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n让我们计算下参数量感受下吧！\n\n假设输入 256 维，输出 512 维，计算参数量：\n- 使用 **5x5 卷积核**，参数量为`5*5*256*512=3276800`\n- 先使用**两个 1x5和5x1 卷积核**，参数`1*5*256*256+5*1*256*512=983040`\n\n从结果`983040/3276800=0.3`可以看到，第二种方式的参数量是第一种方式0.3倍，比使用多个小卷积核替代大卷积核的方法减少还多。\n\nInception V4考虑到借鉴了微软的ResNet网络结构思想，等以后再做详细介绍。\n\n## Bottleneck\n我们发现使用上面的结构和方法，参数量还是较大，于是人们提出了 **Bottleneck** 的结构降低参数量。\n\n Bottleneck结构分三步走，首先用Pointwise Conv进行降维，再用常规卷积核进行卷积，最后使用Pointwise Conv进行进行升维，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806135210339.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n来吧，又到了计算参数量的时刻！\n\n假设输入 256 维，输出 512 维，计算参数量：\n- 使用 **3x3 卷积核**，参数量为`3*3*256*256=589824`\n- 使用 **Bottleneck** 的方式，先使用**1x1卷积核**将输入的256维讲到64维，再使用**3x3卷积核**进行卷积，最后用**1x1卷积核**将64升到256维，参数量为`1*1*256*64+3*3*64*64+1*1*64*256=69632`\n\n从结果`69632/3276800=0.12`可以看到，第二种方式的参数量是第一种方式0.12倍，参数量降得令人惊叹！\n\n\n## Depthwise Separable Conv\n人们发现上面的方法参数量还是不少啊，于是又提出了**Depthwise Separable Conv**（深度可分离卷积），这就是大名鼎鼎的**Xception**的网络结构。\n\n\n\nDepthwise Separable Conv的核心思想是**首先经过1\\*1卷积，即Pointwise Convolution（逐点卷积），然后对每一个通道分别进行卷积，即Depthwise Conv（深度卷积）**，这就是**Xception**，即**Extreme Inception**。\n\n\n\n\n我们来回顾一下从Inception到Xception的过程：\n\n（1）典型的Inception结构（Inception V2）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806211303167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（2）简单的Inception结构：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806211439767.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（3）对简单Inception结构进行严格等价变形的Inception结构：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806211608765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（4）极端的Inception结构（Extreme Inception），即Xception（Depthwise Separable Conv）：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806211840236.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\nXception Net的主题结构是以Separable Conv+relu为**基本模块**，再加上1x1卷积作为跳层连接，结构如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806151901810.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n现在我们来对比一下，计算参数量吧！\n\n一般的卷积如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200806142140252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n上图，输入通道2，输出通道3，卷积核大小3x3，参数量为`3*3*2*3=54`\n\nDepthwise Separable Conv如下：\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200904164732940.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70#pic_center)\n\n\n输入通道2，先进行经过1\\*1卷积，输出通道为3，参数量：`1*1*2*3=6`，再对这三个通道分别进行卷积，即进行Depthwise Conv（深度卷积），参数量：`3*3*3=27`，总的参数量为`6+27=33`\n\n\n\n从结果`33/54=0.61`可以看到，第二种方式的参数量是第一种方式0.61倍，如果有更多卷积核对不同通道进行卷积，则参数量降低的效果更明显。\n\n> 需要注意的是，Xception里面的Depthwise Separable Convolution是先PW，后DW。而MobileNet里面的Depthwise Separable Convolution是先DW，后PW，这个在我后面的博客MobileNet里面会有详细介绍，并计算量这两种方式的参数量和性能。\n\n## Suummary\n- Inception v1的多尺度卷积利用不同大小的卷积核实现不同尺度的感知，可以得到图像更好的表征。\n- Inception v1的Pointwise Conv利用1x1卷积核进行压缩降维，减少参数量，使模型更加精简。\n- Inception v2使用多个小卷积核替代大卷积核的方法，不仅使参数量少了，深度也变深了，提升了神经网络的效果。\n- Inception v3的卷积核非对称拆分不仅可以降低参数量，而且可以处理更多，更丰富的空间特征。\n- Bottleneck卷积结构分三步走，参数量降得令人惊叹！\n- Xception的Depthwise Separable Conv首先经过PW，然后DW，再度减少参数量，使分组卷积这样的思想被广泛用于设计性能高效的网络。\n\n基于Xception的网络结构MobileNets构建了轻量级的28层神经网络，成为了移动端上的高性能优秀基准模型；Resnet的残差连接直接skip connect，解决了深层网络的训练问题；可变形卷积 deformable convolution network 通过可变的感受野提升了CNN对具有不同几何形变物体识别能力的模型；DenseNet密集连接网络，把残差做到了极致，提高了特征的利用率；非局部神经网络转换一种思维，采用Non-Local连接，让神经网络具有更大的感受视野；多输入网络可以输入多张图片来完成一些任务；3D卷积虽然带来了暴涨的计算量，但是可以用于视频分类和分割；RNN和LSTM用于处理非固定长度或者大小的视频，语音等，更加适合用来处理这些时序信号；非生成对抗网络GAN已从刚开始的一个生成器一个判别器发展到了多个生成器多个判别器等各种各样的结构......人类的探索历程永无止境，未来必然有更加优秀的卷积方式和CNN架构出现，加油吧，后浪！\n\n\n【参考文档】\n[1] [GoogLeNet中的inception结构，你看懂了吗](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029565&idx=1&sn=330e398a4007b7b24fdf5203a5bf5d91&chksm=871345c0b064ccd6dd7d954c90d63f1f3b883c7d487844cbe3424bec3c9abb66625f1837edbd&scene=21#wechat_redirect)\n[2] [总结12大CNN主流模型架构设计思想](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649031450&idx=1&sn=3f7f159458e5f1621531ee107be11a98&chksm=8712bd67b0653471c052e32b9d18a26f4d6a07852f56b50f6589b3baa7a46e1e44f302204a4e&mpshare=1&scene=1&srcid=0804G8KDpyT32uItY7tg5ELC&sharer_sharetime=1596532639265&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=92bd8fadcb6a4858a01a73460ab9243614f9e6d48f8d78ffc0a9c2f26b5f667bf5a4c95bda3770b77eac3a83af0df071fc66fe56a156ae26d89306dd2ae948ff43fc09a2489c9bc7df445f1a3adb3bbe&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AaY04ggBFXJJbqFKz4uc9W0=&pass_ticket=bfbIoM7yRmV2MGkwcfISFD0R1Uc2EfrGFv2CzbEqH1kNmM/wiobhHOk806C/dvoE)\n[3] [对于xception非常好的理解](https://www.jianshu.com/p/4708a09c4352)\n[4] Chollet F.  Xception: DeepLearningwithDepthwiseSeparableConvolutions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Xception"],"categories":["神经网络"]},{"title":"Alexnet网络结构逐层详细分析+代码实现","url":"/2020/11/24/222439/","content":"\n在2012年Imagenet比赛冠军—Alexnet （以第一作者Alex命名）直接刷新了ImageNet的识别率，奠定了深度学习在图像识别领域的优势地位。网络结构如下图：\n\n<!-- more -->\n\n\n\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080609545260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n下面分别对每层进行介绍：\n（1）**Input** 层：为输入层，AlexNet卷积神经网络默认的输入数据必须是维度为224×224×3的图像，即输入图像的高度和宽度均为224，\n色彩通道是R、G、B三个。\n（2）**Conv1** 层：为AlexNet的第1个卷积层，使用的卷积核为`(11*11*3)*96`（卷积核大小为11\\*11，输入通道为3，输出通道为96），步长为4，Padding为2。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为55，即$55=\\frac{224-11+4}{4}+1$   ，最后输出的特征图的维度为55×55×96。卷积通用公式参考我的博客[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)中卷积中的特征图大小计算方式。\n（3）**MaxPool1** 层  ：为AlexNet的第1个最大池化层，池化核大小为3×3，步长为2。通过套用池化通用公式，可以得到最后输出的特征图的高度和宽度均为27，即 $27=\\frac{55-3}{2}+1$   ，最后得到的输出的特征图的维度为27×27×96。\n（4）**Norm1** 层：为AlexNet的第1个归一化层，即**LRN1**层，local_size=5（相邻卷积核个数设为5），输出的特征图的维度为27*27*96。\n（5）**Conv2** 层  ：为AlexNet的第 2个卷积层，使用的卷积核为`(5*5*96)*256`，步长为1，Padding为2。通过套用卷积通用公式，可以得\n到最后输出的特征图的高度和宽度均为27，即 $27=\\frac{27-5+4}{1}+1$   ，最后得到输出的特征图的维度为27×27×256。\n（6）**MaxPool2** 层  ：为AlexNet的第2个最大池化层，池化核大小为为3×3，步长为2。通过套用池化通用公式，可以得到最后\n输出的特征图的高度和宽度均为13，即  $13=\\frac{27-3}{2}+1$ ，最后得到输出的特征图的维度为13×13×256。\n（7）**Norm2** 层：为AlexNet的第2个归一化层，即**LRN2**层，local_size=5（相邻卷积核个数设为5），输出的特征图的维度为13×13×256。\n（8）**Conv3** 层  ：为AlexNet的第3个卷积层，使用的卷积核`(3*3*256)*384`，步长为1，Padding为1。通过套用卷积通用公式，可以得到最后输出的特征图的高度和宽度均为13，即   $13=\\frac{13-3+2}{1}+1$，最后得到特征图的维度为13×13×384。\n（9）**Conv4** 层  ：为AlexNet的第4个卷积层，使用的卷积核为`(3*3*384)*384`，步长为1，Padding为1。通过套用卷积通用公式，可以得\n到最后输出的特征图的高度和宽度均为13，即 $13=\\frac{13-3+2}{1}+1$   ，最后得到输出的特征图的维度为13×13×384。\n（10）**Conv5** 层  ：为AlexNet的第5个卷积层，使用的卷积核为`(3*3*384)*256`，步长为1，Padding为1。通过套用卷积通用公式，可以得\n到最后输出的特征图的高度和宽度均为13，即 $13=\\frac{13-3+2}{1}+1$，最后得到输出的特征图的维度为13×13×256。\n（11）**MaxPool3** 层  ：为AlexNet的第3个最大池化层，池化核大小为为3×3，步长为2。通过套用池化通用公式，可以得到最后\n输出的特征图的高度和宽度均6，即 $6=\\frac{13-3}{2}+1$，最后得到输出的特征图的维度为6×6×256。\n（12）**FC6** 层  ：为AlexNet的第1个全连接层，输入的特征图的维度为6×6×256，首先要对输入的特征图进行扁平化处理，将其变成维度为1×9216的输入特征图，因为本层要求输出数据的维度是1×4096，所以需要一个维度为9216×4096的矩阵完成输入数据和输出数据的全连接，最后得到输出数据的维度为1×4096。\n（13）**Dropout6** 层：在训练的时候以1/2概率使得隐藏层的某些神经元的输出为0，这样就丢掉了一半节点的输出，反向传播的时候也不更新这些节点，输出的特征图的维度为1×4096。\n（14）**FC7** 层  ：为AlexNet的第2个全连接层，输入数据的维度为1×4096，输出数据的维度仍然是1×4096，所以需要一个维度为4096×4096的矩阵完成输入数据和输出数据的全连接，最后得到输出数据的维度依旧为1×4096。\n（15）**Dropout7** 层：在训练的时候以1/2概率使得隐藏层的某些神经元的输出为0，这样就丢掉了一半节点的输出，反向传播的时候也不更新这些节点，输出的特征图的维度为1×4096(这些神经元还存在，只是置为0了，因此输出维度不变)。\n（16）**FC8** 层  ：为AlexNet的第3个全连接层，输入数据的维度为1×4096，输出数据的维度要求是1×1000，所以需要一个维度为4096×1000的矩阵完成输入数据和输出数据的全连接，最后得到输出数据的维度为1×1000。\n\n**总结**：\n1. 网络比LeNet更深，包括5个卷积层和3个全连接层。\n2. 使用relu激活函数，收敛很快，解决了Sigmoid在网络较深时容易出现梯度消失(或梯度弥散)的问题。\n3. 加入了dropout层，防止过拟合。\n4. 使用了LRN归一化层，通过在相邻卷积核生成的feature map之间引入竞争，从而有些本来在feature map中显著的特征在A中更显著，而在相邻的其他feature map中被抑制，这样让不同卷积核产生的feature map之间的相关性变小，从而增强了模型的泛化能力。\n5. 使用裁剪翻转等操作做数据增强，增强了模型的泛化能力。预测时使用提取图片四个角加中间五个位置并进行左右翻转一共十幅图片的方法求取平均值，这也是后面刷比赛的基本使用技巧。\n6. .分块训练，当年的GPU没有这么强大，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起。\n7. 总体的数据参数大概为240M。\n\n\n**代码实现：**\n\n```python\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n```\n\n参考文档\n深度学习之Pytorch实战计算机视觉[唐进民著]\n[从LeNet到VGG，看卷积+池化串联的网络结构](https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&mid=2649029512&idx=1&sn=a46fc10de7daba25694bda75a916aa91&chksm=871345f5b064cce3c16ab3b7c671f9e93c838836e20d0aa91bc83f7879915d0c8318bcd9d187&mpshare=1&scene=1&srcid=0804y5ewJsTSJKBSVaMNmvrm&sharer_sharetime=1596532567452&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=92bd8fadcb6a4858b2c5b0a38954321b0f8c3dc80d539d1fc2a0778dc107c45ce2aca8614afc433452f4fd83aba02ddb6a1be7e244027038c09196c4dc62cca07dafbdb87d527756f0a49d5105425e85&ascene=1&uin=MjA2Nzc1NzU0Mg==&devicetype=Windows%2010%20x64&version=6209007b&lang=zh_CN&exportkey=AZ6oMa1fen0omFBd4MdcdrU=&pass_ticket=bfbIoM7yRmV2MGkwcfISFD0R1Uc2EfrGFv2CzbEqH1kNmM/wiobhHOk806C/dvoE)","tags":["Alexnet"],"categories":["神经网络"]},{"title":"深入理解ReLU、Leaky ReLU、 PReLU、ELU、Softplus","url":"/2020/11/24/222236/","content":"\n## ReLU\n**ReLU**（Rectified Linear Unit，修正线性单元），也叫Rectifier 函数，它的定义如下：\n\n<!-- more -->\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805112618602.png)\n\nRelu可以实现**单侧抑制**（即把一部分神经元置0），能够稀疏模型， Sigmoid 型活tanh激活函数会导致一个非稀疏的神经网络，而Relu大约 50% 的神经元会处于激活状态，具有很好的稀疏性。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805144836975.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\nRelu函数右侧线性部分梯度始终为1，具有 **宽兴奋边界的特性** （即兴奋程度可以非常高），不会发生神经网络的梯度消失问题， 能够加速梯度下降的收敛速度。而tanh和sigmoid在离0点近的时候梯度大，在远离0点的时候梯度小，容易出现梯度消失。\n\n>  在生物神经网络中， 同时处于兴奋状态的神经元非常稀疏． 人脑中在同一时刻大概只有 1% ∼ 4% 的神经元处于活跃状态\n\n**Relu的缺点**：ReLU 函数不是在0周围， 相当于给后一层的神经网络引入**偏置偏移**，会影响梯度下降的效率。另外，在训练时， 如果参数在一次不恰当的更新后， 某个 ReLU 神经元输出为0，那么这个神经元自身参数的梯度永远都会是0，在以后的训练过程中永远不能被激活， 这种现象称为**死亡 ReLU 问题** （Dying ReLU Problem）\n\n>ReLU 神经元指采用 ReLU 作为激活函数的神经元。\n\n\n\n## Leaky ReLU\n**Leaky ReLU**（带泄露的 ReLU ）在输入 $x < 0$ 时， 保持一个很小的梯度 $\\gamma$． 这样当**神经元输出值为负数**也能有一个非零的梯度可以更新参数， 避免永远不能被激活，Leaky ReLU定义如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805151056568.png)\n其中 $\\gamma$ 是一个很小的常数， 比如 0.01． 当 $\\gamma$ < 1 时， Leaky ReLU 也可以写为\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805151239226.png)\n$max(0.1x,x)$的图像如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805152201645.png)\n\n##  PReLU\n**PReLU**（Parametric ReLU， PReLU，即带参数的 ReLU）引入一个可学习的参数， **不同神经元可以有不同的参数**。 对于第 𝑖 个神经元，ReLU 的定义为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805151431635.png)\n$\\gamma_i$是$x \\le 0$时的梯度， 如果$\\gamma_i$ = 0， 那么PReLU 就退化为 ReLU． 如果 $\\gamma_i$ 为一个很小的常数， 则 PReLU 可以看作Leaky ReLU。 PReLU 可以允许不同神经元具有不同的参数， 也可以一组神经元共享一个参数。\n\n## ELU \n**ELU**（Exponential Linear Unit， 指数线性单元）定义为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805152305703.png)\n其中 $\\gamma$ ≥ 0 是一个超参数，图像如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805152447816.png)\n## Softplus \n**Softplus** 函数 可以看作 Relu 函数的平滑版本，其定义为\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805152555701.png)\n**Softplus 函数其导数刚好是 Logistic 函数。 Softplus 函数虽然也具有单侧抑制、 宽兴奋边界的特性， 却没有稀疏激活性，不会稀疏模型。** 图像如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805154409790.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n这几个函数的图像如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805154737405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n","tags":["激活函数"],"categories":["神经网络"]},{"title":"深入理解dropout(原理+手动实现+实战)","url":"/2020/11/24/222059/","content":"\n在这篇博客中你可以学到\n\n- 什么是dropout\n- dropout为什么有用\n- dropout中的多模型原理\n- 手动实现dropout\n- 在pytorch中使用dropout\n\n\n<!-- more -->\n\n\n\n\n\n当训练一个深度神经网络时， 我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法就称为**dropout**(丢弃法)。\n\n每次选择丢弃的神经元是随机的．最简单的方法是设置一个固定的概率 p．对每一个神经元都以概率 p 随机丢弃（即置0），其原理如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804220653389.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*上图，Bernoulli是概率p的伯努利分布，取值为0或1，即该分布中的每一个元素取值为0的概率是p，$y_{}^{\\left( l \\right)}$表示第 $l$ 个全连接层（或卷积层），x是特征向量*\n\n\n\n在没有使用dropout的情况下，第 $l$ 层的神经元的值经过线性（或卷积）运算后，通过激活函数输出。\n\n如果使用了dropout，第 $l$ 层的神经元的值乘上概率为p的Bernoulli分布，假如第 $l$ 层有10个神经元，那么产生的Bernoulli分布可能是$[0,1,1,0,0,1,0,0,0,1]^T$（相当于以概率p=0.6随机将$l$ 层的神经元置0），然后第 $l$ 层神经元的输出在第 $l+1$ 层经过线性（或卷积）运算后，再通过激活函数输出\n\n\n\n在train阶段，**dropout的本质通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。比如，以概率 p=0.6 随机将神经元置0，就相当于在10个神经元选4个神经元输出(4个神经元在工作，另外6神经元置0)，这时我们就相当于训练了 $C_{10}^4$ 个模型，只是每个模型的参数量更少了**（这也就是集成学习的思想）。使用了dropout的神经网络如下图所示：\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804225113464.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*左图是一般的神经网络，右图是应用了Dropout的网络，Dropout通过随机选择并删除神经元，停止向前传递信号*\n\n\n>机器学习中经常使用集成学习。所谓集成学习，就是让多个模型单独进行学习，推理时再取多个模型的输出的平均值。用神经网络的语境来说，比如，准备5个结构相同（或者类似）的网络，分别进行学习，测试时，以这 5 个网络的输出的平均值作为答案。实验告诉们，通过进行集成学习，神经网络的识别精度可以提高好几个百分点，这个集成学习与Dropout 有密切的关系。这是因为可以将Dropout理解为，通过在学习过程中随机删除神经元，从而每一次都让不同的模型进行学习。并且，推理时，通过对神经元的输出乘以删除比例（比如，0.5 等），可以取得模型的平均值。\n\n\n**由于在测试时， 所有的神经元都是可以激活的， 这会造成训练和测试时网络的输出不一致，那么，测试的时候该怎么办呢？**\n\n答案是**测试的时候让每个模型投票来得到结果**。\n\n比如，训练的时候，10个神经元置中6个置为0(p=0.6，相当于训练时随机删除了6个神经元，**只有4个神经元在工作**)，**测试**的时候是用10个神经元来投票，那么每个神经元的权重是0.4（$1- p = 0.4$），操作的方法是将dropout层这10个神经元的值加起来乘以0.4，即每个神经元的值都乘以0.4。\n\n\n\n\n注意，是**所有神经元输出的值**乘以0.4，比如 **10个神经元每次只选一个神经元工作(以概率p=0.9将神经元置0)，就相当于训练了10个模型**，最后这10个神经元的结果都要输出，做法是把这10个神经元的值加起来乘以0.1（测试时），即相当于投票得出了结果。但是输出的个数不能少，该输出几个数还是几个数。\n\n> 有的教材设定保留神经元的概率为p（保留率），即神经元有效的概率是p，那么，测试的时候将dropout层的神经元乘以 p 输出，而这里神经元无效的概率是p（废弃率），因此，测试的时候将dropout层的神经元乘以 1-p 输出\n\n总的来说，对于一个神经网络层  $y = f\\left( {W \\cdot X + b} \\right)$，我们可以引入一个**掩蔽函数mask**使得 $y = f\\left( {W \\cdot ma{\\rm{s}}k(X) + b} \\right)$ ，设神经元**废弃率**为 p ，**掩蔽函数mask**可表示为：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804231847285.png)\n\n\n\n\n\n\n 一般来讲， 对于隐藏层的神经元， 其**废弃率** p = 0.5 时效果最好， 这对大部分的网络和任务都比较有效． 当 p = 0.5 时， 在训练时有一半的神经元被丢弃， 只剩余一半的神经元是可以激活的， 随机生成的网络结构**最具多样性**，比如10个神经元随机删除5个，则可训练的模型有$C_{10}^5$，相当于取了最大值。 对于输入层的神经元， 其保留率通常设为更接近 1 的数， 使得输入变化不会太大。 **对输入层神经元进行丢弃时， 相当于给数据增加噪声， 以此来提高网络的鲁棒性**。\n\n下面我们就来实现dropout吧\n\n**手动实现dropout：**\n\n```python\nimport numpy as np\nclass Dropout:\n    def __init__(self, dropout_ratio=0.5):\n        self.dropout_ratio = dropout_ratio\n        self.mask = None\n    def forward(self, x, train_flg=True):\n        if train_flg:\n            # *为序列解包\n            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n            return x * self.mask\n        else:\n            return x * (1.0 - self.dropout_ratio)\n    def backward(self, dout):\n        return dout * self.mask\n```\n\n\n\n这里的要点是，每次正向传播时，**掩蔽函数**`self.mask`中都会以False的形式保存要删除的神经元(相当于概率p的伯努利分布)。`self.mask`会随机生成和x形状相同的数组，并将值比dropout_ratio大的元素设为True。反向传播时的行为和ReLU相同。也就是说，**正向传播时传递了信号的神经元，反向传播时按原样传递信号；正向传播时没有传递信号的神经元，反向传播时信号将停在那里**。\n\n\n在pytorch中使用dropout，只需要一行`torch.nn.Dropout(p=0.5)`即可，如下所示\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200805094501511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)","tags":["dropout"],"categories":["神经网络"]},{"title":"Pytorch离线下载并使用torchvision.models预训练模型","url":"/2020/11/24/221921/","content":"\nPytorch离线下载并使用torchvision.models预训练模型\n\n<!-- more -->\n\n原本直接在IDE中执行`models.alexnet(pretrained=True)`就行了，**但是一直报错，搞得我好不难受**！\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804162456348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n不用说，肯定是**由于网络不好导致模型下载失败**，能不能离线下载完之后在本地直接使用？答案是肯定的\n\n其实步骤很简单(但是对于新手要命)，就和我们下载软件一样，详细步骤如下：\n\n1. 复制需要下载的模型地址，粘贴到浏览器地址栏中下载，各种模型的下载地址如下：\n\n```python\n1. Resnet:\n  model_urls = {\n      'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n      'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n      'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n      'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n      'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n  }\n\n2. inception:\n model_urls = {\n      Inception v3 ported from TensorFlow\n     'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n }\n\n3. Densenet: \n model_urls = {\n     'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n     'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n     'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n     'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n }\n\n4. Alexnet:\n model_urls = {\n     'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n}\n\n5. vggnet:\n model_urls = {\n     'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n     'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n     'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n     'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n     'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n     'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n     'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n     'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n }\n```\n2. 这里以`Alexnet`为例，复制`https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth`浏览器地址栏中下载\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020080416345458.png)\n\n大约233M，慢慢下吧，友情提示一下，**在手机上下载每秒几M，在电脑下载每秒几kb，推荐在手机上下载好之后，再发送到电脑上**\n\n\n\n3. 将下载好的文件剪切到**torch缓存文件夹下即可**，windos和linux的torch缓存文件夹分别如下：\n- windows：**C:\\Users\\wang1\\\\.cache\\torch\\checkpoints**\t(wang1是你的电脑用户名)\n- linux：**/root/.cache/torch/hub/checkpoints/alexnet-owt-4df8aa71.pth**\n\n如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804163926693.png)\n4. 然后执行`models.alexnet(pretrained=True)`，发现OK，大功告成！\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200804164034307.png)","tags":["pytorch"],"categories":["pytorch"]},{"title":"python中超级实用的30个内置函数","url":"/2020/11/24/221744/","content":"\n>**python的内置函数是指不需要任何导入，就可以使用的函数**\n\n<!-- more -->\n\n\n\n\n\n\n\n\n\n# max(iterable, *[, default=obj, key=func])\n内置函数max的作用是找到最大值，**对所有容器型数据都可以使用**\n\n- 找到容器的最大值\n\n```python\nIn [311]: a = [1,2,3,3,3,4,2,3]\nIn [312]: max(a)\nOut[312]: 4\n\n# 对于集合，默认是找出键的最大值\nIn [320]: di = {'a':3,'b1':1,'c':4}\nIn [321]: max(di)\nOut[321]: 'c'\n\nIn [316]: max('63447')\nOut[316]: '7'\n# 这里要注意，对于字符串，max是按照第一个字符的Ascii码比较的\nIn [318]: max({'3','10','7'})\nOut[318]: '7'\nIn [319]: max({'3','9','7'})\nOut[319]: '9'\n```\n\n- 找到列表最多重复的元素\n\n```python\nIn [313]: max(a,key=lambda x: a.count(x))\nOut[313]: 3\n```\n\n- 如果容器为0，设置默认值为0\n\n```python\nIn [315]: max([],default=0)\nOut[315]: 0\n```\n\n\n\n\n- 当内置函数max使用`lambda`时，lambda里的x就是容器里面的一个个元素\n\n\n\n```python\n# 找到年龄最大的人\nIn [323]: a = [{'name':'a','age':18,'gender':'male'},{'name':'b','age':20,'gender':'female'}]\n\nIn [324]: max(a,key=lambda x: x['age'])\nOut[324]: {'name': 'b', 'age': 20, 'gender': 'female'}\n```\n\n- 找到每一个列表中第二个元素最大的列表\n\n```python\nIn [325]: lst = [[1,3],[0,6],[4,5]]\nIn [326]: max(lst,key=lambda x: x[1])\nOut[326]: [0, 6]\n```\n\n\n\n# sum(iterable, start=0, /)\n\n- 列表(所有容器型数据均可)求和\n\n\n```python\nIn [327]: a = [1,3,2,1,4,2]\n\nIn [328]: sum(a)\nOut[328]: 13\n\nIn [329]: sum(a,2) # start=2 表示求和的初始值为 2\nOut[329]: 15\n```\n\n\n\n\n\n# sorted(iterable, /, *, key=None, reverse=False)\n\n- 列表排序\n\n```python\nIn [330]: a = [1,2,3,3,4,2,3]\n# 默认从小到大排序\nIn [331]: sorted(a)\nOut[331]: [1, 2, 2, 3, 3, 3, 4]\n# 从大到小排序\nIn [332]: sorted(a,reverse=True)\nOut[332]: [4, 3, 3, 3, 2, 2, 1]\n```\n\n- 按照每一个列表的第二个元素排序\n\n```python\nIn [333]: lst = [[1,4],[3,2]]\nIn [334]: sorted(lst,key = lambda x:x[1])\nOut[334]: [[3, 2], [1, 4]]\n```\n\n\n- 字典排序\n\n```python\n# 对字典直接使用sorted是对键排序\nIn [335]: d = {'a':5,'c':7,'d':6}\nIn [336]: sorted(d)\nOut[336]: ['a', 'c', 'd']\n# 按照字典的值排序，注意是d.items()\nIn [337]: sorted(d.items(),key = lambda x:x[1])\nOut[337]: [('a', 5), ('d', 6), ('c', 7)]\n```\n\n\n\n\n# len(obj, /)\n- 求容器中元素的个数\n\n```python\nIn [340]: dic = {'a':1,'b':3}\nIn [341]: len(dic)\nOut[341]: 2\n\nIn [342]: s = 'abc'\nIn [343]: len(s)\nOut[343]: 3\n```\n\n\n\n\n\n\n\n# pow(x, y, z=None, /)\n\n- x 为底的 y 次幂，如果 z 给出，取余\n\n\n```python\nIn [344]: pow(3, 2)\nOut[344]: 9\n\nIn [345]: pow(3, 2, 4)\nOut[345]: 1\n```\n\n\n\n\n# round(number, ndigits=None)\n\n- 四舍五入，ndigits 代表小数点后保留几位\n\n\n```python\nIn [346]: round(10.0222222, 3)\nOut[346]: 10.022\n\nIn [347]: round(10.02252222, 3)\nOut[347]: 10.023\n\nIn [349]: round(10.0222222)\nOut[349]: 10\n# 默认ndigits为0，返回int\nIn [348]: type(round(10.0222222))\nOut[348]: int\n```\n\n\n\n\n# abs(x, /)\n\n\n```python\nIn [350]: abs(-6)\nOut[350]: 6\n\nIn [351]: abs(-10.223555)\nOut[351]: 10.223555\n```\n\n\n# all(iterable, /)\n- 接受一个迭代器，如果迭代器的所有元素都为真，返回 True，否则返回 False\n\n\n```python\nIn [352]: all([1,0,3,6])\nOut[352]: False\n\nIn [353]: all([1,2,3])\nOut[353]: True\n```\n\n\n#  any(iterable, /)\n\n- 接受一个迭代器，如果迭代器里有一个元素为真，返回 True，否则返回 False\n\n\n```python\nIn [354]: any([0,0,0,[]])\nOut[354]: False\n\nIn [355]: any([0,0,1])\nOut[355]: True\n```\n\n\n\n# bin(number, /)\n\n- 将十进制转换为二进制，返回二进制的字符串\n\n\n```python\nIn [356]: bin(10)\nOut[356]: '0b1010'\n# 0b代表二进制\nIn [357]: 0b1010\nOut[357]: 10\n```\n\n\n\n\n# oct(number, /)\n\n- 将十进制转换为八进制，返回八进制的字符串\n\n\n```python\nIn [358]: oct(12)\nOut[358]: '0o14'\n# 0o代表八进制\nIn [359]: 0o14\nOut[359]: 12\n```\n\n\n\n# hex(number, /)\n\n- 将十进制转换为十六进制，返回十六进制的字符串\n\n\n```python\nIn [360]: hex(15)\nOut[360]: '0xf'\n# 0x代表16进制\nIn [361]: 0xf\nOut[361]: 15\n```\n\n\n# bool(x)\n\n- 如果是一个值，如果为0返回False，如果为1返回True，如果是一个容器，容器为空返回Flase，容器不为空返回True\n\n\n```python\nIn [362]: bool(0)\nOut[362]: False\n\nIn [363]: bool(1)\nOut[363]: True\n\nIn [364]: bool([1,0,0,0])\nOut[364]: True\n\nIn [365]: bool([0])\nOut[365]: True\n\nIn [366]: bool([])\nOut[366]: False\n# 容器中如果是空元素，也返回True\nIn [367]: bool([[],[]])\nOut[367]: True\n\nIn [368]: bool([[]])\nOut[368]: True\n```\n\n\n\n# str(object='')\n\n- 将字符类型、数值类型等转换为字符串类型\n\n\n```python\n# 默认为空\nIn [383]: str()\nOut[383]: ''\nIn [369]: i =123\nIn [370]: str(i)\nOut[370]: '123'\nIn [371]: str(10.235)\nOut[371]: '10.235'\n```\n\n\n\n# ord(c, /)\n\n- 查看某个字符对应的ASCII码，必须传入单个字符串\n\n\n```python\nIn [372]: ord('A')\nOut[372]: 65\n\nIn [374]: ord('0')\nOut[374]: 48\n```\n\n\n\n# dict()、dict(mapping)、dict(iterable)\n\n- 创建数据字典\n- `dict()`，通过构造函数常见字典\n- `dict(mapping)`，通过映射创建字典\n- `dict(iterable)`，通过迭代器创建字典\n\n\n```python\nIn [92]: dict()\nOut[92]: {}\n\nIn [93]: dict(a='a',b='b')\nOut[93]: {'a': 'a', 'b': 'b'}\n\nIn [94]: dict(zip(['a','b'],[1,2]))\nOut[94]: {'a': 1, 'b': 2}\n\nIn [95]: dict([('a',1),('b',2)])\nOut[95]: {'a': 1, 'b': 2}\n```\n\n# object()\n\n- 返回一个根对象，它是所有类的基类\n\n\n```python\nIn [137]: o = object()\nIn [138]: type(o)\nOut[138]: object\n```\n\n- 使用python内置函数dir，返回object的属性、方法列表\n\n\n```python\nIn [379]: dir(o)\nOut[379]: \n['__class__',\n '__delattr__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__']\n```\n\n# int(x, base=10)\n\n`int(x, base =10)`，x 可能为字符串或数值，将 x 转换为一个整数，base是基数\n\n\n\n```python\nIn [380]: int('12')\nOut[380]: 12\n# int没有四舍五入的功能\nIn [382]: int(13.56)\nOut[382]: 13\n```\n\n- `int`的基数base有很大的作用，**可以将任何一个其它进制的数据转化为十进制**\n\n\n```python\n# 将八进制转化为十进制\n# 1*8+2\nIn [384]: int('12',8)\nOut[384]: 10\n# 将16进制转化为10进制\n# 1*16+2\nIn [386]: int('12',16)\nOut[386]: 18\n# 二进制转十进制\nint('0100',2)\n```\n\n\n- 将其它进制的数据转化为十进制的时候，传入的x必须是字符串，否则报错\n\n```python\n# x必须是字符串\nIn [387]: int(12,16)\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-387-2153b26001c8> in <module>\n----> 1 int(12,16)\n\nTypeError: int() can't convert non-string with explicit base\n```\n\n\n\n# float(x=0, /)\n\n- 将一个字符串或整数转换为浮点数\n\n\n```python\nIn [390]: float()\nOut[390]: 0.0\n\nIn [388]: float('30.01')\nOut[388]: 30.01\n\nIn [389]: float(30)\nOut[389]: 30.0\n```\n\n\n\n# list(iterable=(), /)\n\n- 将一个容器转化为列表类型\n\n\n```python\nIn [391]: a = {1,2,3}\nIn [392]: list(a)\nOut[392]: [1, 2, 3]\n\nIn [393]: d = {'a':1,'b':2,'c':3}\nIn [394]: list(d)\nOut[394]: ['a', 'b', 'c']\n\nIn [395]: list(d.items())\nOut[395]: [('a', 1), ('b', 2), ('c', 3)]\n```\n\n\n\n# set()、set(iterable)\n\n- `set()`创建一个空的集合对象\n- `set(iterable)`返回一个集合对象，并允许创建后再增加、删除元素。\n\n**集合的一大优点，容器里不允许有重复元素，因此可对列表内的元素去重。**\n\n\n```python\nIn [397]: a=set()\nIn [399]: a.add('a')\nIn [400]: a\nOut[400]: {'a'}\n\nIn [401]: a = [1,2,1,3,4]\nIn [402]: set(a)\nOut[402]: {1, 2, 3, 4}\n```\n\n\n\n\n# slice(stop)、slice(start, stop[, step])\n\n返回一个由 `range(start, stop, step)` 所指定索引集的 slice 对象\n\n\n```python\nIn [403]: a = [1,2,1,3,4,6,7]\n\nIn [404]: a[slice(0,7,2)] #等价于a[0:7:2]\nOut[404]: [1, 1, 4, 7]\nIn [405]: a[0:7:2]\nOut[405]: [1, 1, 4, 7]\n```\n\n\n\n\n# tuple(iterable=(), /)\n- 将一个迭代器转化为元祖\n\n```python\nIn [409]: a = [1,2,3]\nIn [410]: tuple(a)\nOut[410]: (1, 2, 3)\n\nIn [411]: t = tuple(range(1,10,2))\nIn [412]: t\nOut[412]: (1, 3, 5, 7, 9)\n```\n\n\n# type(object)\n\n- 查看对象的类型\n\n\n```python\nIn [413]: type([1,2,3])\nOut[413]: list\n\nIn [414]: type((1,2,3))\nOut[414]: tuple\n\nIn [415]: type({1,2,3})\nOut[415]: set\n\nIn [416]: type({'a':1,'b':2})\nOut[416]: dict\n```\n\n\n\n# zip(*iterables)\n\n- 创建一个迭代器，聚合每个可迭代对象的元素的`元祖`。\n\n- 参数前带 *，意味着是可变序列参数，可传入 1 个，2 个或多个参数。\n\n\n```python\na = [1,2,3]\nfor i in zip(a):\n    print(i)\n\"\"\"\n    (1,)\n    (2,)\n    (3,)\n\"\"\"\nb = ['a','b','c']\nfor m,n in zip(a,b):\n    print(m,n)\n\"\"\"\n    1 a\n    2 b\n    3 c\n\"\"\"\n```\n\n\n# dir([object])　\n\n- 不带参数时，返回当前范围内的变量、方法和定义的类型列表；带参数时返回参数的属性、方法列表\n\n\n```python\nIn [417]: lst = [1,2,3]\nIn [418]: dir(lst)\nOut[418]: \n['__add__',\n '__class__',\n '__contains__',\n '__delattr__',\n '__delitem__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__mul__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rmul__',\n '__setattr__',\n '__setitem__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n 'append',\n 'clear',\n 'copy',\n 'count',\n 'extend',\n 'index',\n 'insert',\n 'pop',\n 'remove',\n 'reverse',\n 'sort']\n```\n\n\n\n# isinstance(object, classinfo)\n- 判断 object 是否为类 classinfo 的实例，若是，返回 true\n\n\n```python\nclass Node():\n    def __init__(self,value):\n        self.value = value\nnode = Node('node')\nisinstance(node,Node)\n# 输出 True\n```\n\n\n# map(func, *iterables)\n内置函数`map()` 会根据提供的函数对指定序列做映射。\n\n第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表\n\n\n```python\n# 计算平方\ndef square(x) :            \n    return x ** 2\n \nIn [426]: list(map(square, [1,2,3,4,5])) # 计算列表各个元素的平方\nOut[426]: [1, 4, 9, 16, 25]\n\nIn [427]: list(map(lambda x: x ** 2, [1, 2, 3, 4, 5]))  # 使用 lambda 匿名函数\nOut[427]: [1, 4, 9, 16, 25]\n# 提供了两个列表，对相同位置的列表数据进行相加\nIn [428]: list(map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10]))\nOut[428]: [3, 7, 11, 15, 19]\n```\n\n\n# reversed(sequence, /)\n- 逆置序列，返回一个迭代器\n\n```python\nIn [421]: ''.join(reversed('123'))\nOut[421]: '321'\nIn [422]: list(reversed([1,2,3]))\nOut[422]: [3, 2, 1]\n```\n\n\n","tags":["python"],"categories":["python"]},{"title":"python中dict和set的30种操作方法","url":"/2020/11/24/221600/","content":"\n# 字典dict\n\n字典（dict），一种映射对象（mapping）类型，键值对的容器\n\n<!-- more -->\n\n\n\n\n## 创建字典(五种方法)\n\n### 手动创建\n\n\n```python\ndic1 = {} # 创建空字典\ndic2 = {'a':1,'c':3,'e':5}\n```\n\n### 使用 dict() 构造函数\n\n\n```python\ndict() #创建空字典\ndict(a=1,b=2,c=3) # {'a': 1, 'b': 2, 'c': 3}\ndict({'a':1,'b':2},c=3,d=4) \n# {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n```\n\n### 使用可迭代对象\n\n```python\ndict([('a',1),('b',2)],c=3) #  {'a': 1, 'b': 2, 'c': 3}\ndict([('c',3),('d',4),('e',5)]) # {'c': 3, 'd': 4, 'e': 5}\ndict([['c',3],['d',4],['e',5]]) # {'c': 3, 'd': 4, 'e': 5}\ndict((('c',3),('d',4),('e',5))) #  {'c': 3, 'd': 4, 'e': 5}\n```\n\n\n\n\n### 使用fromkeys() 方法\n\n已知键集合（keys），values 为初始值\n\n\n```python\n{}.fromkeys(['k1','k2','k3'],[1,2,3])\n# {'k1': [1, 2, 3], 'k2': [1, 2, 3], 'k3': [1, 2, 3]}\n{'a':1,'b':2}.fromkeys(['c','d'],[1,2])\n# {'c': [1, 2], 'd': [1, 2]}\n```\n\n\n### 使用内置函数zip\n\n\n```python\nlist1 = ['a','b','c','d','e']\nlist2 = [1,3,2,5,6]\ndict(zip(list1,list2))\n# {'a': 1, 'b': 3, 'c': 2, 'd': 5, 'e': 6}\n```\n\n\n\n## 遍历字典\n- d.items()将字典转换为可遍历的列表\n\n```python\nd = {'a':1,'b':2,'c':3}\nfor key, val in d.items():\n    print(key,val)\n\"\"\"\n输出：\na 1\nb 2\nc 3\n\"\"\"\nd.items()\n# dict_items([('a', 1), ('b', 2), ('c', 3)])\n```\n\n下面的写法会报错\n\n```python\nIn [180]: d = {'a':1,'b':2,'c':3}\n\nIn [181]: for key, val in d:\n     ...:     print(key,val)\n     ...: \n---------------------------------------------------------------------------\nValueError: not enough values to unpack (expected 2, got 1)\n```\n\n可以这样写，直接遍历所有的键\n\n```python\nIn [180]: d = {'a':1,'b':2,'c':3}\nIn [183]: for key in d:\n     ...:     print(key)\n     ...: \na\nb\nc\n```\n\n\n## 获取字典所有键集合\n\n\n```python\nd = {'a':1,'b':2,'c':3,'d':4}\n# 方法1\nset(d.keys())\n# 方法2\nset(d)\n# {'a', 'b', 'c', 'd'}\n```\n\n\n## 获取字典所有值集合\n\n\n```python\nlist(d.values())\n# [1, 2, 3, 4]\n```\n\n\n\n## 判断键是否在字典中\n\n```python\nIn [184]: d = {'a':1,'b':2,'c':3,'d':4}\nIn [185]: 'c' in d\nOut[185]: True\n\nIn [186]: 'e' in d\nOut[186]: False\n\nIn [187]: 'e' not in d\nOut[187]: True\n```\n\n\n## 获取某键对应的值\n\n\n```python\nd = {'a':1,'b':2,'c':3,'d':4}\nd.get('c') # 3\n```\n\n\n## 添加或修改一个键值对\n\n\n```python\nIn [189]: d = {'a':1,'b':2,'c':3,'d':4}\n# 添加键值对\nIn [190]: d['e'] = 4\nIn [191]: d\nOut[191]: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 4}\n# 修改键值对\nIn [192]: d['e'] = 'aa'\nIn [193]: d\nOut[193]: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 'aa'}\n```\n\n\n\n## 删除一个键值对\n\n\n```python\nd = {'a':1,'b':2,'c':3,'d':4}\ndel d['d']\nd # {'a': 1, 'b': 2, 'c': 3}\n```\n\n\n## 获取字典视图\n\n字典自带的三个方法 `d.items()、d.keys()、d.values()`，分别返回如下对象：\n\n\n```python\nIn [194]: d = {'a': 1, 'b': 2, 'c': 3}\nIn [195]: d.keys()\nOut[195]: dict_keys(['a', 'b', 'c'])\n\nIn [196]: d.values()\nOut[196]: dict_values([1, 2, 3])\n\nIn [197]: d.items()\nOut[197]: dict_items([('a', 1), ('b', 2), ('c', 3)])\n```\n\n它们都是原字典的视图，修改原字典对象，视图对象的值也会发生改变。\n\n## 键必须是可哈希的对象\n\n**可哈希的对象才能作为字典的键，不可哈希的对象不能作为字典的键，字典的哈希表实现使用从键值计算的哈希值来查找键。**\n\n简要的说可哈希的数据类型，即不可变的数据结构(数字类型（int，float，bool）字符串str、元组tuple、自定义类的对象)。如果一个对象是可哈希的,那么在它的生存期内必须不可变(而且该对象需要一个哈希函数)\n\n**对于不可变类型而言，不同的值意味着不同的内存，相同的值存储在相同的内存**。详情可参考[详解Python中的可哈希对象与不可哈希对象](https://blog.csdn.net/qq_27825451/article/details/102822506)\n\n*同理，不可哈希的数据类型，即可变的数据结构 (字典dict，列表list，集合set)*\n\n\n\n\n\n\n**dict中键必须是可哈希的对象**\n\n\n- list是不可哈希对象\n\n```python\n# list是不可哈希对象\nIn [198]: lst = [1,2]\nIn [199]: d = {lst:'ok'}\n---------------------------------------------------------------------------\nTypeError: unhashable type: 'list'\n```\n\n\n- 元祖是可哈希对象\n\n\n```python\n# 元祖是可哈希对象\nIn [200]: tup = (1,2)\nIn [201]: d = {tup:'ok'}\nIn [202]: d[tup]\nOut[202]: 'ok'\n```\n\n- 自定义类的对象也是可哈希的\n\n```python\nclass Animal:\n    def __init__(self, name):\n        self.name=name\n    def eat(self):\n        print(\"i love eat !\")\n\nan = Animal('123')\nd = {an:'ok'}   \nd[an]\n'''\n'ok'\n'''\n```\n\n\n\n\n## 批量插入键值对\n\n-  使用字典的update方法批量插入键值对\n\n```python\nIn [203]: d = {'a': 1, 'b': 2}\nIn [204]: d.update({'c':3,'d':4,'e':5})\nIn [205]: d\nOut[205]: {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\n```\n\n\n\n## 字典键值对存在不插入，不存在则插入\n\n如果仅当字典中不存在某个键值对时，才插入到字典中；如果存在，不必插入（也就不会修改键值对），这种情况下，使用字典自带方法 setdefault\n\n```python\nIn [206]: d = {'a':1,'b':2}\n# setdefault返回插入的value值\nIn [207]: r = d.setdefault('c',3) # r: 3\nIn [208]: r\nOut[208]: 3\nIn [209]: d\nOut[209]: {'a': 1, 'b': 2, 'c': 3}\n# 已经存在 'c':3 的键值对，所以 setdefault 时 d 无改变\nIn [210]: r = d.setdefault('c',33)\nIn [211]: r\nOut[211]: 3\nIn [212]: d\nOut[212]: {'a': 1, 'b': 2, 'c': 3}\n```\n\n\n\n## 将两个字典合并\n\n\n```python\nIn [213]: d1 = {'a':1,'b':2}\n\nIn [214]: {*d1}\nOut[214]: {'a', 'b'}\n\nIn [215]: {**d1}\nOut[215]: {'a': 1, 'b': 2}\n\nIn [216]: d2 = {'c':3,'a':2}\n# {**d1,**d2} 实现合并 d1 和 d2，返回一个新字典\nIn [217]: {**d1,**d2} # 后面的key会覆盖前面的\nOut[217]: {'a': 2, 'b': 2, 'c': 3}\n# {*d1,*d2} 只能合并 d1 和 d2 的键\nIn [218]: {*d1,*d2}\nOut[218]: {'a', 'b', 'c'}\n```\n\n\n\n\n## 求两个字典的差集\n\n\n```python\nd1 = {'a':1,'b':2,'c':3}\nd2 = {'b':2}\nd3 = dict([(k,v) for k,v in d1.items() if k not in d2])\nd3\n#  {'a': 1, 'c': 3}\n```\n\n\n\n## 按字典的key排序\n\n如果直接使用python内置函数sorted，则只是返回key排序后的集合，可以使用`lambda`按字典的key排序\n\n```python\nIn [220]: d = {'a':5,'d':7,'c':6}\n\nIn [221]: sorted(d)\nOut[221]: ['a', 'c', 'd']\n# 注意是d.items()\nIn [222]: sorted(d.items(),key = lambda x:x[0])\nOut[222]: [('a', 5), ('c', 6), ('d', 7)]\n```\n\n\n\n## 按字典的value排序\n\n\n```python\nIn [220]: d = {'a':5,'d':7,'c':6}\nIn [224]: sorted(d.items(),key = lambda x:x[1])\nOut[224]: [('a', 5), ('c', 6), ('d', 7)]\n```\n\n\n## 获取字典最大key的value\n\n\n```python\nIn [225]: d = {'a':3,'c':1,'b':2}\nIn [226]: max_key = max(d.keys())\nIn [227]: max_key\nOut[227]: 'c'\n\nIn [228]: d[max_key]\nOut[228]: 1\n\nIn [229]: (max_key,d[max_key])\nOut[229]: ('c', 1)\n```\n\n\n\n## 获取字典最大value的key\n\n- 获取字典最大value的key可能有很多\n\n```python\n# 获取字典最大value的key可能有很多\nIn [230]: d = {'a':3,'c':3,'b':2}\nIn [231]: max_val = max(d.values())\nIn [232]: max_vals = [(key,val) for key,val in d.items() if d[key]==max_val ]\n\nIn [233]: max_vals\nOut[233]: [('a', 3), ('c', 3)]\n```\n\n\n\n# 集合\n**集合（set）是一个无序的不重复元素序列，不能用列表直接索引的方式获取集合中的元素**\n\n## 创建集合\n可以使用set() 函数创建集合，注意：**创建一个空集合必须用 set() 而不是 { }，因为 { } 是用来创建一个空字典**\n\n```python\nIn [234]: s_1 = set()\nIn [235]: s_1\nOut[235]: set()\n\nIn [236]: s_2 = { 'orange',  'pear', 'orange', 'banana'}\nIn [237]: s_2\nOut[237]: {'banana', 'orange', 'pear'}\n```\n\n\n\n## 集合并集\n**集合并集就是将两个集合中的元素合并**\n\n- 方法1，集合转化为列表，使用列表的特性\n\n```python\nset1 = {1,3,5,7} \nset2 = {4,5,6}\nset(list(set1)+list(set2))\n#  {1, 3, 4, 5, 6, 7}\n```\n\n- 方法2，使用集合extend方法\n\n```python\n# list添加多个元素的操作是extend\nIn [279]: s_1.update([1,2,3]) #添加多个元素\nIn [280]: s_1.update({3,4}) # 添加集合\n\nIn [281]: s_1\nOut[281]: {1, 2, 3, 4, 'a'}\n```\n- 方法3，使用`|`运算符\n\n```python\nIn [265]: a = {'a','b','c'}\nIn [266]: b = {'c','d'}\n\nIn [268]: a|b\nOut[268]: {'a', 'b', 'c', 'd'}\n```\n\n\n## 集合交集\n\n\n```python\nIn [265]: a = {'a','b','c'}\nIn [266]: b = {'c','d'}\n\nIn [267]: a & b\nOut[267]: {'c'}\n```\n\n## 集合差集\n\n```python\n# 集合a与b的差集：在集合a存在，不在集合b存在的元素\nIn [265]: a = {'a','b','c'}\nIn [266]: b = {'c','d'}\n\nIn [269]: a-b\nOut[269]: {'a', 'b'}\n```\n\n\n## 集合异或\n\n```python\nIn [265]: a = {'a','b','c'}\nIn [266]: b = {'c','d'}\n\nIn [270]: a^b\nOut[270]: {'a', 'b', 'd'}\n```\n\n集合a与b的异或,可以理解为先求出只存在于a的元素集合，在求出只存在于b的元素集合，然后取并集\n\n异或是指相同为1，不同为0\n\n\n\n## 添加元素\n集合添加元素的方法是add，list添加元素的方法是append,insert，**由于集合中的元素是无序的，因此不支持在指定位置添加元素，故没有insert方法**\n\n```python\nIn [274]: s_1={'banana', 'orange', 'pear'}\nIn [275]: s_1.add('apple') #添加一个元素\n\n\nIn [277]: s_1\nOut[277]: {'apple', 'banana', 'orange', 'pear'}\n```\n\n## 移除元素\n- 集合的remove和discard方法都可以移除元素\n\n```python\nIn [282]: s_1 = {'apple', 'banana', 'orange', 'pear'}\nIn [283]: s_1.remove('apple')\n\nInIn [284]: \nIn [284]: s_1\nOut[284]: {'banana', 'orange', 'pear'}\n\nIn [285]: s_1.discard('pear')\nIn [286]: s_1\nOut[286]: {'banana', 'orange'}\n\n```\n注意：***区别*** 来了\n\n\n```python\nIn [287]: 'apple' in s_1\nOut[287]: False\nIn [288]: s_1.remove('apple')\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\n<ipython-input-288-e8c4186ba334> in <module>\n----> 1 s_1.remove('apple')\n\nKeyError: 'apple'\n\nIn [289]: s_1.discard('apple')\n```\n当删除的元素不存在时\n- remove会报错\n- discard不会报错\n\n**集合的pop方法也可以移除元素，由于set是无序的，故set.pop()是随机删除元素**,也正因此，set没有提供排序函数\n\n所以pop的索引是不能用的，即pop里面不能有参数\n\n```python\nIn [290]: print(s_1)\n{'orange', 'banana'}\n\nIn [291]: s_pop = s_1.pop()\nIn [292]: s_pop\nOut[292]: 'orange'\nIn [293]: s_1\nOut[293]: {'banana'}\n```\n\n**set的pop()是随机删除元素**\n\n\n\n\n\n## 集合元素限制\n\n可哈希的数据类型，即不可变的数据结构(数字类型（int，float，bool）字符串str、元组tuple、自定义类的对象)。如果一个对象是可哈希的,那么在它的生存期内必须不可变(而且该对象需要一个哈希函数)\n\n**对于不可变类型而言，不同的值意味着不同的内存，相同的值存储在相同的内存**。详情可参考[详解Python中的可哈希对象与不可哈希对象](https://blog.csdn.net/qq_27825451/article/details/102822506)\n\n同理，不可哈希的数据类型，即可变的数据结构 (字典dict，列表list，集合set)\n\n**集合中的元素必须是可哈希的数据类型**\n\n- 列表是不可哈希的，将不可哈希的列表放入集合中就会报错，如下：\n\n\n```python\nIn [294]: {[1,2]}\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-294-4a5722e7ef02> in <module>\n----> 1 {[1,2]}\n\nTypeError: unhashable type: 'list'\n```\n\n- 将可哈希的元祖放入列表中，则不会报错：\n\n\n```python\nIn [295]: {(1,2),(1,2,3),(1,2)}\nOut[295]: {(1, 2), (1, 2, 3)}\n```\n\n- bool类型也是可哈希的数据类型\n\n```python\nIn [296]: {True,False,True}\nOut[296]: {False, True}\n```\n\n- 字符串也是可哈希的数据类型\n\n```python\nIn [297]: set1 = {'1','2','1'}\nIn [298]: set1\nOut[298]: {'1', '2'}\n```\n\n- 自定义类的对象也是可哈希的\n\n```python\nclass Animal:\n    def __init__(self, name):\n        self.name=name\n    def eat(self):\n        print(\"i love eat !\")\n        \nIn [306]: an = Animal('狗')\nIn [307]: set1 = {an}\nIn [308]: an.name='猫'\n\nIn [309]: a = set1.pop()\nIn [310]: a.name\nOut[310]: '猫'\n```\n\n\n**set集合也可以用python内置函数list()将其转化为列表，从而使用list的所有操作方法**\n\n\n","tags":["python"],"categories":["python"]},{"title":"Python 中 （&，|）和（and，or）之间的区别","url":"/2020/11/24/221418/","content":"\n`（&，|）` 和 `（and，or）`是两组比较相似的运算符。他们的用法如下：\n\n<!-- more -->\n\n\n\n```text\na & b\na | b\na and b\na or b\n```\n（1）如果a，b是数值变量， 则`&`、`|`表示位运算，`and`、`or`则依据是否非0来决定输出，\n\n- **`&`、`|`**\n\n` 1 & 2`，2在二进制里面是`10`，1在进制中是`01`，那么`01`与运算`10`得到是0\n\n```python\nIn [239]: 1 & 2\nOut[239]: 0\n```\n\n- **`and`、`or`**\n\n`and`运算时，`and`中含0，则返回0，均为非0时，则返回后一个值\n\n```python\nIn [240]: 2 and 0\nOut[240]: 0\n\nIn [241]: 2 and 1\nOut[241]: 1\n\nIn [242]: 1 and 2\nOut[242]: 2\n```\n`or`运算时，至少一个非0时，则返回第一个非0\n\n\n```python\nIn [243]: 2 or 0\nOut[243]: 2\n\nIn [244]: 2 or 1\nOut[244]: 2\n\nIn [245]: 0 or 1\nOut[245]: 1\n```\n\n（2）如何a, b是逻辑变量， 则两类的用法基本一致\n\n```python\nIn [247]: True | False\nOut[247]: True\n\nIn [248]: True & False\nOut[248]: False\n\nIn [249]: True and False\nOut[249]: False\n\nIn [250]: True or False\nOut[250]: True\n```\n\n（3）`&、|` 支持set集合运算\n\n如果a与b是两个set集合，则可以做如下运算：\n\n- a与b的交集\n\n```python\nIn [265]: a = {'a','b','c'}\nIn [266]: b = {'c','d'}\n\nIn [267]: a & b\nOut[267]: {'c'}\n```\n\n- a与b的并集\n\n```python\nIn [268]: a|b\nOut[268]: {'a', 'b', 'c', 'd'}\n```\n\n\n除了 `&`、`|` 之外，set集合也支持 `-`、`^` 运算\n\n- a与b的差集：在集合a存在，不在集合b存在的元素\n \n\n```python\nIn [269]: a-b\nOut[269]: {'a', 'b'}\n```\n\n\n- a与b的异或\n\n```python\nIn [270]: a^b\nOut[270]: {'a', 'b', 'd'}\n```\n\na与b的异或,可以理解为先求出只存在于a的元素集合，在求出只存在于b的元素集合，然后取并集\n\n异或是指相同为1，不同为0\n\n\n\n\n【参考文档】\nhttps://www.cnblogs.com/danjiu/p/11332278.html\n","tags":["python"],"categories":["python"]},{"title":"Python中字符串与正则表达式的25个常用操作","url":"/2020/11/24/221218/","content":"\nPython 中没有像 C++ 表示的字符类型（char），所有的字符或串都被统一为 `str` 对象。如单个字符 `c` 的类型也为 `str`，因此在python中**字符也就是字符串**\n\nstr 类型会被经常使用，一些高频用法如下\n\n<!-- more -->\n\n\n\n\n\n# 字符串去空格\n\n- 使用字符串的strip方法去除字符串**开头的结尾**的空格，也可以用字符串的replace方法替换掉所有的空格\n\n```python\nIn [57]: '  I love python  '.strip()\nOut[57]: 'I love python'\nIn [58]: '  I love python  '.replace(' ','')\nOut[58]: 'Ilovepython'\n```\n\n\n\n# 字符串替换\n\n- 使用字符串的replce进行字符替换\n```python\n# 替换所有的字符\nIn [59]: 'i love python'.replace(' ','_')\nOut[59]: 'i_love_python'\n```\n\n# 字符串串联\n- 使用字符串的join方法将**一个容器型中的字符串**联为一个字符串\n\n```python\nIn [60]: '_'.join(['book', 'store','count'])\nOut[60]: 'book_store_count'\nIn [66]: '_'.join(('1','2','3'))\nOut[66]: '1_2_3'\n```\n\n\n# 查找子串位置\n- 使用字符串的find方法返回匹配字符串的**起始位置索引**\n\n```python\nIn [96]: 'i love python'.find('python')\nOut[96]: 7\n```\n\n\n\n# 反转字符串\n- 方法1，使用字符串的join方法和python内置函数将字符串反转\n\n```python\n\nIn [99]: s = \"python\"\nIn [100]: rs = ''.join(reversed(s))\nIn [101]: rs\nOut[101]: 'nohtyp'\n```\n\n- 方法2，利用字符串的切片，只要列表可以使用的切片功能，字符串都可以用\n\n\n\n\n\n```python\nIn [104]: s = \"python\"\nIn [105]: s[::-1]\nOut[105]: 'nohtyp'\n```\n\n\n\n# 字符串切片\n\n- 只要列表可以使用的切片功能，字符串都能用\n\n\n```python\nIn [110]: s = '123456'\nIn [111]: s[1:5]\nOut[111]: '2345'\n\nIn [112]: s[1:5:2]\nOut[112]: '24'\n\nIn [113]: s[::-2]\nOut[113]: '642'\n```\n\n\n\n# 分割字符串\n\n根据指定字符或字符串，分割一个字符串时，使用方法 split。\n\n**join是字符串串联， 和可以把join和split 可看做一对互逆操作**\n\n```python\nIn [114]: 'I_love_python'.split('_')\nOut[114]: ['I', 'love', 'python']\n```\n\n\n# 子串判断\n\n判断 a 串是否为 b 串的子串。\n\n- 方法1，使用成员运算符`in`\n\n```python\nIn [115]: a = 'abc'\nIn [116]: b = 'mnabcdf'\nIn [117]: a in b\nOut[117]: True\n```\n\n- 方法2，使用方法 find，返回字符串 b 中匹配子串 a 的最小索引\n\n  注意：str的find方法与list的index方法用途一样\n\n\n```python\nIn [118]: b.find(a)\nOut[118]: 2\n```\n\n## 去除重复元素\n\n```python\nIn [257]: s = 'abcadcba'\nIn [258]: s = set(s)\nIn [259]: s\nOut[259]: {'a', 'b', 'c', 'd'}\n\nIn [260]: ''.join(s)\nOut[260]: 'bdac'\n```\n\n**得到的结果是乱序的，如果要求和原来的循序一样，勿用此方法**\n\n\n# 正则表达式\n\n字符串封装的方法，处理一般的字符串操作，还能应付。但是，稍微复杂点的字符串处理任务，需要靠正则表达式，简洁且强大。\n\n首先，导入所需要的模块 re\n\n\n```python\nimport re\n```\n\n认识常用的**元字符**：\n\n- `.` 匹配除 \"\\n\" 和 \"\\r\" 之外的任何单个字符。\n- `^` 匹配字符串开始位置\n- `$` 匹配字符串中结束的位置\n- `*` 前面的原子重复 0 次、1 次、多次\n- `?` 前面的原子重复 0 次或者 1 次\n- `+` 前面的原子重复 1 次或多次\n- `{n}` 前面的原子出现了 n 次\n- `{n,}` 前面的原子至少出现 n 次\n- `{n,m}` 前面的原子出现次数介于 n-m 之间\n- `( )` 分组，输出需要的部分\n\n再认识常用的**通用字符**：\n\n- `\\s` 匹配空白字符\n- `\\w` 匹配任意字母/数字/下划线\n- `\\W` 和小写 w 相反，匹配任意字母/数字/下划线以外的字符\n- `\\d` 匹配十进制数字\n- `\\D` 匹配除了十进制数以外的值\n- `[0-9]` 匹配一个 0~9 之间的数字\n- `[a-z]` 匹配小写英文字母\n- `[A-Z]` 匹配大写英文字母\n\n正则表达式，常会涉及到以上这些元字符或通用字符，下面是一些使用方式和小技巧\n\n## search 第一个匹配串\n\n\n```python\nimport re\ns = 'I am a good student'\npat = 'good'\nr = re.search(pat,s)\n# 返回子串的起始位置和终止位置\nr.span()\n# 输出  (7, 11)\n```\n\n\n## match匹配开始位置\n\n正则模块中，match、search 方法匹配字符串不同\n\n- match 在原字符串的开始位置匹配\n- search 在字符串的任意位置匹配\n\n使用match方法的时候，如果子串不是在开始位置则报错\n\n\n```python\nimport re\ns = 'helloworld'\npat = 'wor'\nr = re.match(pat,s)\nr.span()\n# 报错  AttributeError: 'NoneType' object has no attribute 'span'\n```\n把子串`wor`放在最前面，再使用match匹配就不会报错了\n\n\n```python\ns = 'world'\npat = 'wor'\nr = re.match(pat,s)\nr.span()\n# 输出(0, 3)\n```\nmatch场景用的不多，如果只是匹配一个子串的位置，大多数情况下，使用search匹配\n\n\n## finditer匹配迭代器\n\n使用正则模块，finditer 方法，**返回所有子串匹配位置的迭代器**\n\n通过返回的对象 `re.Match`，使用它的方法 span 找出匹配位置\n\n\n```python\nIn [119]: s = 'I am a good student'\nIn [120]: pat = 'a'\nIn [121]: r = re.finditer(pat,s)\nIn [124]: for i in r:\n     ...:     print(i)\n     ...: \n<re.Match object; span=(2, 3), match='a'>\n<re.Match object; span=(5, 6), match='a'>\n```\n\n\n## findall 所有匹配\n\n`findall` 方法能查找出子串的所有匹配。\n\n注意：\n - `findall`是返回所有的匹配\n - `finditer`是返回所有匹配的位置\n\n\n\n```python\ns = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\n```\n\n目标查找出所有所有数字：通用字符 `\\d` 匹配一位数字 [0-9]，`+` 表示匹配数字前面的一个字符 1 次或多次。\n\n不带元字符`+`情况下，输出的是匹配到的一个个数字，这肯定不符合要求\n\n\n```python\nIn [125]: s = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [126]: pat = r'\\d'\nIn [127]: r = re.findall(pat,s)\nIn [128]: print(r)\n['8', '3', '7', '1', '9', '5', '6', '3']\n```\n\n带上元字符`+`\n\n\n```python\nIn [125]: s = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [129]: pat = r'\\d+'\nIn [130]: r = re.findall(pat,s)\nIn [131]: print(r)\n['8371', '9', '56', '3']\n```\n\n`re.findall`返回一个列表，里面包含四个数字，可以看到里面没有小数点，如果我们要找到`9.56`，应该怎么做呢？\n\n## 匹配浮点数和整数\n\n- 元字符`?` 表示前一个字符匹配 0 或 1 次\n- 元字符`.?` 表示匹配小数点（`.`）0 次或 1 次。\n\n匹配浮点数和整数，我们先来看正则表达式：`r'\\d+\\.?\\d+'`，该正则表达式可以理解为：先匹配1个或多个数字，再匹配小数点（`.`）0 次或 1 次，最后匹配1个或多个数字，分解演示如下：\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731172504960.jpg)\n\n```python\ns = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [132]: s = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [133]: pat = r'\\d+\\.?\\d+'\nIn [134]: r = re.findall(pat,s)\nIn [135]: r\nOut[135]: ['8371', '9.56']\n```\n\n\n可以看到，**没有匹配到3**，哪里出错了呢？\n\n出现问题原因：`r'\\d+\\.?\\d+'`， 前面的`\\d+` 表示至少有一位数字，后面的`\\d+`也表示至少有一位数字，因此，整个表达式至少会匹配两位数。\n\n现在将最后的 `+` 后修改为 `*`，表示匹配前面字符 0 次、1 次或多次。如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731172652929.jpg)\n\n\n```python\nIn [132]: s = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [136]: pat = r'\\d+\\.?\\d*'\nIn [137]: r = re.findall(pat,s)\nIn [138]: r\nOut[138]: ['8371', '9.56', '3']\n```\n\n到这里就大功完成了，到这里我们再思考一下，如果把`.?`前面的`\\`去掉以后会怎么样？如下：\n\n\n```python\nIn [132]: s = '呼叫战狼,我是8371,请您在9.56秒后回到3号机场'\nIn [139]: pat = r'\\d+.?\\d*'\nIn [140]: r = re.findall(pat,s)\nIn [141]: r\nOut[141]: ['8371,', '9.56', '3号']\n```\n\n可以看到，匹配到了一个汉字，为什么会出现这种情况呢？因为这里`.?`的含义就变了，之前是把`\\.?`作为一个整体，现在`.?`的含义是附加到`\\d.?`上。\n\n\n`\\d+.?\\d`中`.?`含义如下：\n- `.` 匹配除 `\\n` 和 `\\r` 之外的任何单个字符。\n- 那`.?`就表示匹配`\\n` 和 `\\r` 之外的任何单个字符0 次或 1 次。\n\n我们看下演示图就知道了，`\\d+.?\\d`的演示图如下\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020073117291416.jpg)\n\n\n## 匹配正整数\n\n案例：**写出匹配所有正整数的正则表达式**\n\n我们先来看几个正则表达式即它们的含义\n\n\n前面讲过\n\n- `\\d+` 表示数字出现1次或多次\n- `\\d*` 表示数字出现0次或多次\n\n1. `\\d*` 表示数字出现0次或多次，也就是会匹配所有的字符\n\n\n```python\nIn [142]: s = [2,'我是1','1是我','123',0, 3,'已经9.56秒了',10,-1]\nIn [143]: pat = r'\\d*'\nIn [144]: [i for i in s if re.match(pat,str(i))]\nOut[144]: [2, '我是1', '1是我', '123', 0, 3, '已经9.56秒了', 10, -1]\n```\n\n2. `^\\d*$`,在数字出现0次或多次前加上了开始位置，再后加上了结束位置。即必须是以数字的开头，以数字结尾，才能匹配到\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731173222954.jpg)\n\n```python\nIn [142]: s = [2,'我是1','1是我','123',0, 3,'已经9.56秒了',10,-1]\nIn [145]: pat =r'^\\d*$'\nIn [146]: [i for i in s if re.match(pat,str(i))]\nOut[146]: [2, '123', 0, 3, 10]\n```\n\n\n可以看到，匹配到了0，我们的目的是匹配所有正整数，所以不正确\n\n\n3. `^[1-9]*$` 表示匹配一个 0~9 之间的数字\n\n\n```python\nIn [147]: s = [2,'我是1','1是我','123',0, 3,'已经9.56秒了',10,-1]\nIn [148]: pat =r'^[1-9]*$'\nIn [149]: [i for i in s if re.match(pat,str(i))]\nOut[149]: [2, '123', 3]\n```\n\n可以看到，不能匹配10，因此这个也不正确\n\n4. `^[1-9]\\d*$` 表示匹配一个 0~9 之间的数字并且匹配的数字出现0次或多次\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731173331745.jpg)\n\n\n```python\nIn [150]: s = [2,'我是1','1是我','123',0, 3,'已经9.56秒了',10,-1]\nIn [151]: pat =r'^[1-9]\\d*$'\nIn [152]: [i for i in s if re.match(pat,str(i))]\nOut[152]: [2, '123', 3, 10]\n```\n\n\n\n## re.I 忽略大小写\n\n找出字符串中所有字符 t 或 T 的位置，不区分大小写。\n\n\n```python\ns = 'HELLO，World'\npat = 'L'\nr = re.finditer(pat,s,re.I)\nfor i in r:\n    print(i.span())\n\"\"\"\n输出：\n    (2, 3)\n    (3, 4)\n    (9, 10)\n\"\"\"\n```\n\n​    \n\n\n```python\ns = 'HELLO，World'\npat = 'L'\nr = re.findall(pat,s,re.I)\nr\n# 输出 ['L', 'L', 'l']\n```\n\n\n## re.split分割单词\n\n**正则模块中 split 函数强大，能够处理复杂的字符串分割任务**\n\n对于简单的分割，直接用分隔符\n\n\n```python\nIn [153]: s = 'I-am-a-good-student'\nIn [154]: s.split('-')\nOut[154]: ['I', 'am', 'a', 'good', 'student']\n```\n\n\n但是，对于分隔符复杂的字符串，split 函数就无能为力\n\n如下字符串，可能的分隔符有`, ; - . |`和空格\n\n\n```python\nIn [155]: s = 'I,,,am |  ;a - good.. student'\nIn [156]: s.split('[,;\\-.|]')\nOut[156]: ['I,,,am |  ;a - good.. student']\n```\n\n可以看到，直接使用是区分不开的，所有可以用**正则模块中的split**\n\n`\\s` 匹配空白字符\n\n\n```python\nIn [157]: s = 'I,,,am |  ;a - good.. student'\nIn [158]: w = re.split(r'[,.\\s;\\-|]+',s)\nIn [159]: w\nOut[159]: ['I', 'am', 'a', 'good', 'student']\n```\n\n注意：**re.split默认匹配所有的候选字符**，因此不需要元字符`+`了\n\n但是，如果在字符串前面和后面加多个空格，`\\s`就区分不开了，如下：\n\n```python\nIn [163]: In [157]: s = '  I,,,am |  ;a -     good.. student    '\nIn [164]: w = re.split(r'[,.\\s;\\-|]+',s)\nIn [165]: w\nOut[165]: ['', 'I', 'am', 'a', 'good', 'student', '']\n```\n\n这是，可以用字符串strip方法去除字符串的前后空格\n\n```python\nIn [163]: In [157]: s = '  I,,,am |  ;a -     good.. student    '\nIn [172]: s=s.strip()\nIn [173]: w = re.split(r'[,.\\s+;\\-|]+',s)\nIn [174]: w\nOut[174]: ['I', 'am', 'a', 'good', 'student']\n```\n\n\n## sub 替换匹配串\n\n正则模块，sub 方法，替换匹配到的子串\n\n\n```python\ns = '你好，我是12306'\npat = r'\\d+'\nw = re.sub(pat,'hello',s)\nw\n# 输出 '你好，我是hello'\n```\n\n\n## compile 预编译\n\n如果要用同一匹配模式，做很多次匹配，可以使用 compile 预先编译串\n\n如果我们要：从一系列字符串中，挑选出所有正浮点数\n\n正则表达式为：`^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$`，字符 `a|b `表示 `a` 串匹配失败后，才执行 `b` 串\n\n\n```python\ns = [-1,10,0,7.21,0.5,'123','你好','3.25',11.0,9.]\nrec = re.compile(r'^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$')\n[ i for i in s if rec.match(str(i))]\n# 输出 [7.21, 0.5, '3.25', 11.0, 9.0]\n```\n\n\n","tags":["python"],"categories":["python"]},{"title":"python中list和tuple的22种操作方法","url":"/2020/11/24/221035/","content":"\n# 列表list\n\n列表（list）作为 Python 中最常用的数据类型之一，是一个可增加、删除元素的可变（mutable）容器。\n\n<!-- more -->\n\n\n\n\n## 创建列表\n\n\n```python\nlst = [] #创建空列表\nlst1 = [1,'xiaoming',29.5,'17312662388']\nlst2 = [['hello','world'],[12,'abc'],['冰箱','空调']]\n```\n\n## 查看列表长度\n\n\n```python\nlen(lst) # 0\nlen(lst1) # 4\nlen(lst2) # 3\n```\n\n\n## 遍历列表\n\n\n```python\nIn [16]: for t in lst1:\n    ...:     print(t)\n    ...: \n1\nxiaoming\n29.5\n17312662388\n```\n\n\n```python\nIn [17]: for t1,t2 in lst2:\n    ...:     print(t1,t2)\n    ...: \nhello world\n12 abc\n冰箱 空调\n```\n\n​    \n\n## 元素在列表中的位置\n\n\n```python\nIn [18]: ls_3=[1, 3, 12.3, 'apple', 0.001, 'apple', 'orange', 1, 2, 3, 4]\n# 从列表ls_3 中找出\"apple\" 第一个匹配项的索引位置\nIn [19]: ls_3.index(\"apple\")\nOut[19]: 3\n\nIn [20]: ls_3.index(3)\nOut[20]: 1\n```\n\n\n\n\n\n## 列表中增加元素\n- 方法1 ，使用列表的append方法在列表尾部添加元素\n\n```python\nIn [21]: lst = ['abc','123']\nIn [22]: lst.append('efg')\nIn [23]: lst\nOut[23]: ['abc', '123', 'efg']\n```\n- 方法2，使用列表的insert方法插入元素\n```python\nIn [24]: lst = ['abc','123']\nIn [25]: lst.insert(1,'hello')\nIn [26]: lst\nOut[26]: ['abc', 'hello', '123']\n```\n\n\n## 合并列表\n- 方法1，使用列表的extend方法添加另一列表\n\n```python\nls_3 = ['abc','123']\nls_3.extend([1, 2, 3]) \nls_3.extend([4,5])\nprint (ls_3)\n# ['abc', '123', 1, 2, 3, 4, 5]\n```\n- 方法2，直接使用运算符+合并列表\n\n```python\nIn [27]: ls_3 = ['abc','123']\nIn [28]: ls_4 = [4,5]\nIn [29]: ls_3+ls_4\nOut[29]: ['abc', '123', 4, 5]\n```\n\n- 方法3，使用`*`合并列表\n\n```python\nIn [27]: ls_3 = ['abc','123']\nIn [28]: ls_4 = [4,5]\nIn [31]: [*ls_3]\nOut[31]: ['abc', '123']\nIn [32]: [ls_3]\nOut[32]: [['abc', '123']]\n\nIn [33]: [*ls_3,*ls_4]\nOut[33]: ['abc', '123', 4, 5]\n```\n\n## 移除列表元素\n- 方法1，使用列表的pop方法移除元素\n\n列表的pop默认移除最后一个元素，一个移除指定元素\n\n```python\nIn [35]: lst = ['abc', '123', 'efg','苹果','香蕉']\n# 列表的pop方法返回移除的元素\nIn [36]: a = lst.pop()\nIn [37]: a\nOut[37]: '香蕉'\nIn [38]: lst\nOut[38]: ['abc', '123', 'efg', '苹果']\nIn [39]: b = lst.pop(1)\nIn [40]: b\nOut[40]: '123'\nIn [41]: lst\nOut[41]: ['abc', 'efg', '苹果']\n```\n\n- 方法2，使用列表的remove方法移除元素\n\n```python\nlst = ['abc', '123', 'efg']\n# 列表的remove方法没有返回值\na = lst.remove('efg')\nprint(a) # None\nprint(lst) # ['abc', '123']\n```\n\n- 方法3，使用关键字del删除列表中的元素\n\n```python\na = ['苹果','香蕉','橘子','香蕉']\ndel a[2]\na # ['苹果', '香蕉', '香蕉']\n```\n\n\n\n\n## 列表的深浅拷贝\n\n\n```python\nlst = ['你好',['hello','world'],[12,'abc']]\n# 列表的copy方法只能实现浅copy\ncopy1 = lst.copy()\ncopy1[1][0] = 3\nprint(lst) # ['你好', [3, 'world'], [12, 'abc']]\nprint(copy1) # ['你好', [3, 'world'], [12, 'abc']]\n```\n\n\n要想实现深度拷贝，需要使用 `copy` 模块的 `deepcopy` 函数\n\n\n```python\nfrom copy import deepcopy\nlst = ['你好',['hello','world'],[12,'abc']]\n# 列表的copy方法只能实现浅copy\ncopy1 = deepcopy(lst)\ncopy1[1][0] = 3\nprint(lst) # ['你好', ['hello', 'world'], [12, 'abc']]\nprint(copy1) # ['你好', [3, 'world'], [12, 'abc']]\n```\n\n\n## 判断元素是否在列表中\n\n列表所有数据类型的元素，都可以用该方法判断\n\n\n```python\na = [1,2,3]\n1 in a # True\n5 in a # False\nb = ['你','好','啊']\n'你' in b #True\nc = [(1,2),(3,4)]\n(1,2) in c # True\nc = [([1,2],2),(3,4)]\n([1,2],2) in c #True\nd = [[1,2],[3,4]]\n[1,2] in d # True\n[1,3] in d # False\n'ab' in 'abc' # True\n```\n\n\n## 列表的切片\n\n\n```python\na = list(range(1,20,3))\nprint(a) # [1, 4, 7, 10, 13, 16, 19]\n```\n\n切片的返回结果也是一个列表\n\n- 使用 `a[:3]` 获取列表 a 的前三个元素\n- 使用 `a[-1]` 获取 a 的最后一个元素，返回 int 型，值为 19\n- 使用 `a[:-1]` 获取除最后一个元素的切片 `[1, 4, 7, 10, 13, 16]`\n- 使用 `a[1:5]` 生成索引为 `[1,5)`（不包括索引 5）的切片 `[4, 7, 10, 13]`\n- 使用 `a[1:5:2]` 生成索引 `[1,5)` 但步长为 2 的切片 `[4,10]`\n- 使用 `a[::3]` 生成索引 `[0,len(a))` 步长为 3 的切片 `[1,10,19]`\n- 使用 `a[::-1]` 生成逆向索引 `[len(a),0)` 的切片 `[19, 16, 13, 10, 7, 4, 1]`\n- 使用 `a[::-3]` 生成逆向索引 `[len(a),0)` 步长为 3 的切片 `[19,10,1]`\n\n需要注意的是，`a[1:5:-1]`执行会返回空列表，不是生成`[1,5)`的逆向索引，如果要生成`[1,5)`的逆向索引，可以用如下方式：\n\n\n```python\na[1:5:-1]  # []\nb = a[1:5]\nb[::-1] # [13, 10, 7, 4]\n```\n\n\n## 列表的操作符\n\n列表的操作符只支持`+、*`\n\n```python\nIn [44]: [1, 2,]+[2, 3] #列表合并\nOut[44]: [1, 2, 2, 3]\n\nIn [42]: [1]*3  #列表元素重复\nOut[42]: [1, 1, 1]\n\nIn [43]: [1,2]*3\nOut[43]: [1, 2, 1, 2, 1, 2]\n\n```\n\n\n\n## 列表中某个元素的数量\n\n\n```python\na = ['苹果','香蕉','橘子','香蕉']\nprint(a.count('苹果')) # 1\nprint(a.count('香蕉')) # 2\n```\n\n\n## 列表转化为集合\n\n\n```python\na = ['苹果','香蕉','橘子','香蕉']\nset(a) # {'橘子', '苹果', '香蕉'}\n\n# 集合里面必须是不可哈希对象(不可变对象)\na = [[1,2],[1,2],[1,2,3]]\nset(a) # 报错 unhashable type: 'list'\n```\n\n\n## 判断中有无重复元素\n\n\n```python\n# 方法1\ndef judge_duplicated(lst):\n    for x in lst:\n        if lst.count(x) > 1: # 判断 x 元素在 lst 中的出现次数\n            return True # 重复返回ture\n    return False  # 无重复返回false\n# 方法2\ndef judge_duplicated(lst):\n    return len(lst) != len(set(lst)) # 重复返回ture，不重复返回False\n```\n\n## 列表使用python内置函数\n\n**python内置函数无需import**\n\n\n```python\nlen([1,2,3,4,5]) # 列表长度 5\nmax([1, 5, 65, 5]) #返回列表最大值 65\nmin([1, -1, 89]) #返回列表最小值 -1\nsorted(['10','3','2']) # 从小到大 ['10', '2', '3']\n# 注意：max，min，sorted只能用在全数值型列表中\n```\n\n\n```python\n# 也可以判断字符串大小，判断字符串大小是根据字符串首字符ASCII编码判断的\nmax(['10','3','2']) # 返回`3`\n# 判断字符串直接用运算符\n# '10'>'3' False\n# '10'<'3' True\n```\n\n\n\n\n\n## 列表数据重洗\n\n\n```python\nfrom random import shuffle\na = [1,3,2,5,6]\nshuffle(a) # 重洗数据\na # [3, 2, 6, 1, 5]\n```\n\n## 列表逆置\n\n- 方法1，使用列表的reverse方法对列表元素逆置\n\n```python\n# 方法一\nIn [52]: a = [1,3,2,5,6]\nIn [53]: a.reverse()\nIn [54]: a\nOut[54]: [6, 5, 2, 3, 1]\n\n```\n\n- 方法2，使用python内置函数reversed方法对列表元素逆置\n\n```python\n# 方法2\nIn [52]: a = [1,3,2,5,6]\nIn [56]: list(reversed(a))\nOut[56]: [6, 5, 2, 3, 1]\n```\n- 方法3，利用列表的切片\n\n```python\nIn [102]: a = [1,3,2,5,6]\nIn [103]: a[::-1]\nOut[103]: [6, 5, 2, 3, 1]\n```\n\n## 列表排序规则\n\n- 一般的列表元素排序\n\n```python\n# sorted(a) a要求必须是数值型\na = [1,3,2,5,6]\nsorted(a)\n```\n\n- 按照列表的某个位置排序\n\n如下所示，按照每一个列表的第二个位置排序：\n\n```python\n# 方法一\nIn [45]: a=[[1,2],[4,1],[9,10],[13,-3]]\nIn [46]: a.sort(key=lambda x: x[1])\nIn [47]: a\nOut[47]: [[13, -3], [4, 1], [1, 2], [9, 10]]\n# 方法二\nIn [48]: a=[[1,2],[4,1],[9,10],[13,-3]]\nIn [49]: sorted(a,key = lambda x: x[1] )\nOut[49]: [[13, -3], [4, 1], [1, 2], [9, 10]]\n```\n\n\n## 列表重复最多的元素\n- 找到列表重复最多的元素\n\n```python\nIn [50]: a = [1,2,3,3,4,2,3]\nIn [51]: max(a,key=lambda x: a.count(x), default=1)\nOut[51]: 3\n```\n\n\n\n\n\n# 元组tuple\n\n元祖与列表很相似，只不过元组是不可变（immutable）对象(即不可哈希对象)，元组中的元素**不能修改**，没有增加、删除元素的方法。**元组一旦创建后，长度就被唯一确定**\n\n**创建元素**\n\n```python\ntup_0 = tuple() #创建空元组\ntup_1 = () #创建空元组\ntup_2 = (1, ) #创建只包含一个元素的元组，注意要有逗号,否则会被认为元素本身\ntup_3 = (1, 3, \"apple\", 66) #创建多元素元组\n```\n\n\n**元组除了没有增加、删除元素的方法，不能修改，其他用法与list完全一样，如果我们想要高效的操作元祖，大可用python内置函数list将元祖转化为列表**\n\n**上述列表中的操作，除了增加、删除元素的操作之外，其他的列表操作方法完全可以用在元组上，这里就不一一介绍了**\n\n这里仅说明一些需要注意的点\n\n对于元组，里面的元素可以是任意数据类型，这就意味着也可以是列表、字典等可哈希类型，如下所示：\n\n```python\nIn [82]: a = ([1,2],)\nIn [83]: a[0][0]=3\nIn [84]: a\nOut[84]: ([3, 2],)\nIn [79]: type(a)\nOut[79]: tuple\n```\n**刚刚明明说好元组中的元素不能改变，为什么这里变了？**\n\n这里元组中存的列表的地址，换句话说列表的地址没有改变，只是地址对应的内容变了，如下\n\n```python\nIn [85]: lst = [1,2]\nIn [91]: id(lst) # id获取地址\nOut[91]: 2763791008392\n\nIn [89]: tup=(lst,)\nIn [90]: tup\nOut[90]: ([1, 2],)\n\nIn [92]: lst[0]=3\nIn [93]: lst\nOut[93]: [3, 2]\nIn [94]: tup\nOut[94]: ([3, 2],)\n\nIn [95]: id(lst)\nOut[95]: 2763791008392\n```\n可以看到，列表的地址并没有改变\n\n","tags":["python"],"categories":["python"]},{"title":"Python入门之运算符与基本数据类型详解","url":"/2020/11/24/220821/","content":"\n# Python 的运算符\n\n## 算数运算符\n\n算数运算符 `+ - * / // % **`\n\n`//` 用于两个数值相除且向下取整\n\n<!-- more -->\n\n\n\n\n\n\n```python\nIn [1]: 5//2\nOut[1]: 2\n\nIn [2]: 5//3.0\nOut[2]: 1.0\n```\n\n`**` 用于幂运算\n\n```python\nIn [3]: 2**3\nOut[3]: 8\n```\n\n\n## 比较运算符\n\nPython比较运算符 `== != > < >= <=`，返回值：True/False\n\nPython 比较运算符还支持链式比较，应用起来更加方便\n\n\n```python\ni = 3\nprint(1 < i < 3) # False\nprint(1 < i <= 3) # True\n```\n\n\n关于`==`的详细的用法见[Python中is、in、==之间的区别](https://blog.csdn.net/qq_37555071/article/details/107664916)\n\n## 赋值运算符\n\nPython赋值运算符 `= 、+=、 -=、 \\*=、 /=、 //=、 %=、 **=、 :=`\n\n\n```python\n# 幂赋值运算符 c **= a 等效于 c = c ** a\n#2的5次方\nIn [5]: a = 2\n   ...: a**=5\n   ...: a\nOut[5]: 32\n```\n\n\n## 逻辑运算符\n\nPython逻辑运算符 `and or not`,是指 `与`  `或`  `非` 的意思\n\n\n```python\nIn [6]: True and True\nOut[6]: True\n\nIn [7]: True and False\nOut[7]: False\n\nIn [8]: True or False\nOut[8]: True\n# not优先级最高，使用时一定要注意\nIn [9]: not True and False\nOut[9]: False\n\nIn [10]: not (True and False)\nOut[10]: True\n```\n\n\n\n## 成员运算符\n\nPython成员运算符 `in 、not in `\n\n- 如果元素 i 是 s 的成员，则 `i in s` 为 True\n- 若不是 s 的成员，则返回 False，也就是`i not in s` 为 True\n\n关于`in 、not in `的详细的用法见[Python中is、in、==之间的区别](https://blog.csdn.net/qq_37555071/article/details/107664916)\n\n## 身份运算符\n\nPython身份运算符 `is 、is not`\n\n`is`是Python身份运算符，用于判断两个对象的标识符是否相等(python中万物皆对象)，实质是用于**比较两个对象是否指向同一存储单元**\n\n关于`is 、is not`的详细的用法见[Python中is、in、==之间的区别](https://blog.csdn.net/qq_37555071/article/details/107664916)\n\n# Python 四大数据类型总结\n\n## 数值型\n\n`int` 整型对象、`float` 双精度浮点型、`bool` 逻辑对象，它们都是单个元素，称为数据型\n\n前缀加 `0x`，创建一个十六进制的整数\n\n\n```python\nIn [11]: 0xa5 # 等于十进制的 165\nOut[11]: 165\n```\n\n\n使用 `e` 创建科学计数法表示的浮点数：\n\n\n```python\nIn [12]: 1.05e3 # 1050.0\nOut[12]: 1050.0\n\nIn [13]: 1e3 # 1000.0\nOut[13]: 1000.0\n```\n\n\n## 容器型\n\n可容纳多个元素的容器对象，常用的比如：list 列表对象、 tuple 元组对象、dict 字典对象、set 集合对象\n\n使用一对中括号 `[]`，创建一个 list 型变量\n\n\n```python\nlst = [1,3,5] # list 变量\n```\n\n使用一对括号 `()`，创建一个 `tuple` 型对象\n\n\n```python\ntup = (1,3,5) # tuple 变量\n```\n\n但需要注意，含单个元素的元组后面必须保留一个逗号，才被解释为元组\n\n\n```python\ntup = (1,) # 必须保留逗号\n```\n\n否则会被认为元素本身\n\n\n```python\ntup=(1)\nprint(type(tup))\n# <class 'int'>\n```\n\n仅使用一对花括号 `{}`，创建一个 set 对象\n\n```python\ns = {1,3,5} # 集合变量\n```\n\n**字符串**\n\nPython 中没有像 C++ 表示的字符类型（char），所有的字符或串都被统一为 `str` 对象。如单个字符 `c` 的类型也为 `str`\n\nstr 类型会被经常使用，一些高频用法如下\n\nstrip 用于去除字符串前后的空格\n\n\n```python\n'  I love python  '.strip()\n# 'I love python'\n```\n\n\nreplace 用于字符串的替换\n\n\n```python\n'i love python'.replace(' ','_')\n# 'i_love_python'\n```\n\n\njoin 用于合并字符\n\n\n```python\n'_'.join(['book', 'store','count'])\n# 'book_store_count'\n```\n\nfind 用于返回匹配字符串的起始位置索引\n\n```python\n'i love python'.find('python')\n# 7\n```\n\n\n","tags":["python"],"categories":["python"]},{"title":"Python中is、in、==之间的区别","url":"/2020/11/24/220637/","content":"\nPython 中，对象相等性比较相关关键字包括` is、in`，比较运算符有 `==`\n\n- `is`判断两个对象的标识符是否相等\n- `in`用于成员检测\n- `==`用于判断值或内容是否相等，默认是基于两个对象的标识号比较\n\n也就是说，如果 `a is b` 为 True 且如果按照默认行为，意味着 `a==b` 也为 True\n\n<!-- more -->\n\nPython 中，对象相等性比较相关关键字包括` is、in`，比较运算符有 `==`\n\n- `is`判断两个对象的标识符是否相等\n- `in`用于成员检测\n- `==`用于判断值或内容是否相等，默认是基于两个对象的标识号比较\n\n也就是说，如果 `a is b` 为 True 且如果按照默认行为，意味着 `a==b` 也为 True\n\n## is 判断标识号是否相等\n\n`is`是Python身份运算符，用于判断两个对象的标识符是否相等(python中万物皆对象)，实质是**用于比较两个对象是否指向同一存储单元**，以下有几点`is`的使用方法：\n\n(1) Python 中使用 `id()` 函数获取对象的标识号，可以理解为内存地址\n\n```python\nIn [49]: a = 1\nIn [50]: b = 1\nIn [51]: id(a)\nOut[51]: 140708412432784\nIn [52]: id(b)\nOut[52]: 140708412432784\nIn [53]: a is b\nOut[53]: True\n\nIn [54]: s1 = 'abc'\nIn [55]: s2 = 'abc'\nIn [56]: id(s1)\nOut[56]: 1554773534064\nIn [57]: id(s2)\nOut[57]: 1554773534064\nIn [58]: s1 is s2\nOut[58]: True\n```\n\n\n(2) 由于创建的两个列表实例位于不同的内存地址，所以它们的标识号不等，即便对于两个空列表实例也一样\n\n```python\nIn [77]: a = [1,2]\nIn [78]: b = [1,2]\nIn [79]: id(a)\nOut[79]: 1552668915144\nIn [80]: id(b)\nOut[80]: 1552668915208\nIn [81]: a is b\nOut[81]: False\nIn [83]: a is not b\nOut[83]: True\nIn [84]: not  a is b\nOut[84]: True\n\nIn [85]: a = []\nIn [86]: b = []\nIn [87]: id(a)\nOut[87]: 1552668699208\nIn [88]: id(b)\nOut[88]: 1552669048456\nIn [89]: a is b\nOut[89]: False\n```\n(3) 对于序列型、字典型、集合型对象，一个对象实例指向另一个对象实例，is 比较才返回真值。\n\n```python\nIn [95]: a = [1,2]\nIn [96]: b = a\nIn [97]: a is b\nOut[97]: True\n```\n\n\n(4) 需要注意的是，Python 解释器，对位于区间 `[-5,256]` 内的小整数，会进行缓存，不在该范围内的不会缓存，因此会出现如下现象：\n\n```python\nIn [90]: a = 12345\nIn [91]: b = 12345\nIn [92]: id(a)\nOut[92]: 1552668913040\nIn [93]: id(b)\nOut[93]: 1552668911312\nIn [94]: a is b\nOut[94]: False\n```\n\n(5) Python 中 None 对象是一个单例类的实例，具有唯一的标识号，在判断某个对象是否为 None 时，最便捷的做法：`variable is None`，如下：\n\n```python\nIn [98]: id(None)\nOut[98]: 140708411956448\nIn [99]: a = None\nIn [100]: a is None\nOut[100]: True\nIn [101]: id(a)\nOut[101]: 140708411956448\n```\n\n## in 用于成员检测\n- 如果元素 i 是 s 的成员，则 `i in s` 为 True；\n- 若不是 s 的成员，则返回 False，也就是` i not in s` 为 True\n\nin 是判断成员是否属于某个序列，in 后即可以跟字符串，也可以跟列表,实际上各种集合类型都可以。\n\n（1） 对于字符串类型，`i in s` 为 True，意味着 i 是 s 的子串。\n\n```python\nIn [104]: '234' in '12345'\nOut[104]: True\n# 当然。也可以用字符串的find()方法判断\nIn [105]: '12345'.find('234')\nOut[105]: 1\n```\n（2）列表中任何数据类型的元素都可以用in判断，同理，元祖和集合也可以这样做\n\n```python\nIn [106]: [1,2] in [[1,2],3,'abc']\nOut[106]: True\nIn [107]: lst = [[1,2],3,'abc']\nIn [109]: [1,2] in lst\nOut[109]: True\nIn [110]: 'abc' in lst\nOut[110]: True\n```\n\n（3）对于字典类型，in 操作判断 i 是否是字典的键，但不能直接判断值，如果要判断一个值是否在字典中，可以用字典的values()方法\n\n```python\nIn [111]: dct = {'a':12,'b':35,'key':'abc'}\nIn [112]: 'a' in dct\nOut[112]: True\nIn [113]: 'key' in dct\nOut[113]: True\n\nIn [114]: 12 in dct\nOut[114]: False\nIn [115]: 12 in dct.values()\nOut[115]: True\nIn [116]: 'abc' in dct.values()\nOut[116]: True\n```\n\n（4）对于自定义类型，判断是否位于序列类型中，需要重写序列类型的 魔法方法 __contains__。\n\n```python\nclass Node():\n    def __init__(self,value):\n        self.value = value\n        \nclass Nodes(list):\n        def __contains__(self,node):\n            for s in self:\n                if s.value == node.value:\n                    return True\n            return False    \n\nn1 = Node('linear')\nn2 = Node('sigmoid')\na = Nodes()\na.extend([n1,n2])\nn3 = Node('linear')\nprint(n3 in a) # True\nn4 = Node('tanh')\nprint(n4 in a) # False\n```\n\n## == 判断值是否相等\n（1） **对于数值型、字符串、列表、字典、集合，默认只要元素值相等，== 比较结果是 True**\n\n```python\nIn [117]: str1 = 'abc'\nIn [118]: str2 = 'abc'\nIn [119]: str1 == str2\nOut[119]: True\n\nIn [120]: a = [1,2]\nIn [123]: b = [1,2]\nIn [124]: a == b\nOut[124]: True\n\nIn [125]: a = [[1,2],3]\nIn [126]: b = [[1,2],3]\nIn [127]: a == b\nOut[127]: True\n\nIn [128]: a = {'a':1,'b':2}\nIn [129]: b = {'a':1,'b':2}\nIn [130]: a == b\nOut[130]: True\n\nIn [131]: a = {1,2}\nIn [132]: b = {1,2}\nIn [133]: a == b\nOut[133]: True\n```\n\n（2）对于自定义类型，当所有属性取值完全相同的两个实例，判断 == 时，返回 False。如果需要用`==`判断两个对象是否相等，需要重写方法 `__eq__`，使用` __dict__ `获取实例的所有属性。\n\n```python\nclass Node():\n    def __init__(self,value):\n        self.value = value\n    def __eq__(self,node):\n        return self.__dict__ == node.__dict__\n    \nn1 = Node('linear')\nn2 = Node('sigmoid')\nn3 = Node('linear')\n\nprint(n1.__dict__) # {'value': 'linear'}\nprint(n1 == n2) # False\nprint(n1 == n3) # True\n```\n","tags":["python"],"categories":["python"]},{"title":"python中print函数的所有输出形式","url":"/2020/11/24/220508/","content":"\npython中print函数的所有输出形式\n\n<!-- more -->\n\n\n## 普通输出\n\n```python\nIn [11]: print('b')\nb\n# end为不换行输出\nIn [14]: for i in range(10):\n    ...:     print(i,end='')\n0123456789\n```\n\n## format输出\n\n```python\nIn [16]: a, b = 1, 2\nIn [17]: print('{},{}'.format(a,b))\n1,2\nIn [18]: print('{1},{0}'.format(a,b))\n2,1\n```\n\n## f输出\n\n```python\nIn [16]: a, b = 1, 2\nIn [19]: print(f'{a},{b}')\n1,2\n```\n## %输出\n- %s --- str 字符串\n- %x --- hex 十六进制\n- %d --- dec 十进制\n- %o --- oct 八进制\n\n```python\nIn [16]: a, b = 1, 2\nIn [20]: print('%s,%s'%(a,b))\n1,2\nIn [29]: nHex = 0x20\nIn [30]: print(\"nHex = %x,nDec = %d,nOct = %o\" %(nHex,nHex,nHex))\nnHex = 20,nDec = 32,nOct = 40\n```\n\n## float格式化输出\n- %f --- float 浮点数\n\n\n```python\nIn [32]: import math\nIn [33]: print(\"PI = %f\"%(math.pi))\nPI = 3.141593\n# 保留三维有效数字\nIn [35]: print(\"PI = %.3f\" % math.pi)\nPI = 3.142\n# width = 10,precise = 3,align = right\nIn [36]: print(\"PI = %10.3f\" % math.pi)\nPI =      3.142\n# width = 10,precise = 3,align = left\nIn [37]: print(\"PI = %-10.3f\" % math.pi)\nPI = 3.142\n# 前面填充字符\nIn [38]: print(\"PI = %06d\" % int(math.pi))\nPI = 000003\n```\n\n","tags":["python"],"categories":["python"]},{"title":"卷积神经网络CNN与LeNet5详解(可训练参数量、计算量、连接数的计算+项目实战)","url":"/2020/11/24/220330/","content":"\n## 神经网络\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728094437615.png)\n神经网络可以看成一个端到端的黑盒，中间是隐藏层(可以很深)，两边是输入与输出层，完整的神经网络学习过程如下：\n1. 定义网络结构（指定输入层、隐藏层、输出层的大小）\n2. 初始化模型参数\n3. 循环操作：\n\t\t3.1.  执行前向传播（输入参数，计算一个个结点的值得到y’，即预测值）\n\t\t3.2.  计算损失函数（拿y’-y计算Loss）\n\t\t3.3.  执行后向传播（求梯度，为了更新参数）\n\t\t3.4.  权值更新\n\n<!-- more -->\n\n\n\n## CNN卷积神经网络\n### CNN的由来\n卷积神经网络（CNN）是人工神经网络的一种，是多层感知机（MLP）的一个变种模型，它是从生物学概念中演化而来的。\n\n> Hubel和Wiesel早期对猫的视觉皮层的研究中得知在视觉皮层存在一种细胞的复杂分布，这些细胞对于外界的输入局部是很敏感的，它们被称为“感受野”（细胞），它们以某种方法来覆盖整个视觉域。这些细胞就像一些滤波器一样，够更好地挖掘出自然图像中的目标的空间关系信息。\n视觉皮层存在两类相关的细胞，S细胞（Simple Cell）和C（Complex Cell）细胞。S细胞在自身的感受野内最大限度地对图像中类似边缘模式的刺激做出响应，而C细胞具有更大的感受野，它可以对图像中产生刺激的模式的空间位置进行精准地定位。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728095934616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70 =500x300)\n卷积神经网络已成为语音和图像识别的研究热点，80年代末，Yann LeCun就作为贝尔实验室的研究员提出了卷积网络技术，并展示如何使用它来大幅度提高手写识别能力。在图像识别领域，CNN已经成为一种高效的识别方法\n\nCNN的应用广泛，包括图像分类，目标检测，目标识别，目标跟踪，文本检测和识别以及位置估计等。\n\n\nCNN的基本概念：\n- 局部感受野（local receptive fields）\n- 共享权重（shared weights）\n- 池化（pooling）\n\n### 局部感受野\n**局部感受野（local receptive fields）**：图像的空间联系是局部的，就像人通过**局部的感受野**去感受外界图像一样，每个神经元只感受局部的图像区域，然后在更高层，将这些感受不同局部的神经元综合起来就可以得到全局的信息了。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728104951198.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**CNN中相邻层之间是部分连接，即某个神经单元的感知区域来自于上层的部分神经单元。这个与MLP多层感知机不同，MLP是全连接，某个神经单元的感知区域来自于上层的所有神经单元。**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728105134988.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n### 共享权重\n**共享权重（shared weights）**：共享权重即参数共享，隐藏层的参数个数和隐藏层的神经元个数无关，只和滤波器的大小和滤波器种类的多少有关。也就是说，对于一个特征图，它的每一部分的卷积核的参数都是一样的。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728105613313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*左图是没有参数共享的情况，右图进行了参数共享*\n\n如果要提取不同的特征，就需要多个滤波器。每种滤波器的参数不一样，表示它提出输入图像的不同特征。**这样每种滤波器进行卷积图像就得到对图像的不同特征的反映，我们称之为Feature Map**；100种卷积核就有100个Feature Map，这100个Feature Map就组成了一层神经元。\n\n### 池化\n池化（pooling）原理：根据图像局部相关的原理，图像某个邻域内只需要一个像素点就能表达整个区域的信息， 池化也称为混合、下采样，目的是减少参数量。分为最大池化，最小池化，平均池化。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072811065160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n### CNN的结构\n\n\nCNN的网络结构如下：\n- 输入层，Input，输入可以是灰度图像或RGB彩色图像（三通道）。对于输入的图像像素分量为 [0, 255]，为了计算方便一般需要归一化（如果使用sigmoid激活函数，会归一化到[0, 1]，如果使用tanh激活函数，则归一化到[-1, 1]）\n- 卷积层，C*，特征提取层，得到特征图，目的是使原信号特征增强，并且降低噪音；\n- 池化层，S*，特征映射层，将C*层多个像素变为一个像素，目的是在保留有用信息的同时，尽可能减少数据量\n- 光栅化：为了与传统的多层感知器MLP全连接，就是把池化层得到的特征图拉平\n- 多层感知器(MLP)：最后一层为分类器，多分类使用Softmax，二分类可以使用Logistic Regression\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072811090764.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n**卷积过程包括**：用一个可训练的滤波器fx去卷积一个输入的图像（第一阶段是输入的图像，后面的阶段就是卷积特征图），然后加一个偏置bx，得到卷积层Cx\n**下采样(池化)过程包括**：每邻域四个像素求和变为一个像素，然后通过标量Wx+1加权，再增加偏置bx+1，然后通过一个sigmoid激活函数，产生一个缩小四倍的特征映射图Sx+1。(**下图很重要，下面可训练参数量的计算就可以从这里看出**)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728111236668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n卷积神经网络就是让权重在不同位置共享的神经网络，在下图中，局部区域圈起来的所有节点会被连接到下一层的一个节点上(卷积核，称为 kernel 或 filter 或 feature detector，filter的范围叫做filter size，比如 2x2的卷积核)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728112632366.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n上图的运算过程可用如下公式表示(**上图有重要作用，下面的连接数和神经元个数就可以从这里看出来**)：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728112703711.png)\nCNN学习可以帮我们进行特征提取，比如我们想要区分人脸和狗头，那么通过CNN学习，背景部位的激活度基本很少。\nCNN layer越多，学习到的特征越高阶，如下图所示：\n- layer 1、layer 2学习到的特征基本上是颜色、边缘等低层特征\n- layer 3开始稍微变得复杂，学习到的是纹理特征，比如网格纹理\n- layer 4学习到的是比较有区别性的特征，比如狗头\n- layer 5学习到的则是完整的，具有辨别性关键特征\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728113651972.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n### 光栅化\n**光栅化（Rasterization）**：为了与传统的MLP（多层感知机）全连接，把上一层的所有Feature Map的每个像素依次展开，排成一列。\n图像经过下采样后，得到的是一系列的特征图，而多层感知器接受的输入是一个向量，所以需要将这些特征图中的像素依次取出，排列成一个向量。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072811181585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n## LeNet5详解\n>1990年，LeCun发表了一篇奠定现在CNN结构的重要文章，他们构建了一个叫做LeNet-5的多层前馈神经网络，并将其用于手写体识别。就像其他前馈神经网络，它也可以使用反向传播算法来训练。它之所以有效，是因为它能从原始图像学习到有效的特征，几乎不用对图像进行预处理。\n\nLeNet5共有7层（不包含输入层）:\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728114959612.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n### LeNet5-C1层\nLeNet5的第一层是卷积层\n- 输入图片大小：`32*32`                \n- 卷积窗大小：`5*5`(作者定义)                        \n- 卷积窗种类：`6`(作者定义)\n- 输出特征图数量：`6`  。\n\t由于卷积窗种类是6，故输出的输出特征图数量也是6\n- 输出特征图大小：`(32-5+1)*(32-5+1)=28*28`   \n\t输出特征图大小计算可参考[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)中的特征图大小计算方式\n- 可训练参数量：`(5*5+1)*6`或`(5*5)*6+6`\n\t参数量就是卷积核中元素的个数+偏置bias，总共6种卷积核\n- 计算量：`(5*5+1)*6*28*28`\n\t每一个像素的计算量是`(5*5+1)`，总共`6*28*28`个像素，所以总的计算量是`(5*5+1)*6*28*28`\n- 神经元数量：`(28*28)*6)`\n\t参考上面卷积的计算方式和图像就可以看出，计算出的一个结果(像素点)就是一个神经元\n- 连接数：`(5*5+1)*6*28*28`\n\t参考上面卷积的计算方式和图像就可以看出，输入特征图的每个像素是一个神经元，输出特征图的每个像素也是一个神经元，**只要参与了计算，两个神经元之间就算做一个连接**，**因此卷积中连接数与计算数是一样的**\n\t\n\n\n### LeNet5-S2层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728154632901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)LeNet5的第二层是池化层（池化核大小`2*2`，步长为2）\n- 输入大小：`(28*28)*6 `                 \n- 采样区域(池化核大小)：`2*2` (作者定义)\n- 下采样数量：`6`\n\t这6个下采样的方式其实是一样的\n- 输出特征图大小：`14*14`\n\t输出特征图大小计算可参考[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)中的特征图大小计算方式，卷积和池化输出特征图大小的计算方式是通用的\n- 可训练参数量：`(1+1)*6`\n 池化层的可训练参数量不是池化核元素的个数，而是每一个池化都有一个权重w和偏置b，总共6个下采样，故可训练参数是`(1+1)*6`\n- 计算量 ：`(2*2+1)*14*14*6`\n\t对于池化层的计算量，可能不同地方的描述不一样，我的理解是，采样区域是`2*2` ，要找到最大的采样点，需要比较3次，也就是3次计算，才能找到最大值(如果采样区域是`3*3`，那么需要比较8次才能找到最大值)，然后这个最大值再乘以权重w，加上偏置b，因此得到一个像素点的计算量是`3+1+1=(2*2-1+1+1)=(2*2+1)`，总共`14*14*6`个像素点，可得总共的计算量为`(2*2+1)*14*14*6`\n- 神经元数量：`(14*14)*6`\n\t计算出的一个结果(像素点)就是一个神经元\n- 连接数：`(2*2+1)*[(14*14)*6]`\n\t每四个输入的像素点(输入四个神经元)，输出的像素点为1个(输出一个神经元)，再加上一个偏置的点(偏置神经元)，可得每计算一个像素点的连接数是`(2*2+1)`，总共`(14*14)*6`个像素点，故总的连接数为`(2*2+1)*[(14*14)*6]`，可以看到，**池化中计算量和连接数也是一样的**\n\n### LeNet5-C3层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728154632901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nLeNet5的第3层是卷积层\n- 输入图片大小：`(14*14)*6`                \n- 卷积窗大小：`5*5`(作者定义)                        \n- 卷积窗种类：`16`(作者定义)              \n- 输出特征图数量：`16`  \n- 输出特征图大小：`(14-5+1)*(14-5+1)=10*10`   \n- 可训练参数量：`(6*5*5+1)*16`\n\t每张图片的输入通道是6，我们需要用对应维度的卷积核做卷积运算，也就是要用`6*5*5`的卷积做运算，输出通道是16，因此要有16个这样的卷积核，每个卷积核再加上一个偏置bias，所以参数量是`(6*5*5+1)*16`，可参考[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)\n- 计算量：`(6*5*5+1)*16*10*10`\n\t一个像素点的计算量为`(6*5*5+1)`，总的输出像素个数为`16*10*10`，故总的计算量为`(6*5*5+1)*16*10*10`，这里要注意：**多维卷积计算后需要把每个卷积的计算结果相加，这个相加的结果才是一个像素点，这个计算就忽略不计了**\n- 神经元数量：`10*10*16`\n\t参考上面卷积的计算方式和图像就可以看出，计算出的一个结果(像素点)就是一个神经元\n- 连接数：`(6*5*5+1)*16*10*10`\n\n\t\n\n\n### LeNet5-S4层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728154632901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\nLeNet5的第四层是池化层（池化核大小`2*2`，步长为2）\n- 输入大小：`(10*10)*16 `                 \n- 采样区域(池化核大小)：`2*2` (作者定义)\n- 下采样数量：`16`\n- 输出特征图大小：`5*5`\n- 可训练参数量：`(1+1)*16`\n- 计算量 ：`(2*2+1)*5*5*16`\n- 神经元数量：`5*5*16`\n- 连接数：`(2*2+1)*5*5*16`\n\t\n\n### LeNet5-C5层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728154632901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nLeNet5的第5层是卷积层\n- 输入图片大小：`(5*5)*16`                \n- 卷积窗大小：`5*5`(作者定义)                        \n- 卷积窗种类：`120`(作者定义)              \n- 输出特征图数量：`120`  \n- 输出特征图大小：`(5-5+1)*(5-5+1)=1*1`   \n- 可训练参数量：`(16*5*5+1)*120`\n- 计算量：`(16*5*5+1)*1*1*120`\n- 神经元数量：`1*1*120`\n- 连接数：`(16*5*5+1)*1*1*120`\n\n\n### LeNet5-F6层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728154632901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\nLeNet5的第六层是全连接层\n- 输入图片大小：`(1*1)*120`                \n- 卷积窗大小：`1*1`(作者定义)                        \n- 卷积窗种类：`84`(作者定义)              \n- 输出特征图数量：`84`  \n- 输出特征图大小：`1*1`   \n- 可训练参数量：`(120+1)*84`(全连接层)\n\t这里相当于84个线性模型，即MLP多层感知机\n- 计算量：`(120+1)*84`\n- 神经元数量：`84`\n- 连接数：`(120+1)*84`(全连接层)\n\n### LeNet5-OUTPUT层\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072818211542.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\nLeNet5的第7层是输出层\n- 输入图片大小：1*84\n- 输出特征图数量：1*10\n输出1000000000，则表明是数字0的分类\n\n\n### 计算公式\n**卷积层：设卷积核大小为`k*k`，步长为1，输入特征图(输入图片)大小为`n*n`，输入通道是`a`，输出通道是`b`(输出通道就是卷积核的种类数)**\n- **输出**特征图大小：`(n-k+1)*(n-k+1)=m*m`\n- 可训练参数量：`(a*k*k+1)*b`\n- 计算量：`(a*k*k+1)*b*m*m`\n- 神经元数量：`m*m*b`\n- 连接数：`(a*k*k+1)*b*m*m`\n\n卷积步长为n的输出特征图大小计算方式可参考[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)\n\n**池化层：设池化核大小为`k*k`，步长是stride，输入特征图(输入图片)大小为`n*n`，输入通道是`a`，输出通道是`a`(池化层输入通道和输出通道是样的)**\n- 输出特征图大小：$\\frac{ n-k}{stride} + 1=m$\n\t可参考[神经网络之多维卷积的那些事](https://blog.csdn.net/qq_37555071/article/details/107541194)中的特征图大小计算方式\n- 可训练参数量：`(1+1)*a`\n\t池化层可训练的参数量和池化核大小没有关系\n- 计算量：`(k*k+1)*(m*m*a)`\n- 神经元数量：`m*m*a`\n- 连接数：`(k*k+1)*(m*m*a)`\n\n\n\n## LeNet5实战\n### 定义网络模型\n\n```python\nimport torch\nfrom torch import nn,optim\nimport torchvision\nimport torch.nn.functional as F\n#没参数可以用nn，也可以用F，有参数的只能用nn\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #定义卷定义层卷积层,1个输入通道，6个输出通道，5*5的filter,28+2+2=32\n        #左右、上下填充padding\n        #MNIST图像大小28，LeNet大小是32\n        self.conv1 = nn.Conv2d(1,6,5,padding=2)\n        #定义第二层卷积层\n        self.conv2 = nn.Conv2d(6,16,5)\n        \n        #定义3个全连接层\n        self.fc1 = nn.Linear(16*5*5,120)\n        self.fc2 = nn.Linear(120,84)\n        self.fc3 = nn.Linear(84,10)\n        \n    #前向传播\n    def forward(self,x):\n        #先卷积，再调用relue激活函数，然后再最大化池化\n        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n        x=F.max_pool2d(F.relu(self.conv2(x)),(2,2))        \n        #num_flat_features=16*5*5\n        x=x.view(-1,self.num_flat_features(x))\n\n        #第一个全连接\n        x=F.relu(self.fc1(x))\n        x=F.relu(self.fc2(x))\n        x=self.fc3(x)\n        return x\n    def num_flat_features(self,x):\n        size=x.size()[1:]\n        num_features=1\n        for s in size:\n            num_features=num_features*s\n        return num_features \n```\n### 初始化模型参数\n\n```python\nimport torchvision.datasets as datasets\n#import torchvision.transforms as transforms \nfrom torchvision import transforms\n\nfrom torch.utils.data import DataLoader\n\n#超参数定义\n#人为定义的参数是超参数，训练的是参数\nEPOCH = 10               # 训练epoch次数\nBATCH_SIZE = 64     # 批训练的数量\nLR = 0.001                # 学习率\n\n#首次执行download=True，下载数据集\n#mnist存在的路径一定不要出现 -.？等非法字符\ntrain_data=datasets.MNIST(root='./dataset',train=True,transform=transforms.ToTensor(),download=False)\ntest_data=datasets.MNIST(root='./dataset',train=False,transform=transforms.ToTensor(),download=False)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint('训练集大小',train_data.train_data.size())\nprint('训练集标签个数',train_data.train_labels.size())\nplt.imshow(train_data.train_data[0].numpy(),cmap='gray')\nplt.show()\n```\n输出：\n\n\t\t训练集大小 torch.Size([60000, 28, 28])\n\t\t训练集标签个数 torch.Size([60000])\n\n\n​\t\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728182811711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n​\t\n\n```python\n#如果有dataloader 的话一般都是在dataset里，dataloader和dataset 这俩一般一起用的\n#使用DataLoader进行分批\n#shuffle=True是设置随机数种子\ntrain_loader=DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\ntest_loader=DataLoader(dataset=test_data,batch_size=BATCH_SIZE,shuffle=True)\n\n#创建model\nmodel=LeNet5()\n#定义损失函数\ncriterion=nn.CrossEntropyLoss()\n#定义优化器\noptimizer=optim.Adam(model.parameters(),lr=1e-3)\n\n#device  cuda:0是指使用第一个gpu\ndevice=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# device=torch.device('cpu')\nprint(device,type(device))\nmodel.to(device)\n```\n### 训练\n\n```python\n\n# 训练\nfor epoch in range(EPOCH):\n    for i,data in enumerate(train_loader):\n        inputs,labels=data\n        #可能会使用GPU，注意掉就不会在gpu里运行了\n        inputs,labels=inputs.to(device),labels.to(device)\n        # print(type(inputs),inputs.size(),'\\n',inputs)\n        #前向传播\n        outpus=model(inputs)\n        \n        #计算损失函数\n        loss=criterion(outpus,labels)\n        #清空上一轮梯度\n        optimizer.zero_grad()\n        #反向传播\n        loss.backward()\n        #参数更新\n        optimizer.step()\n \n    print('epoch {} loss:{:.4f}'.format(epoch+1,loss.item()))\n```\n输出：\n\n\tepoch 1 loss:0.1051\n\tepoch 2 loss:0.0102\n\tepoch 3 loss:0.1055\n\tepoch 4 loss:0.0070\n\tepoch 5 loss:0.2846\n\tepoch 6 loss:0.1184\n\tepoch 7 loss:0.0104\n\tepoch 8 loss:0.0014\n\tepoch 9 loss:0.0141\n\tepoch 10 loss:0.0126\n\n\n​\t\n### 测试准确率\n\n```python\n#保存训练模型\ntorch.save(model,'dataset/mnist_lenet.pt')\nmodel=torch.load('dataset/mnist_lenet.pt')\n\n#测试\n\"\"\"\n训练完train_datasets之后，model要来测试样本了。\n在model(test_datasets)之前，需要加上model.eval(). \n否则的话，有输入数据，即使不训练，它也会改变权值。\n\"\"\"\nmodel.eval()\ncorrect=0\ntotal=0\n\nfor data in test_loader:\n    images,labels=data\n    images,labels=images.to(device),labels.to(device)\n    #前向传播  model(images)  和 model.forward(x)一样的\n    out=model(images)\n    \"\"\"\n    首先得到每行最大值所在的索引（比图第7个分类是最大值，则索引是7）\n    然后，与真实结果比较（如果一个样本是图片7，那么该labels是7），如果相等，则加和\n    \"\"\"\n    _,predicted=torch.max(out.data,1)\n    total=total+labels.size(0)\n    correct=correct+(predicted==labels).sum().item()\n    \n#输出测试的准确率\nprint('10000张测试图像 准确率：{:.4f}%'.format(100*correct/total))\n```\n输出：\n\n\t\t10000张测试图像 准确率：98.9400%\n### 预测结果\n\n```python\n#记住，输入源一定要转化为torch.FloatTensor，否则无法预测，并且一定要加model.eval()，否则会更新权重\ndef predict_Result(img):\n    \"\"\"\n    预测结果，返回预测的值\n    img，numpy类型，二值图像\n    \"\"\"\n    model.eval()\n    img=torch.from_numpy(img).type(torch.FloatTensor).unsqueeze(0).unsqueeze(1)\n    img=img.to(device)\n    out=model(img)\n    _,predicted=torch.max(out.data,1)\n    return predicted.item()\n    \nimg2=train_data.train_data[167].numpy()\nplt.imshow(img2,cmap='gray')\nprint('预测结果：',predict_Result(img2))\n```\n\n输出：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200728183140187.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n","tags":["LeNet5"],"categories":["神经网络"]},{"title":"Python函数参数之*与**用法详解","url":"/2020/11/24/220157/","content":"\n首先，我们来看一个函数定义：\n\n```python\ndef f(a,*b,**c):\n    print(f'a:{a},b:{b},c:{c}')\n```\n`*b与**c`都是可变参数\n- 出现带一个星号的参数 b，**这是可变位置参数**\n- 带两个星号的参数 c，**这是可变关键字参数**\n\n<!-- more -->\n\n\n\n首先，我们来看一个函数定义：\n\n```python\ndef f(a,*b,**c):\n    print(f'a:{a},b:{b},c:{c}')\n```\n`*b与**c`都是可变参数\n- 出现带一个星号的参数 b，**这是可变位置参数**\n- 带两个星号的参数 c，**这是可变关键字参数**\n\n现在执行如下代码：\n\n```python\nIn [2]: f(1,2,3,w=4,h=5)\na:1,b:(2, 3),c:{'w': 4, 'h': 5}\n```\n可以看到，参数 b 被传递 2 个值，参数 c 也被传递 2 个值。**可变位置参数 b 被解析为元组，可变关键字参数 c 被解析为字典**。\n\n下面有几个重要规则：\n\n（1）**可变位置参数不能传入关键字参数**\n\n```python\nIn [41]: def f(*a):\n    ...:   print(a)\nIn [42]: f(1)\n(1,)\nIn [43]: f(1,2,3)\n(1, 2, 3)\nIn [44]: f(a=1)\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-44-6a0ab2c303a9> in <module>\n----> 1 f(a=1)\nTypeError: f() got an unexpected keyword argument 'a'\n```\n（2） **可变关键字参数不能传入位置参数**\n\n```python\nIn [45]: def f(**a):\n    ...:   print(a)\nIn [46]: f(a=1)\n{'a': 1}\nIn [47]: f(a=1,b=2,width=3)\n{'a': 1, 'b': 2, 'width': 3}\nIn [48]: f(1)\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-48-281ab0a37d7d> in <module>\n----> 1 f(1)\nTypeError: f() takes 0 positional arguments but 1 was given\n```\n","tags":["python"],"categories":["python"]},{"title":"Anaconda与jupyter安装、操作及插件安装","url":"/2020/11/24/215911/","content":"# 一、anaconda简介\n\n1. 进入官网https://www.anaconda.com\n2. 点解download进入下载页面\n3. 按步骤安装(默认，下一步)\n4. 启动jupyterlab应用\n\n![\\[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-pELNUSl3-1595855913557)(attachment:launch.jpg)\\]](https://img-blog.csdnimg.cn/20200727212201931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n<!-- more -->\n\n\n\n# 二、jupyter lab 基本操作\n\n## 1. jupyter lab 简介\n\n- JupyterLab包含了Jupyter Notebook所有功能。\n- JupyterLab作为一种基于web的集成开发环境，你可以使用它编写notebook、操作终端、编辑markdown文本、打开交互模式、查看csv文件及图片等功能\n\n## 2. jupyter lab 基本操作\n\n### 2.1 操作模式\n\n两种操作模式 `command  mode`  和  `edit  mode`\n\n在一个`cell`中按下`enter`就进入edit  mode，按下`Esc`进入command  mode\n\n### 2.2 cell转换类型\n\n- code:代码环境\n- markdown: 带有latex公式输入的增强markdown\n- raw：纯文本\n\n**cell类型转换方式**\n\n- 鼠标操作\n- 快捷键\n\ncommand模式下：m:markdown r:raw text y:code\n\n### 2.3 运行cell\n\n- shift+enter:运行并跳转到下一个cell\n- control+enter：运行并停留在当前cell\n\n### 2.4 增加/删除cell\n\n- 鼠标操作：两种模式均可\n- 快捷键：a/d command模式\n\n\n1. A 在当前cell的上面添加cell\n2. B 在当前cell的下面添加cell\n3. 双击D  快速删除当前cell\n\n### 2.5 代码提示功能\n\n- tab 代码补全或缩进\n- Shift-Tab 提示\n- 更多快捷键参照 [Jupyter Notebook骚操作](https://mp.weixin.qq.com/s?__biz=MzU5MjI3NzIxMw==&mid=2247488276&idx=2&sn=696900f0744474486eece7dee706e31e&chksm=fe2368a6c954e1b01e7e5943b697c1aec840aba995446230d9c6dc385f8471750002539a5921&mpshare=1&scene=24&srcid=&sharer_sharetime=1591664539198&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&ascene=14&devicetype=android-29&version=27000f3d&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&exportkey=AX%2BZM%2BDxUN6bs5k3X3SQbQY%3D&pass_ticket=njbcV9rUgIhNR7K4XdDWqfGsAPAcyPs1nE8Eoab4vyjmTWneMPO%2FDwraZRwPmQxP&wx_header=1)\n\n### 2.6 注释多行代码\n- ctrl / 注释多行代码\n\n### 2.6 运行py文件\n```python\n% run path/filename \n```\n例如：\n```python\n%run C:\\Users\\wang1\\Desktop\\go.py\n```\n\n\n### 2.7 Markdown标题级别\n\n- 命令行模式下，1 2 3 4 5 6分别是1-6级标题\n\n### 2.8 cell加行号\n\n- 命令行模式下，shilt+L为所有cell加上行号，L不持支给单个cell加行号\n- 鼠标点击view显示行号\n\n### 2.9 cell合并分割\n\n- 编辑模式，`crtl shift - 在光标处分割cell`\n- 命令行模式 `shift 鼠标 选中多个cell`  \n`shift m 合并选中给的cell`\n\n# 三、插件安装\n- 更新插件：`jupyter labextensio update 插件名`\n- 更新所有插件：`jupyter labextension update --all`\n- 卸载插件：`jupyter labextensio uninstall 插件名`\n- 安装插件：`jupyter labextensio install 插件名`\n- 远程仓库安装插件：`jupyter labextension install 参考地址`\n- 安装制定版本插件：`jupyter labextensio install 插件名=版本号`\n- 查看已安装插件：`jupyter labextension list`\n\n安装目录插件，可以执行如下命令：\n```powershell\njupyter labextension install @jupyterlab/toc\n或者\njupyter labextension install https://github.com/jupyterlab/jupyterlab-toc.git\n```\n收藏了几个很实用的jupyter插件网站，如下：\n\n## 1.Jupyter Notebook目录插件\n\nhttps://www.jianshu.com/p/f314e9868cae\n\n## 2.Jupyter lab目录插件\n\nhttps://www.pinggu.com/post/details/5eccf61a7fba3d625f75771d\n\n## 3.jupyterlab_code_formatter–代码pep8\n\nhttps://www.brothereye.cn/python/362/\n\n**jupyterlab_code_formatter官网**\n- https://github.com/ryantam626/jupyterlab_code_formatter\n\n## 4.15个好用到爆炸的Jupyter Lab插件\n\nhttps://zhuanlan.zhihu.com/p/101070029\n\n## 5.工具篇-Jupyter Lab效率提升插件\n\nhttps://zhuanlan.zhihu.com/p/73374773\n\n## 6.解决build失败问题\n\n终止JupyterLab后，在命令行下输入`jupyter-lab build`\n\n","tags":["jupyter"],"categories":["工具"]},{"title":"万字详解决策树之ID3、CART、C4.5【原理+实例+代码实现】","url":"/2020/11/24/215647/","content":"\n## 决策树的含义\n首先我们先来了解下什么是决策树。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727111117277.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n上图就是一颗带有决策的树，其中天气、温度等称为特征，后面问号的位置称为阈值，如温度=35°，则阈值为35。\n\n\n<!-- more -->\n\n\n\n\n- 决策树是一种基本的分类与回归方法。这里主要讨论决策树用于分类。\n- 决策树的结点和有向边分别表示\n\t1. 内部结点表示一个特征或者属性。\n\t2. 叶子结点表示一个分类。\n\t3. 有向边代表了一个划分规则。\n- 决策树从根结点到子结点的的有向边代表了一条路径。\n- 决策树的路径是互斥并且是完备的。\n- 用决策树分类时，是对样本的某个特征进行测试，根据测试结果将样本分配\n- 如果将样本分配到了树的子结点上，每个子结点对应该特征的一个取值。\n- 决策树的优点：可读性强，分类速度快。\n- 决策树学习通常包括3个步骤：\n\t1. 数据标注\n\t2. 特征选择。\n\t3. 决策树生成。\n\t4. 分类和识别。\n\n决策树模型可以认为是if-then规则的集合。决策树学习的算法通常是遍历选择最优特征和特征值，并根据该特征对训练数据进行分割，使得对各个子数据集有一个最好的分类，这一过程对应着特征空间的划分，也对应着决策树的构建。\n\n## (信息熵+信息增益)&ID3\n\n**信息熵(Entropy)用来度量不确定性的，当熵越大，信息的不确定性越大，对于机器学习中的分类问题，那么，当前类别的熵越大，它的不确定性就越大**\n\nH(D)代表一个决策树的熵，熵的数学公式如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727112506781.png)\n*n是分类的数目，$p_i$是当前分类发生的概率。*\n\n细想一下，如果10个硬币，分类结果是10个正面，没有反面，那么信息熵为0，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727144929893.png)\n信息熵为0，就意味着信息确定，就意味着分类完成了。\n\n\n\n在原有树的熵 H(D) 增加了一个分裂节点，使得熵变成了H(D|A)，则**信息增益(Information Gain，IG)**为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727114424888.png)\n*A是选择作为分裂依据的特征，g(D,A)也称为条件熵*\n\n**即信息增益 = 分裂前的信息熵-分裂后的信息熵**\n\n也有更加准确的定义方法：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727154914395.png)\n*V表示根据特征a对样本集D划分(分裂)后，获得的总共类别数量(一般是二分类)；$D^v$表示每一个新类别中样本数量；Ent(D)和H(D)的含义相同，表示信息熵*\n\n\n我们以判断学生好坏的案例，计算信息熵和信息增益：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725210419125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n（1）在初始状态下，有10个学生，7个是好学生，3个不是好学生，计算树的信息熵(此时只有一个根节点) `H(D)=0.88`，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725202826602.png)\n\n（2）我们根据分数这个特征对树进行分裂，设置分数的阈值为70，计算分裂后树的信息熵`H(D|A1)=0.4344`，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727140142378.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n（3）把(2)的特征有分数改为出勤率，设置出勤率阈值为75%，计算分裂后树的信息熵`H(D|A2)=0.79`，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727140432832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n从上面的计算中，我们得到了3个熵：\n- 在初始状态下，信息熵为0.88，\n- 设置分数阈值为70进行分裂，信息熵为0.4344\n- 设置出勤率阈值为75%进行分裂，信息熵为0.79\n\n只要增加分裂节点后的熵比之前的熵小，那么就可以认为本次分裂是有效的，现在(2)和(3)的分裂都有效，但是哪个更好呢？\n在设置分数阈值为70的熵比设置出勤率阈值为75%的熵要小，即前者分裂后数据比较纯一些，整个数据的确定性大了，因此设置分数阈值为70分裂方式效果更好，所以我们以该方式为基准进行分裂。\n\n\n现在来计算信息增益，**信息增益 = 分裂前的信息熵-分裂后的信息熵**，计算如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727141600553.png)\n*A1是以分数这个特征进行分裂，A2是以出勤率这个特征进行分裂*\n\n可以看到，以设置分数阈值为70进行分裂，信息增益更大。\n\n> 信息增益在决策树算法中是用来选择特征的指标，信息增益越大，则这个特征的选择性越好，该特征具有更强的分类能力，如果一个特征的信息增益为0，则表示该特征没有什么分类能力。\n\n\n\n**ID3的原理：**\n\n**利用数据标注和信息增益以及遍历，可以完成一个决策树中的特征和阈值的选择(得到最大信息增益的特征和阈值)，利用这三个(标注、信息增益、遍历)就可以完成一颗树，决策的树，分类的树，这个算法就是ID3()算法的思想**\n\n**ID3(Iterative Dichotomisor 3) 迭代二分类三代，用信息增益准则选择特征，判定分类器的性能，从而构建决策树**\n\n经过上面的例子，可以得到如下结论：\n- 只要分类后的总熵为0，那么这课树就训练完了（也就是分类完了）\n- 熵在决策树中的作用：判断分类后，有没有达到我们的需求和目的，也就是数据是不是更加纯了，更加确定了。如果经过分类后，信息总熵的值更加小了，那么这次分类就是有效的。\n- 熵越大，不确定就越大，分类未完成时，熵不为0\n- 熵越小，分得越好，分类完成时，熵为0\n\n\n根据上述思想，可以完成如下一颗树：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725212940738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n\n## (纯度+基尼系数)&CART\n在上面的例子中，我们是用决策树做分类的，那么做回归的时候该怎么做呢？ 现在把上述的分类结果由好学生换成是否为好学生的概率，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725214016787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n分类的结果是概率，是个连续的变量，无法计算信息熵和信息增益了，这个时候怎么做呢？\n\n为了解决这个问题，引入了纯度的概念。\n\n**纯度的定义如下：**\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727145525183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*𝑃_𝑙 和𝑃_r  是按照某一特征分裂后，树的两个分裂结点各自占的比例，Var是方差，就是计算左侧和右侧部分的方差，y_i是具体的值(这里是好学生的概率)*\n\n**纯度增益 = 分裂前的纯度 - 分裂后的纯度**\n\n可以看到，纯度和方差的定义大致一样(这里的纯度没有除以n，方差的定义需要除以n)，在有的文献中也称为偏差，其实含义都一样，都是**表示数据的离散程度**\n\n细想一下，如果上述10个学生的是好学生的概率都一样(比如都是0.9)，那么纯度(方差)是0，说明数据完全没有离散性，非常的确定。\n> 可以看到，纯度和信息熵所代表的含义是一样的，只不过熵表示分类信息的不确定性，纯度表示数据的离散程度，下面即将要介绍的基尼系数，表示的也是分类(CART的分类)信息的确定性\n\n（1）在初始状态下，计算树的纯度(此时只有一个根节点) `纯度=0.4076`，如下所示：\n\n```python\nimport numpy as np\na = [0.9,0.9,0.8,0.5,0.3,0.8,0.85,0.74,0.92,0.99]\na = np.array(a)\na_mean = np.mean(a)\n# 不用除以n\na_va = np.sum(np.square(a-a_mean))\na_va\n# 输出 0.4076000000000001\n```\n\n(2) 设置分数阈值为70进行分裂，计算`纯度=0.2703`，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725215757527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n(3) 设置出勤率阈值为75%进行分类，计算纯度：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072522060291.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n从上面的计算中，我们得到了3个纯度：\n- 在初始状态下，纯度为0.4076，\n- 设置分数阈值为70进行分裂，纯度为0.2703\n- 设置出勤率阈值为75%进行分裂，纯度0.1048\n\n从这三个纯度可以得知，这两种方式的分裂均有效，按照出勤率阈值=75%计算的纯度更小，说明分裂的效果更好，信息更确定了。\n\n也可以计算出纯度的增益：\n- 设置分数阈值为70进行分裂，纯度的增益为`0.4079 - 0.2703 = 0.1376`\n- 设置出勤率阈值为75%进行分裂，纯度的增益为`0.4079 - 0.1048 =0.3031`\n\n设置出勤率阈值为75%进行分裂得到纯度增益更大，说分裂效果更好(这里和信息熵及信息增益的原理是一样的)\n\n\n**思考：为什么决策树分类和回归的结果不同？**\n因为我们的标注不同，之前标注的是好学生与坏学生，现在重新标注了是好学生的概率，标注不同对我们模型训练的引导就不同，造成的结果就不同。\n\n\n**思考：将模型训练完之后怎么去得到具体回归的那个值呢？**\n如果最后只有一个结点，就是指这个结点的值，如果最后有多个结点，那应该是平均值\n\n**利用数据标注和纯度以及遍历，可以完成一个决策树中的特征和阈值的选择(得到最大信息增益的特征和阈值)，利用这三个(标注、纯度、遍历)就可以完成一颗树，决策的树，回归的树，这个算法就是CART的回归算法**\n\nCART做回归时用的是纯度，做分类时用的是基尼系数。\n\n\n**基尼系数**\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727152553331.png)\n\n*n代表n分类，$p_i$表示不同类别的概率*\n\n按照某一特征分裂后的基尼系数为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727152816890.png)\n\n**基尼增益 = 分裂前的基尼 - 分裂后的基尼**\n\n我们以硬币来举例子解释基尼系数，假设10个硬币做二分类，10个是正面，没有反面，那么基尼系数为：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725231308198.png)\n如果10个硬币做二分类，5个是正面，5个是反面，那么基尼系数为\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725231336871.png)\n\n可以看到，当分类完成时，基尼系数为0，因此基尼系数与信息的含义类似，基尼系数越大，信息的不确定性就越大。\n\n**注意：基尼系数和信息熵都是用于分类的**\n\n然后，按照某一特征进行分裂，比如按照硬币的大小(或面值)进行分裂，计算分裂后的基尼系数，最后计算基尼增益，得到的基尼增益最大的特征和阈值就是我们要找的分裂方式。\n> 纯度增益、基尼增益、信息增益的原理完全一样\n\n\n**CART（classification and regression tree）分类和回归树，分类是使用基尼系数判定分类器的性能，回归时使用纯度判定分类器的性能**\n\n##  信息增益率&C4.5\n**信息增益准则对可取值数目较多的特征有所偏好**，为了减少这种偏好可能带来的不利影响，C4.5决策树算法使用了“增益率”：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072715533054.png)\n其中IV(a)称为特征a的“固有值”，称为特征a的分裂信息度量，其实就是特征a的信息熵(注意：这个和信息增益减去的按特征a分裂后的信息熵不一样，在下面具体例子中可看到)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727155553702.png)\n**需要注意的是，信息增益率对可取值数目较少的特征所有偏好，因此，C4.5算法并不是直接选择信息增益率最大的特征进行分裂，而是使用了一个启发式：先找出信息增益高于平均水平的特征，再从中选择增益率最高的。** 可以看出，使用信息增益率可以解决分裂后叶子结点过多的问题，从而解决过拟合\n\n我们用下面的例子计算信息增益率(抱歉，没找到更清晰的图片)\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727160759867.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n（1）第一步：计算样本集D的信息熵\n\nEnt(D) = `-9/14*log2(9/14) – 5/14*log2(5/14) = 0.940`\n*Ent(D)表示熵，也可以H(D)表示*\n\n（2）第二步：依据每个特征划分样本集D，并计算每个特征（划分样本集D后）的信息熵\n\n- Ent(天气) = `5/14*[-2/5*log2(2/5)-3/5*log2(3/5)] + 4/14*[-4/4*log2(4/4)] + 5/14*[-3/5log2(3/5) – 2/5*log2(2/5)] = 0.694`\n- Ent(温度) = 0.911\n- Ent(湿度) = 0.789\n- Ent(风速) = 0.892\n\n（3）第三步：计算信息增益\n\n- Gain(天气) = Ent(D) - Ent(天气) = 0.246\n- Gain(温度) = Ent(D) - Ent(温度) = 0.029\n- Gain(湿度) = Ent(D) - Ent(湿度) = 0.150\n- Gain(风速) = Ent(D) - Ent(风速) = 0.048\n\n（4）第四步：计算特征(属性)分裂信息度量\n\n- IV(天气) = `-5/14*log2(5/14) – 4/14*log2(4/14) – 5/14*log2(5/14) = 1.577`\n- IV(温度) = 1.556\n- IV(湿度) = 1.000\n- IV(风速) = 0.985\n\n（5）第五步：计算信息增益率\n\n- Gain_ratio(天气) = 0.246 / 1.577 = 0.155\n- Gain_ratio(温度) = 0.0187\n- Gain_ratio(湿度) = 0.151\n- Gain_ratio(风速) = 0.048\n\n可以看到，天气的信息增益率最高，选择天气为分裂属性。发现分裂了之后，天气是“阴”的条件下，类别是”纯“的，所以把它定义为叶子节点，选择不“纯”的结点继续分裂。\n\n我们在ID3和CART中的例子特征值是离散的，即特征值是一个个数值，不是本例中的类别，如果特征是类别的样本，就没有阈值的选择，直接按该特征的类别进行分裂，比如本例中按天气把决策树分裂成晴、阴、雨三个结点。\n\n思考：为什么说**信息增益准则对可取值数目较多的特征有所偏好**？\n\n就如本例中的天气特征，它的可取值数据为3个：晴、阴、雨，如果天气特征的可取值数目增加到5个，那么按照天气分裂后的信息熵就会降低的更多，它的信息增益就越大，因为天气特征的可取值数目越多，分裂的就清晰。如果把天气特征的可取值数目增加到与样本数一样，那么分裂后的信息熵就是0了，所以说信息增益准则对可取值数目较多的特征有所偏好。\n\n思考：为什么说**信息增益率对可取值数目较少的特征所有偏好**？\n\n还拿本例中的天气特征来说，它的可取值数据为3个：晴、阴、雨，如果天气特征的可取值数目减少到一个，那么天气特征(属性)分裂信息度量就为0了，此时，信息增益率就是无穷大，因此信息增益率对可取值数目较少的特征所有偏好。\n\n## 各种决策树比较与总结\n\n**ID3、CART、C4.5比较**\n信息增益和信息增益率通常用于离散型的特征划分，ID3和C4.5通常情况下都是多叉树，也就是根据离散特征的取值会将数据分到多个子树中，当然采用信息增益和信息增益率的时候也可以对连续特征进行划分并计算最优点，如上面判断好坏学生的例子。CART树为二叉树，使用基尼指数作为划分准则，对于离散型特征和连续行特征都能很好的处理。\n**离散型的特征是指：特征是分类，如天气：晴、阴、雨，不是连续的值\n连续型的特征是指：特征是一个个值，如分数、身高等，不是分类**\n\n\n**决策树的参数和训练方法：**\n\n- 决策树的参数：选择的特征及其对应的阈值，还有它的拓扑结构\n- 训练方法：就是遍历的方法，用纯度、基尼系数、信息熵、信息增益或信息增益率来表示\n- 决策树既可以做分类，也可以做回归，既可以做二分类，也可以做多分类\n\n**决策树中的分类器**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725221843381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n**如何求解决策树？**\n\n求解决策树，实际上就是求解分类器(求解每个特征和阈值)，步骤如下：\n1. 设定一个评价分类结果的好坏的准则(信息增益、基尼系数、纯度、信息增益率)\n2. 用遍历的方法求解\n\n\n## 决策树编程实战\n\n### 调用sklearn库实现回归决策树\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import linear_model\n \n# Data set\nx = np.array(list(range(1, 11))).reshape(-1, 1)\ny = np.array([5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05]).ravel()\n \n# Fit regression model\nmodel1 = DecisionTreeRegressor(max_depth=1)\nmodel2 = DecisionTreeRegressor(max_depth=3)\nmodel3 = linear_model.LinearRegression()\nmodel1.fit(x, y)\nmodel2.fit(x, y)\nmodel3.fit(x, y)\n \n# Predict\nX_test = np.arange(0.0, 10.0, 0.01)[:, np.newaxis]\ny_1 = model1.predict(X_test)\ny_2 = model2.predict(X_test)\ny_3 = model3.predict(X_test)\n \n# Plot the results\nplt.figure()\nplt.scatter(x, y, s=20, edgecolor=\"black\",\n            c=\"darkorange\", label=\"data\")\nplt.plot(X_test, y_1, color=\"cornflowerblue\",\n         label=\"max_depth=1\", linewidth=2)\nplt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=3\", linewidth=2)\nplt.plot(X_test, y_3, color='red', label='liner regression', linewidth=2)\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\nplt.title(\"Decision Tree Regression\")\nplt.legend()\nplt.show()\n```\n输出\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727174125995.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n### 手动实现ID3决策树\n\n```python\n#coding:utf-8\nimport torch\nimport pdb\n\n# 样本的特征，每个样本包含七个特征\nfeature_space=[[1., 3., 2., 2., 3., 0.,3.], \n[2., 0., 2., 5., 1., 2.,3.], \n[3., 2., 3., 3., 2., 3.,2.], \n[4., 0., 3., 3., 2., 0.,1.], \n[3., 1., 2., 2., 5., 1.,3.], \n[1., 4., 3., 3., 1., 5.,2.], \n[3., 3., 3., 3., 1., 0.,1.], \n[5., 1., 1., 4., 2., 2.,2.], \n[6., 2., 3., 3., 2., 3.,0.], \n[2., 2., 2., 2., 5., 1.,4.]]\n\ndef get_label(idx):\n    label= idx\n    return label\n\n#  计算以某个特征某个阈值进行分裂时的信息熵，即条件熵\ndef cut_by_node(d,value,feature_space,list_need_cut):\n    # 分别存放以某个特征某个阈值分裂后的左右侧样本点\n    right_list=[]\n    left_list=[]\n    for i in list_need_cut:\n\n        if feature_space[i][d]<=value:\n             right_list.append(i)\n        else:\n             left_list.append(i)\n\n    left_list_t = list2label(left_list,[0,0,0,0,0,0,0,0,0,0])\n    right_list_t = list2label(right_list,[0,0,0,0,0,0,0,0,0,0])\n    e1=get_emtropy(left_list_t) \n    e2=get_emtropy(right_list_t) \n    n1 = float(len(left_list))\n    n2 = float(len(right_list))\n    e = e1*n1/(n2+n1) + e2*n2/(n1+n2)\n\n    return e,right_list,left_list\n\n# 将分到样本点转为one-hot各式，方便计算信息熵\ndef list2label(list_need_label,list_label):\n     for i in list_need_label:\n         label=get_label(i)\n         list_label[label]+=1\n     return list_label\n\ndef get_emtropy(class_list):\n   E = 0\n   sumv = float(sum(class_list))\n   if sumv == 0:\n       sumv =0.000000000001\n   for cl in class_list:\n       if cl==0:\n           cl=0.00000000001\n       p = torch.tensor(float(cl/sumv))\n       # log以2为底\n       E += -1.0 * p*torch.log(p)/torch.log(torch.tensor(2.))\n   return E.item()\n```\n\n```python\ndef get_node(complate,d,list_need_cut):\n    # 初始时的信息熵，设为最大(根节点计算之前的信息熵)\n    e = 10000000\n    # node 代表以那个维度的那个特征值进行分裂\n    node=[]\n    # list_select:树分裂好的一个个结点序列，不包含已经分类好可以识别的结点\n    list_select=[]\n    # 存放可以识别的结点\n    complate_select=[]\n    # 0~8就是选择的阈值\n    for value in range(0,8):\n        complate_tmp=[]\n        etmp=0\n        list_select_tmp=[]\n        # 子序列总的长度\n        sumv=0.000000001\n        # 要进行分裂的所有结点序列\n        for lnc in list_need_cut:\n\n            # 计算条件熵，返回熵、左侧结点的样本点，右侧结点的样本点\n            etmptmp,r_list,l_list=cut_by_node(d,value,feature_space,lnc)\n            # 这行代码和etmp/sumv 就是求分裂后的总熵，就是那个pl*H1+pr*H2的公式\n            etmp+=etmptmp*len(lnc)\n            sumv+=float(len(lnc))\n            # 存放可以识别的结点\n            if len(r_list)>1:\n                list_select_tmp.append(r_list)\n            if len(l_list)>1:\n                list_select_tmp.append(l_list)\n            if len(r_list)==1:\n                complate_tmp.append(r_list)\n            if len(l_list)==1:\n                complate_tmp.append(l_list)\n            # print('子序列child:以每个样本的第{}个特征，特征值大小为{}划分{}子序列，得到的熵为{}'.format(d,value,lnc,etmptmp))    \n            \n        etmp = etmp/sumv\n        sumv=0\n        \n        # print('总序列All：以每个样本的第{}个特征，特征值大小为{}划分{}序列，得到的总熵为{}'.format(d,value,list_need_cut,etmp))    \n        \n        # 得到第n个特征以某一阈值分裂后的最小信息熵，及此时分裂后序列\n        if etmp<e:\n            e=etmp\n            node=[d,value]\n            list_select=list_select_tmp\n            complate_select=complate_tmp\n    for ll in complate_select:\n         complate.append(ll)\n    return node,list_select,complate\n```\n\n```python\nimport pdb\ndef get_tree():\n#     pdb.set_trace()\n    # 10个样本：0, 1, 2, 3, 4, 5, 6, 7, 8, 9，注意是这里是二维数组\n    ## 二维数组里刚开始只有一个序列，即初始时只有一个根节点\n    all_list=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] \n    # complate的含义是：比如树的某个结点只有一个样本，那么存放到complate中\n    ## 即complate存放的是已经分类好的可以识别的结点\n    complate=[]\n    # 遍历样本的7个特征，这个序列就是遍历的先后顺序\n    ## d 首先遍历每个样本的第3个特征，把分类的结果返回\n    for d in [3,4,2,5,0,1,6]:\n        # node 代表以那个维度的那个特征值进行分裂\n        # all_list:树分裂好的一个个结点序列，不包含已经分类好可以识别的结点\n        node,all_list,complate=get_node(complate,d,all_list)\n        print(\"node=%s,complate=%s,all_list=%s\"%(node,complate,all_list))\n\nif __name__==\"__main__\":\n    get_tree()\n```\n输出：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727185457146.png)\n\n### 使用sklearn库回归决策树预测boston房价\n[decision_sklearn_tree_regressor_boston](https://gitee.com/wxler/AIProjectTraining/blob/master/practice/%E5%86%B3%E7%AD%96%E6%A0%91/decision_sklearn_tree_regressor_boston.ipynb)\n### 使用sklearn库分类决策树对iris分类\n[decision_sklearn_tree_classify_iris](https://gitee.com/wxler/AIProjectTraining/blob/master/practice/%E5%86%B3%E7%AD%96%E6%A0%91/decision_sklearn_tree_classify_iris.ipynb)\n\n参考文档\n[信息增益、信息增益比、基尼指数的比较](https://www.cnblogs.com/rezero/p/13057584.html)\n[华校专的决策树](http://www.huaxiaozhuan.com/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/chapters/4_decision_tree.html)\n[机器学习（二）-信息熵，条件熵，信息增益，信息增益比，基尼系数](https://www.cnblogs.com/xiaofeiIDO/p/11947380.html)\n","tags":["决策树"],"categories":["机器学习"]},{"title":"k-means及k-means++原理【python代码实现】","url":"/2020/11/24/215155/","content":"\n\n\n## 前言\n\nk-means算法是无监督的聚类算法，实现起来较为简单，k-means++可以理解为k-means的增强版，在初始化中心点的方式上比k-means更友好。\n\n<!-- more -->\n\n\n\n## k-means原理\nk-means的实现步骤如下：\n1. 从样本中随机选取k个点作为聚类中心点\n2. 对于任意一个样本点，求其到k个聚类中心的距离，然后，将样本点归类到距离最小的聚类中心，直到归类完所有的样本点（聚成k类）\n3. 对每个聚类求平均值，然后将k个均值分别作为各自聚类新的中心点\n4. 重复2、3步，直到中心点位置不在变化或者中心点的位置变化小于阈值\n\n优点：\n- 原理简单，实现起来比较容易\n- 收敛速度较快，聚类效果较优\n\n缺点：\n- 初始中心点的选取具有随机性，可能会选取到不好的初始值。\n\n## k-means++原理\n\n**k-means++是k-means的增强版，它初始选取的聚类中心点尽可能的分散开来，这样可以有效减少迭代次数，加快运算速度**，实现步骤如下：\n1. 从样本中随机选取一个点作为聚类中心\n2. 计算每一个样本点到已选择的聚类中心的距离，用D(X)表示：D(X)越大，其被选取下一个聚类中心的概率就越大\n3. 利用**轮盘法**的方式选出下一个聚类中心(D(X)越大，被选取聚类中心的概率就越大)\n4. 重复步骤2，直到选出k个聚类中心\n5. 选出k个聚类中心后，使用标准的k-means算法聚类\n\n>这里不得不说明一点，有的文献中把**与已选择的聚类中心最大距离的点选作下一个中心点**，这个说法是不太准确的，准的说是**与已选择的聚类中心最大距离的点被选作下一个中心点的概率最大**，但不一定就是改点，因为总是取最大也不太好（遇到特殊数据，比如有一个点离某个聚类所有点都很远）。\n\n一般初始化部分，始终要给些随机。因为数据是随机的。\n\n尽管计算初始点时花费了额外的时间，但是在迭代过程中，k-mean 本身能快速收敛，因此算法实际上降低了计算时间。\n\n现在重点是利用**轮盘法**的方式选出下一个聚类中心，我们以一个例子说明K-means++是如何选取初始聚类中心的。\n\n假如数据集中有8个样本，分布分布以及对应序号如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200726212919102.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n我们先用 k-means++的步骤1选择6号点作为第一个聚类中心，然后进行第二步，计算每个样本点到已选择的聚类中心的距离D(X)，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200726213127851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n- D(X)是每个样本点与所选取的聚类中心的距离(即第一个聚类中心)\n- P(X)每个样本被选为下一个聚类中心的概率\n- Sum是概率P(x)的累加和，用于轮盘法选择出第二个聚类中心。\n\n然后执行 k-means++的第三步：利用**轮盘法**的方式选出下一个聚类中心，**方法是随机产生出一个0~1之间的随机数，判断它属于哪个区间，那么该区间对应的序号就是被选择出来的第二个聚类中心了**。\n\n在上图1号点区间为[0,0.2)，2号点的区间为[0.2, 0.525)，4号点的区间为[0.65,0.9)\n\n从上表可以直观的看到，1号，2号，3号，4号总的概率之和为0.9，这4个点正好是离第一个初始聚类中心(即6号点)较远的四个点，因此选取的第二个聚类中心大概率会落在这4个点中的一个，其中2号点被选作为下一个聚类中心的概率最大。\n\n## k-means及k-means++代码实现\n\n这里选择的中心点是样本的特征(不是索引)，这样做是为了方便计算，选择的聚类点(中心点周围的点)是样本的索引。\n\n**k-means实现**\n\n```python\n# 定义欧式距离\nimport numpy as np\ndef get_distance(x1, x2):\n    return np.sqrt(np.sum(np.square(x1-x2)))\n```\n\n```python\nimport random\n# 定义中心初始化函数，中心点选择的是样本特征\ndef center_init(k, X):\n    n_samples, n_features = X.shape\n    centers = np.zeros((k, n_features))\n    selected_centers_index = []\n    for i in range(k):\n        # 每一次循环随机选择一个类别中心,判断不让centers重复\n        sel_index = random.choice(list(set(range(n_samples))-set(selected_centers_index)))\n        centers[i] = X[sel_index]\n        selected_centers_index.append(sel_index)\n    return centers\n```\n\n```python\n# 判断一个样本点离哪个中心点近， 返回的是该中心点的索引\n## 比如有三个中心点，返回的是0，1，2\ndef closest_center(sample, centers):\n    closest_i = 0\n    closest_dist = float('inf')\n    for i, c in enumerate(centers):\n        # 根据欧式距离判断，选择最小距离的中心点所属类别\n        distance = get_distance(sample, c)\n        if distance < closest_dist:\n            closest_i = i\n            closest_dist = distance\n    return closest_i\n```\n\n```python\n# 定义构建聚类的过程\n# 每一个聚类存的内容是样本的索引，即对样本索引进行聚类，方便操作\ndef create_clusters(centers, k, X):\n    clusters = [[] for _ in range(k)]\n    for sample_i, sample in enumerate(X):\n        # 将样本划分到最近的类别区域\n        center_i = closest_center(sample, centers)\n        # 存放样本的索引\n        clusters[center_i].append(sample_i)\n    return clusters\n```\n\n```python\n# 根据上一步聚类结果计算新的中心点\ndef calculate_new_centers(clusters, k, X):\n    n_samples, n_features = X.shape\n    centers = np.zeros((k, n_features))\n    # 以当前每个类样本的均值为新的中心点\n    for i, cluster in enumerate(clusters):  # cluster为分类后每一类的索引\n        new_center = np.mean(X[cluster], axis=0) # 按列求平均值\n        centers[i] = new_center\n    return centers\n```\n\n```python\n# 获取每个样本所属的聚类类别\ndef get_cluster_labels(clusters, X):\n    y_pred = np.zeros(np.shape(X)[0])\n    for cluster_i, cluster in enumerate(clusters):\n        for sample_i in cluster:\n            y_pred[sample_i] = cluster_i\n            #print('把样本{}归到{}类'.format(sample_i,cluster_i))\n    return y_pred\n```\n\n```python\n# 根据上述各流程定义kmeans算法流程\ndef Mykmeans(X, k, max_iterations,init):\n    # 1.初始化中心点\n    if init == 'kmeans':\n        centers = center_init(k, X)\n    else: centers = get_kmeansplus_centers(k, X)\n    # 遍历迭代求解\n    for _ in range(max_iterations):\n        # 2.根据当前中心点进行聚类\n        clusters = create_clusters(centers, k, X)\n        # 保存当前中心点\n        pre_centers = centers\n        # 3.根据聚类结果计算新的中心点\n        new_centers = calculate_new_centers(clusters, k, X)\n        # 4.设定收敛条件为中心点是否发生变化\n        diff = new_centers - pre_centers\n        # 说明中心点没有变化，停止更新\n        if diff.sum() == 0:\n            break\n    # 返回最终的聚类标签\n    return get_cluster_labels(clusters, X)\n```\n\n```python\n# 测试执行\nX = np.array([[0,2],[0,0],[1,0],[5,0],[5,2]])\n# 设定聚类类别为2个，最大迭代次数为10次\nlabels = Mykmeans(X, k = 2, max_iterations = 10,init = 'kmeans')\n# 打印每个样本所属的类别标签\nprint(\"最后分类结果\",labels)\n## 输出为  [1. 1. 1. 0. 0.]\n```\n\n```python\n# 使用sklearn验证\nfrom sklearn.cluster import KMeans\nX = np.array([[0,2],[0,0],[1,0],[5,0],[5,2]])\nkmeans = KMeans(n_clusters=2,init = 'random').fit(X)\n# 由于center的随机性，结果可能不一样\nprint(kmeans.labels_)\n```\n**k-means++实现**\n\n```python\n## 得到kmean++中心点\ndef get_kmeansplus_centers(k, X):\n    n_samples, n_features = X.shape\n    init_one_center_i = np.random.choice(range(n_samples))\n    centers = []\n    centers.append(X[init_one_center_i])\n    dists = [ 0 for _ in range(n_samples)]\n\n    # 执行\n    for _ in range(k-1):\n        total = 0\n        for sample_i,sample in enumerate(X):\n            # 得到最短距离\n            closet_i = closest_center(sample,centers)\n            d = get_distance(X[closet_i],sample)\n            dists[sample_i] = d\n            total += d\n        total = total * np.random.random()\n\n        for sample_i,d in enumerate(dists): # 轮盘法选出下一个聚类中心\n            total -= d\n            if total > 0:\n                continue\n            # 选取新的中心点\n            centers.append(X[sample_i])\n            break\n    return centers\n```\n\n```python\nX = np.array([[0,2],[0,0],[1,0],[5,0],[5,2]])\n# 设定聚类类别为2个，最大迭代次数为10次\nlabels = Mykmeans(X, k = 2, max_iterations = 10,init = 'kmeans++')\nprint(\"最后分类结果\",labels)\n## 输出为  [1. 1. 1. 0. 0.]\n```\n\n```python\n# 使用sklearn验证\nX = np.array([[0,2],[0,0],[1,0],[5,0],[5,2]])\nkmeans = KMeans(n_clusters=2,init='k-means++').fit(X)\nprint(kmeans.labels_)\n```\n\n参考文档\n[K-means与K-means++](https://www.cnblogs.com/wang2825/articles/8696830.html)\n[K-means原理、优化及应用](https://blog.csdn.net/weixin_42029738/article/details/81978038)","tags":["k-means"],"categories":["机器学习"]},{"title":"在jupyter中使用python pdb调试代码","url":"/2020/11/24/215133/","content":"\n> 目前在jupyter中还没有可视化调试界面，而python pdb是代码调试的一个不错的选择，它支持设置断点和单步调试，使用起来非常方便\n\n<!-- more -->\n\n\n\n\n## pdb常用命令\n\n| 参数 | 说明      |  实例\n|:--------:| :-----------|:-------------|\n|`h`  | help 帮助文档 | `h b`： 查看 b 命令的文档|\n|`b` | break 打断点|`b`：查看所有断点 <br> `b 5`： 给第5行打断点 <br>    `b function_name`：当前文件名为 function_name 的函数打断点<br> `b test1.A.add`：在 import test1 文件的 A 类的 add 方法打断点   <br> `b A.add`：在 A 类的 add 方法打断点 |\n|`tbreak` | 设置临时断点，运行完毕后会删除这个断点| 设置方法和 b 一样|\n|`w `| where 查看当前执行的位置| `w`|\n| `cl`| clear 清除断点| `cl`：清除所有断点  <br> `cl 2`：清除断点列表中编号为2断点 <br> `cl test.py:18`：清除 test.py 文件编号为18断点 <br>`cl test1:18`：清除 import test1 文件编号为18的断点 |\n|`condition ` | 给断点设置条件| `condition 1 i==4`：当断点列表中编号为1的断点中变量 i 等于 4 的时候执行断点|\n|`s` | step 执行下一条命令，遇到函数则进入\t| 参考下面执行效果|\n|`n` |next 执行下一条语句，遇到函数不进入 |参考下面执行效果 |\n| `c`|continue  继续执行，直到遇到下一条断点\t |参考下面执行效果 |\n|`r` | return  执行当前运行函数到结束| 参考下面执行效果  |\n|`args` | args  打印当前函数的所有参数及参数值 | 参考下面执行效果 |\n| `p`| print 打印出当前所在函数中的变量或表达式结果 | `p a`：打印变量a <br> `p dir(a)`：打印变量a所有属性|\n|`pp`| 格式化打印出来的结果| `pp a`：格式化打印变量a|\n`run`| 重新执行| |\n|`q` | quit 退出pdb调试| |\n\n## pdb进阶阶命令\n| 参数 | 说明      |  实例\n|:--------:| :-----------|:-------------|\n| `l`| list 列出当前或范围周围代码  |`l 5, 20`： 列出5到20行代码 <br>`l`： 查看当前位置的代码 |\n|`disable ` |  停用断点|  `disable`：清除所有断点  <br> `disable 2`：清除断点列表中编号为2断点 <br> `disable test.py:18`：清除 test.py 文件编号为18断点 <br>`disable test1:18`：清除 import test1 文件编号为18的断点|\n|`enable`  |启动断点\t | 用法和`disable`一样|\n| `ignore bpnumber`| 忽略某个断点几次| `ignore 1 3`：忽略断点列表中第1个断点3次，一般循环中用， |\n| `commands`| 给断点写一个脚本执行 | `commands 1`：给断点编号为1的的断点写脚本 |\n| `unt`| until 执行到下一行 | 参考下面 unt 执行效果 |\n| `j`| jump 跳转至指定程序行，如果是前行，则忽略中间行代码。<br>如果是后退，状态重设为回退行状态 | 注意：是跳转到不是执行 |\n|`alias` | 自定义一个函数，参数可由％1，％2来表示。<br>类似 Python 的 lambda| |\n|`unalias` | 删掉别名函数| `unalias name`|\n\n\n\n\n## 实例1\n代码如下：\n\n```python\nimport pdb\npdb.set_trace()\ndef mul(a, b,e = 88):\n    c = a * b\n    return c\n\nfor i in range(10):\n    a = i\n    b = i + 1\n    r = mul(a, b)\n    print(r)\n```\n\n\n使用`condition`给编号为6的断点设置条件为`i==3`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725175733203.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n给第8行设置断点，然后输入n单步执行(遇到函数不进入)：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072518002253.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n给第8行设置断点，但函数位置输入s遇到函数进入，然后输入r，直接执行到函数尾部：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725180402190.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n输入`args`打印当前函数的所有参数及参数值，注意：只有在函数内部该命令才有效\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725181732246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n使用`commands 22`为编号为22的断点编写脚本\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725183606110.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n使用`unt`命令执行到下一行\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725183902126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n\n## 示例2\n代码如下：\n\n```python\nimport pdb\npdb.set_trace()\nclass A():\n    def __init__(self,value):\n        self.value = value\n    def printParam(self):\n        print(self.value)\nv = 3\na = A(v)\na.printParam()\n```\n\n\n输入`p dir(a)` 打印a的所有属性：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725181606662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n输入`l`列出当前位置的代码\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200725182355224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n参考文档\n[python pdb 代码调试 - 最全最详细的使用说明](https://www.jianshu.com/p/8e5fb5fe0931)\n\n","tags":["jupyter"],"categories":["工具"]},{"title":"手推公式带你轻松理解L1/L2正则化","url":"/2020/11/24/214850/","content":"\n## 前言\n\n\n>L1/L2正则化的目的是为了解决过拟合，因此我们先要明白什么是过拟合、欠拟合。\n\n- 过拟合：训练出的模型在测试集上Loss很小，在训练集上Loss较大\n- 欠拟合：训练出的模型在测试集上Loss很大，在训练集上Loss也很大\n- 拟合：训练的刚刚好，在测试集上Loss很小，在训练集上Loss也很小\n\n现在，让我们开启L1/L2正则化正则化之旅吧！\n\n<!-- more -->\n\n\n\n## L1/L2正则化原理\nL1与L2正则是通过在损失函数中增加一项对网络参数的约束，使得参数渐渐变小，模型趋于简单，以防止过拟合。\n\n**损失函数Loss**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724182727639.png)\n*上述Loss，MSE均方误差的Loss*\n\n**L1正则化的损失函数**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724182742754.png)\n*W代表网络中的参数，超参数λ需要人为指定。需要注意的是，**L1使用绝对值来约束参数***\n\n**L2正则化的损失函数**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724182808385.png)\n*相比于L1正则化，L2正则化则使用了平方函数来约束网络参数*\n\n> 需要注意的是，在有的文献中，把L2正则项定义为权值向量w中各个元素的平方和然后再求平方根，其实，L2正则加不加平方根影响不大，原理都是一样的，但不加平方根更容易数学公式推导\n\n\n我们知道，当W的值比较大时(即W的值距离0很远，取几百甚至几千的值)，则拟合的曲线比较陡，x稍微一变化，y的影响就比较大，如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724184041339.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n可以看到，你的模型复杂度越大，拟合的曲线就越陡，惩罚项W就越大，在这种情况容易出现过拟合，所以要避免W出现比较大的值，一个有效的方法是给loss加上一个与W本身有关的值，即L1正则项或L2正则项，这样，我们在使用梯度下降法让Loss趋近于0的时候，也必须让W越来越小，W值越小，模型拟合的曲线会越平缓，从而防止过拟合。也可以从奥卡姆剃刀原理的角度去解释，即在所有可以选择的模型中，能够很好拟合当前数据，同时又十分简单的模型才是最好的。\n\nL1与L2正则化让W变小的原理是不同的：\n\n- **L1能产生等于0的权值，即能够剔除某些特征在模型中的作用（特征选择），即产生稀疏的效果**。\n- **L2可以得迅速得到比较小的权值，但是难以收敛到0，所以产生的不是稀疏而是平滑的效果**。\n\n下面，从两个角度理解L1/L2正则化这两个结论\n\n##  从数学的角度理解L1/L2正则化\n我们来看看**L1正则化的损失函数的求导及梯度更新公式**：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724201746252.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*lr是学习率(更新速率)，上述求导是Loss或$Loss_l1$对$w_i$的偏导，为了方便书写，将$w_i$写成W*\n\n- 上面是加上L1正则化的损失函数后，W更新公式及loss对W求梯度的公式(准确的说是对wi求偏导)，|W|对Wi的导数是1或-1，这样W更新公式就变为加上或减去一个常量lr，\n- 就是说权值每次更新都固定减少一个特定的值(比如0.01)，那么经过若干次迭代之后，权值就有可能减少到0。\n\n**L1正则化的损失函数的求导及梯度更新公式(假设$\\lambda=1/4$)**：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724203126899.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n- 从上面的公式中可以看到，加上L2正则项后，W实际上每次变为原来的C倍(另一项忽略不计），假如C=0.5，那么，W每次缩小为原来的一半，虽然权值W不断变小，但是因为每次都等于上一次的一半，所以很快会收敛到较小的值但不为0。\n\n## 从几何的角度理解L1/L2正则化\n由于L1正则化项是$|w_1+w_2+...+w_n|$，为了便于理解，我们假设，L1正则项是$w_1+w_2$，将其画在二维坐标轴上如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724204849791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n- 横轴是w1,纵轴是w2，优化空间是一个等高线图，可以看优化曲线在圆圈上移动时，**只有直达W2轴的交点处，才能满足两个条件：让loss最小，让w1+w2最小，此时w2=0**，所以说，L1中两个权值倾向于一个较大另一个为0即产生稀疏的效果\n\n由于L2正则化使用了平方函数，而如果两个参数的平方和相同，呈现出的形状会是一个圆。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200724205519269.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n- 可以看优化曲线在圆圈上移动时，**只有在两个圆圈的交点处，才能满足两个条件：让loss最小，让$w^1+w^2$最小，此时L2中两个权值都倾向于为非零的较小数**，所以说，L2产生平滑的效果。\n\n\n\n## L1/L2正则化使用情形\n\n- L1能产生等于0的权值，即能够剔除某些特征在模型中的作用（特征选择），即产生稀疏的效果，如果需要做模型的压缩，L1正则是一个不错的选择。\n\n- 如果不做模型的压缩，在实际中更倾向于L2正则化，因为在实际操作的过程中，模型该用多少层，模型的参数量，这个不好确定，我们也不知道解决这个实际问题要用多少层网络，用多少个参数，只能去试。在试的过程中，最快最经济的做法是：**在模型最开始的时候就加上正则化，不管是在欠拟合或过拟合都加上正则化，然后就不断的去训练，后面根据模型的拟合情况只要增加模型参数和模型结构就行了，不用考虑其他的，即把正则化作为默认的选项去试就可以了。**\n\n\n\n","tags":["normalize"],"categories":["normalize"]},{"title":"numpy和torch数据类型转化问题","url":"/2020/11/24/214655/","content":"\n>在实际计算过程中，float类型使用最多，因此这里重点介绍numpy和torch数据float类型转化遇到的问题，其他类型同理。\n\n<!-- more -->\n\n\n\n## numpy数据类型转化\n\n- numpy使用astype转化数据类型，float默认转化为64位，可以使用`np.float32`指定为32位\n\n\n```python\n#numpy转化float类型\na= np.array([1,2,3])\na = a.astype(np.float)\nprint(a)\nprint(a.dtype)\n```\n\n`[1. 2. 3.]`  \n`float64`\n    \n\n- 不要使用a.dtype指定数据类型，会使数据丢失\n\n\n```python\n#numpy转化float类型\nb= np.array([1,2,3])\nb.dtype= np.float32\nprint(b)\nprint(b.dtype)\n```\n\n`[1.e-45 3.e-45 4.e-45]`  \n`float32`\n    \n\n- 不要用float代替np.float，否则可能出现意想不到的错误\n- 不能从np.float64位转化np.float32，会报错\n- np.float64与np.float32相乘，结果为np.float64\n\n> 在实际使用过程中，可以指定为np.float，也可以指定具体的位数，如np.float，不过直接指定np.float更方便。\n\n## torch数据类型转化\n\n- torch使用`torch.float()`转化数据类型，float默认转化为32位，torch中没有`torch.float64()`这个方法\n\n\n```python\n# torch转化float类型\nb = torch.tensor([4,5,6])\nb = b.float()\nb.dtype\n```\n\n\n\n\n    torch.float32\n\n\n\n- `np.float64`使用`torch.from_numpy`转化为torch后也是64位的\n\n\n```python\nprint(a.dtype)\nc = torch.from_numpy(a)\nc.dtype\n```\n\n`float64`  \n`torch.float64`\n\n\n\n- 不要用float代替torch.float，否则可能出现意想不到的错误\n- torch.float32与torch.float64数据类型相乘会出错，因此相乘的时候注意指定或转化数据float具体类型\n\n> np和torch数据类型转化大体原理一样，只有相乘的时候，torch.float不一致不可相乘，np.float不一致可以相乘，并且转化为np.float64\n\n\n## numpy和tensor互转\n- tensor转化为numpy\n\n```python\nimport torch\nb = torch.tensor([4.0,6])\n# b = b.float()\nprint(b.dtype)\nc = b.numpy()\nprint(c.dtype)\n```\n\n`torch.int64`  \n`int64`\n\n- numpy转化为tensor\n\n```python\nimport torch\nimport numpy as np\nb= np.array([1,2,3])\n# b = b.astype(np.float)\nprint(b.dtype)\nc = torch.from_numpy(b)\nprint(c.dtype)\n```\n`int32`  \n`torch.int32`  \n\n**可以看到，torch默认int型是64位的，numpy默认int型是32位的**","tags":["pytorch","numpy"],"categories":["pytorch"]},{"title":"Batch Normalization：批量归一化详解","url":"/2020/11/24/214400/","content":"\n## 为什么要使用BN\n在深度学习中，层数很多，可能有几十层甚至上百层，每次训练激活的过程中，参数不断改变，导致后续每一层输入的分布也发生变化，而学习的过程就是要使每一层适应输入的分布，如果不做BN就会使模型学的很小心，也会使学习速率变慢，因此我们不得不降低学习率、小心地初始化。\n\n**那怎么才能让我们的模型学习的更高效呢？**\n原有的方式可能是歪着学的，学的效果不是很好，如下图B所示，现在我们需要让它激活到一个更适合学习的位置上，那就需要把它放到原点，这个位置更适合，这时候就需要BN了\n>原点周围更敏感，假定一开始你的数据不在原点周围，后面如果越来越偏，说不定会偏去哪，也就是指W一会大一会小，一会是正值，一会是负值，如下图B所示，也不利于更新。\n\n<!-- more -->\n\n\n\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723220500179.png)\n\n\n## BN的工作原理\n>批量归一化 （Batch Normalization， BN）方法是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。\n\n\nBatch Normalization，顾名思义，以进行学习时的batch为单位，按batch进行规范化。具体而言，把每层神经网络任意神经元输入值的分布强行拉回到均值为0方差为1的标准正态分布，用数学式表示的话，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072322071327.png)\n\n*m代表batch的大小，$μ_B$为批处理数据的均值，$σ^2_B$为批处理数据的方差。*\n\n减去平均值是将数据放在原点周围，除以方差是因为让原来挤在一起的数据变得更均匀一些，如下图C->图D，原来分散的，也会让它们更加紧促一些，在这样一个数据分布里面，使得非线性变换函数的输入值落入对输入比较敏感的区域，从而避免梯度消失问题。这样输入的小变化就会导致损失函数较大的变化（使得梯度变大，避免梯度消失)。可以看出，提高参数更新的效率条件有：让数据的分布在原点附近，让数据分布不离散也不紧凑。\n\n\n将数据转化为均值为0、方差为1的数据分布后，接着，BN层会对正规化后的数据进行缩放和平移的变换，用数学式可以如下表示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723222606550.png)\n\n*这里，γ和β是参数。一开始γ=1，β=0，然后再通过学习调整到合适的值。*\n\n**思考：为什么BN要引入线性变化操作？**\n\nBN层相当于固定了每一层的输入分布，从而加速网络模型的收敛速到，但是这也限制了网络模型中数据的表达能力，浅层学到的参数信息会被BN的操作屏蔽掉，因此，BN层又增加了一个线性变换操作，让数据尽可能地恢复本身的表达能力\n\n\n## BN的优点\n**缓解梯度消失，加速网络收敛速度**。BN层可以让激活函数(非线性变化函数)的输入数据\n落入比较敏感的区域，缓解了梯度消失问题。\n\n**简化调参的负担，网络更稳定**。在调参时，学习率调得过大容易出现震荡与不收敛，BN层则抑制了参数微小变化随网络加深而被放大的问题，因此对于参数变化的适应能力更强，更容易调参。\n\n**防止过拟合**。BN层将每一个batch的均值与方差引入到网络中，由于每个batch的这两个值都不相同，可看做为训练过程增加了随机噪音，可以起到一定的正则效果，防止过拟合\n\n\n在测试时应该注意的问题：\n**在测试时，由于是对单个样本进行测试，没有batch的均值与方差，通常做法是在训练时将每一个batch的均值与方差都保留下来，在测试时使用所有训练样本均值与方差的平均值。**\n\n\n## PyTorch中使用BN层\n\n```python\n>>> import torch.nn as nn\n>>> import torch\n# 使用BN层需要传入一个参数为num_features，即特征的通道数\n>>> bn = nn.BatchNorm2d(64)\n# eps为公式中的є，momentum为均值方差的动量，affine为添加可学习参数\n>>> bn\nBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n>>> input = torch.randn(4, 64, 224, 224)\n>>> output = bn(input)\n>>> output.shape\n# BN层不改变输入、输出的特征大小\ntorch.Size([4, 64, 224, 224])\n>>>     \n```\n## BN的弊端\n管BN层取得了巨大的成功，但仍有一定的弊端，主要体现在以下两点：\n- 由于是在batch的维度进行归一化，BN层要求较大的batch才能有效地工作，而物体检测等任务由于占用内存较高，限制了batch的大小，这会限制BN层有效地发挥归一化功能。\n- 数据的batch大小在训练与测试时往往不一样。**在训练时一般采用滑动来计算平均值与方差(一个batch一个batch计算)，在测试时直接拿训练集的平均值与方差来使用**。这种方式会导致测试集依赖于训练集，然而有时训练集与测试集的数据分布并不一致。\n\n\n因此，我们能不能避开batch来进行归一化呢？答案是可以的，最新的GN（Group  Normalization）从通道方向计算均值与方差，使用更为灵活有效，避开了batch大小对归一化的影响。具体来讲，GN先将特征图的通道分为很多个组，对每一个组内的参数做归一化，而不是batch。GN之所以能够工作的原因，可以认为是在特征图中，不同的通道代表了不同的意义，例如形状、边缘和纹理等，这些不同的通道并不是完全独立地分布，而是可以放到一起进行归一化分析。\n\n\n参考文档\n\n深度学习之PyTorch物体检测实战[董洪义著]\n深度学习入门基于Python的理论与实现[斋藤康毅著，陆宇杰译]\n神经网络与深度学习[邱锡鹏著]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["normalize"],"categories":["normalize"]},{"title":"神经网络之多维卷积的那些事(一维、二维、三维)","url":"/2020/11/24/214142/","content":"\n## 前言\n一般来说，一维卷积用于文本数据，二维卷积用于图像数据，对宽度和高度都进行卷积，三维卷积用于视频及3D图像处理领域（检测动作及人物行为），对立方体的三个面进行卷积 。二维卷积的用处范围最广，在计算机视觉中广泛应用。\n<!-- more -->\n\n\n## 一维卷积Conv1d\n一维卷积最简单，实质是对一个词向量做卷积，如下所示：\n![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hsZXIvYmxvZ2ltZy9yYXcvbWFzdGVyL2ltZ3MvMjAyMDA3MTAxNzM0NTEucG5n?x-oss-process=image/format,png)\n\n- 图中的输入的数据维度为8，过滤器的维度为5。卷积后输出的数据维度为8−5+1=4\n- 如果过滤器数量仍为1，输入数据的channel数量变为16，则输入数据维度为8×16\n- 一维卷积常用于序列模型，自然语言处理领域。\n\n\nPytorch中nn.Conv1d卷积运算要求输入源是3维，输入源的三个维度分别是：第一个维度代表每个序列的个数即样本数，第二个维度代表每一个序列的通道数，第三个维度代表这个词向量序列，如下所示：\n```python\nimport torch\nimport torch.nn as nn\n# 输入源：1个样本，16个通道，8个数据\na = torch.randn(1,16,8)\n# 卷积：输入通道为16，输出通道为1，卷积核大小 5*5\nconv = nn.Conv1d(16, 1, 5)\nc = conv(a)\nprint('a:', a.size())\nprint('c:', c.size())\n```\n\n**output**\n\n```\na: torch.Size([1, 16, 8])\nc: torch.Size([1, 1, 4])\n```\n\n## 二维卷积Conv2d\n二维卷积是最常见、用途最广泛的卷积。先假定卷积核(过滤器)数量为1，图片通道数为1，卷积操作如下：\n![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hsZXIvYmxvZ2ltZy9yYXcvbWFzdGVyL2ltZ3MvMjAyMDA3MTAxNzM4NDUucG5n?x-oss-process=image/format,png)\n\n- 图中的输入的数据维度为`14×14`，卷积核数量为1，图片通道数为1\n- 二维卷积输出的数据尺寸为`8−5+1=4`，即`4×4`\n\n这是最简单的二维卷积的场景，现在重点来了，假定图片通道数为3，卷积核的数量为1，则卷积操作如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723171151348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n- 如上图所示，输入源是`6*6*3`（图片大小`6*6`,三个通道），卷积核大小`3*3`，filters(卷积核数量)=1,即权重矩阵是`3*3*3*1`，得到的结果`4*4*1`（图片大小`4*4`,一个通道）\n- 其实就是三个`3*3`的卷积核分别对图片的三个通道做卷积，然后把结果相加得到一个`4*4`的图片。所以，这里卷积核w的参数个数是`(3*3*3+1)*1`，(输入通道`3`，卷积核大小`3*3`，一个偏置，输出通道1)\n- 上图卷积 Pytorch中表示为：`nn.Conv2d(3,1,kernel_size=(3,3),stride=1)`\n\n**到这里可能有人会问，卷积核大小为3\\*3，为什么变成3\\*3\\*3了？**\n可以细想一下，图片的大小是`6*6*3`（图片大小6\\*6,三个通道），也就是三维的图片，二维的卷积是肯定不能对其操作的，所以卷积核的维度会随着图片的输入通道改变，如果图片的输入通道是3，那么卷积核的维度也是3，如果图片的输入通道是1，那么卷积核的维度也是1，这也就是为什么Pytorch中nn.Conv2d的输入通道要与图片的输入通道保持一致的原因，否则无法进行卷积操作。\n\n**现在，假定图片通道数为3，卷积核的数量为2，则卷积操作如下**：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723172020944.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n- 如上图所示，输入源是`6*6*3`（图片大小`6*6`,三个通道），卷积核大小`3*3`，filters=2，即权重矩阵是`3*3*3*2`，得到的结果`4*4*2`\n- 上图每一个卷积核卷积参数的个数是`(3*3*3+1)*2`\n- 上图卷积 Pytorch中表示为：`nn.Conv2d(3,2,kernel_size=(3,3),stride=2)`\n\n计算图如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200731150746946.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n二维卷积常用于计算机视觉、图像处理领域。\n\n\nPytorch中nn.Conv2d卷积运算要求输入源是4维，输入源的四个维度分别是：第一个维度代表图片的个数即样本数，第二个维度代表每一张图片的通道数，后面二个维度代表图片的像素矩阵，如下所示：\n\n```python\nimport torch\nimport torch.nn as nn\na = torch.Tensor([[[[1,2,3,4],\n                [5,6,7,8],\n                [9,10,11,12],\n                [13,14,15,16]]],\n               [[[1,2,3,4],\n                [5,6,7,8],\n                [9,10,11,12],\n                [13,14,15,16]]]])\nprint('a:',a.size())\n# 卷积核：输入通道为1，输出通道6，卷积核大小2*2\nconv = nn.Conv2d(1,6,2)\nc = conv(a)\nprint('c:',c.size())\n\nconv1 = nn.Conv2d(6,16,2)\nc1 = conv1(c)\nprint('c1:',c1.size())\n```\n\n**output**\n```\na: torch.Size([2, 1, 4, 4])\nc: torch.Size([2, 6, 3, 3])\nc1: torch.Size([2, 16, 2, 2])\n```\n\n## 三维卷积Conv3d\n\n![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hsZXIvYmxvZ2ltZy9yYXcvbWFzdGVyL2ltZ3MvMjAyMDA3MTAxNzU3NTMucG5n?x-oss-process=image/format,png)\n\n三维卷积具体思想与一维卷积、二维卷积相同，假设卷积核大小为`f1*f2*f3`(类似于二维卷积，三维卷积实际计算的时候卷积核是四维的，另一个维度由输入源的通道数决定)\n\n- 假设输入数据的大小为`a1×a2×a3`\n- 基于上述情况，三维卷积最终的输出为`(a1−f1+1)×(a2−f2+1)×(a3−f3+1)`\n- 三维卷积常用于医学领域（CT影响），视频处理领域（检测动作及人物行为）。\n\nPytorch中nn.Conv3d要求输入源是5维的，输入源的5个维度分别表示为：第一个维度代表样本的个数，第二个维度代表每个样本的通道数，后面三个维度代表三维立体图形的像素矩阵，如下所示：\n\n```python\nimport torch\nimport torch.nn as nn\nx = torch.randn(1,2,6,1,1)\nconv = nn.Conv3d(in_channels=2,\n                 out_channels=6,\n                 kernel_size=(2,1,1))\nc = conv(x)\nprint('x:', x.size())\nprint('c:', c.size())\n```\n\n**output**\n```\nx: torch.Size([1, 2, 6, 1, 1])\nc: torch.Size([1, 6, 5, 1, 1])\n```\n*说明：通道数从输入的2转化为6，一个立体像素矩阵，输入前大小为6\\*1\\*1, 卷积核2\\*1\\*1，得到结果为(6-2+1)\\*(1-1+1)\\*(1-1+1)=5\\*1\\*1*\n\n\n## 卷积中的特征图大小计算方式\n在神经网络卷积操作主要是提取特征的，因此卷积的输出称为**特征图(FeatureMap)**，神经网络中有多层卷积，所以除了最开始输入的原始图像外，我们认为卷积输入的也是特征图\n\n当卷积操作步长为1的时候，进行卷积操作后特征图的尺寸比较容易计算，如果步长为2或者更大就不容易计算了。其实这里有一个通用的公式，如下所示：\n$$W_{out} = \\frac{ W_{in}+2*padding-K}{stride} + 1$$\n其中，$W_{out}$为输出特征图的大小，$W_{in}$为输入特征图的大小，K为卷积核大小，stride为卷积步长，padding为特征图填充的圈数。\n\n这里不得不提一下，**池化操作对上述公式也适用，我看有的文章里说，卷积除不尽的结果都向下取整，池化除不尽的结果都向上取整，这个说法是错误，我经过测试得出Pytorch和TensorFlow默认都是向下取整**。如下所示：\n\n**卷积操作向下取整**\n```python\n# 卷积操作向下取整\nimport torch\nimport torch.nn as nn\na = torch.rand(1,1,10,10)\n# (10+2*2-5)/2.0+1 = 5.5\nconv2d = nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(5,5),padding=2,stride=2)\noutput = conv2d(a)\noutput.size()\n# 输出为：torch.Size([1, 1, 5, 5])\n```\n**池化默认也是向下取整**\n```python\n# 池化默认也是向下取整\nimport torch\nimport torch.nn as nn\na = torch.rand(1,1,10,10)\n# (10+2*2-5)/2.0+1 = 5.5\nmaxpool = nn.MaxPool2d(kernel_size=(5,5),stride=2,padding=2)\noutput = maxpool(a)\noutput.size()\n# 输出为：torch.Size([1, 1, 5, 5])\n```\n**但是，Pytorch中池化层有个参数ceil_node=True是向上取整的，它默认是False，TensorFlow里面没找到类似的参数**\n\n```python\n# 池化层ceil_mode=True向上取整\nimport torch\nimport torch.nn as nn\na = torch.rand(1,1,10,10)\n# (10+2*2-5)/2.0+1 = 5.5\nmaxpool = nn.MaxPool2d(kernel_size=(5,5),stride=2,padding=2,ceil_mode=True)\noutput = maxpool(a)\noutput.size()\n# 输出为：torch.Size([1, 1, 6, 6])\n```\n\n\n\n\n## 总结\n到这里我们学到了\n- 不同卷积的应用\n- 多维卷积的原理\n- 多维卷积核参数的个数\n- 卷积中的特征图计算方式\n\n是不是感觉收获满满！！！\n\n\n\n","tags":["卷积"],"categories":["神经网络"]},{"title":"PyTorch之torchvision.transforms详解[原理+代码实现]","url":"/2020/11/24/213959/","content":"## 前言\n\n我们知道，在计算机视觉中处理的数据集有很大一部分是图片类型的，如果获取的数据是格式或者大小不一的图片，则需要进行归一化和大小缩放等操作，这些是常用的数据预处理方法。如果参与模型训练中的图片数据非常有限，则需要通过对有限的图片数据进行各种变换，如缩小或者放大图片的大小、对图片进行水平或者垂直翻转等，这些都是数据增强的方法。庆幸的是，这些方法在torch.transforms中都能找到，在torch.transforms中有大量的数据变换类，有很大一部分可以用于实现**数据预处理（Data Preprocessing）和数据增广（Data Argumentation）**。\n<!-- more -->\n\n\n## torchvision.transforms常用变换类\n\n\n### transforms.Compose\ntransforms.Compose类看作一种容器，它能够同时对多种数据变换进行组合。传入的参数是一个列表，列表中的元素就是对载入的数据进行的各种变换操作。\n\n**首先使用PIL加载原始图片**\n\n```python\n#Pyton Image Library  PIL 一个python图片库\nfrom PIL import Image\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimg = Image.open(\"./imgs/dianwei.jpg\")\nprint(img.size)\nplt.imshow(img)\n```\n输出：\n`(1102, 735)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103029941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n```python\ntransformer = transforms.Compose([                                \n    transforms.Resize(256),\n    transforms.transforms.RandomResizedCrop((224), scale = (0.5,1.0)),\n    transforms.RandomHorizontalFlip(),\n])\ntest_a = transformer(img)\nplt.imshow(test_a)\n```\n输出：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103150561.png)\n\n\n### transforms.Normalize(mean, std)\n\n这里使用的是标准正态分布变换，这种方法需要使用原始数据的均值（Mean）和标准差（Standard Deviation）来进行数据的标准化，在经过标准化变换之后，数据全部符合均值为0、标准差为1的标准正态分布。计算公式如下：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723113549916.png)\n一般来说，mean和std是实现从原始数据计算出来的，对于计算机视觉，更常用的方法是从样本中抽样算出来的或者是事先从相似的样本预估一个标准差和均值。如下代码，对三通道的图片进行标准化：\n\n```python\n# 标准化是把图片3个通道中的数据整理到规范区间 x = (x - mean(x))/stddev(x)\n# [0.485, 0.456, 0.406]这一组平均值是从imagenet训练集中抽样算出来的\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n```\n### transforms.Resize(size)\n对载入的图片数据按照我们的需要进行缩放，传递给这个类的size可以是一个整型数据，也可以是一个类似于 (h  ,w) 的序列。如果输入是个(h,w)的序列，h代表高度，w代表宽度，h和w都是int，则直接将输入图像resize到这个(h,w)尺寸，相当于force。如果使用的是一个整型数据，则将图像的短边resize到这个int数，长边则根据对应比例调整，图像的长宽比不变。\n```python\n# 等比缩放\ntest1 = transforms.Resize(224)(img)\nprint(test1.size)\nplt.imshow(test1)\n```\n输出：\n`(335, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103305748.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n### transforms.Scale(size)\n对载入的图片数据我们的需要进行缩放，用法和torchvision.transforms.Resize类似。。**传入的size只能是一个整型数据**，`size`是指缩放后图片最小边的边长。举个例子，如果原图的`height>width`,那么改变大小后的图片大小是`(size*height/width, size)`。\n```python\n# 等比缩放\ntest2 = transforms.Scale(224)(img)\nprint(test2.size)\nplt.imshow(test2)\n```\n输出：\n`(335, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103356414.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n\n### transforms.CenterCrop(size)\n以输入图的中心点为中心点为参考点，按我们需要的大小进行裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于(h,w)的序列。**如果输入的是一个整型数据，那么裁剪的长和宽都是这个数值**\n```python\ntest3 = transforms.CenterCrop((500,500))(img)\nprint(test3.size)\nplt.imshow(test3)\n```\n输出：\n`(500, 500)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103440830.png)\n```python\ntest4 = transforms.CenterCrop(224)(img)\nprint(test4.size)\nplt.imshow(test4)\n```\n输出：\n`(224, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103532667.png)\n\n\n\n### transforms.RandomCrop(size)\n用于对载入的图片按我们需要的大小进行随机裁剪。传递给这个类的参数可以是一个整型数据，也可以是一个类似于(h,w)的序列。**如果输入的是一个整型数据，那么裁剪的长和宽都是这个数值**\n```python\ntest5 = transforms.RandomCrop(224)(img)\nprint(test5.size)\nplt.imshow(test5)\n```\n输出：\n`(224, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727103718102.png)\n```python\ntest6 = transforms.RandomCrop((300,300))(img)\nprint(test6.size)\nplt.imshow(test6)\n```\n输出：\n`(300, 300)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072710391757.png)\n\n\n\n### transforms.RandomResizedCrop(size,scale)\n\n先将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为size的大小。即先随机采集，然后对裁剪得到的图像安装要求缩放，默认scale=(0.08, 1.0)。scale是一个面积采样的范围，假如是一个100\\*100的图片，scale = (0.5,1.0)，采样面积最小是0.5\\*100\\*100=5000，最大面积就是原图大小100\\*100=10000。先按照scale将给定图像裁剪，然后再按照给定的输出大小进行缩放。\n```python\ntest9 = transforms.RandomResizedCrop(224)(img)\nprint(test9.size)\nplt.imshow(test9)\n```\n输出：\n`(224, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104231793.png)\n```python\ntest9 = transforms.RandomResizedCrop(224,scale=(0.5,0.8))(img)\nprint(test9.size)\nplt.imshow(test9)\n```\n输出：\n`(224, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104330982.png)\n\n\n\n\n### transforms.RandomHorizontalFlip\n用于对载入的图片按随机概率进行水平翻转。我们可以通过传递给这个类的参数自定义随机概率，如果没有定义，则使用默认的概率值0.5。\n```python\ntest7 = transforms.RandomHorizontalFlip()(img)\nprint(test7.size)\nplt.imshow(test7)\n```\n输出：\n`(1102, 735)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104041714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n### transforms.RandomVerticalFlip\n用于对载入的图片按随机概率进行垂直翻转。我们可以通过传递给这个类的参数自定义随机概率，如果没有定义，则使用默认的概率值0.5。\n```python\ntest8 = transforms.RandomVerticalFlip()(img)\nprint(test8.size)\nplt.imshow(test8)\n```\n输出：\n`(1102, 735)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104127721.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n### transforms.RandomRotation\n```python\ntransforms.RandomRotation(\n    degrees,\n    resample=False,\n    expand=False,\n    center=None,\n    fill=None,\n)\n```\n- 功能：按照degree随机旋转一定角度\n- degree：加入degree是10，就是表示在（-10，10）之间随机旋转，如果是（30，60），就是30度到60度随机旋转\n- resample是重采样的方法\n- center表示中心旋转还是左上角旋转\n\n```python\ntest10 = transforms.RandomRotation((30,60))(img)\nprint(test10.size)\nplt.imshow(test10)\n```\n![在这里插入图片描述](https://img-blog.csdnimg.cn/202009022028180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n### transforms.ToTensor\n用于对载入的图片数据进行类型转换，将之前构成PIL图片的数据转换成Tensor数据类型的变量，让PyTorch能够对其进行计算和处理。\n\n### transforms.ToPILImage\n用于将Tensor变量的数据转换成PIL图片数据，主要是为了方便图片内容的显示。\n\n## torchvision.transforms编程实战\n```python\n# RandomResizedCrop 将给定图像随机裁剪为不同的大小和宽高比，然后缩放所裁剪得到的图像为制定的大小\nprint(\"原图大小：\",img.size)\n# Crop代表剪裁到某个尺寸\ndata1 = transforms.RandomResizedCrop(224)(img)\n# data1、data2、data3尺寸一样，长宽都是224*224  size也可以是一个Integer，在这种情况下，切出来的图片的形状是正方形\nprint(\"随机裁剪后的大小:\",data1.size)\ndata2 = transforms.RandomResizedCrop(224)(img)\ndata3 = transforms.RandomResizedCrop(224)(img)\n\n# 放四个格，布局为2*2\nplt.subplot(2,2,1),plt.imshow(img),plt.title(\"Original\")\nplt.subplot(2,2,2),plt.imshow(data1),plt.title(\"Transform 1\")\nplt.subplot(2,2,3),plt.imshow(data2),plt.title(\"Transform 2\")\nplt.subplot(2,2,4),plt.imshow(data3),plt.title(\"Transform 3\")\nplt.show()\n```\n输出：\n`原图大小： (1102, 735)`\n`随机裁剪后的大小: (224, 224)`\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072710460549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n```python\n# 以输入图的中心点为中心点做指定size的crop操作\nimg1 = transforms.CenterCrop(224)(img)\nimg2 = transforms.CenterCrop(224)(img)\nimg3 = transforms.CenterCrop(224)(img)\n# img1、img2、img3三个图是一样的\nplt.subplot(2,2,1),plt.imshow(img),plt.title(\"Original\")\nplt.subplot(2,2,2), plt.imshow(img1), plt.title(\"Transform 1\")\nplt.subplot(2,2,3), plt.imshow(img2), plt.title(\"Transform 2\")\nplt.subplot(2,2,4), plt.imshow(img3), plt.title(\"Transform 3\")\nplt.show()\n```\n输出：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104637657.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n```python\n# 以给定的概率随机水平旋转给定的PIL的图像，默认为0.5\nimg1 = transforms.RandomHorizontalFlip()(img)\nimg2 = transforms.RandomHorizontalFlip()(img)\nimg3 = transforms.RandomHorizontalFlip()(img)\n\nplt.subplot(2,2,1),plt.imshow(img),plt.title(\"Original\")\nplt.subplot(2,2,2), plt.imshow(img1), plt.title(\"Transform 1\")\nplt.subplot(2,2,3), plt.imshow(img2), plt.title(\"Transform 2\")\nplt.subplot(2,2,4), plt.imshow(img3), plt.title(\"Transform 3\")\nplt.show()\n```\n输出：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200727104701915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n\n源码在[PyTorch之torchvision.transforms实战](https://gitee.com/wxler/AIProjectTraining/blob/master/practice/PyTorch%E4%B9%8Btorchvision.transforms%E5%AE%9E%E6%88%98.ipynb)，请自提！\n\n\n参考文档\n深度学习pytoch实战计算机视觉(唐进民著)\n\n\n","categories":["数据预处理"]},{"title":"深入理解GAN对抗生成网络","url":"/2020/11/24/213812/","content":"\n##  什么是GAN\n>Generative Adversarial Networks，生成式对抗网络，Ian Goodfellow 在2014 年提出的一种生成式模型\n基本思想来自博弈论的二人零和博弈（纳什均衡）, 由一个生成器和一个判别器构成，通过对抗学习来训练\n\n- 生成器的目的是尽量去学习真实的数据分布\n- 判别器的目的是尽量正确判别输入数据是来自真实数据还是来自生成器\n- 生成器和判别器就是一个矛和盾互相PK的过程\n- 为了取得游戏胜利，这两个游戏参与者需要不断优化， 各自提高自己的生成能力和判别能力，这个学习优化过程就是寻找二者之间的一个纳什均衡\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722120217603.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*G代表生成器，D代表判别器，Z是输入源，称为Noise source，就是一个随机编码。给出一个random code(即Z)由生成器G生成假数据X'，假数据X'和真实数据X喂给判别器D，由D判别出哪个是real，哪个是fake，这个就是gan的基本原理*\n\n<!-- more -->\n\n@[TOC]\n\n\n## 纳什均衡\n我们以囚徒困境的例子来解释纳什均衡的含义\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722120703173.png)\nA和B属于零和游戏，需要在A和B的决策中进行Trade Off(权衡)，由此看出，抵赖对两个人来说都是最优的结果，这个就是纳什均衡。\n\n>亚当·斯密的“看不见的手”，在市场经济中，每一个人都从利己的目的出发，不断调和与迭代，最终全社会达到利他的效果\n\n## GAN的学习过程\nGAN的学习过程其实就是把D和G达成一个均衡，这是我们的目标，因此不仅要训练G，也要训练D\n\n**为什么D和G是对抗的？**\nG是生成器，它生成的数据是虚假的，它目标是让生成的数据骗过D。D是判别器，它的目标是要把虚假的数据给找出来，因此D和G是对抗的\n\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2020072212094128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n对于 GAN 的学习过程 ，需要训练模型D来最大化判别数据来源于真实数据或者伪数据分布 ，同时，我们需要训练模型 G来最小化 loss。\n\n**我们该采用怎样的优化方法，对生成器G和判别器D进行优化呢？**\n\n- Step1，固定生成器 G=>优化判别器 D，让D的判别准确率最大化\n- Step2，固定判别器 D => 优化生成器 G，让D的判别准确率最小化\n\n训练 GAN 时，在同一轮参数更新中，通常对 D 的参数更新 k 次，再对 G的参数更新 1 次，这样做的目的是让D学的更快点，因为我们最终要的是G，为此需要把D这个教练先变得越来越好，由此才能训练出更好的G\n\n**Generator与Discriminator的工作原理**\n\n- Generator，在输入一个随机编码（random code）z之后，它将输出一幅由神经网络自动生成的、假的图片G(z)\n- Discriminator，接受G输出的图像作为输入，然后判断这幅图像的真假，真的输出1，假的输出0\n- G生成的图像会越来越逼真，D也越来越会判断图片的真假，最后我们就不要D了，直接用G来生成图像\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722121543593.png)\n我们就是要在最大化D的能力的前提下，最小化D对G的判断能力 ，所以称之为 最小最大值问题\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722121618497.png)\n*损失函实际上是一个交叉熵，判别器的目的是尽可能的令D(x)接近1(对于真图像x的处理评分要高)，令D(G(z))接近0(对于假图像G(z)的处理评分要尽量降低)，所以D主要是最大化上面的损失函数(让D的辨别能力更强)，G恰恰相反，他主要是最小化上述损失函数(让生成的假图像G(z)变得更真实)。*\n\n为了增强D的能力，我们分别考虑输入真的图像和假的图像的情况\n\n**D的目标是什么？G的目标是什么？**\n- D的目标是：D(G(z))处理的是假图像G(z) => 评分D(G(z))要尽量降低，对于真图像x的处理 => 评分要高，这样D的辨别能力才会更强\n- G的目标是：让生成的假图像G(z)变得更真实、更逼真，让D难以辨别\n\n\n\n## GAN的局限性\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722121848640.png)\n\n用户输入random code由生成器G参数 fake image即G(Z)，传统的GAN中会出现如下局限性：\n\n 1. 在传统的GAN里，由于没有用户控制能力，输入一个随机噪声，就会输出一幅随机图像（可能输出猫在左边或是猫在右边的图像）\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722121929235.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n>这里user input 是指输入的random code，output是G生成的G(Z)，还要从现实世界中取一张或者画一张真实图像，与output一起输入判别器\n\n2. 低分辨率（Low resolution）和低质量（Low quality）问题\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722122102813.png)\n生成的图片看起来不错，但放大看，会发现细节相当模糊\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722122125898.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n## 如何改善GAN的局限性\n如改善GAN的局限性可以从以下两个方面入手：\n- 提高GAN的用户控制能力\n- 提高GAN生成图片的分辨率和质量\n\n从以上两个方面提出新的算法模型：\n\n1. pix2pix，有条件的使用用户输入，使用成对的数据（paired data）进行训练。比如，输入的是猫在左边，你就不能生成猫在右边的图。Pix2pix的缺点：在训练过程中，需要人为给它标出数据的对应关系，比如 现在的输入条件是猫在左边，人要给它画一张或找一张猫在左边的图像，才会让G更好的学习，以产生猫在右边的图像，这对数据源的要求会很高\n2. CycleGAN，使用不成对的数据（unpaired data）就能训练。  \n以马为例，马训练马是成对的数据，用马生成斑马，是不成对数据。由于现实生活中成对的样本比较少，对于没有成对样本的情况，使用CycleGAN，CycleGAN有两个生成器，马->斑马，斑马->马，我们最终想要的是马->斑马，利用理论上开始的马和马->斑马->马是一样的，同时优化马->斑马，斑马->马两个生成器，最终使用马->斑马。\nCycleGAN本质是优化生成器的一个思想，拿文本翻译来说，你把一段英文翻译成中文，再把中文翻译回英文，假如翻译回来的英文和一开始的英文天差地别，那么这个两次翻译的结果肯定是很差的；反之，如果能够让翻译回来的英文和原本的一样，就相当于是改进了两次翻译的效果，CycleGAN利用这种方式来优化生成器。\n\n\n3. pix2pixHD，生成高分辨率、高质量的图像\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200722122528208.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n未来还会持续更新：\n\n- Conditional GAN\n- pix2pix\n- CycleGAN\n- GauGAN\n\n谢谢支持！","tags":["GAN"],"categories":["神经网络"]},{"title":"Pycharm 2020 中导入Anaconda3创建的环境","url":"/2020/11/24/213628/","content":"\n## 在pycharm配置环境Anaconda环境\n之前用的Anaconda3中的jupyter Lab写python程序，后来根据需要用到pycharm，又不想重新安装python库，直接用到Anaconda3中下载好的库该有多好，现在尝试用pycharm2020配置Anaconda3创建的环境。\n<!-- more -->\n\n\n\n\n假设pycharm2020和Anaconda3安装好了，现在就开始配置流程吧，选择File->Setting->Project Interpreter，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707153748538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n点击右上角齿轮->add![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707153849133.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n选择Conda Environment->Existing enviroment\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707153952159.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n到这里只要选择你的python虚拟环境所在的目录就行了，不知道conda安装的python虚拟环境在哪里？这好办，在开始菜单打开Anconda Powershell Prompt\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707154203781.png)\n然后执行`jupyter kernelspec list`,就可以显示Anaconda所有的python内核环境,如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/202007071544150.png)\n不过这里显示的可不是python环境真正的目录，以上图第一个虚拟环境所示，在文件管理器中打开`D:\\install\\anaconda3\\share\\jupyter\\kernels\\python3`，可以找到文件kernel.json，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707154711688.png)\n上面划线部分才是真正python虚拟环境所在的目录，将`D:/install/anaconda3\\\\python.exe`应用到Interpreter所在位置即可\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707154847886.png)\n*注意：Make available to all projects:应用到所有项目，推荐勾选*\n\n目录加载之后，会自动加载该python环境下的包，如下所示，点击apply即可\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707155226636.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n## 用配置好的环境新建项目\n在pycharm新建有两种方式，分别是New enviroment using 和 Existing interpreter，如下所示：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707155611812.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n- New enviroment using：用新环境创建项目\n- Existing interpreter：用已存在的环境创建项目\n\n###  用Existing interpreter方式新建项目\n\n我们先用Existing interpreter创建项目，项目命名为test4，创建完成后，导入torch（在Anaconda安装了pytorch，并没有在pycahrm中安装），新建一个tset.py，可以看到，程序完美运行。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707160012207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\ntest.py运行结果如下：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707160621212.png)\n### 用New enviroment using方式新建项目\n\n- New environment using 设置新的依赖环境。它是pycharm自带的virtualenv创建项目，可以在项目目录中新建一个venv（virtualenv）目录，用于存放虚拟的python环境，这里所有的类库依赖都可以直接脱离系统安装的python独立运行。\n- Location：填写新环境的文件目录\n- Base interpreter下拉框：选择基础解释器，默认是环境中配置的，可以修改。\n- Inherit global site-packages：可以使用base interpreter（基础解释器）中的第三方库，可能会花费时间进行复制；如果不勾选将和外界完全隔离，会在base interpreter的基础上创建一个新的虚拟解释器。\n- Make available to all projects：是否将此虚拟环境提供给其他项目使用。勾选之后，可以提供给其他项目，等再新建下一个项目的时候，可以修改Base interpreter，位置指向现在建立的虚拟环境。\n\n看到上面的解释，我们大致对New enviroment using方式新建项目有所了解了。现在，新建一个项目，命名为test5。该方式创建项目的过程会比较慢，因为它要项目加载所需要类库\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707161010286.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n可以看到，以这种方式新建的项目目录下，会多出一个venv目录（用于存放该项目用到的类库），如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707162417938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n下图可以看出，以这种方式新建的项目，不能直接使用Anaconda的python环境\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707162630586.png)\n如果想要使用Anaconda的python环境，只需要将其Project Interpreter改为我们刚刚配置的Conda环境即可。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200707162849405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n从上面可以看出，用New enviroment using方式新建项目，不仅无法使用conda中的环境，还会自己生成一个用于存放python解释器的目录，所以创建的项目会非常大，不推荐使用。\n\n\n参考文档\n\n[pycharm创建工程的两种方式](https://www.cnblogs.com/xiaohailuo/p/11083211.html)\n[PyCharm新建项目教程](https://blog.csdn.net/Aidiying/article/details/104889259)\n[Pycharm 2020 中导入Anaconda3创建的环境](https://blog.csdn.net/qq_37555071/article/details/107182623)\n","categories":["工具"]},{"title":"hexo设置permalink以比避免url中出现中文","url":"/2020/11/24/204707/","content":"\n当我把hexo的博客标题的时候，url中就会出现中文，很不雅观，这里我通过permalink设置博客链接！\n\n\n\n<!-- more -->\n\n\n\n## 第一步\n\n在_config.yml文件中修改permalink\n\n```bash\n# permalink: :year/:month/:day/:title/ 这是之前的设置\npermalink: :year/:month/:day/:id/\npermalink_defaults:\n```\n\n## 第二步\n\n第一步的`:id`是自己添加的，因此需要在`scaffolds/post.md`中添加id，如下:\n\n```bash\ntitle: {{ title }}\nid: \ndate: {{ date }}\ncategories: Life  #文章分类\ntags: [tag1,tag2]  #文章标签，多标签时使用英文逗号隔开\n```\n\n我一般是把id设置为时分秒，如现在是`20:47:07`，我将id设置为`204707`\n\n\n\n\n\n参考文档\n\n[hexo设置permalink-避免url中出现中文](https://blog.csdn.net/weixin_30394669/article/details/97839708)  ","tags":["hexo"],"categories":["工具"]},{"title":"Anaconda中离线升级jupyterlab并为jupyterlab安装插件","url":"/2020/11/24/194523/","content":"\n## Anaconda中升级jupyterlab\n\n我之前尝试了如下两种方法，升级失败：\n\n- `conda update -c conda-forge jupyterlab`\n- 在Anaconda Navigator 界面升级\n\n后来直接在[anaconda官网](https://anaconda.org/)下载jupyterlab的安装文件，然后执行`conda install 文件名`就安装成功了。\n<!-- more -->\n\n\n\n\n首先，在[anaconda官网](https://anaconda.org/)下载文件时，在搜索栏输入jupyterlab，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706193847540.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n然后点击文件名，进如下页面，再点击Files就可以下载文件\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706194046685.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n最后，打开Anaconda Powershell Prompt（如果配置了环境变量，直接打开cmd也可以），`cd 文件所在目录`，执行`conda install 文件名`就成功啦。比如我下载的是jupyterlab-2.1.5-py_0.tar.bz2，执行`conda install jupyterlab-2.1.5-py_0.tar.bz2`即可，**安装成功后，会默认覆盖Anaconda自带的jupyterlab，所以就意味着升级了jupyterlab**，安装jupyterlab之后，并不能在shell命令窗口直接输入jupyterlab直接启动，但是可以在Anaconda Navigator界面启动。如果想要在shell窗口启动，则需要配置conda环境变量。\n\n**这个安装方法其实算是一类离线安装方法，无法通过命令安装的anaconda插件，都可以在[anaconda官网](https://anaconda.org/)下载之后离线安装**\n\n## 升级jupyterlab插件出现问题\n升级之和，之前在低版本jupyterlab下安装的一部分插件就可能过时，在Anaconda Powershell Prompt执行`jupyter labextension list`就可以查看插件的情况，如下所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200706195338601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n遇见过时的插件，可以执行`jupyter labextensio update 插件名`或`jupyter labextension update --all`来更新插件，但是我尝试了之后，没有一个插件能够更新成功，索性就执行`jupyter labextensio uninstall 插件名`把过时的插件都卸载了，然后执行`jupyter labextensio install 插件名`安装需要的插件即可，比如我要安装jupyter的目录插件，可以执行：\n\n```powershell\njupyter labextension install @jupyterlab/toc\n或者\njupyter labextension install https://github.com/jupyterlab/jupyterlab-toc.git\n```\n\n## conda&jupyterlab插件相关命令\n### conda命令\n删除一个名为 mytest 的环境或库。-n为该环境或库的名字，--all 说明删除 mytest 环境下的所有内容，也就是这个环境被删除了：`conda remove -n mytest --all`\n\n删除一个库`conda remove 库名`,卸载一个库`conda uninstall 库名 --force`，根据帮助中的描述,这两个命令是一样的。假如如果你安装了tensorflow和numpy,想把numpy降级到另外一个版本。使用conda uninstall numpy会把tensorflow、pytorch等其他依赖numpy的库一起删除.此时加上conda uninstall numpy --force就仅卸载numpy了.一定要看看conda 的帮助.然后在安装需要的numpy版本。\n\n在不指定的情况下，conda install命令默认从 conda 官网 https://conda.anaconda.org/ 上下载。比如下面的，conda-forge 是一个用户，他上传了一个 opencv 的 python 库。opencv=3.2.0 指定了版本，不指定的情况下，下载最新版本：\n```powershell\nconda install -c conda-forge opencv=3.2.0\n```\n当然，你也可以使用 -c 参数，指定一个远程仓库，从这个仓库中下载：\n```powershell\nconda install -c https://conda.anaconda.org/menpo opencv3\n```\n\n**可以通过`anaconda-navigator --reset`解决Anaconda启动慢的问题**\n\n\n\n### jupyterlab插件命令\n\n- 更新插件：`jupyter labextensio update 插件名`\n- 更新所有插件：`jupyter labextension update --all`\n- 卸载插件：`jupyter labextensio uninstall 插件名`\n- 安装插件：`jupyter labextensio install 插件名`\n- 远程仓库安装插件：`jupyter labextension install 参考地址`\n- 安装制定版本插件：`jupyter labextensio install 插件名=版本号`\n- 查看已安装插件：`jupyter labextension list`\n\n\n\n\n\n\n参考文档\n\n[附录C：conda相关命令](https://www.jianshu.com/p/b2b46dd6332b)","categories":["工具"]},{"title":"数据预处理：归一化/标准化详解","url":"/2020/11/24/192901/","content":"\n## 前言\n\n一般而言，样本的原始特征中的每一维特征由于来源以及度量单位不同，其特征取值的分布范围往往差异很大，比如身高、体重、血压等它们的度量和分布范围往往是不一样的。当我们计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。这样，**对于基于相似度比较的机器学习方法（比如最近邻分类器），必须先对样本进行预处理，将各个维度的特征归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理想的结果**。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但是会导致训练效率比较低。\n\n<!-- more -->\n\n\n\n\n\n## 归一化的必要性及价值\n现在假设一个只有一层的网络：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723211349432.png)\n我们知道，tanh 函数的导数在区间 [−2, 2] 上是敏感的，其余的导数接近于 0，tanh图像如下图所示：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723211508510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n\n因此，如果 $w1x1 + w2x2 + b$ 过大或过小，都会导致梯度过小，难以训练。**为了提高训练效率，我们需要使$w1x1 + w2x2 + b$在 [−2, 2] 区间，我们需要将w1 设得小一点，比如在 [−0.1, 0.1] 之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数**。因此，如果每一个特征的取值范围都在相似的区间，比如 [0, 1] 或者 [−1, 1]，那该多好啊，我们就不太需要区别对待每一个参数，减少人工干预。\n\n>我们经常见到，归一化、标准化、规范化，其实他们的含义是一样的，都是消除数据量纲带来的差异，加快模型的训练效率\n\n除了参数初始化之外，不同输入特征的取值范围差异比较大时，梯度下降法的效率也会受到影响。下图给出了数据归一化对梯度的影响。其中，图a为未归一化数据的等高线图。**取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛**。如果我们把数据归一化为取值范围相同，如图b所示，大部分位置的梯度方向近似于最优搜索方向。这样，**在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高**。\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723212620723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n## 归一化的方式\n归一化的方法有很多种，最常用的是最小最大归一化和标准归一化\n\n**最小最大归一化**使结果落到[0,1]区间，转换函数如下：\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723213531858.png)\n\n*其中 min(x) 和 max(x) 分别是特征 x 在所有样本上的最小值和最大值。*\n\n**标准归一化**也叫 z-score 归一化，将每一个维特征都处理为符合标准正态分布（均值为 0，标准差为 1）。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200723214316862.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTU1MDcx,size_16,color_FFFFFF,t_70)\n*这里 σ 不能为 0。如果标准差为 0，说明这一维特征没有任务区分性，可以直接删掉。在标准归一化之后，每一维特征都服从标准正态分布。*\n\n## 总结\n\n总的来说，归一化的好处是：帮助你去除数据的量纲和数据大小的差异，让数据每一个特征的取值范围都在相似的区间，可以让数据在同一个数量级下来做一个比较。这样做可以让模型更快的收敛，因为它不需要去考虑那些夸大的特征，把所有特征的尺度看的同等重要\n\n参考文档\n神经网络与深度学习[邱锡鹏著]","categories":["数据预处理"]},{"title":"深入理解model.eval()与torch.no_grad()","url":"/2020/11/24/192512/","content":"\n我们用pytorch搭建神经网络经常见到model.eval()与torch.no_grad()，它们有什么区别？是怎么工作的呢？现在就让我们来探究其中的奥秘\n<!-- more -->\n\n## model.eval()\n\n- 使用model.eval()切换到测试模式，不会更新模型的k，b参数\n- 通知dropout层和batchnorm层在train和val中间进行切换\n在train模式，**dropout层会按照设定的参数p设置保留激活单元的概率（保留概率=p，比如keep_prob=0.8），batchnorm层会继续计算数据的mean和var并进行更新**\n在val模式下，**dropout层会让所有的激活单元都通过，而batchnorm层会停止计算和更新mean和var，直接使用在训练阶段已经学出的mean和var值**\n- model.eval()不会影响各层的gradient计算行为，即gradient计算和存储与training模式一样，只是不进行反向传播(backprobagation)\n\n## torch.no_grad()\n使用方法：\n```python\nwith torch.no_grad()：\n\t# 代码块\n```\n\n\n- 用于停止autograd模块的工作，起到加速和节省显存的作用（具体行为就是停止gradient计算，从而节省了GPU算力和显存）\n- 不会影响dropout和batchnorm层的行为\n\n\n`model.eval()`与`torch.no_grad()`可以同时用，更加节省cpu的算力\n\n## 思考\n\n在val模式下，为什么让dropout层所有的激活单元都通过，因为train阶段的dropout层已经屏蔽掉了一些激活单元，在val模式下，让所有的激活单元都通过还能预测数据吗?\n**在val模式下，让所有的激活单元都通过当然能预测数据了，相当于学习时限定你每次只能选择一份资料学，考试时开卷所有资料你都带着。val模式下，虽然让所有的激活单元都通过，但是对于各个神经元的输出， 要乘上训练时的删除比例后再输出。**","tags":["pytorch"],"categories":["pytorch"]},{"title":"使用VGG迁移学习开启《猫狗大战挑战赛》","url":"/2020/11/24/181519/","content":" 使用VGG迁移学习开启《猫狗大战挑战赛》，内容如下：\n一、前言\n二、加载数据集\n三、数据预处理\n四、构建VGG模型\n五、训练VGG模型\n六、保存与测试模型\n七、总结\n\n \n\n<!-- more -->\n\n\n\n\n\n# 一、前言\n\n猫狗大战挑战由Kaggle于2013年举办的，目前比赛已经结束，不过仍然可以把[AI研习社猫狗大战赛平台](https://god.yanxishe.com/41)作为练习赛每天提交测试结果，该平台数据集包含猫狗图片共24000张，没有任何标注数据，选手需要训练模型正确识别猫狗图片，**1= dog，0 = cat**。这里使用在 ImageNet 上预训练的 VGG 网络模型进行测试，因为原网络的分类结果是1000类，所以要进行迁移学习，对原网络进行 fine-tune （即固定前面若干层，作为特征提取器，只重新训练最后两层），并把测试结果提交到该平台。那么，现在就让我们开始吧。\n\n\n\n\n\n# 二、加载数据集\n\n前期如何把**解压后的竞赛数据集**放到colab上着实耗费了我大量的时间，我认为非常有必要把这个单独作为一章讲一下。如果你本地有很强的GPU，不需要在colab上跑代码，这章节可以忽略，由于我的电脑跑不动这么多数据，GPU也不行，所以只能在colab上运行。在这个过程中许多问题本是可以避免的，由于对一些操作和指令不熟练，导致许多时间白白流失，即打消了初学者的自信心，也拖慢了实验的进度，究其原因，主要有以下几点：\n\n1. 在google drive上传和解压数据集时间特别慢，需要数十个小时\n\n2. colab运行时间有时限，长时间不操作（大概20分钟左右）会导致当前训练的数据被回收\n\n3. 猫狗大战数据集是没有标签的，需要自己定义Dataset类加载数据\n\n现在就来一个个解决上面的几个痛点吧！\n\n**（1）colab上传和解压大数据集**\n\n我们的目的是要在colab上读取竞赛数据集的图片，达到目的的方式有三个：\n\n- 方式一：把数据集压缩包上传到google drive，在drive上解压\n- 方式二：数据集解压后再上传到google drive\n- 方式三：把数据集压缩包上传到google drive，在colab连接的虚拟机上解压\n\n上面几种方式哪个好呢？我先不直接说结果，来实验下吧！\n\n首先，采用方式一，把数据集压缩包上传到google drive，在drive上解压，操作很简单，在google drive上右键上传[竞赛数据集cat_dog.rar](https://static.leiphone.com/cat_dog.rar)，文件大小521MB，上传时间二十多分钟，上传完毕后，再drive上解压，现在痛点来了，**时间竟然要十几个小时**，具体操作如下：\n\n- 打开colab，挂载google drive，方法可以参考我的博客[Google Colab挂载drive上的数据文件](https://blog.csdn.net/qq_37555071/article/details/107544680)。\n\n- 解压drive上的cat_dog.rar文件，命令为\n\n  ```bash\n  ! apt-get install rar\n  !unrar x \"/content/drive/Colab/人工智能课/cat_dog.rar\" \"/content/drive/Colab/人工智能课/\"\n  ```\n\n  解压过程如下：\n\n  ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120155811.png)\n\n\n\n\n我大致算了一下，每张图片解压时间5秒钟左右，24000张图片要大约33小时啊！！！所以，这种方式直接pass掉。\n\n再来看，方式二，把数据集解压后再上传到google drive，解压后的数据集文件夹大小虽然只有五百多兆，但上传速度特别慢，大概要5至7个小时，**并且一旦中间断网或是网络不稳定，极有可能导致数据损坏**。我就是花费了大半天时间把所有解压后的文件上传完了，由于中间网络不稳定，导致数据读取不正确，最终这种方式也放弃了，哎，说多了都是泪！\n\n最后，就只有方式三了，把数据集压缩包上传到google drive，在colab连接的虚拟机上解压文件，方法是：\n\n- 将google drive上数据集文件cat_dog.rar拷贝到colab连接的虚拟机上\n  ```bash\n  !cp -i /content/drive/Colab/人工智能课/cat_dog.rar /content/\n  ```\n- 在虚拟机上解压压缩文件：\n  ```bash\n  ! apt-get install rar\n  ! unrar x cat_dog.rar\n  ```\n  运行过程如下：![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120162337.png)\n\n\n\n这种方式速度非常快，如果操作正确，**解压时间仅有一分钟左右**，非常值得推荐！\n\n**（2）阻止Colab自动掉线**\n\n在colab上训练代码，页面隔一段时间无操作之后就会自动掉线，之前训练的数据都会丢失。现在你体会到我之前连续几个小时在google drive解压数据集文件的艰辛路程了吧。不过好在最后终于找到了一种可以让其自动保持不离线的方法，用一个js程序自动点击连接按钮。代码如下：\n\n```js\nfunction ClickConnect(){\n  console.log(\"Working\"); \n  document\n    .querySelector(\"#top-toolbar > colab-connect-button\")\n    .shadowRoot\n    .querySelector(\"#connect\")\n    .click()\n}\n \nsetInterval(ClickConnect,60000)\n```\n\n使用方式是：按快捷键`ctrl+shift+i`，并选择`Console`，然后复制粘贴上面的代码，并点击回车，该程序便可以运行了，如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120163050.png)\n\n**（3）猫狗大战数据集是没有标签的，需要自己定义Dataset类才能加载数据**\n\n猫狗大战数据集是没有标签的，但是从其训练集和验证集的图片名字可以获取标签，这就需要我们自己定义Dataset类了，由于这个部分篇幅较多，我们放在下一章讲吧。\n\n\n\n\n\n\n\n# 三、数据预处理\n\n传统的mnist数据集是集成到`torchvision.datasets`，我们使用`datasets.MNIST`就可以方便加载数据，不用做过多的其它处理，而猫狗大战竞赛数据集是如下图方式，并没有用标签对文件夹分类存放，所以我们需要通过图片名称获取标签，并自定义Dataset类加载图片。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120201612.png)\n\n我定义的Dataset类如下所示：\n\n```python\nfrom torch.utils.data import Dataset,DataLoader\n# 创建自己的类：MyDataset,继承 Dataset 类\nclass MyDataset(Dataset):\n    def __init__(self, txt, data_path=None, transform=None, target_transform=None, loader=default_loader):\n        super(MyDataset, self).__init__()\n        file_path = data_path + txt\n        file = open(file_path, 'r', encoding='utf8')\n        imgs = []\n        for line in file:\n            line = line.split()\n            imgs.append((line[0],line[1].rstrip('\\n')))\n\n        self.imgs = imgs\n        self.transform = transform\n        self.target_transform = target_transform\n        self.loader = loader\n        self.data_path = data_path\n\n    # 可以通过索引进行条用，如data[1]\n    def __getitem__(self, index):\n        # 按照索引读取每个元素的具体内容\n        imgName, label = self.imgs[index]\n        # imgPath = self.data_path + imgName\n        imgPath = imgName\n        # 调用那张图片读哪张，最大限度发挥GPU显存\n        img = self.loader(imgPath)\n        if self.transform is not None:\n            img = self.transform(img)\n            label = torch.from_numpy(np.array(int(label)))\n        return img, label\n\n    def __len__(self):\n        # 数据集的图片数量\n        return len(self.imgs)\n    \n# 定义读取文件的各式\ndef default_loader(path):\n    return Image.open(path).convert('RGB')\n```\n\n具体要加载图片数据还要进行几个处理，即事先准备好train、val数据集的路径和标签，以及test数据集的路径，然后使用`MyDataset`加载图片路径文件，最后就可以通过`torch.utils.data.DataLoader`加载图片数据了。具体步骤如下：\n\n（1）首先，读取cat_dog文件夹下的图片路径\n\n```python\n#读一个文件夹下的所有文件名称\ndef read_file_name(file_dir):\n    filename = []\n    for root, dirs, files in os.walk(file_dir):\n        filename = files #当前路径下所有非目录子文件\n        break #这里只要图片文件，执行一次即可退出\n    return filename\n```\n\n（2）然后将文件名格式化为竞赛要求的类型，这里cat标签为0，dog为1\n\n```python\n# 将文件名格式化为要求的类型，这里cat标签为0，dog为1\ndef format_inputAndlabel(file_dir):\n    format_result = []\n    filename = read_file_name(file_dir)\n    for n in filename:#cat为0，dog为1\n        if \"cat\" in n:\n            format_result.append(n+\" 0\")\n        else:\n            format_result.append(n+\" 1\")\n    return format_result\n```\n\n（3）分别传入train、test、val路径读取数据\n\n```python\n# 格式化读取train、test、val\nformat_train_result = format_inputAndlabel(\"cat_dog/train\")\nformat_test_result = format_inputAndlabel(\"cat_dog/test\")\nformat_val_result = format_inputAndlabel(\"cat_dog/val\")\n```\n\n（4）由于自定义的DataSet必须知道文件路径，所以先将格式化的文件名写入文件里，再用自定义的MyDataset读取\n\n```python\ndef convert_format(content):\n  result = []\n  for t in content:\n    v = t.split('.')\n    result.append(int(v[0]))\n  return result\n# 写入train、val文件\ndef write_file(path,file_prefix,content):\n  with open(path, 'w', encoding='utf8') as f:\n      for line in content:\n          f.write(file_prefix+line+'\\n')\n# 写入test文件，由于读取时候文件名是乱序的，因此要先排序\ndef write_test_file(path,test_file_prefix,content):\n  content=convert_format(content)\n  content.sort() #排序\n  with open(path, 'w', encoding='utf8') as f:\n      for line in content: \n          f.write(test_file_prefix+str(line)+'.jpg 0'+'\\n')# test文件没有标签，默认用0填充就行\n\n# 因为自定义的DataSet必须知道文件路径，所以先将格式化的文件名写入文件里，再用自定义MyDataset读取\nwrite_file(path=\"cat_dog/train.txt\",file_prefix=\"cat_dog/train/\",content=format_train_result)\nwrite_file(path=\"cat_dog/val.txt\",file_prefix=\"cat_dog/val/\",content=format_val_result)\nwrite_test_file(path=\"cat_dog/test.txt\",test_file_prefix=\"cat_dog/test/\",content=format_test_result)\n```\n\n（5）对数据进行预处理变换\n\n```python\nfrom torch.utils.data import Dataset,DataLoader\nimport torchvision.transforms as transforms\n# 预处理设置\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ntrain_transformer = transforms.Compose([\n    transforms.Resize(256),\n    transforms.transforms.RandomResizedCrop((224), scale = (0.5,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    normalize])\n\n# val和test是类似的，训练的时候可以多一些增强，这里只做验证就可以\nval_transformer = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    normalize\n])\n```\n\n（6）使用`MyDataset`加载图片路径文件\n\n```python\n# 数据集加载方式设置\ncmd_path='cat_dog/'\ntrainset = MyDataset(txt='train.txt',data_path=cmd_path,transform=train_transformer)\nvalset = MyDataset(txt='val.txt',data_path=cmd_path,transform=val_transformer)\ntestset = MyDataset(txt='test.txt',data_path=cmd_path,transform=val_transformer)\nprint('训练集：',trainset.__len__())\nprint('验证集：',valset.__len__())\nprint('测试集：',testset.__len__())\n\"\"\"\n输出：\n训练集： 20000\n验证集： 2000\n测试集： 2000\n\"\"\"\n```\n\n（7）使用`torch.utils.data.DataLoader`加载图片数据，并将其放入`dataloaders_dict`\n\n```python\nbatchsize=128\n# 构建DataLoader\ntrain_loader = DataLoader(trainset, batch_size = batchsize, drop_last = False, shuffle = True)\n## val_loader和train_loader不做shuffle\nval_loader = DataLoader(valset, batch_size = batchsize, drop_last = False, shuffle = False)\ntest_loader = DataLoader(testset, batch_size = batchsize, drop_last = False, shuffle = False)\ndataloaders_dict = {'train':train_loader,'val':val_loader,'test':test_loader}\n```\n\n最终，数据集文件被放入`dataloaders_dict`，后面就可以通过该字典方便的传入相应的数据集了。\n\n\n\n# 四、构建VGG模型\n\nVGG 模型如下图所示，主体由三种元素组成：\n\n- 卷积层（CONV）是发现图像中局部的 pattern\n- 全连接层（FC）是在全局上建立特征的关联\n- 池化（Pool）是给图像降维以提高特征的 invariance(不变性)\n\n关于VGG模型的更详细介绍，可以参考我的博客[深入解读VGG网络结构](https://blog.csdn.net/qq_37555071/article/details/108199352)\n\n![VGG](http://fenggao-image.stor.sinaapp.com/20191006215625.jpg)\n\n\n\n默认情况下，当我们加载预训练的模型时，所有参数都具有`requires_grad = True`，如果我们从头开始或进行微调训练就不用更改。但是，如果我们要进行特征提取，并且只想为新初始化的图层计算梯度，那么我们希望所有其他参数都不需要梯度更新，需要用`set_parameter_requires_grad`函数将模型中参数的requires_grad属性设置为False，具体如下：\n\n```python\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n```\n\n这里我使用预训练好的VGG模型进行迁移学习，只想更新最后一层的参数，并且希望所有其他参数都不需要梯度更新，所以要用`set_parameter_requires_grad`函数将模型最后一层参数的requires_grad属性设置为False，由于猫狗大战数据集是二分类，需要把最后的`nn.Linear` 层由1000类，替换为2类。如下：\n\n```python\ndef initialize_model(num_classes, feature_extract, use_pretrained=True):\n    # 初始化模型变量\n    model_vgg = None\n    # 加载预训练模型\n    model_vgg = models.vgg16(pretrained=use_pretrained)\n    # 更改输出层\n    set_parameter_requires_grad(model_vgg, feature_extract)\n    model_vgg.classifier[6] = nn.Linear(4096, num_classes)\n    model_vgg.classifier.add_module('7',torch.nn.LogSoftmax(dim = 1))\n    return model_vgg\n\nmodel_vgg_new = initialize_model(num_classes=2,feature_extract = True,use_pretrained=True)\nprint(model_vgg_new.classifier)\n```\n\n输出`model_vgg_new`的`classifier`层，如下所示，可以看到最后一层全连接输出为2，并且使用`LogSoftmax`为output层。\n\n```tex\nSequential(\n  (0): Linear(in_features=25088, out_features=4096, bias=True)\n  (1): ReLU(inplace=True)\n  (2): Dropout(p=0.5, inplace=False)\n  (3): Linear(in_features=4096, out_features=4096, bias=True)\n  (4): ReLU(inplace=True)\n  (5): Dropout(p=0.5, inplace=False)\n  (6): Linear(in_features=4096, out_features=2, bias=True)\n  (7): LogSoftmax(dim=1)\n)\n```\n\n\n\n# 五、训练VGG模型\n\n训练定义好的VGG模型，即训练最后一层全连接层，具体操作步骤如下：\n\n（1）创建损失函数和优化器\n\n损失函数 `NLLLoss()` 的输入是一个对数概率向量和一个目标标签，它不会为我们计算对数概率，适合最后一层是`log_softmax()`的网络。Adam优化器是目前性能比较好的优化器之一，因此这里采用Adam。\n\n```python\n'''\n第一步：创建损失函数和优化器\n'''\n# 损失函数\ncriterion = nn.NLLLoss()\n# 学习率\nlr = 0.001\n# 优化器\noptimizer_vgg = torch.optim.Adam(model_vgg_new.classifier[6].parameters(),lr = lr)\n```\n\n（2）判断是否存在GPU设备，并将model切换到相应的device\n\n```py\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint('Using gpu: %s ' % torch.cuda.is_available())\nmodel_vgg_new.to(device)\n```\n\n（3）训练模型\n\n这里我定义了一个`train_model`训练的方法，并将验证集上结果最好的一次训练存储下来，为了减少训练时间，我把`epoch`设置为4\n\n```python\n'''\n第三步：训练模型\n'''\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n    since = time.time()\n    val_acc_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # 每个epoch都进行训练和验证\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # 将模型设置为训练模式\n            else:\n                model.eval()   # 将模型设置为验证模式\n\n            running_loss = 0.0 # 记录训练时的loss下降过程\n            running_corrects = 0\n\n            # 遍历数据\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # 梯度初始化\n                optimizer.zero_grad()\n                # 前向传播\n                outputs = model(inputs)\n                loss = criterion(outputs, labels.long())\n                # 得到预测结果\n                _, preds = torch.max(outputs, 1)\n                # 仅在训练时更新梯度，反向传播，backward + optimize\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # 将验证集上结果最好的一次训练存储下来\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history\n\n# 训练\nmodel_new_vgg, hist = train_model(model_vgg_new, dataloaders_dict, criterion, optimizer_vgg, num_epochs=4)\n\n```\n\n经过4次epoch，输出的记录如下，可以看到虽然训练次数不多，但是在验证集上效果还是很不错的\n\n```python\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nplt.title(u\"val acc plot\")\nplt.xlabel(u\"epoch\")\nplt.ylabel(u\"val acc\")\nacc= hist\nplt.xticks(range(len(acc)))\nplt.plot(acc)\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120204636.png)\n\n\n\n\n\n\n\n# 六、保存与测试模型\n\n（1）保存训练好的模型\n\npytorch保存和加载模型有两种方式，**不同的保存方式对应不同的读取方式**，两者各有利弊。\n\n方式一：直接保存整个模型\n\n```python\ntorch.save(model_new_vgg, 'model_new_vgg.pt')\nmodel_new_vgg = torch.load('model_new_vgg.pt')\n```\n\n方式二：只保存模型中的参数\n\n```python\nmodel = initialize_model(num_classes=2,feature_extract = True,use_pretrained=True)\nmodel.to(device)\nmodel.load_state_dict(torch.load(\"model_new_vgg.pt\"))\n```\n\n可以看到，用第一种方法能够直接保存模型，加载模型的时候直接把读取的模型给一个参数就行。而第二种方法则只是保存参数，在读取模型参数前**要先定义一个模型**（模型必须与原模型相同的构造），然后对这个模型导入参数。虽然麻烦，但是可以**同时保存多个模型**的参数，而第一种方法则不能，而且第一种方法**有时不能保证模型的相同性**（你读取的模型并不是你想要的）。所以，这里我采用第二种方式来保存并加载模型。\n\n（2）对模型进行测试\n\n接下来就要用test数据集对模型进行测试了，把测试结果保存到`pred_outputs`，具体如下：\n\n```python\ndef test_model(model, test_loader):\n    model.eval() #把训练好的参数冻结\n    total,correct = 0,0\n    pos = 0\n    pred_outputs= np.empty(len(test_loader.dataset),dtype=np.int)\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            pred_outputs[pos:pos+len(preds)]=preds.cpu().numpy()\n            pos += len(preds)\n    return pred_outputs\n\npred_outputs = test_model(model,dataloaders_dict['test'])\n```\n\n（3）将测试结果写入`cat_dog_result.csv`\n\n```python\nwith open(\"cat_dog_result.csv\", 'w') as f:\n    for i in range(len(test_loader.dataset)):\n        f.write(\"{},{}\\n\".format(i, pred_outputs[i]))\n```\n\n因为我是在colab环境上训练的，还要把`cat_dog_result.csv`拷贝到google drive才能下载，命令如下：\n\n```bash\n!cp -i /content/cat_dog_result.csv /content/drive/\n```\n\n（4）提交测试结果\n\n把`cat_dog_result.csv`提交到[AI研习社猫狗大战--经典图像分类题](https://god.yanxishe.com/41)，现在就让我们见证奇迹的时刻吧！\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201120181445.png)\n\n可以看到，只训练了4次epoch，测试就达到了98.9的准确率，把epoch设置得更大，结果应该会更好，由于时间原因，就不训练了。\n\n\n\n\n\n# 七、总结\n\n从加载猫狗大战竞赛数据集到colab上，到测试完模型并提交，我大概花费了几天的时间，并且主要时间不是用在定义模型和调参上，而是如何处理数据上。我认为这次的收获还是很大的，因为我知道了**如何以最快最有效的方式在colab上加载要训练的数据**，并定义了自己Dataset类，**以后对于任何类型、任何格式的训练数据，我应该都能定义相应Dataset类并且去处理它**。这次我用了近三天，下次可能一个小时不到就搞定了，这难道不是一个巨大的进步吗？此外，我通过预训练好的VGG模型进行迁移学习，训练了猫狗大战数据集，仅训练了4次epoch，测试数据就达到了98.9的准确率，说明预训练好的VGG模型是非常容易学习的，以后再遇到类似的识别分类任务，就不需要从头开始训练了，真的是非常快速又方便。\n\n最后，附上我的colab共享地址：https://drive.google.com/file/d/1t-DVQwo92dBuy3JgNhdYFD_CndwyBE3U/view?usp=sharing\n\n里面格式有点乱，但是内容一点都不少哦！","tags":["VGG"],"categories":["神经网络"]},{"title":"Hexo博客发布和配置的一些常用命令","url":"/2020/11/24/165533/","content":"\nHexo博客发布和配置的一些常用命令，在此记录！如果遇到新的且使用的命令，会不端完善！\n<!-- more -->\n\n\n\n## 基本命令\n\n`hexo init`  \n初始化站点，生成一个简单网站所需的各种文件。\n\n`hexo clean == hexo c`  \n清除缓存 网页正常情况下可以忽略此条命令\n\n`hexo generate == hexo g`  \n生效新增、修改、更新的文件\n\nHexo 能够监视文件变动并立即重新生成静态文件，在生成时会比对文件的 SHA1 checksum，只有变动的文件才会写入。`hexo generate --watch`\n\n\n\n`hexo server == hexo s`  \n启动本地网站，可在本地观察网站效果，同时也可以输入`http://localhost:4000/admin`管理文章\n\n`hexo s --draft`\n这个发布时可以预览草稿\n\n`hexo s --debug`  \n以调试模式启动本地网站，在此模式下，对文件的更改无需停止网站只需刷新即可看到效果，调试非常方便\n\n\n`hexo clean && hexo s`  \n一次执行两个命令\n\n`hexo deploy == hexo d`  \nhexo的一键部署功能，执行此命令即可将网站发布到配置中的仓库地址，执行此命令前需要配置站点配置文件_config.yml\n\n**一键本地启动**：`hexo clean && hexo g && hexo s`\n\n**一键部署**：`hexo clean && hexo g && hexo d`\n\n您可执行下列的其中一个命令，让 Hexo 在生成完毕后自动部署网站，两个命令的作用是相同的。\n\n```\n$ hexo generate --deploy\n$ hexo deploy --generate  或 hexo g -d or hexo d -g\n```\n\n## 创建和发布文章\n\n`hexo new [layout] <title>`\n新建一篇新文章，会自动按照模板里面的格式创建文章\n\n里面的布局（layout），默认为 post，布局共有三种：\n\n```tex\npost\tsource/_posts\npage\tsource\ndraft\tsource/_drafts\n```\n\n**发布草稿命令：**\n\n1. `hexo publish 文章文件名`\n2. 或者是手动将`_drafts`目录下的草稿移动到`_posts`目录下即可发布草稿为正式文章。\n\n\n\n## PicGO图床快捷键\n快捷键为：`ctrl+shift+p`\n\n\n\n## Hexo博客头部配置\n\n（1）文章置顶\n\n在文章的 Front-Matter 中，使用 `top: true` 来实现置顶。在文章的 Front-Matter 中，使用 `top: true` 来实现置顶。\n\n（2）自定义样式\n\n如果你想修改主题的样式，推荐将样式代码添加到 `source/css/_custom` 目录下的 `index.styl` 文件中。这样，当主题更新时，不会覆盖你已经修改了的样式代码。\n\n> 当然，你也可以进行模块化分类：在该目录下新建样式文件，然后通过 `@import xxx` 语句在同目录下的 `index.styl` 文件中引入你新建的样式文件。\n\n（3）文章左侧目录\n\n启用文章目录后，默认对所有文章页面生效。你可以在 Front-Matter 中，设置 `toc: false` 来指定某篇文章不启用该功能。\n\n（4）文章业内目录\n\n`@[TOC]( )`这个写到文章页面内任何一个地方即可\n\n更多详细设置，请参考[ hexo-theme-stun](https://theme-stun.github.io/docs/zh-CN/)\n\n","categories":["工具"]},{"title":"Typora需要注意的换行符","url":"/2020/11/24/104944/","content":"\n在Typora中一定要换行符，包括普通换行，以及整个段落的换行，这些和普通的markdown编辑器是不太一样的\n\n\n\n\n\n<!-- more -->\n\n（1）首先，Typora中如果只按`Enter`键，**则把其看做另起一个段落**，段落之间的间距是比较大的，从Typora的界面上就可以看出来，如下图所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124110809.png)\n\n（2）其次，如果要只换行，而不另起一个段落，则需要使用`<br/>`或`<br/>`或按下`Shift`+`Enter`键，这时候不会另起一段，两行仍然在一个段落里面，此时间距是比较小的，如下所示：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111640.png)\n\n\n\n（3）另外，需要注意的是，对于**有序或无序排列**，如果要在一个排列里面写多行东西，不要只按`Enter`键，这样会另起一段，Typora会使所有的排序当做单独的一段，在源码模式下可以看到如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111559.png)\n\n（4）可以采用`<br/>`或`<br/>`或按下`Shift`+`Enter`键的方式另起一行，这就所有的排序就在一段内了，如下：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124111952.png)\n\n\n\n（5）先按下两个空格，再按下`Shift`+`Enter`键，会出现如下符号，我认为这和只用`Shift`+`Enter`是一样的效果，目前还没发现什么问题，以后若发现区别会再补充。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124132953.png)\n\n\n\n（6）需要注意的是，一定要勾选，菜单栏中编辑->空格与换行->保留单独的换行符，如下图所示，这样才能使用`Shift`+`Enter`键的方式另起一行，如果不勾选，只能用`<br/>`或`<br/>`的方式另起一行。\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124112415.png)\n\n","categories":["工具"]},{"title":"使用pytorch的auto_grad实现线性模型对mnist数据集多分类","url":"/2020/07/18/181520/","content":"\n使用pytorch的auto_grad实现线性模型对mnist数据集多分类，选取mnist100张图片，前80张为测试集，后20张为训练集，eporch 500次\n\n\n## 知识储备\n\n使用多个线性模型进行多分类 原理：每一个线性模型做二分类  \n多个线性模型 = 感知机，实质就是每一个线性模型做二分类\n\n<!-- more -->\n\n## 数据加载&归一化\n\n\n```python\nimport torch\nfrom mnist import MNIST\nimport numpy as np\nimport pdb\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nmndata = MNIST('dataset/python-mnist')\nimage_data_all, image_label_all = mndata.load_training()\nimage_data = image_data_all[0:100]\nimage_data = np.array(image_data,dtype = np.float)/255\nimage_label = image_label_all[0:100]\nimage_label = np.array(image_label,dtype = np.int)\nprint(image_data.shape,image_label.shape)\n```\n\n    (100, 784) (100,)\n\n\n## 定义模型\n\n\n```python\ndef model(image_data_one,weights,bias):\n    \"\"\"\n    这里直接使用图片本身作特征，也可以提取features后传入模型中\n    \"\"\"\n    # image_data_one转化为二维\n    xt = torch.from_numpy(image_data_one.reshape(1,28*28))\n    y = xt.mm(weights)+bias\n    return y\n\ndef get_acc(image_data,image_label,weights,bias,start_i,end_i):\n    correct = 0\n    # 这里可以不加，因为loss计算于此无关\n    with torch.no_grad():\n        for i in range(start_i,end_i):\n            y = model(image_data[i],weights,bias)\n            # 获取第i张图片的label\n            gt = image_label[i]\n            # 获取与y最近接的label值\n            pred = torch.argmin(torch.from_numpy(np.array([torch.min((torch.abs(y-j))).item() for j in range(0,10)]))).item()\n            if gt == pred:\n                correct += 1\n    # 确保万一，除法分子或分母一个指定为float        \n    return float(correct/float(end_i-start_i))\n```\n\n\n```python\n#显示训练集和测试集精度变换\ndef show_acc(train_accs,test_accs):\n    plt.figure(figsize = (10,4))\n    plt.title('train_accs and test_accs')\n    plt.plot(np.arange(len(train_accs)), train_accs, color='green', label='train_accs')\n    plt.plot(np.arange(len(test_accs)), test_accs, color='red', label='test_accs')\n    plt.legend() # 显示图例\n    plt.xlabel('index')\n    plt.ylabel('accs')\n    plt.show()\n```\n\n\n```python\ndef train_model(image_data,image_label,weights,bias,lr):\n    loss_value_before=1000000000000000.\n    loss_value=10000000000000.\n    train_accs = []\n    test_accs = []\n    for epoch in range(0,500): \n        loss_value_before=loss_value\n        loss_value=0\n        for i in range(0,80):\n            y = model(image_data[i],weights,bias)\n            # 获取第i张图片的label\n            gt = image_label[i]\n            # 只关心一个值，更新的时候也只更新对应线性模型的weights和bias\n            loss = torch.sum((y[0,gt:gt+1]-gt).mul(y[0,gt:gt+1]-gt))\n            loss_value += loss.data.item()\n            loss.backward()\n            weights.data.sub_(weights.grad.data*lr)\n            weights.grad.data.zero_()\n            bias.data.sub_(bias.grad.data*lr)\n            bias.grad.data.zero_()            \n\n        train_acc = get_acc(image_data,image_label,weights,bias,0,80)\n        test_acc = get_acc(image_data,image_label,weights,bias,80,100)\n        train_accs.append(train_acc)\n        test_accs.append(test_acc)\n        #print(\"epoch=%s,loss=%s/%s,train/test_acc=%s/%s,\"%(epoch,loss_value,loss_value_before,train_acc,test_acc))\n    show_acc(train_accs,test_accs)\n```\n\n## 训练\n\n\n```python\nweights = torch.randn(28*28,10,dtype = torch.float64,requires_grad = True)\nbias = torch.zeros(10,dtype = torch.float64,requires_grad = True)\nlr = 1e-3\n# 对模型进行训练：\ntrain_model(image_data,image_label,weights,bias,lr)    \n```\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200718181909.png)\n\n> 由于样本少，导致程序过拟合，结果是训练集精度高，测试集精度低。\n","tags":["pytorch","MLP"],"categories":["project实战"]},{"title":"numpy和torch数据类型转化","url":"/2020/07/18/164540/","content":"\n在实际计算过程中，float类型使用最多，因此这里只介绍numpy和torch数据float类型转化，其他类型同理。\n<!-- more -->\n\n## numpy数据类型转化\n\n- numpy使用astype转化数据类型，float默认转化为64位，可以使用`np.float32`指定为32位\n\n\n```python\n#numpy转化float类型\na= np.array([1,2,3])\na = a.astype(np.float)\nprint(a)\nprint(a.dtype)\n```\n\n`[1. 2. 3.]`  \n`float64`\n    \n\n- 不要使用a.dtype指定数据类型，会使数据丢失\n\n\n```python\n#numpy转化float类型\nb= np.array([1,2,3])\nb.dtype= np.float32\nprint(b)\nprint(b.dtype)\n```\n\n`[1.e-45 3.e-45 4.e-45]`  \n`float32`\n    \n\n- 不要用float代替np.float，否则可能出现意想不到的错误\n- 不能从np.float64位转化np.float32，会报错\n- np.float64与np.float32相乘，结果为np.float64\n\n> 在实际使用过程中，可以指定为np.float，也可以指定具体的位数，如np.float，不过直接指定np.float更方便。\n\n## torch数据类型转化\n\n- torch使用`torch.float()`转化数据类型，float默认转化为32位，torch中没有`torch.float64()`这个方法\n\n\n```python\n# torch转化float类型\nb = torch.tensor([4,5,6])\nb = b.float()\nb.dtype\n```\n\n\n\n\n    torch.float32\n\n\n\n- `np.float64`使用`torch.from_numpy`转化为torch后也是64位的\n\n\n```python\nprint(a.dtype)\nc = torch.from_numpy(a)\nc.dtype\n```\n\n`float64`  \n`torch.float64`\n\n\n\n- 不要用float代替torch.float，否则可能出现意想不到的错误\n- torch.float32与torch.float64数据类型相乘会出错，因此相乘的时候注意指定或转化数据float具体类型\n\n> np和torch数据类型转化大体原理一样，只有相乘的时候，torch.float不一致不可相乘，np.float不一致可以相乘，并且转化为np.float64\n","tags":["pytorch","numpy"]},{"title":"Google Colab挂载drive上的数据文件","url":"/2020/07/18/103558/","content":"\nGoogle Colab是完全云端的，所以，每次如果想让他访问谷歌云盘的内容，必须要先进性授权操作，直接在colab的jupyter中进行绑定授权操作\n\n**每次在Google Colab中打开notebook文件时，都必须重新执行命令获得授权。**\n<!-- more -->\n\n## 获取授权脚本代码\n```bash\n!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n!apt-get update -qq 2>&1 > /dev/null\n!apt-get -y install -qq google-drive-ocamlfuse fuse\nfrom google.colab import auth\nauth.authenticate_user()\nfrom oauth2client.client import GoogleCredentials\ncreds = GoogleCredentials.get_application_default()\nimport getpass\n!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\nvcode = getpass.getpass()\n!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n```\n**期间会输入两次授权码，点击相应链接复制即可**\n\n## 挂载到drive上\n```bash\n!mkdir -p drive\n!google-drive-ocamlfuse drive\n```\n\n## 切换到工作文件夹\n\n```python\n# 指定当前的工作文件夹\nimport os\n# google drive中的文件路径为/content/drive\nos.chdir(\"/content/drive/Colab\") \n```\n也可以使用`%cd`切换工作路径，推荐使用\n\n\n## 几个常用命令\n\n- `%cd`切换工作目录\n- `!ls`查看当前目录下的文件\n- `!pwd`查看当前的工作路径\n\n\n\n参考文档\n\n[谷歌云盘Colaboratory如何载入文件](https://blog.csdn.net/Einstellung/article/details/81006408)  \n","tags":["colab"],"categories":["工具"]},{"title":"使用numpy实现逻辑回归对IRIS数据集二分类","url":"/2020/07/16/175900/","content":"使用numpy实现逻辑回归对IRIS数据集二分类，使用对数似然损失(Log-likelihood Loss)，并显示训练后loss变化曲线。\n\n知识储备如下：\n- 逻辑回归Logistic Regression\n- 对数似然损失\n- IRIS数据集介绍\n- np.concatenate使用\n<!-- more -->\n\n\n## 知识储备\n\n### 逻辑回归Logistic Regression\n\n$$y = \\frac{1}{1+e^{-(wx+b)}}$$\n名字虽然叫回归，但是一般处理的是分类问题，尤其是二分类，比如垃圾邮件的识别，推荐系统，医疗判断等，因为其逻辑与实现简单，在工业界有着广泛的应用。\n\n__优点__：\n\n* 实现简单，计算代价不高，易于理解和实现, 广泛的应用于工业问题上；\n* 分类时计算量非常小，速度很快，存储资源低；\n\n__缺点__：\n\n* 容易欠拟合，当特征空间很大时，逻辑回归的性能不是很好；\n* 不能很好地处理大量多类特征或变量；\n\n### 对数似然损失\n对数损失, 即对数似然损失(Log-likelihood Loss), 也称逻辑斯特回归损失(Logistic Loss)或交叉熵损失(cross-entropy Loss), 是在概率估计上定义的。它常用于(multi-nominal, 多项)逻辑斯特回归和神经网络,以及一些期望极大算法的变体,可用于评估分类器的概率输出。可参考[对数损失函数(Logarithmic Loss Function)的原理和 Python 实现](https://www.cnblogs.com/klchang/p/9217551.html)了解详情\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716170728.png)\n\n损失函数:\n\n\n$$L=\\frac{1}{m}*\\sum_i^m -y_ilog(f(x_i))-(1-y_i)log(1-f(x_i))$$\n梯度计算：\n$$\\frac{\\partial L}{\\partial w} = \\frac{1}{m}X^T*(f(x)-y)$$\n\n权重更新：\n$$w = w -\\alpha\\frac{\\partial L}{\\partial w}$$\n\n### IRIS数据集介绍\n\n该数据集包含4个特征变量，1个类别变量。iris每个样本都包含了4个特征：花萼长度，花萼宽度，花瓣长度，花瓣宽度，以及1个类别变量（label）。详情见[加载数据](#加载数据)\n\n### np.concatenate使用\n\n\n```python\na = np.array([[1, 2],[3, 4]])\nb = np.array([[5, 6]])\nnp.concatenate((a, b), axis = 0)\n```\n\n\n\n\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n\n\n\n\n```python\nnp.concatenate((a, b.T), axis = 1)\n```\n\n\n\n\n    array([[1, 2, 5],\n           [3, 4, 6]])\n\n\n\n## 加载数据\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.datasets import load_iris\n%matplotlib inline\n```\n\n\n```python\ndataset = load_iris()\ninputs = dataset['data']\ntarget = dataset['target']\nprint('inputs.shape:', inputs.shape)\nprint('target.shape:', target.shape)\n# 三个类别\nprint('labels:', set(target))\n```\n\n    inputs.shape: (150, 4)\n    target.shape: (150,)\n    labels: {0, 1, 2}\n\n\n\n```python\ntarget\n```\n\n\n\n\n    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n           0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n           2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n           2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\n\n```python\nvalues = [np.sum(target == 0), np.sum(target == 1), np.sum(target == 2)]\nplt.pie(values,labels=[0, 1, 2], autopct = '%.1f%%')\nplt.show()\n```\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171020.png)\n\n\n关于参数train_test_split的`random_state`的解释：  \n>Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls.   \nrandom_state即随机数种子，**目的是为了保证程序每次运行都分割一样的训练集和测试集。否则，同样的算法模型在不同的训练集和测试集上的效果不一样。**\n\n\n```python\nfrom sklearn.model_selection import train_test_split\n# 只取前两类， 做二分类\ntwo_class_input = inputs[:100]\ntwo_class_target = target[:100]\nx_train, x_test, y_train, y_test = train_test_split(\n                    two_class_input,two_class_target,\n                    test_size = 0.3,\n                    random_state = 0)\ny_train = y_train.reshape(-1,1)\ny_test = y_test.reshape(-1,1)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n```\n\n    (70, 4) (30, 4) (70, 1) (30, 1)\n\n\n\n```python\n# add one feature to x\nx_train = np.concatenate([x_train, np.ones((x_train.shape[0], 1))], axis = 1)\nx_test = np.concatenate([x_test, np.ones((x_test.shape[0], 1))], axis = 1)\nprint(x_train.shape, x_test.shape)\n```\n\n    (70, 5) (30, 5)\n\n\n## 定义模型\n\n\n```python\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\nx = np.arange(-10, 10, step = 0.1)\nfig, ax = plt.subplots(figsize = (8, 4))\nax.plot(x, sigmoid(x), c = 'green')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x28f77053348>]\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171106.png)\n\n\n\n```python\ncompute_loss = lambda pred_y, y: np.mean(-y * np.log(pred_y)-(1-y) * np.log(1-pred_y))\n# weight and bias init\nw = np.random.randn(5, 1)\n# 上一个loss\nlosses = []\nlast_loss = 10000\npred_y =sigmoid(np.dot(x_train, w))\n# 当前loss\nnow_loss = compute_loss(pred_y, y_train)\ni = 0\nwhile abs(now_loss - last_loss)>1e-4:\n    last_loss = now_loss\n    i = i + 1\n    # 计算梯度\n    grad = x_train.T.dot((pred_y - y_train)) / len(y_train)\n    # 更新梯度\n    w = w - 0.001 * grad\n    \n    # 前导计算\n    pred_y = sigmoid(np.dot(x_train, w))\n    now_loss = compute_loss(pred_y, y_train)\n    losses.append(now_loss)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n    [<matplotlib.lines.Line2D at 0x28f77053508>]\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716171124.png)\n\n\n## 测试样例\n\n\n```python\n# 测试\ntest_pred = sigmoid(np.dot(x_test, w))\npre_test_y = np.array(test_pred > 0.5, dtype = np.float32)\nacc = np.sum(pre_test_y == y_test) / len(y_test)\nprint(\"the accary of model is {}\".format(acc*100))\n```\n\n    the accary of model is 100.0\n\n\n\n```python\nprint(pre_test_y.reshape(1,-1))\nprint(y_test.reshape(1,-1))\n```\n\n`[[0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.\n      0. 0. 0. 1. 1. 1.]]`   \n`[[0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1]]`\n    \n","tags":["numpy","逻辑回归"],"categories":["project实战"]},{"title":"使用numpy实现线性模型预测boston房价","url":"/2020/07/16/115900/","content":"使用numpy实现线性模型预测boston房价，激活函数为Relu，使用MSE_loss，手动求导，并显示训练后loss变化曲线。\n\n知识储备如下：\n- Scikit-learn\n- boston房价数据解读\n- 标准差公式\n- Linear及MSE_loss求导公式\n<!-- more -->\n\n## 知识储备\n\n### Scikit-learn\n\nScikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。其优点为：\n- 简单高效的数据挖掘和数据分析工具\n- 让每个人能够在复杂环境中重复使用\n- 建立NumPy、Scipy、MatPlotLib之上\n\n安装方法 pip install scikit-learn\n\n### boston房价数据解读\n\n使用sklearn.datasets.load_boston即可加载相关数据。该数据集是一个回归问题。每个类的观察值数量是均等的，共有506个观察，13个输入变量和1个输出变量。每条数据包含房屋以及房屋周围的详细信息。其中包含城镇犯罪率，一氧化氮浓度，住宅平均房间数，到中心区域的加权距离以及自住房平均房价等等，具体如下：\n- CRIM：城镇人均犯罪率。\n- ZN：住宅用地超过 25000 sq.ft. 的比例。\n- INDUS：城镇非零售商用土地的比例。\n- CHAS：查理斯河空变量（如果边界是河流，则为1；否则为0）。\n- NOX：一氧化氮浓度。\n- RM：住宅平均房间数。\n- AGE：1940 年之前建成的自用房屋比例。\n- DIS：到波士顿五个中心区域的加权距离。\n- RAD：辐射性公路的接近指数。\n- TAX：每 10000 美元的全值财产税率。\n- PTRATIO：城镇师生比例。\n- B：1000（Bk-0.63）^ 2，其中 Bk 指代城镇中黑人的比例。\n- LSTAT：人口中地位低下者的比例。\n- MEDV：自住房的平均房价，以千美元计。\n- 预测平均值的基准性能的均方根误差（RMSE）是约 9.21 千美元。\n\n### 标准差公式\n\n如x1,x2,x3...xn的平均数为M，则方差可表示为：\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125539.png)\n\n样本标准差=方差的算术平方根=s=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/(n-1) )  \n总体标准差=σ=sqrt(((x1-x)^2 +(x2-x)^2 +......(xn-x)^2)/n )  \n如是总体，标准差公式根号内除以n  \n如是样本，标准差公式根号内除以（n-1)。  \n因为我们大量接触的是样本，所以普遍使用根号内除以（n-1)。  \n\n\n```python\na=np.array([[1,2,3],[4,5,6]])\nnp.mean(a,axis=1)\n```\n\n\n\n\n    array([2., 5.])\n\n\n\n\n```python\n# axis = 1表示行，ddof = 1是除以n-1\nnp.std(a, axis = 1,ddof = 1) \n```\n\n\n\n\n    array([1., 1.])\n\n\n\n\n```python\n# ddof默认为0,是除以n\nnp.std(a, axis = 1) \n```\n\n\n\n\n    array([0.81649658, 0.81649658])\n\n\n\n\n```python\n# 求所有数平均值\nnp.mean(a)\n```\n\n\n\n\n    3.5\n\n\n\n### Linear及MSE_loss求导公式\n\n损失函数\n$L = \\frac{1}{2N}\\sum_{i=1}^{N}(z^{i} - y^{i})^{2}$\n\n线性函数\n$z^i = \\sum_{j=0}^{N}x_j^{(i)}w^{(j)} + b^{(j)}$\n\n对 $w$ 偏导，得到$w$ 更新梯度\n$\\frac{\\partial L}{\\partial w_j} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})x_j^{(i)}$\n\n对 $b$ 偏导，得到$b$ 更新梯度\n$\\frac{\\partial L}{\\partial b} = \\frac{1}{N}\\sum_{i}^{N}(z^{(i)} - y^{(i)})$\n\n## 数据加载\n\n\n```python\nfrom sklearn.datasets import load_boston\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n\n```python\ndata = load_boston()\nX_ = data['data']\ny = data['target']\nprint(type(data), type(X_), type(y))\nprint('data keys:', data.keys())\nprint('X_.shape:', X_.shape)\nprint('y.shape:', y.shape)\n```\n\n\n`<class 'sklearn.utils.Bunch'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> ` \n`data keys: dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])  `\n`X_.shape: (506, 13)  `\n `y.shape: (506,)  `\n\n\n\n\n\n## 数据规范化\n\n\n```python\n# 转化为标准正态分布\nX_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis = 0)\ny = y.reshape(-1,1) # reshape转化为vector\nprint(X_.shape)\nprint(y.shape)\n```\n\n`(506, 13)  `\n`(506, 1)`\n    \n\n## 建立激活函数\n\n\n```python\ndef sigmoid(x):\n    r = 1 / (1 + np.exp(-x))\n    return r\nnums = np.arange(-10, 10, step = 1)\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(nums, sigmoid(nums), c='red')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125621.png)\n\n\n```python\ndef relu(x):\n    return (x > 0) * x\nfig, ax = plt.subplots(figsize = (10, 4))\nnums = np.arange(-10, 10, step = 1)\nax.plot(nums, relu(nums), c = 'blue')\n```\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125708.png)\n\n\n## 定义模型\n\n线性模型：$y = wx + b$\n\n\n```python\ndef Linear(x, w, b):\n    y_pre = x.dot(w) + b\n    return y_pre\n```\n\n**在计算损失时，需要把每个样本的损失都考虑到，所以我们需要对单个样本的损失函数进行求和，并除以样本总数N。**\n\n\n```python\ndef MSE_loss(y_pre, y):\n    loss = np.mean(np.square(y_pre - y))\n    return loss\n```\n\n\n```python\ndef gradient(x, y_pre, y):\n    n = x.shape[0]\n    grad_w = x.T.dot(y_pre - y)/n\n    grad_b = np.mean(y_pre - y)\n    return grad_w, grad_b\n    \n```\n\n\n```python\n# 初始化网络\nn = X_.shape[0] # 样本数量506\nn_features = X_.shape[1] #特征数量13\n\n# 初始化网络参数\n# randn从标准正态分布中返回一个或多个样本值\nW = np.random.randn(n_features, 1)\nb = np.zeros(1)\n\n#设定学习率\nlearning_rate = 1e-2\n\n#训练次数\nepoch = 10000\n```\n\n## 训练(不加激活函数)\n\n\n```python\nlosses = []\n# 训练 \nfor t in range(epoch):\n    # 向前传播\n    y_pred = Linear(X_, W, b)\n    # 计算损失函数\n    loss = MSE_loss(y_pred,y)\n    losses.append(loss)\n    grad_w, grad_b = gradient(X_, y_pred, y)\n    \n    #权重更新\n    W = W - grad_w * learning_rate\n    b = b - grad_b * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n\n\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125735.png)\n\n\n```python\nn_hidden = 10 #设计隐藏神经元个数（可修改）\nW1 = np.random.randn(n_features, n_hidden)  # 维度 n_features * n_hidden\nb1 = np.zeros(n_hidden)                     # 维度 1 * n_hidden\nW2 = np.random.randn(n_hidden, 1)           # 维度 n_hidden * 1\nb2 = np.zeros(1)                            # 维度1\n```\n\n## 训练(加激活函数)\n\n\n```python\n# 训练\nlosses = []\nfor t in range(epoch):\n    #向前传播\n    y_pred1 = Linear(X_, W1, b1)     # 维度 n * n_hidden\n    y_relu = relu(y_pred1)           # 维度 n * n_hidden\n    y_pred = Linear(y_relu, W2, b2) # 维度 n * 1\n    \n    #计算损失函数\n    loss = MSE_loss(y_pred, y)\n    losses.append(loss)\n    \n    #反向传播，求梯度\n    grad_y_pred = y_pred - y                 # 维度n*1\n    grad_w2 = y_relu.T.dot(grad_y_pred) / n  # 维度n_hidden*1\n    grad_b2 = np.mean(grad_y_pred, axis = 0) # 维度1*1\n    grad_relu = grad_y_pred.dot(W2.T)        # 维度n*n_hidden\n    #注意：y_pred1与relu直接相关\n    grad_relu[y_pred1 < 0] = 0\n    grad_w1 = X_.T.dot(grad_relu) / n        # 维度n_features* n_hidden\n    grad_b1 = np.mean(grad_relu, axis = 0)   # 维度n_hidden*1\n    \n    #更新梯度\n    W1 = W1 - grad_w1 * learning_rate\n    b1 = b1 - grad_b1 * learning_rate\n    W2 = W2 - grad_w2 * learning_rate\n    b2 = b2 - grad_b2 * learning_rate\n\nfig, ax = plt.subplots(figsize = (10, 4))\nax.plot(np.arange(len(losses)), losses, c = 'r')\n```\n\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20200716125832.png)\n\n参考文档\n\n[波士顿房价数据集解读](https://blog.csdn.net/appleyuchi/article/details/84998894)\n","tags":["numpy","线性回归"],"categories":["project实战"]},{"title":"奥卡姆剃刀","url":"/2020/07/15/0/","content":"任何一件事情，都要从简单的开始做起，若无必要，勿增实体！！！\n\n![img](https://gitee.com/wxler/blogimg/raw/master/imgs/20200715105539.jpg)\n","categories":["Life"]},{"title":"git基本使用方法","url":"/2020/06/17/115900/","content":"由于平时写代码和博客常常用到git和github，每次用到都去百度，感觉太麻烦了，也大大降低了效率，索性自己整理一下常用到的git指令和使用方法，对git的使用能有一个系统的认识。这里只介绍一下基本用法，对更高级的用法如果以后用到再进行补充。\n<!-- more -->\n\n## git安装和配置\ngit的安装和配置在我的这篇[搭建个人博客](https://wxler.github.io/2020/06/01/hexoCreateAndConfig/#%E5%AE%89%E8%A3%85git)里，请自行参考配置，主要有一下几点：\n- 下载安装git程序\n- 配置github账户\n- 配置SSH KEY\n## git工作原理\nGit是分布式版本控制系统，那么它就没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作的时候就不需要联网了，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，那多个人如何协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这时，你们两之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。Git在执行更新操作时，更像是对数据的一组快照，每次你提交更新，它主要对当时的全部文件制作一个快照并保存这个快照的索引。为了高效，如果文件没有修改，Git不再重新存储该文件，而是只保留一个链接指向之前存储的文件。  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125501.png)\n如上图所示，在version2中的B即是因为File B没有改变，所以直接存储了一个指向FileB的链接。只有修改了的文件才会产生一个新的文件，覆盖原来的文件。\ngit的工作原理/流程如下:  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125536.png)\n\n- Workspace：工作区(本地目录文件)\n- Index / Stage：暂存区/缓存区\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n## 基本操作\n\n### 初始化仓库\n仓库的初始化有两种方式：一种是直接从远程仓库克隆，另一种则是直接从当前目录初始化。远程初始化命令在[从远程仓库获取](#从远程仓库获取)，本地初始化命令的方法是首先创建一个文件夹，我命名为mygit，然后执行如下命令：  \n```bash\n$ git init\n```\n执行完毕后，当前目录下会出现一个隐藏的.git文件夹，git所需的数据和资源都放在改目录中。\n\n### 查看仓库状态\n\n通过`git status`来查看仓库状态，执行效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125612.png)\n可以看到nothing to commit，表示本地工作区没有要提交的文件，我们再创建一个one.txt的文件，然后在执行`git status`，效果如下： \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130149.png)\n从结果Untracked files可以看到，one.txt还没有被add到暂存区。\n\n### 添加文件到暂存区\n\n`git add`命令可以将一个文件添加到暂存区,执行如下命令将one.txt添加到暂存区：\n```bash\ngit add one.txt\n```\n将one.txt添加到暂存区后，再次执行`git status`,可看到如下效果：  ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125701.png)\n从Changes to be committed可以看出，one.txt已被添加到暂存区，但还未被添加到本地仓库。\n\n### 提交到本地仓库\n\n当文件提交到暂存区之后，执行`git commit`命令将当前暂存区的文件提交到本地仓库，执行如下命令：\n```bash\ngit commit -m '新增一个one.txt'\n```\n-m是指将当前暂存区的文件提交到本地仓库的时候，加上提交备注/说明，再次执行`git status`,可以看到已经没有要add或commit的文件了。这里要强调一下，如果直接执行`git commit`命令，会自动打开一个vi编辑器，在里面输入备注/说明即可。此外，当我们提交成功后，还可以通过`git commit --amend  `修改备注信息。\n### 查看更改前后的差异\n使用`git diff`命令可以查看**工作区和暂存区的区别**，在one.txt里面写入一行hello world，然后执行`git diff`命令，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130230.png)\n根据结果可以看到新增了一行hello world，如果我们要比较**工作区与最新本地版本库的区别**，可以执行`git diff HEAD`，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130230.png)\n\n### 查看提交历史\n\n使用`git log`查看提交历史，我们首先将工作区的内容提交到本地仓库，执行`git add one.txt`将更改后的one.txt添加到暂存区，执行` git commit -m '添加了一行hello world'`将暂存区的内容提交到本地仓库，然后执行`git log`，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125804.png)\n\n## git撤销修改\n\n### 工作区的代码撤销\n\n使用`git checkout`撤销工作区的代码。我们先向one.txt添加一行hello everyone，执行`cat one.txt`查看内容，再执行`git checkout -- one.txt`撤销之前的操作，让one,txt恢复之前的状态，然后执行`cat one.txt`再次查看内容，效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124125909.png)  \n可以看到，工作区的内容已经被修改,这时候本地文件刚刚添加的内容就被撤销了。\n\n### 暂存区的代码撤销\n\n使用`git reset HEAD`撤销暂存区的代码。首先在one.txt添加一行hello people，执行`git add one.txt`将更改的内容提交到暂存区，`git reset HEAD`来撤销暂存区的代码，如下图：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130403.png)\n撤销暂存区的代码之后，如需要将代码添加到暂存区，则需要再次执行`git add`命令\n\n### 本地仓库的代码撤销\n\n可以使用`git reset --hard <版本号>`来撤销本地仓库的代码，版本号有几种不同的写法：\n1. 可以使用HEAD^来描述版本，一个^表示前一个版本，两个^^表示前两个版本，以此类推。\n2. 也可以使用数字来代替^，比如说前100个版本可以写作HEAD~100。\n3. 也可以直接写版本号，表示跳转到某一个版本处。我们每次提交成功后，都会生成一个哈希码作为版本号，所以这里我们也可以直接填版本号，哈希码很长，但是我们不用全部输入，只需要输入前面几个字符即可，就能识别出来。执行`git log`后那一串长符号就是哈希码版本号。\n\n依次执行如下命令：\n```bash\n$ git add 'one.txt'\n$ git commit -m '添加一行hello people'\n$ git reset --hard head^\n```\n执行`git reset --hard head^`后的效果如下：\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130427.png)  \n可以从结果看出，前半部分816b208是执行撤销操作以后，当前版本的版本号前七位，后半部分是该版本的备注，可以用`git log`来查看不同版本的版本号和备注。  \n\n再次查看本地one.txt文件，发现本地目录的刚刚添加的内容已经没有了，如需要再次提交到本地仓库，则可执行`git add`和`git commit`命令。**需要注意的是，当撤销到最开始版本的时候，`git reset --hard head^`就不能再用了，否则会报如下的错误：**  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130454.png)\n\n## git分支管理\n\n### 查看分支\n通过`git branch`来查看当前仓库有哪些分支和我们处于哪一分支中，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130516.png) \n可以看到，当前本地仓库只有一个master分支，这是git默认创建出来的，master前面的\\*表示我们当前处于这一个分支中。\n\n### 分支创建和切换\n可以利用`git branch <分支名>`来创建一个分支，利用`git checkout <分支名>`来切换分支，如下所示： \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130558.png)\n\n### 分支合并\n\n由于math分支是从master分支中创建出来的，所以此时math分支的内容和master分支的内容是一致的，现在，我们在math分支向one.txt添加一行hello branch math(由于刚刚执行了[本地仓库的代码撤销](#本地仓库的代码撤销)，所以one.txt现在的内容是空白的)，此时math分支的one.txt和math分支的one.txt就不同了，具体效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130558.png)  \n执行完毕后，我们也可以在本地查看，先在math分支下，打开one.txt可以看到我们刚刚添加的内容，然后再切换到master分支，再从本地打开one.txt文件，就看不到内容了。\n**可以通过`git merge <分支名>`合并分支**，先切换到master分支，然后执行` git merge math`合并math分支到master分支上，效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130633.png)  \n可以看到再次在master分支下查看one.txt，就可以显示math分支的内容了。\n\n通常合并分支时，git一般使用”Fast forward”模式，fast-forward方式表示当条件允许时，git直接把HEAD指针指向合并分支的头，完成合并，这种方式合并速度快，但是在整个过程中没有创建commit。在这种模式下，删除分支后，会丢掉分支信息，可使用带参数 `–no-ff`来禁用”Fast forward”模式，即删除时可以实用`git merge --no-ff <分支名>`\n\n### 以图表方式查看分支\n可以用`git log --graph`命令来直观的查看分支的创建和合并等操作，合并math和master分支前的效果如下： \n    ![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130807.png)\n合并math和master分支后的效果如下：   \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130807.png)\n\n### 解决冲突\n\n我们创建一个新的分支dev,并在dev分支下给one.txt添加一行12345，然后提交，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130943.png)  \n同样，我们现在切换到master分支上来，也在one.txt添加一行内容，内容为56789，并提交，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124130943.png)  \n现在，我们将dev分支合并到master上来，如下所示：\n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131003.png)  \n从结果中可以看出，=======之前是主分支的内容，=======之后是dev分支的内容，此时我们用文本编辑器修改one.txt的冲突然后提交即可，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131140.png)\n\n**分支策略：首先master主分支应该是非常稳定的，也就是用来发布新版本，一般情况下不允许在上面干活，干活一般情况下在新建的dev分支上干活，干完后，dev分支代码可以合并到主分支master上来。**\n\n## github远程仓库\n\n### 关联远程仓库\n在此之前我相信你已经配置SSH KEY，如果没有，可以参考我的这篇[搭建个人博客](https://wxler.gitee.io/2020/06/01/hexoCreateAndConfig/#git%E9%85%8D%E7%BD%AE)里进行配置，配置完成以后在github上创建一个仓库，这里命名为test，我们可以看到仓库的地址，例如：`https://github.com/wxler/test.git`。然后将我们之前的本地仓库和这个远程仓库进行关联，使用`git remote add`命令，如下：\n```bash\n$ git remote add origin https://github.com/wxler/test.git\n```\n### 推送到远程仓库\n把本地库的内容推送到远程，使用`git push -u origin master`命令，实际上是把当前分支master推送到远程。由于远程库是空的，我们第一次推送master分支时，加上了–u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令,不用加-u了,效果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131213.png) \n推送成功后，可以立刻在github页面中看到远程库的内容已经和本地一模一样了。从现在起，只要本地作了提交，就可以通过命令：`git push origin master`把本地master分支的最新修改推送到github上了，现在你就拥有了真正的分布式版本库了。  \n**我们一般不把其它分支推送到远程仓库，master主分支是最稳定的版本，一般情况下不允许在上面干活，干活一般情况下在新建的分支上干活，干完后，把分支代码可以合并到主分支master上来。**当然，你也可以将其它分支推送到远程仓库，可以执行如下命令：\n\n```bash\n$ git checkout fa\n$ git push -u origin fa\n```\n### 从远程仓库获取\n我们可以通过git clone命令克隆一个远程仓库到本地,方式也简单，在本地创建一个空文件夹，执行如下命令：\n```bash\n$ git clone https://github.com/wxler/test.git\n```\n此时克隆的是master分支到本地仓库，我们可以通过`git branch -a`来查看本地仓库和远程仓库的信息，-a参数可以同时显示本地仓库和远程仓库的信息，如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131310.png)\n我们也可以把远程仓库其它分支的内容clone下来，可以执行如下命令：\n\n```bash\n$ git branch fa origin/dev\n$ git checkout dev\n```\n上面的指令表示根据远程仓库的dev分支创建一个本地仓库的dev分支，然后再切换到dev分支，**注意由于dev分支就是从远程仓库克隆下来的，所以这里可以不添加-u参数。**\n\n### 从远程仓库更新\n使用`git pull`获取远程仓库最新的代码和数据，例如，我们可以通过以下代码将远程主机的master分支最新内容拉下来后与当前本地分支直接合并\n```bash\ngit pull origin master\n```\n\n## git命令大全\ngit常用命令速查表，方便查阅：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124131337.png)\n\n## 遗留问题\n\n到现在，我们就可以使用git的大多数操作了，但是还有git的一些操作平常没有用到，我也就不主动去一个个试了，毕竟一口吃不成胖子，查了也记不住，就不自找苦吃了，遗留的问题主要有：\n- git分支衍合\n- git标签管理\n- bug分支&stash功能\n\n## 参考文档\n[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)\n[Git从入门到熟练使用](https://www.jianshu.com/p/34cfe097e06a)\n[史上最简单Git入门教程](https://www.cnblogs.com/jjlee/p/10305194.html)\n[git命令大全](https://www.jianshu.com/p/46ffff059092)\n\n>特别声明：本篇博客只做个人学习交流和参考手册使用，不作任何商业目的，内容上较多参考了[松哥git教程](https://mp.weixin.qq.com/s?__biz=MzI1NDY0MTkzNQ==&mid=100004284&idx=1&sn=f9adbded2bac4d8efb9b07a0262a0e8a&chksm=69c343dc5eb4cacaa45d2a968ab935e85eccbcb11f9493d32ef147da5c1a1ff53cc45a1f32a2&mpshare=1&scene=1&srcid=0616SVENp6ameT2V21QsW2nZ&sharer_sharetime=1592289626242&sharer_shareid=18383980e942ee6dfd94ea4b7b61fcbe&key=1de400e48ea73360020a1786d1997d16a5b67307619595df7c6b06fc16be187dba8368d87386b6a57a40d3c3f3671fae6927462285e9b59479eb08a036e5aa45b02add3de42bb86044ef6649218a6531&ascene=1&uin=MjA2Nzc1NzU0Mg%3D%3D&devicetype=Windows+10+x64&version=6209007b&lang=zh_CN&exportkey=ASZhqnZ2JNrU1FCHtEQsA0s%3D&pass_ticket=DNBBiZIg7%2Fjg4GBZz9sSD49h8dYitJv5rAPR21lJbAICH1bIYdByWmp3fQOoDyHW)，根据自己实际应用进行删减，并加上了自己的理解和补充，如有侵权，请联系博主本人删除。","tags":["git"],"categories":["工具"]},{"title":"使用hexo平台从0搭建个人博客","url":"/2020/06/01/122000/","content":"搭建这个博客，花费了我不少时间，这期间我遇到各种各样的问题，这些问题本可以避免，因操作不规范、对指令代码的不理解、网络不稳定、配置上的错误，使得最后暴露出来的各种bug很不容易解决。前前后后我也重新搭建了三次，经历了心态上的各种起伏。为此，我记录下我制作的过程，让想和我一样自建博客的人少走一些弯路。\n\n我使用的hexo博客框架，stun主题，搭建环境和过程可分为几个部分:\n\n1. 安装git\n2. 安装nodejs\n3. 安装hexo\n4. hexo搭桥github\n5. hexo-admin使用\n6. npm&hexo常用命令\n<!-- more -->\n\n## 安装git\n\n### git下载\n下载[git](https://git-scm.com/download)，双击安装，然后一直next，按键Ctrl+r，然后在弹出框中出入cmd，在弹出的界面输入git，回车,出来一大串命令符就代表安装成功了。可以使用git version查看自己的git版本。\n\n### git配置\n\n1. git安装好去GitHub上注册一个账号，注册好后，桌面空白地方右键选择Git Bash，要git账户进行环境配置  \n```bash\n//usename是用户名\ngit config --global user.name \"username\"\ngit config --global user.email \"username@email.com\"\n```\n2. 当以上命令执行结束后，可用 `git config --global --list` 命令查看配置是否OK  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133328.png)\n3. 在命令框中输入命令`ssh-keygen -t rsa`，连敲三次回车键，结束后去系统盘目录下（一般在 C:\\Users\\你的用户名.ssh）(mac: /Users/用户/.ssh）查看是否有。ssh文件夹生成，此文件夹中以下两个文件  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133402.png)\n4. 将ssh文件夹中的公钥（ id_rsa.pub）添加到GitHub管理平台中，在GitHub的个人账户的设置中找到如下界面，title随便起一个，将公钥（ id_rsa.pub）文件中内容复制粘贴到key中，然后点击Ass SSH key  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133430.png)\n5、测试一下配置是否成功，在Git Bush命令框（就是刚才配置账号和邮箱的命令框）中继续输入命令`ssh -T git@github.com`，回车,出现如下界面即说明成功  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133448.png)\n\n## 安装nodejs\n\nHexo是基于nodeJS环境的静态博客，里面的npm工具很有用。下载[nodejs](https://nodejs.org/en/)，(说明：LTS为长期支持版，Current为当前最新版)，下载后一路next进行安装，在git bash下使用node -v查看版本。\n\n## 安装hexo\n\n我建议先看一下npm&hexo常用命令部分，了解命令的结构和大体含义之后，在配置的过程中可以避免很多错误，少走很多弯路。  \n执行 `npm config list`查看当前的配置，如下所示：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133516.png)\n可以看到，最初的镜像地址是官方的npm镜像，我最初使用的就是这个配置，执行起来很不稳定，导致大多数错误都是网络问题导致的,执行如下命令,切换淘宝镜像\n\n```bash\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\nnpm config set registry https://registry.npm.taobao.org\n```\n接下来，就可以安装hexo了，执行`npm install -g hexo-cli`或`npm install -g hexo`，如果之前安装失败，可以先执行`npm uninstall hexo-cli -g`或`npm uninstall hexo -g` 卸载hexo，再进行安装，结果如下：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133610.png)\n查看版本信息` hexo v`  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133628.png)\n初始化hexo,执行 `hexo init myblog`，然后`cd myblog`，再次执行`hexo v`，就可以看到hexo的版本：  \n![](https://gitee.com/wxler/blogimg/raw/master/imgs/20201124133657.png)  \n打开myblog文件夹，我们可以看到hexo的结构\n\n> * node_modules：是依赖包\n> * public：存放的是生成的页面\n> * scaffolds：命令生成文章等的模板\n> * source：用命令创建的各种文章\n> * themes：主题\n> * _config.yml：整个博客的配置\n> * db.json：source解析所得到的\n> * package.json：项目所需模块项目的配置信息  \n\n\n到这里我们的hexo博客就安装完成啦，只有搭桥到github,才能进行部署。\n\n## hexo搭桥github\n\n创建一个repo，名称为yourname.github.io,其中yourname是你的github名称，按照这个规则创建才有用，这个仓库就是存放你博客的地方。\n1. 用编辑器打开你的blog项目，修改_config.yml  \n```text\ndeploy:  \n\ttype: git\n\trepo:https://github.com/YourgithubName/YourgithubName.github.io.git\n\tbranch: master\n```\n2. 回到gitbash中，进入你的blog目录，分别执行以下命令：\n```bash\nhexo clean\nhexo generate\nhexo server\n```\n需要注意的是，hexo 3.0把服务器独立成个别模块，需要单独安装：`npm i hexo-server`\n3. 打开浏览器输入：`http://localhost:4000`\n4. 先安装一波：`npm install hexo-deployer-git --save`（这样才能将你写好的文章部署到github服务器上并让别人浏览到） \n5. 执行命令\n```bash\nhexo clean\nhexo generate\nhexo deploy\n```\n6. 在浏览器中输入`http://yourgithubname.github.io`就可以看到你的个人博客啦。\n\n我使用的主题是stun，如果大家也想使用这个主题，可以到[ hexo-theme-stun](https://liuyib.github.io/hexo-theme-stun/zh-CN/)查阅配置。\n\n\n## hexo-admin使用\n\n\n用原生的方法来管理博文十分的不便，因此便有了Hexo Admin这一插件来方便我们的操作。执行`npm install --save hexo-admin`安装hexo-admin，安装成功后，在`http://localhost:4000/admin`就可以访问hexo-admin页面。\n详细情形我就不多说了，推荐大家到[hexo博客使用hexo-admin插件管理文章](https://blog.csdn.net/nineya_com/article/details/103380243?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)，这位作者的[hexo-admin插件windows系统插入图片失败问题](https://blog.csdn.net/nineya_com/article/details/103384546)修复了windows下粘贴图片的裂图和显示功能，我使用起来非常好，推荐大家看看。\n\n除此之外，我还要强调一点，hexo-admin创建文章的时候，首先创建英文名，再在里面编辑成中文，这样你的文章显示的链接就不会带有中文了。hexo-admin的文章只有未发布状态才能删除，并且删除后在source/_discarded文件夹，未发布变成draft,发布直接到post。\n\n## npm&hexo常用命令\n### npm&cnpm介绍\nnpm（node package manager）：nodejs的包管理器，用于node插件管理（包括安装、卸载、管理依赖等），使用`npm -v`查看版本信息。\n\ncnpm:因为npm安装插件是从国外服务器下载，受网络的影响比较大，可能会出现异常，如果npm的服务器在中国就好了，所以我们乐于分享的淘宝团队干了这事。来自官网：“这是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步”，更多详情可以查看[淘宝 NPM 镜像](https://developer.aliyun.com/mirror/NPM?from=tnpm)，使用`cnpm -v`查看版本信息。\n\n\nnpm和cnpm安装命令一样，只不过是多了一个c。\n\n### npm命令\n使用npm命令首先要设置下载的镜像，模式是npm官网的镜像(服务器在国外)，建议设置国内的淘宝镜像,设置以后我们就可以用npm从淘宝镜像下载数据了  \n永久使用：  \n`npm config set registry https://registry.npm.taobao.org`  \n临时使用：  \n`npm install node-sass --registry=http://registry.npm.taobao.org`  \n还有个清除缓存命令，可以解决些奇怪的问题:  \n`npm cache clean --force`  \n查看已安装的npm插件，这个命令很实用，可以查看缺少哪些插件  \n`npm ls --depth 0`   \n可以通过定制的 cnpm 命令行工具代替默认的 npm  \n`npm install -g cnpm --registry=http://registry.npm.taobao.org`  \n**在使用过程中要么用npm，要么用cnpm，不能混用**  \n查看当前的配置命令`npm config list `,操作之前一定要先查看配置再进行操作。  \n**下面需要强调后缀参数的作用和区别**  \n`npm install packagename --save 或 -S`    \n--save、-S参数意思是把模块的版本信息保存到dependencies（生产环境依赖）中，即你的package.json文件的dependencies字段中。  \n`npm install packagename --save-dev 或 -D`  \n--save-dev 、 -D参数意思是吧模块版本信息保存到devDependencies（开发环境依赖）中，即你的package.json文件的devDependencies字段中。  \n`npm install packagename -g 或 --global`  \n安装全局的模块（不加参数的时候默认安装本地模块），\n**使用npm安装插件的时候一定要加上--save添加依赖，否则容易出错** ，更多关于npm详情，请点击[npm常用命令及参数详解](https://segmentfault.com/a/1190000012099112?utm_source=tag-newest)\n\n### hexo命令\n\n`hexo init`  \n初始化站点，生成一个简单网站所需的各种文件。\n\n`hexo clean == hexo c`  \n清除缓存 网页正常情况下可以忽略此条命令\n\n`hexo generate == hexo g`  \n生效新增、修改、更新的文件\n\n`hexo server == hexo s`  \n启动本地网站，可在本地观察网站效果，同时也可以输入`http://localhost:4000/admin`管理文章\n\n`hexo s --debug`  \n以调试模式启动本地网站，在此模式下，对文件的更改无需停止网站只需刷新即可看到效果，调试非常方便\n\n\n`hexo clean && hexo s`  \n一次执行两个命令\n\n`hexo deploy == hexo d`  \nhexo的一键部署功能，执行此命令即可将网站发布到配置中的仓库地址，执行此命令前需要配置站点配置文件_config.yml","tags":["hexo"],"categories":["工具"]}]